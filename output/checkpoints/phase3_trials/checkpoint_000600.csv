ref_pmid,ref_is_clinical_trial_pt_type,ref_publication_types,ref_primary_nct_number,ref_primary_nct_source,ref_all_registry_ids,ref_all_nct_numbers,ref_all_structured_nct_numbers,ref_all_nct_source_pairs,ref_all_structured_nct_source_pairs,ref_has_abstract,ref_abstract,ref_fetch_status
24835439,False,Journal Article,,,,,,,,False,,success
30031107,False,Consensus Development Conference;Journal Article,,,,,,,,False,,success
28063810,False,Consensus Development Conference;Journal Article;Practice Guideline,,,,,,,,False,,success
29055505,False,Journal Article;Review;Consensus Development Conference,,,,,,,,True,"Mitral regurgitation (MR) is a complex valve lesion that can pose significant management challenges for the cardiovascular clinician. This Expert Consensus Document emphasizes that recognition of MR should prompt an assessment of its etiology, mechanism, and severity, as well as indications for treatment. A structured approach to evaluation based on clinical findings, precise echocardiographic imaging, and when necessary, adjunctive testing, can help clarify decision making. Treatment goals include timely intervention by an experienced heart team to prevent left ventricular dysfunction, heart failure, reduced quality of life, and premature death.",success
16980116,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Valvular heart diseases are not usually regarded as a major public-health problem. Our aim was to assess their prevalence and effect on overall survival in the general population. We pooled population-based studies to obtain data for 11 911 randomly selected adults from the general population who had been assessed prospectively with echocardiography. We also analysed data from a community study of 16 501 adults who had been assessed by clinically indicated echocardiography. In the general population group, moderate or severe valve disease was identified in 615 adults. There was no difference in the frequency of such diseases between men and women (p=0.90). Prevalence increased with age, from 0.7% (95% CI 0.5-1.0) in 18-44 year olds to 13.3% (11.7-15.0) in the 75 years and older group (p<0.0001). The national prevalence of valve disease, corrected for age and sex distribution from the US 2000 population, is 2.5% (2.2-2.7). In the community group, valve disease was diagnosed in 1505 (1.8% adjusted) adults and frequency increased considerably with age, from 0.3% (0.2-0.3) of the 18-44 year olds to 11.7% (11.0-12.5) of those aged 75 years and older, but was diagnosed less often in women than in men (odds ratio 0.90, 0.81-1.01; p=0.07). The adjusted mortality risk ratio associated with valve disease was 1.36 (1.15-1.62; p=0.0005) in the population and 1.75 (1.61-1.90; p<0.0001) in the community. Moderate or severe valvular diseases are notably common in this population and increase with age. In the community, women are less often diagnosed than are men, which could indicate an important imbalance in view of the associated lower survival. Valve diseases thus represent an important public-health problem.",success
31219554,False,Editorial;Comment,,,,,,,,False,,success
24603191,False,Journal Article;Practice Guideline,,,,,,,,False,,success
28315732,False,Journal Article;Practice Guideline,,,,,,,,False,,success
30280640,True,"Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",NCT01626079,databank,NCT01626079,NCT01626079,NCT01626079,NCT01626079|databank,NCT01626079|databank,True,"Among patients with heart failure who have mitral regurgitation due to left ventricular dysfunction, the prognosis is poor. Transcatheter mitral-valve repair may improve their clinical outcomes. At 78 sites in the United States and Canada, we enrolled patients with heart failure and moderate-to-severe or severe secondary mitral regurgitation who remained symptomatic despite the use of maximal doses of guideline-directed medical therapy. Patients were randomly assigned to transcatheter mitral-valve repair plus medical therapy (device group) or medical therapy alone (control group). The primary effectiveness end point was all hospitalizations for heart failure within 24 months of follow-up. The primary safety end point was freedom from device-related complications at 12 months; the rate for this end point was compared with a prespecified objective performance goal of 88.0%. Of the 614 patients who were enrolled in the trial, 302 were assigned to the device group and 312 to the control group. The annualized rate of all hospitalizations for heart failure within 24 months was 35.8% per patient-year in the device group as compared with 67.9% per patient-year in the control group (hazard ratio, 0.53; 95% confidence interval [CI], 0.40 to 0.70; P<0.001). The rate of freedom from device-related complications at 12 months was 96.6% (lower 95% confidence limit, 94.8%; P<0.001 for comparison with the performance goal). Death from any cause within 24 months occurred in 29.1% of the patients in the device group as compared with 46.1% in the control group (hazard ratio, 0.62; 95% CI, 0.46 to 0.82; P<0.001). Among patients with heart failure and moderate-to-severe or severe secondary mitral regurgitation who remained symptomatic despite the use of maximal doses of guideline-directed medical therapy, transcatheter mitral-valve repair resulted in a lower rate of hospitalization for heart failure and lower all-cause mortality within 24 months of follow-up than medical therapy alone. The rate of freedom from device-related complications exceeded a prespecified safety threshold. (Funded by Abbott; COAPT ClinicalTrials.gov number, NCT01626079 .).",success
30145927,True,"Clinical Trial, Phase III;Comparative Study;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",NCT01920698,databank,NCT01920698,NCT01920698,NCT01920698,NCT01920698|databank,NCT01920698|databank,True,"In patients who have chronic heart failure with reduced left ventricular ejection fraction, severe secondary mitral-valve regurgitation is associated with a poor prognosis. Whether percutaneous mitral-valve repair improves clinical outcomes in this patient population is unknown. We randomly assigned patients who had severe secondary mitral regurgitation (defined as an effective regurgitant orifice area of >20 mm<sup>2</sup> or a regurgitant volume of >30 ml per beat), a left ventricular ejection fraction between 15 and 40%, and symptomatic heart failure, in a 1:1 ratio, to undergo percutaneous mitral-valve repair in addition to receiving medical therapy (intervention group; 152 patients) or to receive medical therapy alone (control group; 152 patients). The primary efficacy outcome was a composite of death from any cause or unplanned hospitalization for heart failure at 12 months. At 12 months, the rate of the primary outcome was 54.6% (83 of 152 patients) in the intervention group and 51.3% (78 of 152 patients) in the control group (odds ratio, 1.16; 95% confidence interval [CI], 0.73 to 1.84; P=0.53). The rate of death from any cause was 24.3% (37 of 152 patients) in the intervention group and 22.4% (34 of 152 patients) in the control group (hazard ratio, 1.11; 95% CI, 0.69 to 1.77). The rate of unplanned hospitalization for heart failure was 48.7% (74 of 152 patients) in the intervention group and 47.4% (72 of 152 patients) in the control group (hazard ratio, 1.13; 95% CI, 0.81 to 1.56). Among patients with severe secondary mitral regurgitation, the rate of death or unplanned hospitalization for heart failure at 1 year did not differ significantly between patients who underwent percutaneous mitral-valve repair in addition to receiving medical therapy and those who received medical therapy alone. (Funded by the French Ministry of Health and Research National Program and Abbott Vascular; MITRA-FR ClinicalTrials.gov number, NCT01920698 .).",success
26550689,True,"Comparative Study;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",NCT00807040,databank,NCT00807040,NCT00807040,NCT00807040,NCT00807040|databank,NCT00807040|databank,True,"In a randomized trial comparing mitral-valve repair with mitral-valve replacement in patients with severe ischemic mitral regurgitation, we found no significant difference in the left ventricular end-systolic volume index (LVESVI), survival, or adverse events at 1 year after surgery. However, patients in the repair group had significantly more recurrences of moderate or severe mitral regurgitation. We now report the 2-year outcomes of this trial. We randomly assigned 251 patients to mitral-valve repair or replacement. Patients were followed for 2 years, and clinical and echocardiographic outcomes were assessed. Among surviving patients, the mean (±SD) 2-year LVESVI was 52.6±27.7 ml per square meter of body-surface area with mitral-valve repair and 60.6±39.0 ml per square meter with mitral-valve replacement (mean changes from baseline, -9.0 ml per square meter and -6.5 ml per square meter, respectively). Two-year mortality was 19.0% in the repair group and 23.2% in the replacement group (hazard ratio in the repair group, 0.79; 95% confidence interval, 0.46 to 1.35; P=0.39). The rank-based assessment of LVESVI at 2 years (incorporating deaths) showed no significant between-group difference (z score=-1.32, P=0.19). The rate of recurrence of moderate or severe mitral regurgitation over 2 years was higher in the repair group than in the replacement group (58.8% vs. 3.8%, P<0.001). There were no significant between-group differences in rates of serious adverse events and overall readmissions, but patients in the repair group had more serious adverse events related to heart failure (P=0.05) and cardiovascular readmissions (P=0.01). On the Minnesota Living with Heart Failure questionnaire, there was a trend toward greater improvement in the replacement group (P=0.07). In patients undergoing mitral-valve repair or replacement for severe ischemic mitral regurgitation, we observed no significant between-group difference in left ventricular reverse remodeling or survival at 2 years. Mitral regurgitation recurred more frequently in the repair group, resulting in more heart-failure-related adverse events and cardiovascular admissions. (Funded by the National Institutes of Health and Canadian Institutes of Health Research; ClinicalTrials.gov number, NCT00807040.).",success
23136163,True,"Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",NCT00413998,databank,NCT00413998,NCT00413998,NCT00413998,NCT00413998|databank,NCT00413998|databank,True,"The role of mitral valve repair (MVR) during coronary artery bypass grafting (CABG) in patients with moderate ischemic mitral regurgitation (MR) is uncertain. We conducted a randomized, controlled trial to determine whether repairing the mitral valve during CABG may improve functional capacity and left ventricular reverse remodeling compared with CABG alone. Seventy-three patients referred for CABG with moderate ischemic MR and an ejection fraction >30% were randomized to receive CABG plus MVR (34 patients) or CABG only (39 patients). The study was stopped early after review of interim data. At 1 year, there was a greater improvement in the primary end point of peak oxygen consumption in the CABG plus MVR group compared with the CABG group (3.3 mL/kg/min versus 0.8 mL/kg/min; P<0.001). There was also a greater improvement in the secondary end points in the CABG plus MVR group compared with the CABG group: left ventricular end-systolic volume index, MR volume, and plasma B-type natriuretic peptide reduction of 22.2 mL/m(2), 28.2 mL/beat, and 557.4 pg/mL, respectively versus 4.4 mL/m(2) (P=0.002), 9.2 mL/beat (P=0.001), and 394.7 pg/mL (P=0.003), respectively. Operation duration, blood transfusion, intubation duration, and hospital stay duration were greater in the CABG plus MVR group. Deaths at 30 days and 1 year were similar in both groups: 3% and 9%, respectively in the CABG plus MVR group, versus 3% (P=1.00) and 5% (P=0.66), respectively in the CABG group. Adding mitral annuloplasty to CABG in patients with moderate ischemic MR may improve functional capacity, left ventricular reverse remodeling, MR severity, and B-type natriuretic peptide levels, compared with CABG alone. The impact of these benefits on longer term clinical outcomes remains to be defined.",success
28473124,False,Letter;Comment,,,,,,,,False,,success
30608523,False,Journal Article;Review,,,,,,,,True,"Transcatheter heart valve interventions have transformed the outcomes of patients with valvular heart disease (VHD) who are unfavourable candidates for surgery. Technological advances have allowed extension of these interventions to younger or lower risk patients and those with other forms of VHD and may in the future permit earlier treatment of VHD in less symptomatic patients or those with moderate disease. The balance of risks and benefits is likely to differ between lower and higher risk patients, and more evidence is needed to evaluate the net benefit of transcatheter technology in these groups. As academic researchers, clinicians, industry, and patient stakeholders collaborate to research these broader indications for transcatheter valve interventions, it is essential to address (i) device durability and deliverability, (ii) specific anatomical needs (e.g. bicuspid aortic valves, aortic regurgitation, mitral and tricuspid valve disease), (iii) operator training, and (iv) the reinforced importance of the multidisciplinary Heart Team.",success
30846107,False,Case Reports;Letter,,,,,,,,False,,success
28449780,False,Journal Article;Review,,,,,,,,True,"Transcatheter mitral valve repair, particularly edge-to-edge leaflet repair, is a well-established alternative for patients with severe primary mitral regurgitation (MR) considered at high or prohibitive surgical risk. More recently, transcatheter mitral valve replacement (TMVR) has emerged as a potential therapeutic option for the treatment of severe MR. TMVR may offer some advantages over transcatheter repair by providing a more complete and reproducible MR reduction. Several devices are under preclinical and clinical evaluation, and the early experience with more than 100 patients has demonstrated the feasibility of TMVR. In this review, we describe the TMVR systems currently in development and the results obtained from early clinical experiences. We also discuss the main challenges in and future perspectives on this emerging field. Future studies with a much larger number of patients are needed to provide consistent safety and efficacy data on each of the TMVR systems.",success
11581597,False,Journal Article,,,,,,,,True,"The aim of this study is to report our results with the central double-orifice technique used for the treatment of complex mitral valve lesions. The central double-orifice repair has been used in 260 patients (mean age, 56 +/- 14.3 years) over a period of 7 years. The mechanism responsible for mitral regurgitation was prolapse of both leaflets in 148 patients, prolapse of the anterior leaflet in 68, prolapse of the posterior leaflet with annular calcification or other unfavorable features in 31, and lack of leaflet coaptation for restricted motion or erosion of the free edge in 13. Degenerative disease was the cause of mitral regurgitation in 80.8% of the patients, rheumatic disease was the cause in 9.6%, endocarditis was the cause in 6.1%, and ischemic disease was the cause in 2.3%. Hospital mortality was 0.7%, and the overall survival at 5 years was 94.4% +/- 2.59%. Thirteen patients required a reoperation (2 early postoperatively and 11 late during the follow-up), for an overall freedom from reoperation of 90.0% +/- 3.37% at 5 years. Freedom from reoperation was lower in patients with rheumatic valve disease and in patients who did not undergo an annuloplasty procedure. The effectiveness and durability of the central double-orifice technique were assessed in this study. This type of repair can be a useful addition to the surgical armamentarium in mitral valve reconstruction.",success
19679246,True,"Journal Article;Multicenter Study;Research Support, Non-U.S. Gov't",NCT00209274,databank,NCT00209274;NCT00209339,NCT00209274;NCT00209339,NCT00209274;NCT00209339,NCT00209274|databank;NCT00209339|databank,NCT00209274|databank;NCT00209339|databank,True,"We undertook a prospective multicenter single-arm study to evaluate the feasibility, safety, and efficacy of the MitraClip system (Evalve Inc., Menlo Park, California). Mitral valve repair for mitral regurgitation (MR) has been performed by the use of a surgically created double orifice. Percutaneous repair based on this surgical approach has been developed by use of the Evalve MitraClip device to secure the mitral leaflets. Patients with 3 to 4+ MR were selected in accordance with the American Heart Association/American College of Cardiology guidelines for intervention and a core echocardiographic laboratory. A total of 107 patients were treated. Ten (9%) had a major adverse event, including 1 nonprocedural death. Freedom from clip embolization was 100%. Partial clip detachment occurred in 10 (9%) patients. Overall, 79 of 107 (74%) patients achieved acute procedural success, and 51 (64%) were discharged with MR of < or =1+. Thirty-two patients (30%) had mitral valve surgery during the 3.2 years after clip procedures. When repair was planned, 84% (21 of 25) were successful. Thus, surgical options were preserved. A total of 50 of 76 (66%) successfully treated patients were free from death, mitral valve surgery, or MR >2+ at 12 months (primary efficacy end point). Kaplan-Meier freedom from death was 95.9%, 94.0%, and 90.1%, and Kaplan-Meier freedom from surgery was 88.5%, 83.2%, and 76.3% at 1, 2, and 3 years, respectively. The 23 patients with functional MR had similar acute results and durability. Percutaneous repair with the MitraClip system can be accomplished with low rates of morbidity and mortality and with acute MR reduction to < 2+ in the majority of patients, and with sustained freedom from death, surgery, or recurrent MR in a substantial proportion (EVEREST I; NCT00209339. EVEREST II; NCT00209274).",success
26718672,True,"Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",NCT00209274,databank,NCT00209274,NCT00209274,NCT00209274,NCT00209274|databank,NCT00209274|databank,True,"In EVEREST II (Endovascular Valve Edge-to-Edge Repair Study), treatment of mitral regurgitation (MR) with a novel percutaneous device showed superior safety compared with surgery, but less effective reduction in MR at 1 year. This study sought to evaluate the final 5-year clinical outcomes and durability of percutaneous mitral valve (MV) repair with the MitraClip device compared with conventional MV surgery. Patients with grade 3+ or 4+ MR were randomly assigned to percutaneous repair with the device or conventional MV surgery in a 2:1 ratio (178:80). Patients prospectively consented to 5 years of follow-up. At 5 years, the rate of the composite endpoint of freedom from death, surgery, or 3+ or 4+ MR in the as-treated population was 44.2% versus 64.3% in the percutaneous repair and surgical groups, respectively (p = 0.01). The difference was driven by increased rates of 3+ to 4+ MR (12.3% vs. 1.8%; p = 0.02) and surgery (27.9% vs. 8.9%; p = 0.003) with percutaneous repair. After percutaneous repair, 78% of surgeries occurred within the first 6 months. Beyond 6 months, rates of surgery and moderate-to-severe MR were comparable between groups. Five-year mortality rates were 20.8% and 26.8% (p = 0.4) for percutaneous repair and surgery, respectively. In multivariable analysis, treatment strategy was not associated with survival. Patients treated with percutaneous repair more commonly required surgery for residual MR during the first year after treatment, but between 1- and 5-year follow-up, comparably low rates of surgery for MV dysfunction with either percutaneous or surgical therapy endorse the durability of MR reduction with both repair techniques. (EVEREST II Pivotal Study High Risk Registry; NCT00209274).",success
21777895,False,News,,,,,,,,False,,success
19660613,True,Clinical Trial;Journal Article;Multicenter Study,,,,,,,,True,"This report presents the procedural results from the AMADEUS trial that support coronary sinus (CS)-based percutaneous mitral annuloplasty. Despite therapeutic advances, functional mitral regurgitation (MR) continues to be a significant clinical problem for patients with dilated cardiomyopathy. CS approaches to mitral valve repair have been viewed with skepticism because of the distance of the CS/great cardiac vein from the mitral valve annulus and the potential to compress a coronary artery. This report presents the procedural results from the AMADEUS trial that support CS-based percutaneous mitral annuloplasty. Patients who met the inclusion criteria were eligible to receive a mitral annuloplasty device. Transesophageal echocardiography was used to assess changes in MR, angiography was used to assess the coronary arteries, and multislice computed tomography was used to evaluate the anatomic relations between the coronary venous system and the mitral valve. Acute MR reduction (grade 3.0 +/- 0.6 to 2.0 +/- 0.8, p <0.0001) and permanent implantation were achieved in 30 of 43 patients in whom an attempt was made. Additional measurements in 20 patients with implants showed reductions in the vena contracta (0.69 +/- 0.29 to 0.46 +/- 0.26 cm, p <0.0001), effective regurgitant orifice area (0.33 +/- 0.17 to 0.19 +/- 0.08 cm(2), p <0.0001), regurgitant volume (40 +/- 20 to 24 +/- 11 ml, p = 0.0005), and jet area/left atrial area (45 +/- 13% to 32 +/- 12%, p <0.0001). The coronary arteries were crossed in 36 patients (84%). Arterial compromise contributed to a lack of implantation in 6 patients (14%). No difference was found in the CS/great cardiac vein position relative to the annulus between the patients who did and did not have a reduction in MR. In conclusion, percutaneous mitral annuloplasty reduces MR and permanent implantation can be achieved in most eligible patients.",success
19597051,True,"Comparative Study;Journal Article;Multicenter Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"Functional mitral regurgitation (FMR), a well-recognized component of left ventricular remodeling, is associated with increased morbidity and mortality in heart failure patients. Percutaneous mitral annuloplasty has the potential to serve as a therapeutic adjunct to standard medical care. Patients with dilated cardiomyopathy, moderate to severe FMR, an ejection fraction <40%, and a 6-minute walk distance between 150 and 450 m were enrolled in the CARILLON Mitral Annuloplasty Device European Union Study (AMADEUS). Percutaneous mitral annuloplasty was achieved through the coronary sinus with the CARILLON Mitral Contour System. Echocardiographic FMR grade, exercise tolerance, New York Heart Association class, and quality of life were assessed at baseline and 1 and 6 months. Of the 48 patients enrolled in the trial, 30 received the CARILLON device. Eighteen patients did not receive a device because of access issues, insufficient acute FMR reduction, or coronary artery compromise. The major adverse event rate was 13% at 30 days. At 6 months, the degree of FMR reduction among 5 different quantitative echocardiographic measures ranged from 22% to 32%. Six-minute walk distance improved from 307+/-87 m at baseline to 403+/-137 m at 6 months (P<0.001). Quality of life, measured by the Kansas City Cardiomyopathy Questionnaire, improved from 47+/-16 points at baseline to 69+/-15 points at 6 months (P<0.001). Percutaneous reduction in FMR with a novel coronary sinus-based mitral annuloplasty device is feasible in patients with heart failure, is associated with a low rate of major adverse events, and is associated with improvement in quality of life and exercise tolerance.",success
20031729,True,"Journal Article;Multicenter Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"We assessed the safety and feasibility of permanent implantation of a novel coronary sinus mitral repair device (PTMA, Viacor Inc). Symptomatic (New York Heart Association class 2 or 3) patients with primarily functional mitral regurgitation (MR) were included. A diagnostic PTMA procedure was performed in the coronary sinus venous continuity. MR was assessed and the PTMA device adjusted to optimize efficacy. If MR reduction (> or =1 grade) was observed, placement of a PTMA implant was attempted. Implanted patients were evaluated with echocardiographic, quality of life, and exercise capacity metrics. Nineteen patients received a diagnostic PTMA study. Diagnostic PTMA was effective in 13 patients (MR grade 3.2+/-0.6 reduced to 2.0+/-1.0), and PTMA implants were placed in 9 patients. Four devices were removed uneventfully (7, 84, 197, and 216 days), 3 for annuloplasty surgery due to observed PTMA device migration and/or diminished efficacy. No procedure or device-related major adverse events with permanent sequela were observed in any of the diagnostic or implant patients. Sustained reductions of mitral annulus septal-lateral dimension from 3D echo reconstruction dimensions were observed (4.0+/-1.2 mm at 3 months). Percutaneous implantation of the PTMA device is feasible and safe. Acute results demonstrate a possibly meaningful reduction of MR in responding patients. Sustained favorable geometric modification of the mitral annulus has been observed, though reduction of MR has been limited. The PTMA method warrants continued evaluation and development.",success
21251638,True,"Clinical Trial, Phase I;Journal Article;Multicenter Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"This study sought to assess the safety and efficacy of transcatheter valve annuloplasty in patients with mitral regurgitation (MR). Mitral regurgitation is associated with a worsened prognosis in patients with dilated cardiomyopathy. Surgical mitral annuloplasty reduces the septal-lateral dimension of the mitral annulus resulting in improved leaflet coaptation with a reduction in regurgitation. Percutaneous annuloplasty with the MONARC device (Edwards Lifesciences, Irvine, California) implanted within the coronary sinus is designed to reduce mitral regurgitation through a similar mechanism. A total of 72 patients with MR grade ≥ 2 were enrolled at 8 participating centers in 4 countries. Clinical evaluation and transthoracic echocardiography were performed at baseline and at 3, 6, and 12 months. Multislice cardiac computed tomography and coronary angiography were performed at baseline and 3 months. The MONARC device was implanted in 59 of 72 patients (82%). The primary safety end point (freedom from death, tamponade, or myocardial infarction at 30 days) was met in 91% of patients at 30 days and in 82% at 1 year. Computed tomography imaging documented passage of the great cardiac vein over an obtuse marginal artery in 55% of patients and was associated with angiographic coronary artery compression in 15 patients and myocardial infarction in 2 patients (3.4%). At 12 months, a reduction in MR by ≥ 1 grade was observed in 50.0% of 22 implanted patients with matched echocardiograms and in 85.7% of 7 patients with baseline MR grade ≥ 3. Implantation of the MONARC device in the coronary sinus is feasible and may reduce MR. However, coronary artery compression may occur in patients in whom the great cardiac vein passes over a coronary artery, necessitating strategies in future studies to avoid this occurrence.",success
30898198,False,Journal Article,,,,,,,,True,"Severe mitral regurgitation (MR) conveys significant morbidity and mortality, and surgical repair or replacement may not be a desirable option. The purpose of this study was to evaluate the feasibility of a percutaneous transseptal transcatheter mitral valve replacement (TMVR) system. This first-in-human study was conducted between August 2017 and August 2018. The system comprises a nitinol dock, which encircles the chordae tendineae, and a balloon-expandable transcatheter heart valve. The dock and transcatheter heart valve form an ensemble, with the native mitral valve leaflets secured in between, thereby abolishing MR. Key inclusion criteria were severe symptomatic MR and high surgical risk; exclusion criteria included left ventricular ejection fraction <30% or screening suggesting unfavorable anatomy. The primary endpoint was technical success as defined by Mitral Valve Academic Research Consortium (MVARC) criteria at completion of the index procedure. The secondary endpoint was freedom from mortality, stroke, and device dysfunction (MR grade >1, mitral gradient >6 mm Hg, left ventricular outflow tract gradient >20 mm Hg) at 30 days. Ten patients with severe MR of various etiologies (4 degenerative, 4 functional, and 2 mixed) were treated. The device was successfully implanted and the primary endpoint was achieved in 9 of 10 patients (90%). By transesophageal echocardiography, total MR was reduced to ≤ trivial in all implanted patients, and mean transmitral gradient was 2.3 ± 1.4 mm Hg. A pericardial effusion occurred in 1 patient: pericardiocentesis was performed, and the device was not implanted. Median length of hospital stay was 1.5 days. At 30 days, there was no stroke, myocardial infarction, rehospitalization, left ventricular outflow tract obstruction, device migration, embolization, or conversion to mitral surgery. One patient had recurrent regurgitation due to a paravalvular leak, treated with a closure device. All other treated patients had ≤1+ MR. No patients died. Percutaneous transvenous transseptal TMVR is feasible and safe in patients with severe MR who are at high risk for mitral valve surgery. Further evaluation is warranted.",success
28662805,True,Journal Article;Multicenter Study,NCT01737528,databank,NCT01737528,NCT01737528,NCT01737528,NCT01737528|databank,NCT01737528|databank,True,"Transcatheter aortic valve replacement (TAVR) has been introduced into U.S. clinical practice with efforts to optimize outcomes and minimize the learning curve. The goal of this study was to assess the degree to which increasing experience during the introduction of this procedure, separated from other outcome determinants including patient and procedural characteristics, is associated with outcomes. The authors evaluated the association of hospital TAVR volume and patient outcomes for TAVR by using data from 42,988 commercial procedures conducted at 395 hospitals submitting to the Transcatheter Valve Therapy Registry from 2011 through 2015. Outcomes assessed included adjusted and unadjusted in-hospital major adverse events. Increasing site volume was associated with lower in-hospital risk-adjusted outcomes, including mortality (p < 0.02), vascular complications (p < 0.003), and bleeding (p < 0.001) but was not associated with stroke (p = 0.14). From the first case to the 400th case in the volume-outcome model, risk-adjusted adverse outcomes declined, including mortality (3.57% to 2.15%), bleeding (9.56% to 5.08%), vascular complications (6.11% to 4.20%), and stroke (2.03% to 1.66%). Vascular and bleeding volume-outcome associations were nonlinear with a higher risk of adverse outcomes in the first 100 cases. An association of procedure volume with risk-adjusted outcomes was also seen in the subgroup having transfemoral access. The initial adoption of TAVR into practice in the United States showed that increasing experience was associated with better outcomes. This association, whether deemed a prolonged learning curve or a manifestation of a volume-outcome relationship, suggested that concentrating experience in higher volume heart valve centers might be a means of improving outcomes. (STS/ACC Transcatheter Valve Therapy Registry [TVT Registry]; NCT01737528).",success
31343669,False,Journal Article,,,,,,,,False,,success
20602478,False,Journal Article,,,,,,,,True,"Minimal information is available on the number and type of procedures being performed for structural and valvular heart disease, the physicians who perform these procedures, and on the training requirements for this emerging field. Surveys were performed using an online survey of members of the Society of Cardiac Angiography and Interventions (SCAI), including its Council on Structural Heart Disease and the Congenital Heart Disease Committee. The responses of 107 US-based interventional cardiologists were analyzed. A second questionnaire of a purposive sample of 10 training directors of US interventional cardiology programs was also performed. Although many procedures (e.g., transseptal puncture, PFO, and ASD closure) are commonly performed by most respondents, others are limited to a significant minority of respondents (e.g., alcohol septal ablation, transcatheter valve repair, and implantation). In addition, the number of procedures performed varies greatly as does the training directors' estimate of the number necessary to gain proficiency. There is no single method being used to gain the requisite skills. A number of factors that limit the more widespread growth of this field were identified. The field of intervention for structural and valvular heart disease is new, growing rapidly, and will require a core knowledge base and new didactic methods. The cardiovascular community will be challenged to devise new training standards and credentialing approaches to serve interventionalists interested in this field.",success
14755804,False,Journal Article,,,,,,,,True,"In view of the major impact of medical economic forces, rapidly changing technology, and other pressures on invasive cardiologists, the Society for Cardiovascular Angiography and Interventions determined that a statement of the ethical issues confronting the modern invasive cardiologist was needed. The various conflicts presented to the cardiologist in his or her roles as practicing clinician, administrator of the catheterization laboratory, educator, or clinical researcher were reviewed. In all instances, the major concern was determined to be the welfare of the patient no matter how forceful the pressures from various outside force or concerns for personal advancement might be.",success
29096801,False,Journal Article,,,,,,,,True,"Post-market surveillance is needed to evaluate the real-world clinical effectiveness and safety of U.S. Food and Drug Administration-approved devices. The authors examined the commercial experience with transcatheter mitral valve repair for the treatment of mitral regurgitation. Data from the Society of Thoracic Surgery/American College of Cardiology Transcatheter Valve Therapy Registry on patients commercially treated with transcatheter mitral valve repair were analyzed. The study population consisted of 2,952 patients treated at 145 hospitals between November 2013 and September 2015. In 1,867 patients, data were linked to patient-specific Centers for Medicare and Medicaid Services administrative claims for analyses. The median age was 82 years (55.8% men), with a median Society of Thoracic Surgery predicted risk of mortality of 6.1% (interquartile range: 3.7% to 9.9%) and 9.2% (interquartile range: 6.0% to 14.1%) for mitral repair and replacement, respectively. Overall, in-hospital mortality was 2.7%. Acute procedure success occurred in 91.8%. Among the patients with Centers for Medicare and Medicaid Services linkage data, the mortality at 30 days and at 1 year was 5.2% and 25.8%, respectively, and repeat hospitalization for heart failure at 1 year occurred in 20.2%. Variables associated with mortality or rehospitalization for heart failure after multivariate adjustment were increasing age, lower baseline left ventricular ejection fraction, worse post-procedural mitral regurgitation, moderate or severe lung disease, dialysis, and severe tricuspid regurgitation. Our findings demonstrate that commercial transcatheter mitral valve repair is being performed in the United States with acute effectiveness and safety. Our findings may help determine which patients have favorable long-term outcomes with this therapy.",success
31320029,True,Journal Article;Multicenter Study;Observational Study,,,,,,,,True,"The aim of this study was to examine the relation between institutional experience and procedural results of transcatheter mitral valve repair. Transcatheter mitral valve repair for the treatment of mitral regurgitation (MR) is a complex procedure requiring navigation of the left atrium, left ventricle, and mitral valve apparatus using echocardiographic guidance. MitraClip procedures from the Society of Thoracic Surgeons/American College of Cardiology TVT (Transcatheter Valve Therapy) Registry were stratified into tertiles on the basis of site-specific case sequence (1 to 18, 19 to 51, and 52 to 482). In-hospital outcomes of procedural success, procedural time, and procedural complications were examined. To evaluate the learning curve for the procedure, generalized linear mixed models were developed using case sequence number as a continuous variable. MitraClip procedures (n = 12,334) performed at 275 sites between November 2013 and September 2017 were analyzed. Optimal procedural success (≤1+ residual MR without mortality or need for cardiac surgery) increased across tertiles of case experience (62.0%, 65.5%, and 72.5%; p < 0.001), whereas procedural time and procedural complications decreased. Acceptable procedural success (≤2+ residual MR without death or need for cardiac surgery) also increased across tertiles of case experience, but the differences were smaller (91.2%, 91.2%; and 92.9%; p = 0.006). In the learning-curve analysis, visual inflection points for procedural time, procedural success, and procedural complications were evident after about 50 cases, with continued improvements observed up to 200 cases. For transcatheter mitral valve repair with the MitraClip, increasing institutional experience was associated with improvements in procedural success, procedure time, and procedural complications. The impact of institutional experience was larger when considering the goal of achieving optimal MR reduction.",success
20552373,False,Journal Article;Review,,,,,,,,True,"The old paradigm of ""see one, do one, teach one"" has now changed to ""see several, learn the skills and simulation, do one, teach one."" Modern medicine over the past 30 years has undergone significant revolutions from earlier models made possible by significant technological advances. Scientific and technological progress has made these advances possible not only by increasing the complexity of procedures, but also by increasing the ability to have complex methods of training to perform these sophisticated procedures. Simulators in training labs have been much more embraced outside the operating room, with advanced cardiac life support using hands-on models (CPR ""dummy"") as well as a fusion with computer-based testing for examinations ranging from the United States medical licensure exam to the examinations administered by the American Board of Surgery and the American Board of Colon and Rectal Surgery. Thus, the development of training methods that test both technical skills and clinical acumen may be essential to help achieve both safety and financial goals.",success
19801196,False,"Evaluation Study;Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"A case series of 5 patients is presented assessing the utility of simulation case rehearsals of individual patients for carotid artery stenting on an endovascular simulator. Simulated and operative device dimensions were similar. Results of subjective surveys indicated that face and content validity were excellent. The simulations predicted difficulty with vessel cannulation, however had difficulty predicting post-stent changes in bifurcation angulation. Our experience suggests that it may be feasible to use patient-specific CTA-derived data in the creation of a realistic case rehearsal simulation. The overall utility of this concept, including cost-benefit analysis, has yet to be determined.",success
17671805,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"In coronary artery bypass graft (CABG) surgery the involved tissues are overstretched, which may lead to intimal hyperplasia and graft failure. We propose a computational methodology for the simulation of traditional CABG surgery, and analyze the effect of two clinically relevant parameters on the artery and graft responses, i.e., incision length and insertion angle for a given graft diameter. The computational structural analyses are based on actual three-dimensional vessel dimensions of a human coronary artery and a human saphenous vein. The analyses consider the structure of the end-to-side anastomosis, the residual stresses and the typical anisotropic and nonlinear vessel behaviors. The coronary artery is modeled as a three-layer thick-walled tube. The finite element method is employed to predict deformation and stress distribution at various stages of CABG surgery. Small variations of the arterial incision have relatively big effects on the size of the arterial opening, which depends solely on the residual stress state. The incision length has a critical influence on the graft shape and the stress in the graft wall. Stresses at the heel region are higher than those at the toe region. The changes in the mechanical environment are severe along all transitions between the venous tissue and the host artery. Particular stress concentrations occur at the incision ends. The proposed computational methodology may be useful in designing a coronary anastomotic device for reducing surgical trauma. It may improve the quantitative knowledge of vessel diseases and serve as a tool for virtual planning of vascular surgery.",success
18372149,False,Journal Article,,,,,,,,True,"Simulator-based endovascular skills training measurably improves performance in catheter-based image-guided interventions. The purpose of this study was to determine whether structured global performance assessment during endovascular simulation correlated well with trainee-reported procedural skill and prior experience level. Fourth-year and fifth-year general surgery residents interviewing for vascular fellowship training provided detailed information regarding prior open vascular and endovascular operative experience. The pretest questionnaire responses were used to separate subjects into low (<20 cases) and moderate (20 to 100) endovascular experience groups. Subjects were then asked to perform a renal angioplasty/stent procedure on the Procedicus Vascular Intervention System Trainer (VIST) endovascular simulator (Mentice Corporation, Gothenburg, Sweden). The subjects' performance was supervised and evaluated by a blinded expert interventionalist using a structured global assessment scale based on angiography setup, target vessel catheterization, and the interventional procedure. Objective measures determined by the simulator were also collected for each subject. A postsimulation questionnaire was administered to determine the subjects' self-assessment of their performance. Seventeen surgical residents from 15 training programs completed questionnaires before and after the exercise and performed a renal angioplasty/stent procedure on the endovascular simulator. The beginner group (n = 8) reported prior experience of a median of eight endovascular cases (interquartile range [IQR], 6.5-17.8; range, 4-20), and intermediate group (n = 9) had previously completed a median of 42 cases (IQR, 31-44; range, 25-89, P = .01). The two groups had similar prior open vascular experience (79 cases vs 75, P = .60). The mean score on the structured global assessment scale for the low experience group was 2.68 of 5.0 possible compared with 3.60 for the intermediate group (P = .03). Scores for subcategories of the global assessment score for target vessel catheterization (P = .02) and the interventional procedure (P = .05) contributed more to the differentiation between the two experience groups. Total procedure time, fluoroscopy time, average contrast used, percentage of lesion covered by the stent, placement accuracy, residual stenosis rates, and number of cine loops utilized were similar between the two groups (P > .05). Structured endovascular skills assessment correlates well with prior procedural experience within a high-fidelity simulation environment. In addition to improving endovascular training, simulators may prove useful in determining procedural competency and credentialing standards for endovascular surgeons.",success
12368674,True,"Clinical Trial;Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",,,,,,,,True,"To demonstrate that virtual reality (VR) training transfers technical skills to the operating room (OR) environment. The use of VR surgical simulation to train skills and reduce error risk in the OR has never been demonstrated in a prospective, randomized, blinded study. Sixteen surgical residents (PGY 1-4) had baseline psychomotor abilities assessed, then were randomized to either VR training (MIST VR simulator diathermy task) until expert criterion levels established by experienced laparoscopists were achieved (n = 8), or control non-VR-trained (n = 8). All subjects performed laparoscopic cholecystectomy with an attending surgeon blinded to training status. Videotapes of gallbladder dissection were reviewed independently by two investigators blinded to subject identity and training, and scored for eight predefined errors for each procedure minute (interrater reliability of error assessment r > 0.80). No differences in baseline assessments were found between groups. Gallbladder dissection was 29% faster for VR-trained residents. Non-VR-trained residents were nine times more likely to transiently fail to make progress (P <.007, Mann-Whitney test) and five times more likely to injure the gallbladder or burn nontarget tissue (chi-square = 4.27, P <.04). Mean errors were six times less likely to occur in the VR-trained group (1.19 vs. 7.38 errors per case; P <.008, Mann-Whitney test). The use of VR surgical simulation to reach specific target criteria significantly improved the OR performance of residents during laparoscopic cholecystectomy. This validation of transfer of training skills from VR to OR sets the stage for more sophisticated uses of VR in assessment, training, error reduction, and certification of surgeons.",success
22575325,False,Journal Article;Practice Guideline;Review;Consensus Development Conference,,,,,,,,False,,success
26740032,True,Journal Article;Multicenter Study,,,,,,,,True,"The Society of Thoracic Surgeons (STS) Quality Measurement Task Force is developing a portfolio of composite performance measures for the most commonly performed procedures in adult cardiac surgery. We now describe the fourth in this series, the STS composite measure for mitral valve repair/replacement (MVRR). We examined all patients undergoing isolated MVRR, with or without concomitant performance of tricuspid valve repair, surgical arrhythmia ablation, or repair of atrial septal defect, between July 1, 2011, and June 30, 2014. In this two-domain model, risk-adjusted mortality and any-or-none major morbidity were combined into a composite score using 3 years of STS data and 95% Bayesian credible intervals to estimate composite scores and star ratings. There were 61,201 MVRR patients studied at 867 participant sites. Mitral valve repair was performed in 57.4% (35,114 of 61,201) and mitral valve replacement in 42.6% (26,087 of 61,201). Mortality was 2.9% (1,773 of 61,201), and occurrence of any major morbidity was 17.0% (10,381 of 61,201). The median composite score was 93.2% (interquartile range, 92.3% to 94.2%). Star rating classifications included 23 of 867 (2.6%) 1-star programs (lower-than-expected performance), 795 of 867 (91.7%) 2-star programs (as-expected or average performance), and 49 of 867 (5.7%) 3-star programs (higher-than-expected performance). STS has developed an MVRR composite performance measure that will be used for participant feedback, quality performance assessment and improvement, and voluntary public reporting.",success
28146260,True,"Journal Article;Multicenter Study;Observational Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"In clinical trials, transcatheter aortic valve replacement (TAVR) has been shown to improve symptoms and quality of life. As this technology moves into general clinical practice, evaluation of the health status outcomes among unselected patients treated with TAVR is of critical importance. To examine the short- and long-term health status outcomes of surviving patients after TAVR in the context of an unselected population. This observational cohort study included patients with severe aortic stenosis who underwent TAVR in the Society of Thoracic Surgeons/American College of Cardiology Transcatheter Valve Therapy (TVT) Registry from November 1, 2011, to March 31, 2016, at more than 450 clinical sites. Disease-specific health status was assessed at baseline and at 30 days and 1 year after TAVR using the Kansas City Cardiomyopathy Questionnaire overall summary (KCCQ-OS) score (range, 0-100 points; higher scores indicate less symptom burden and better quality of life). Factors associated with health status at 1 year after TAVR were examined using multivariable linear regression, with adjustment for baseline health status and accounting for clustering of patients within sites. The 30-day analytic sample included 31 636 patients, and the 1-year cohort included 7014 surviving patients (3454 women [49.2%] and 3560 men [50.8%]; median [interquartile range] age, 84 [78-88] years). The mean (SD) baseline KCCQ-OS score was 42.3 (23.7), indicating substantial health status impairment. Surviving patients had, on average, large improvements in health status at 30 days that persisted to 1 year, with a mean improvement in the KCCQ-OS score of 27.6 (95% CI, 27.3-27.9) points at 30 days and 31.9 (95% CI, 31.3-32.6) points at 1 year. Worse baseline health status, older age, higher ejection fraction, lung disease, home oxygen use, lower mean aortic valve gradients, prior stroke, diabetes, pacemaker use, atrial fibrillation, slow gait speed, and nonfemoral access were significantly associated with worse health status at 1 year. Overall, 62.3% of patients had a favorable outcome at 1 year (alive with reasonable quality of life [KCCQ-OS score, ≥60] and no significant decline [≥10 points] from baseline), with the lowest rates seen among patients with severe lung disease (51.4%), those undergoing dialysis (47.7%), or those with very poor baseline health status (49.2%). In a national, contemporary clinical practice cohort of unselected patients, improvement in health status after TAVR was similar to that seen in the pivotal clinical trials. Although the health status results were favorable for most patients, approximately 1 in 3 still had a poor outcome 1 year after TAVR. Continued efforts are needed to improve patient selection and procedural/postprocedural care to maximize health status outcomes of this evolving therapy.",success
23230306,True,"Comparative Study;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't;Validation Study",,,,,,,,True,"Improving functional status and quality of life are important goals of treatment for patients with severe aortic stenosis. The Kansas City Cardiomyopathy Questionnaire (KCCQ) is a heart failure health status measure and has been used in studies of patients with aortic stenosis. However, its psychometric properties have not yet been evaluated in these patients. We analyzed data from 955 patients, enrolled in the PARTNER trial of transcatheter aortic valve replacement, to evaluate the reliability, responsiveness, validity, and prognostic importance of the KCCQ in patients with severe aortic stenosis. The KCCQ was administered at baseline and at 1, 6, and 12 months after randomization to medical therapy, transcatheter aortic valve replacement, or surgical valve replacement. Among clinically stable patients, there were only small changes in the KCCQ domain scores over time (mean differences 0.1-4.2 points), and the intraclass correlation coefficients showed good agreement between paired assessments (0.65-0.76). However, the domain scores of patients who underwent transcatheter aortic valve replacement showed large changes after treatment (mean differences 13-30 points). Construct validity was demonstrated by comparing each domain against a relevant reference measure (Spearman correlations 0.46-0.69). Finally, among 157 patients randomized to medical management, lower KCCQ overall summary scores at baseline were strongly associated with an increased risk of mortality during the following 12 months. The KCCQ is a highly reliable, responsive, and valid measure of symptoms, functional status, and quality of life in patients with severe, symptomatic aortic stenosis.",success
26643740,True,"Journal Article;Multicenter Study;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Although transcatheter aortic valve replacement (TAVR) is an effective treatment for aortic stenosis, long-term mortality after TAVR remains high and challenging to predict. The Kansas City Cardiomyopathy Questionnaire (KCCQ) is a health status measure, assessed directly from patients, that integrates 2 clinically relevant factors (symptoms and functional status) that may predict TAVR outcomes. Among 7769 patients from 286 sites in the Society of Thoracic Surgeons (STS)/American College of Cardiology (ACC) Transcatheter Valve Therapy (TVT) Registry, we examined the association between preprocedure (baseline) patient health status, as assessed by the KCCQ, and 1-year mortality after TAVR. The KCCQ Overall Summary Score was categorized as very poor: <25, poor: 25 to 49, fair: 50 to 74, or good: ≥75. Before TAVR, health status was rated as very poor in 28%, poor in 38%, fair in 24%, and good in 10%. Patients with worse health status were more likely to be women and had more comorbidities and higher STS mortality risk scores. Compared with those with good health status before TAVR and after adjusting for a broad range of baseline covariates, patients with very poor health status had a 2-fold increased hazard of death over the first year after TAVR (adjusted hazard ratio, 2.00; 95% confidence interval, 1.58-2.54), whereas those with poor and fair health status had intermediate outcomes (adjusted hazard ratio, 1.54; 95% confidence interval, 1.22-1.95 and adjusted hazard ratio, 1.20; 95% confidence interval, 0.94-1.55, respectively). In a national, contemporary practice cohort, worse preprocedure patient health status, as assessed by the KCCQ, was associated with greater long-term mortality after TAVR. These results support the measurement and integration of the KCCQ into mortality risk assessments for patients considering TAVR.",success
12468705,False,Comparative Study;Letter;Comment,,,,,,,,False,,success
15568194,False,Comparative Study;Journal Article,,,,,,,,True,"'Funnel plots' are recommended as a graphical aid for institutional comparisons, in which an estimate of an underlying quantity is plotted against an interpretable measure of its precision. 'Control limits' form a funnel around the target outcome, in a close analogy to standard Shewhart control charts. Examples are given for comparing proportions and changes in rates, assessing association between outcome and volume of cases, and dealing with over-dispersion due to unmeasured risk factors. We conclude that funnel plots are flexible, attractively simple, and avoid spurious ranking of institutions into 'league tables'.",success
29054308,False,Journal Article;Practice Guideline,,,,,,,,False,,success
26184623,False,"Consensus Development Conference;Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Mitral regurgitation (MR) is one of the most prevalent valve disorders and has numerous etiologies, including primary (organic) MR, due to underlying degenerative/structural mitral valve (MV) pathology, and secondary (functional) MR, which is principally caused by global or regional left ventricular remodeling and/or severe left atrial dilation. Diagnosis and optimal management of MR requires integration of valve disease and heart failure specialists, MV cardiac surgeons, interventional cardiologists with expertise in structural heart disease, and imaging experts. The introduction of transcatheter MV therapies has highlighted the need for a consensus approach to pragmatic clinical trial design and uniform endpoint definitions to evaluate outcomes in patients with MR. The Mitral Valve Academic Research Consortium is a collaboration between leading academic research organizations and physician-scientists specializing in MV disease from the United States and Europe. Three in-person meetings were held in Virginia and New York during which 44 heart failure, valve, and imaging experts, MV surgeons and interventional cardiologists, clinical trial specialists and statisticians, and representatives from the U.S. Food and Drug Administration considered all aspects of MV pathophysiology, prognosis, and therapies, culminating in a 2-part document describing consensus recommendations for clinical trial design (Part 1) and endpoint definitions (Part 2) to guide evaluation of transcatheter and surgical therapies for MR. The adoption of these recommendations will afford robustness and consistency in the comparative effectiveness evaluation of new devices and approaches to treat MR. These principles may be useful for regulatory assessment of new transcatheter MV devices, as well as for monitoring local and regional outcomes to guide quality improvement initiatives.",success
23644082,False,"Journal Article;Research Support, Non-U.S. Gov't",NCT01737528,databank,NCT01737528,NCT01737528,NCT01737528,NCT01737528|databank,NCT01737528|databank,True,"The Society of Thoracic Surgeons (STS) and American College of Cardiology (ACC) transcatheter valve therapy (TVT) registry is a novel, national registry for all new TVT devices created through a partnership of the STS and the ACC in close collaboration with the Food and Drug Administration, the Center for Medicare and Medicaid Services, and the Duke Clinical Research Institute. The registry will serve as an objective, comprehensive, and scientifically based resource to improve the quality of patient care, to monitor the safety and effectiveness of TVT devices, to serve as an analytic resource for TVT research, and to enhance communication among key stakeholders.",success
22999725,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"The National Cardiovascular Data Registry (NCDR) developed the Data Quality Program to meet the objectives of ensuring the completeness, consistency, and accuracy of data submitted to the observational clinical registries. The Data Quality Program consists of 3 main components: 1) a data quality report; 2) a set of internal quality assurance protocols; and 3) a yearly data audit program. Since its inception in 1997, the NCDR has been the basis for the development of performance and quality metrics, site-level quality improvement programs, and peer-reviewed health outcomes research. Before inclusion in the registry, data are filtered through the registry-specific algorithms that require predetermined levels of completeness and consistency for submitted data fields as part of the data quality report. Internal quality assurance protocols enforce data standards before reporting. Within each registry, 300 to 625 records are audited annually in 25 randomly identified sites (i.e., 12 to 25 records per audited site). In the 2010 audits, the participant average raw accuracy of data abstraction for the CathPCI Registry, ICD Registry, and ACTION Registry-GWTG were, respectively, 93.1% (range, 89.4% minimum, 97.4% maximum), 91.2% (range, 83.7% minimum, 95.7% maximum), and 89.7.% (range, 85% minimum, 95% maximum). The 2010 audits provided evidence that many fields in the NCDR accurately represent the data from the medical charts. The American College of Cardiology Foundation is undertaking a series of initiatives aimed at creating a quality assurance rapid learning system, which, when complete, will monitor, evaluate, and improve data quality.",success
31320030,False,Editorial;Comment,,,,,,,,False,,success
28476349,False,Journal Article,,,,,,,,True,"Degenerative mitral valve repair rates remain highly variable, despite established benefits of repair over replacement. The contribution of surgeon-specific factors is poorly defined. This study evaluated the influence of surgeon case volume on degenerative mitral valve repair rates and outcomes. A mandatory New York State database was queried and 5,475 patients were identified with degenerative mitral disease who underwent mitral valve operations between 2002 and 2013. Mitral repair rates, mitral reoperations within 12 months of repair, and survival were analyzed using multivariable Cox modeling and restricted cubic spline function. Median annual surgeon volume of any mitral operations was 10 (range 1 to 230), with a mean repair rate of 55% (n = 20,797 of 38,128). In the subgroup of patients with degenerative disease, the mean repair rate was 67% (n = 3,660 of 5,475), with a range of 0% to 100%. Mean repair rates ranged from 48% (n = 179 of 370) for surgeons with total annual volumes of ≤10 mitral operations to 77% (n = 1,710 of 2,216) for surgeons with total annual volumes of >50 mitral operations (p < 0.001). Higher total annual surgeon volume was associated with increased repair rates of degenerative mitral valve disease (adjusted odds ratio [OR]: 1.13 for every additional 10 mitral operations; 95% confidence interval [CI]: 1.10 to 1.17; p < 0.001); a steady decrease in reoperation risk until 25 total mitral operations annually; and improved 1-year survival (adjusted hazard ratio: 0.95 for every additional 10 operations; 95% CI: 0.92 to 0.98; p = 0.001). For surgeons with a total annual volume of ≤25 mitral operations, repair rates were higher (63.8%; n = 180 of 282) if they operated in the same institution as a surgeon with total annual mitral volumes of >50 and degenerative mitral valve repair rates of >70%, compared with surgeons operating in the other institutions (51.3%; n = 580 of 1,130) (adjusted OR: 1.79; 95% CI: 1.24 to 2.60; p < 0.001). This study suggests that individual surgeon volume is a determinant of not only mitral repair rates, but also freedom from reoperation, and survival. The data from this study support the guideline's concept of reference referral to experienced mitral surgeons to improve outcomes in patients with degenerative mitral valve disease.",success
31577335,True,"Comparative Study;Journal Article;Multicenter Study;Observational Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"Volume metrics may have relevance in the evaluation of valve center expertise. However, a paucity of data exists regarding the quantity, volume, and geographic location of mitral valve (MV) surgical centers in the United States and the proportion of underserved populations they treat. To evaluate the hospital, patient, and procedural characteristics of mitral valve repair or replacement (MVRR) in the United States as a function of hospital procedure volume. This cross-sectional, multicenter observational study was conducted from July 2014 to June 2018. Patients in the Society of Thoracic Surgeons Adult Cardiac Surgery Database undergoing any surgical procedure involving MVRR in the United States were included. Volume distribution of MVRR by hospital and hospital referral region. There were 165 405 MVRRs performed in 1082 centers during the study period, of which 86 488 (52.3%) were MV repairs. There were 575 centers (53.1%) that performed 25 or more MVRRs per year. The geographic distribution of centers performing 25 or more MVRRs per year differed from those performing fewer than 25 MVRRs per year. Of 304 designated hospital referral regions, 235 (77.3%) had at least 1 center performing 25 or more MVRRs per year, representing accessibility to 1 or more such centers for 296.4 million of 320.1 million US residents (92.6% of the US population; Midwest, 60.0 million of 68.0 million [88.4%]; South, 112.6 million of 122.6 million [91.9%]; West, 68.6 million of 72.9 million [94.1%]; and Northeast, 54.9 million of 56.6 million [97.1%]). Of 304 hospital referral regions, 168 (55.3%) had at least 1 center performing 40 or more MVRRs per year, representing accessibility to 1 or more such centers for 259.8 million of 317.90 million (81.7%) of the US population (Midwest, 50.5 million of 67.9 million [74.5%]; South, 94.5 million of 121.1 million [78.1%]; West, 64.0 million of 72.8 million [88.0%]; Northeast, 50.1 million of 56.3 million [90.2%]). More black and Hispanic patients received operations in centers performing 25 or more MVRRs per year (22 984) vs those performing fewer than 25 MVRRs per year (3227), yet the proportion was higher in lower-volume centers (22 984 of 148 385 [15.5%] vs 3227 of 17 020 [19.0%]; P < .001). In centers performing 25 or more MVRRs per year vs fewer than 25 MVRRs per year, there was a lower percentage of Medicare and Medicaid patients (47 920 of 148 385 [32.3%] vs 6183 of 17 020 [.3%]; P < .001) and patients from rural zip codes (21 208 of 148 385 [14.3%] vs 3146 of 17 020 [18.5%]; P < .001). Fifty-three percent of all centers performed 25 or more MVRRs per year, and 92.6% of the US population lived in an hospital referral region with at least 1 such center. Disparities in race/ethnicity, rurality, and insurance status exist among patients being treated at centers with different volumes. These data indicate that efforts to centralize care based on volume metrics will need to balance access vs quality.",success
30794876,False,Journal Article;Practice Guideline,,,,,,,,False,,success
30032907,False,Comparative Study;Journal Article,,,,,,,,True,"Data from The Society of Thoracic Surgeons Adult Cardiac Surgery Database were analyzed to identify trends in patient characteristics and outcomes of mitral valve operations in North America. All patients with isolated primary mitral valve operations with or without tricuspid valve repair, surgical atrial fibrillation ablation, or atrial septal defect closure performed July 2011 to September 2016 were identified. A subgroup analysis assessed patients with degenerative leaflet prolapse (DLP). Isolated primary mitral valve operations were performed on 87,214 patients at 1,125 centers, increasing by 24% between 2011 (n = 14,442) and 2016 (n = 17,907). The most common etiology was DLP (60.7%); 4.3% had functional mitral regurgitation. Preoperatively, 47.3% of patients had an ejection fraction less than 60% and 34.2% had atrial fibrillation. Overall mitral valve repair rate was 65.6%, declining from 67.1% (2011) to 63.2% (2016; p < 0.0001). Repair rates were related to etiology (DLP, 82.5%; rheumatic, 17.5%). Of the 29,970 mitral valve replacements, 16.2% were preceded by an attempted repair. Repair techniques included prosthetic annuloplasty (94.3%), leaflet resection (46.5%), and artificial cord implantation (22.7%). Bioprosthetic valves were implanted with increasing frequency (2011, 65.4%; 2016, 75.8%; p < 0.0001). Less-invasive operations were performed in 23.0% and concomitant tricuspid valve repair in 15.7%. Unadjusted operative mortality was 3.7% (replacements) and 1.1% (repairs). Patients undergoing primary isolated mitral valve operations commonly have ventricular dysfunction, atrial fibrillation, and heart failure. Although contemporary outcomes are excellent, earlier guideline-directed referral and increased frequency and quality of repair may further improve results of mitral valve operations.",success
27040451,True,"Comparative Study;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",NCT00806988,databank,NCT00806988,NCT00806988,NCT00806988,NCT00806988|databank,NCT00806988|databank,True,"In a trial comparing coronary-artery bypass grafting (CABG) alone with CABG plus mitral-valve repair in patients with moderate ischemic mitral regurgitation, we found no significant difference in the left ventricular end-systolic volume index (LVESVI) or survival after 1 year. Concomitant mitral-valve repair was associated with a reduced prevalence of moderate or severe mitral regurgitation, but patients had more adverse events. We now report 2-year outcomes. We randomly assigned 301 patients to undergo either CABG alone or the combined procedure. Patients were followed for 2 years for clinical and echocardiographic outcomes. At 2 years, the mean (±SD) LVESVI was 41.2±20.0 ml per square meter of body-surface area in the CABG-alone group and 43.2±20.6 ml per square meter in the combined-procedure group (mean improvement over baseline, -14.1 ml per square meter and -14.6 ml per square meter, respectively). The rate of death was 10.6% in the CABG-alone group and 10.0% in the combined-procedure group (hazard ratio in the combined-procedure group, 0.90; 95% confidence interval, 0.45 to 1.83; P=0.78). There was no significant between-group difference in the rank-based assessment of the LVESVI (including death) at 2 years (z score, 0.38; P=0.71). The 2-year rate of moderate or severe residual mitral regurgitation was higher in the CABG-alone group than in the combined-procedure group (32.3% vs. 11.2%, P<0.001). Overall rates of hospital readmission and serious adverse events were similar in the two groups, but neurologic events and supraventricular arrhythmias remained more frequent in the combined-procedure group. In patients with moderate ischemic mitral regurgitation undergoing CABG, the addition of mitral-valve repair did not lead to significant differences in left ventricular reverse remodeling at 2 years. Mitral-valve repair provided a more durable correction of mitral regurgitation but did not significantly improve survival or reduce overall adverse events or readmissions and was associated with an early hazard of increased neurologic events and supraventricular arrhythmias. (Funded by the National Institutes of Health and Canadian Institutes of Health Research; ClinicalTrials.gov number, NCT00806988.).",success
11368702,False,Guideline;Journal Article;Practice Guideline,,,,,,,,False,,success
24220553,False,Journal Article,,,,,,,,False,,success
30586774,False,Journal Article;Practice Guideline;Systematic Review,,,,,,,,True,"Since 1980, the American College of Cardiology (ACC) and American Heart Association (AHA) have translated scientific evidence into clinical practice guidelines with recommendations to improve cardiovascular health. These guidelines, which are based on systematic methods to evaluate and classify evidence, provide a foundation for the delivery of quality cardiovascular care. The ACC and AHA sponsor the development and publication of clinical practice guidelines without commercial support, and members volunteer their time to the writing and review efforts. Clinical practice guidelines provide recommendations applicable to patients with or at risk of developing cardiovascular disease (CVD). The focus is on medical practice in the United States, but these guidelines are relevant to patients throughout the world. Although guidelines may be used to inform regulatory or payer decisions, the intent is to improve quality of care and align with patients’ interests. Guidelines are intended to define practices meeting the needs of patients in most, but not all, circumstances, and should not replace clinical judgment. Recommendations for guideline-directed management and therapy, which encompasses clinical evaluation, diagnostic testing, and both pharmacological and procedural treatments, are effective only when followed by both practitioners and patients. Adherence to recommendations can be enhanced by shared decision-making between clinicians and patients, with patient engagement in selecting interventions on the basis of individual values, preferences, and associated conditions and comorbidities. The ACC/AHA Task Force on Clinical Practice Guidelines strives to ensure that the guideline writing committee both contains requisite expertise and is representative of the broader medical community by selecting experts from a broad array of backgrounds, representing different geographic regions, sexes, races, ethnicities, intellectual perspectives/biases, and scopes of clinical practice, and by inviting organizations and professional societies with related interests and expertise to participate as partners or collaborators. The ACC and AHA have rigorous policies and methods to ensure that documents are developed without bias or improper influence. The complete policy on relationships with industry and other entities (RWI) can be found online. Beginning in 2017, numerous modifications to the guidelines have been and continue to be implemented to make guidelines shorter and enhance “user friendliness.” Guidelines are written and presented in a modular knowledge chunk format, in which each chunk includes a table of recommendations, a brief synopsis, recommendation-specific supportive text and, when appropriate, flow diagrams or additional tables. Hyperlinked references are provided for each modular knowledge chunk to facilitate quick access and review. More structured guidelines–including word limits (“targets”) and a web guideline supplement for useful but noncritical tables and figures–are 2 such changes. This Preamble is an abbreviated version, with the detailed version available online. The reader is encouraged to consult the full-text guideline for additional guidance and details, since the executive summary contains mainly the recommendations.",success
29659693,False,"Historical Article;Journal Article;Research Support, U.S. Gov't, Non-P.H.S.;Review",,,,,,,,True,"Evidence-based dietary guidance in the United States has progressed substantially since its inception >100 y ago. This review describes the historical development and significance of dietary guidance in the United States, including the Dietary Guidelines for Americans (DGAs), and emphasizes the foundations upon which they were developed, the process in the formation of past and current guidelines, and present and future applications. Dietary guidance during the first half of the 20th century was focused primarily on food groups in a healthy diet, food safety, safe food storage, and the role of some minerals and vitamins in the prevention of disease. This was punctuated by World War II messaging to reduce food waste and increase food storage. In 1980, the first DGA report was released, and later, the USDA and the Department of Health and Human Services (HHS) were given a mandate for reissuance and reassessment every 5 y. An ad hoc advisory committee made up of nongovernmental experts was established for each edition to review the scientific evidence and provide content recommendations to the Secretaries of the USDA and the HHS. Wording was changed from negative (avoid) to positive (choose) and emphasis was increasingly placed on reducing the prevalence of overweight and obesity and prevention of chronic diseases. Today, the DGAs guide all federally funded feeding and educational programs, including food policies, food assistance programs, and consumer education programs, as well as these programs at the regional, state, and local levels. Additional users include dietitians and other health professionals, food service personnel, food and beverage manufacturers, schools, and day care facilities. Currently, the DGAs are intended for individuals aged ≥2 y. Future editions of the DGAs will include guidance for infants and children <2 y, as well as pregnant women.",success
30879355,False,"Journal Article;Research Support, Non-U.S. Gov't;Review",,,,,,,,False,,success
26699442,False,Journal Article;Practice Guideline,,,,,,,,True,"An Expert Panel convened by the National Lipid Association previously developed a consensus set of recommendations for the patient-centered management of dyslipidemia in clinical medicine (part 1). These were guided by the principle that reducing elevated levels of atherogenic cholesterol (non-high-density lipoprotein cholesterol and low-density lipoprotein cholesterol) reduces the risk for atherosclerotic cardiovascular disease. This document represents a continuation of the National Lipid Association recommendations developed by a diverse panel of experts who examined the evidence base and provided recommendations regarding the following topics: (1) lifestyle therapies; (2) groups with special considerations, including children and adolescents, women, older patients, certain ethnic and racial groups, patients infected with human immunodeficiency virus, patients with rheumatoid arthritis, and patients with residual risk despite statin and lifestyle therapies; and (3) strategies to improve patient outcomes by increasing adherence and using team-based collaborative care.",success
29903993,False,Journal Article,,,,,,,,True,"The 2015 Dietary Guidelines for Americans recommends that individuals should minimize their dietary cholesterol intake. However, current dietary cholesterol intake and its food sources have not been well-characterized. We examined dietary cholesterol intake by age, sex, race, and food sources using 24-h dietary recall data from a nationally representative sample of 5047 adults aged 20 years or older who participated in NHANES (2013⁻2014 survey cycle). We also reported trends in cholesterol intake across the past seven NHANES surveys. Mean dietary cholesterol intake was 293 mg/day (348 mg/day for men and 242 mg/day for women) in the 2013⁻2014 survey cycle; 39% of adults had dietary cholesterol intake above 300 mg/day (46% for men and 28% for women). Meat, eggs, grain products, and milk were the highest four food sources of cholesterol, contributing to 96% of the total consumption. Both average cholesterol intake and food source varied by age, sex, and race (each <i>p</i> < 0.05). Mean cholesterol intake of the overall population had been relatively constant at ~290 mg/day from 2001⁻2002 to 2013⁻2014 (<i>p</i>-trend = 0.98). These results should inform public health efforts in implementing dietary guidelines and tailoring dietary recommendations.",success
8688759,False,"Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"To examine the association between fat intake and the incidence of coronary heart disease in men of middle age and older. Cohort questionnaire study of men followed up for six years from 1986. The health professionals follow up study in the United States. 43 757 health professionals aged 40 to 75 years free of diagnosed cardiovascular disease or diabetes in 1986. Incidence of acute myocardial infarction or coronary death. During follow up 734 coronary events were documented, including 505 non-fatal myocardial infarctions and 229 deaths. After age and several coronary risk factors were controlled for significant positive associations were observed between intake of saturated fat and risk of coronary disease. For men in the top versus the lowest fifth of saturated fat intake (median = 14.8% v 5.7% of energy) the multivariate relative risk for myocardial infarction was 1.22 (95% confidence interval 0.96 to 1.56) and for fatal coronary heart disease was 2.21 (1.38 to 3.54). After adjustment for intake of fibre the risks were 0.96 (0.73 to 1.27) and 1.72 (1.01 to 2.90), respectively. Positive associations between intake of cholesterol and risk of coronary heart disease were similarly attenuated after adjustment for fibre intake. Intake of linolenic acid was inversely associated with risk of myocardial infarction; this association became significant only after adjustment for non-dietary risk factors and was strengthened after adjustment for total fat intake (relative risk 0.41 for a 1% increase in energy, P for trend < 0.01). These data do not support the strong association between intake of saturated fat and risk of coronary heart disease suggested by international comparisons. They are compatible, however, with the hypotheses that saturated fat and cholesterol intakes affect the risk of coronary heart disease as predicted by their effects on blood cholesterol concentration. They also support a specific preventive effect of linolenic acid intake.",success
14525873,False,"Journal Article;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"To examine the association between intake of total fat, specific types of fat, and cholesterol and risk of stroke in men. Design and setting Health professional follow up study with 14 year follow up. 43 732 men aged 40-75 years who were free from cardiovascular diseases and diabetes in 1986. Relative risk of ischaemic and haemorrhagic stroke according to intake of total fat, cholesterol, and specific types of fat. During the 14 year follow up 725 cases of stroke occurred, including 455 ischaemic strokes, 125 haemorrhagic stokes, and 145 strokes of unknown type. After adjustment for age, smoking, and other potential confounders, no evidence was found that the amount or type of dietary fat affects the risk of developing ischaemic or haemorrhagic stroke. Comparing the highest fifth of intake with the lowest fifth, the multivariate relative risk of ischaemic stroke was 0.91 (95% confidence interval 0.65 to 1.28; P for trend = 0.77) for total fat, 1.20 (0.84 to 1.70; P = 0.47) for animal fat, 1.07 (0.77 to 1.47; P = 0.66) for vegetable fat, 1.16 (0.81 to 1.65; P = 0.59) for saturated fat, 0.91 (0.65 to 1.28; P = 0.83) for monounsaturated fat, 0.88 (0.64 to 1.21; P = 0.25) for polyunsaturated fat, 0.87 (0.62 to 1.22; P = 0.42) for trans unsaturated fat, and 1.02 (0.75 to 1.39; P = 0.99) for dietary cholesterol. Intakes of red meats, high fat dairy products, nuts, and eggs were also not appreciably related to risk of stroke. These findings do not support associations between intake of total fat, cholesterol, or specific types of fat and risk of stroke in men.",success
9149659,False,"Journal Article;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"The relation of intakes of specific fatty acids and the risk of coronary heart disease was examined in a cohort of 21,930 smoking men aged 50-69 years who were initially free of diagnosed cardiovascular disease. All men participated in the Finnish Alpha-Tocopherol, Beta-Carotene Cancer Prevention Study and completed a detailed and validated dietary questionnaire at baseline. After 6.1 years of follow-up from 1985-1988, the authors documented 1,399 major coronary events and 635 coronary deaths. After controlling for age, supplement group, several coronary risk factors, total energy, and fiber intake, the authors observed a significant positive association between the intake of trans-fatty acids and the risk of coronary death. For men in the top quintile of trans-fatty acid intake (median = 6.2 g/day), the multivariate relative risk of coronary death was 1.39 (95% confidence interval (CI) 1.09-1.78) (p for trend = 0.004) as compared with men in the lowest quintile of intake (median = 1.3 g/day). The intake of omega-3 fatty acids from fish was also directly related to the risk of coronary death in the multivariate model adjusting also for trans-saturated and cis-monounsaturated fatty acids (relative risk (RR) = 1.30, 95% CI 1.01-1.67) (p for trend = 0.06 for men in the highest quintile of intake compared with the lowest). There was no association between intakes of saturated or cis-monounsaturated fatty acids, linoleic or linolenic acid, or dietary cholesterol and the risk of coronary deaths. All the associations were similar but somewhat weaker for all major coronary events.",success
22265275,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Whether intakes of dietary fat and cholesterol are associated with risk of stroke remain unclear. We examined the associations between intakes of total fat, specific types of fat, and cholesterol and risk of stroke in a prospective cohort of women. The study population consisted of 34,670 women, aged 49-83 years, in the Swedish Mammography Cohort who were free of cardiovascular disease and completed a food-frequency questionnaire in 1997. Cox proportional hazard regression models were used to estimate relative risks (RR) with 95% confidence intervals (CI). During a mean follow-up of 10.4 years, we ascertained 1680 stroke events, including 1310 cerebral infarctions, 233 hemorrhagic strokes, and 137 unspecified strokes. After adjustment for other stroke risk factors, intake of long-chain omega-3 polyunsaturated fatty acids (PUFA) was inversely associated with risk of total stroke. The multivariable RR of total stroke for the highest compared with the lowest quintile of long-chain omega-3 PUFA intake was 0.84 (95% CI, 0.72-0.99; P for trend=0.04). Dietary cholesterol was positively associated with risk of total stroke (highest versus lowest quintile: RR=1.20; 95% CI, 1.00-1.44; P for trend=0.01) and cerebral infarction (corresponding RR=1.29; 95% CI, 1.05-1.58; P for trend=0.004). Total fat, saturated fat, monounsaturated fat, polyunsaturated fat, α-linolenic acid, and omega-6 PUFA intakes were not associated with stroke. These findings suggest that intake of long-chain omega-3 PUFAs is inversely associated with risk of stroke, whereas dietary cholesterol is positively associated with risk.",success
22383309,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"To examine the associations between dietary fat intake and ischemic stroke among postmenopausal women. We conducted a prospective cohort study of 87,025 generally healthy postmenopausal women (age, 50-79 years) enrolled in the Women's Health Initiative Observational Study. Repeated and validated dietary assessments were done using a self-administered food frequency questionnaire. We used Cox proportional hazards models to estimate hazard ratios (HRs) of ischemic stroke based on quintiles of the cumulative average of fat intake. We documented 1,049 incident cases of ischemic stroke over 663,041 person-years of follow-up. Women in the highest quintile of trans fat intake had a significantly higher incidence of ischemic stroke (HR, 1.39; 95% confidence interval [CI], 1.08-1.79; p-trend = 0.048) compared with women in the lowest quintile, while controlling for multiple covariates. The observed association was modified by aspirin use (p-interaction = 0.02). The HR was 1.66 (95% CI, 1.21-2.36; p-trend < 0.01) among baseline non-aspirin users (n = 67,288) and 0.95 (95% CI, 0.60-1.48; p-trend = 0.43) among aspirin users (n = 19,736). No significant associations were found between intakes of saturated, monounsaturated, or polyunsaturated fat and ischemic stroke or any ischemic stroke subtypes. In this large cohort of postmenopausal women, higher intake of trans fat was associated with incident ischemic stroke independent of major lifestyle/dietary factors. Aspirin use may attenuate the potential adverse effect of trans fat intake on ischemic stroke.",success
9366580,False,"Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"The relation between dietary intake of specific types of fat, particularly trans unsaturated fat and the risk of coronary disease remains unclear. We therefore studied this relation in women enrolled in the Nurses' Health Study. We prospectively studied 80,082 women who were 34 to 59 years of age and had no known coronary disease, stroke, cancer, hypercholesterolemia, or diabetes in 1980. Information on diet was obtained at base line and updated during follow-up by means of validated questionnaires. During 14 years of follow-up, we documented 939 cases of nonfatal myocardial infarction or death from coronary heart disease. Mutivariate analyses included age, smoking status, total energy intake, dietary cholesterol intake, percentages of energy obtained from protein and specific types of fat, and other risk factors. Each increase of 5 percent of energy intake from saturated fat, as compared with equivalent energy intake from carbohydrates, was associated with a 17 percent increase in the risk of coronary disease (relative risk, 1.17; 95 percent confidence interval, 0.97 to 1.41; P=0.10). As compared with equivalent energy from carbohydrates, the relative risk for a 2 percent increment in energy intake from trans unsaturated fat was 1.93 (95 percent confidence interval, 1.43 to 2.61; P<0.001); that for a 5 percent increment in energy from monounsaturated fat was 0.81 (95 percent confidence interval, 0.65 to 1.00; P=0.05); and that for a 5 percent increment in energy from polyunsaturated fat was 0.62 (95 percent confidence interval, 0.46 to 0.85; P= 0.003). Total fat intake was not signficantly related to the risk of coronary disease (for a 5 percent increase in energy from fat, the relative risk was 1.02; 95 percent confidence interval, 0.97 to 1.07; P=0.55). We estimated that the replacement of 5 percent of energy from saturated fat with energy from unsaturated fats would reduce risk by 42 percent (95 percent confidence interval, 23 to 56; P<0.001) and that the replacement of 2 percent of energy from trans fat with energy from unhydrogenated, unsaturated fats would reduce risk by 53 percent (95 percent confidence interval, 34 to 67; P<.001). Our findings suggest that replacing saturated and trans unsaturated fats with unhydrogenated monounsaturated and polyunsaturated fats is more effective in preventing coronary heart disease in women than reducing overall fat intake.",success
11171795,False,"Journal Article;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"-Dietary animal fat and protein have been inversely associated with a risk of intraparenchymal hemorrhage in ecological studies. In 1980, 85 764 women in the Nurses' Health Study cohort, who were 34 to 59 years old and free of diagnosed cardiovascular disease and cancer, completed dietary questionnaires. From these questionnaires, we calculated fat and protein intake. By 1994, after 1.16 million person-years of follow-up, 690 incident strokes, including 74 intraparenchymal hemorrhages, had been documented. Multivariate-adjusted risk of intraparenchymal hemorrhage was higher among women in the lowest quintile of energy-adjusted saturated fat intake than at all higher levels of intake (relative risk [RR], 2.36; 95% CI, 1.10 to 5.09; P:=0.03). For trans unsaturated fat, the corresponding RR was 2.50 (95% CI, 1.35 to 4.65; P:=0.004). Animal protein intake was inversely associated with risk (RR in the highest versus lowest quintiles, 0.32; 95% CI, 0.10 to 1.00; P:=0.04). The excess risk associated with low saturated fat intake was observed primarily among women with a history of hypertension (RR, 3.66; 95% CI, 1.09 to 12.3; P=0.04), but such an interaction was not seen for trans unsaturated fat or animal protein. These nutrients were not related to risk of other stroke subtypes. Dietary cholesterol and monounsaturated and polyunsaturated fat were not related to risk of any stroke subtype. Low intake of saturated fat and animal protein was associated with an increased risk of intraparenchymal hemorrhage, which may help to explain the high rate of this stroke subtype in Asian countries. The increased risk with low intake of saturated fat and trans unsaturated fat is compatible with the reported association between low serum total cholesterol and risk.",success
9151243,False,Journal Article,,,,,,,,True,"To assess the relationship between dietary lipids and incidence of cerebral infarction in a Japanese rural population. A cohort study from July 1977 through December 1992. Akadani-Ijimino (A-I) district, Niigata Prefecture, Japan. All the residents, 1,182 men and 1,469 women, aged 40 years and over. Out of these members, 954 men and 1,329 women who were initially free of stroke completed a semiquantitative food frequency questionnaire in 1977, and were then subjected to a follow-up for 15.5 years. The occurrence of stroke was determined by the annual follow-up examination and registry. Dietary lipid was adjusted for total energy or fat intake by the residual method. Sex- and age-stratified and blood pressure- and atrial fibrillation-adjusted relative risk for cerebral infarction was estimated by the Cox proportional hazard model. There were 75 new cases of cerebral infarction during the observation period. The relative risk for cerebral infarction was less than one in the highest quartile level of total fat, saturated fatty acids (S), Keys score and westernized dietary pattern: 0.68-0.94. It ranged between 1.36 and 1.57 in the highest level of polyunsaturated (P), n-3 and n-6 fatty acids, and P/S ratio. This study suggests the possibility that the traditional Japanese diet, very low fat intake, was likely to increase the risk of stroke through the low level of serum cholesterol as an intermediary factor.",success
6720666,False,Journal Article,,,,,,,,True,"Nutrient intake was determined in over 8000 men of Japanese ancestry residing on the island of Oahu. Nutrient determination took place at the initial examination during the years 1965-1968. This report relates nutrient intake to the risk of developing coronary heart disease in the 10 years subsequent to the initial examination. Men who developed coronary heart disease had a lower average intake of calories, carbohydrates, starch, and vegetable protein than men who remained free of coronary heart disease. Men who developed coronary heart disease also had a higher mean intake of percentage of calories from protein, fat, saturated fatty acids, and polyunsaturated fatty acids than men who remained free of coronary heart disease. These men also had a significantly lower mean percentage of calories from carbohydrates and a higher mean ingestion of cholesterol per 1000 calories than men who remained free of coronary heart disease. In multivariate analyses including age, systolic blood pressure, serum cholesterol, cigarettes smoked per day, and physical activity index, carbohydrates, vegetable protein, percentage of calories from saturated fatty acids, and percentage of calories from polyunsaturated fatty acids are no longer significantly related to incidence.",success
8606322,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"The diet-heart hypothesis proposes that elevated intakes of total fat, saturated fat, and dietary cholesterol raise serum cholesterol, which in turn increases the risk of developing coronary heart disease (CHD). To examine the relationship between dietary intake and 12-year CHD mortality we used data from the Lipid Research Clinics Prevalence Follow-Up Study. Dietary intake was measured at study entry using the 24-hour recall technique among 4546 North American men and women who were at least 30 years old and initially free of CHD. Proportional hazards analyses controlling for total energy intake indicated that increasing percentages of energy intake as total fat (RR 1.04, 95% CI = 1.01-1.08), saturated fat (RR 1.11, CI = 1.04-1.18), and monounsaturated fat (RR 1.08, CI = 1.01-1.16) were significant risk factors for CHD mortality among 30 to 59 year olds. The increasing percentage of energy intake from carbohydrate had a significant protective effect (RR 0.96, CI = 0.94-0.99). The strength of these associations was not diminished after adjustment for specific serum lipids, suggesting that serum lipids did not mediate the effect of diet on CHD mortality. None of the dietary components were significantly associated with CHD mortality among those aged 60-79 years. We conclude that future research must be directed toward better understanding the pathway between dietary intake and coronary disease as the current diet-lipid-heart hypothesis may be overly simplistic.",success
9415002,False,Journal Article,,,,,,,,True,"To investigate dietary determinants of ischaemic heart disease (IHD) in health conscious individuals to explain the reduced risk in vegetarians, and to examine the relation between IHD and body mass index (BMI) within the normal range. Prospective observation of vegetarians, semi-vegetarians, and meat eaters for whom baseline dietary data, reported weight and height information, social class, and smoking habits were recorded. 10,802 men and women in the UK aged between 16 and 79, mean duration of follow up 13.3 years. Death rate rations for IHD and total mortality in relation to dietary and other characteristics recorded at recruitment (reference category death rate = 100). IHD mortality was less than half that expected from the experience reported for all of England and Wales. An increase in mortality for IHD was observed with increasing intakes of total and saturated animal fat and dietary cholesterol-death rate ratios in the third tertile compared with the first tertile: 329, 95% confidence interval (CI) 150 to 721; 277, 95% CI 125 to 613; 353, 95% CI 157 to 796, respectively. No protective effects were observed for dietary fibre, fish or alcohol. Within the study, death rate ratios were increased among those in the upper half of the normal BMI range (22.5 to < 25) and those who were overweight (BMI > or = 25) compared with those with BMI 20 to < 22.5. In these relatively health conscious individuals the deleterious effects of saturated animal fat and dietary cholesterol appear to be more important in the aetiology of IHD than the protective effect of dietary fibre. Reduced intakes of saturated animal fat and cholesterol may explain the lower rates of IHD among vegetarians compared with meat eaters. Increasing BMI within the normal range is associated with increased risk of IHD. The results have important public health implications.",success
17023718,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"The results of previous studies on the association between dietary fat intake and coronary heart disease (CHD) incidence are inconsistent. The aim of this study was to examine the association between dietary fat intake and CHD incidence in American Indians in the Strong Heart Study. A total of 2938 participants aged 47-79 y and free of CHD at the second examination (1993-1995) were examined and followed for CHD, nonfatal CHD, and fatal CHD events to 31 December 2002. Dietary intake was assessed by using a 24-h diet recall and was calculated as percentages of energy. Participants were followed for a mean (+/-SD) of 7.2 +/- 2.3 y. During follow-up, 436 incident CHD cases (298 nonfatal CHD and 138 fatal CHD events) were ascertained. Participants aged 47-59 y in the highest quartile of intake of total fat, saturated fatty acids, or monounsaturated fatty acids had higher CHD mortality than did those in the lowest quartile [hazard ratio (95% CI): 3.57 (1.21, 10.49), 5.17 (1.64, 16.36), and 3.43 (1.17, 10.04), respectively] after confounders were controlled for. These associations were not observed for those aged 60-79 y. Total fat, saturated fatty acid, and monounsaturated fatty acid intake were strong predictors of CHD mortality in American Indians aged 47-59 y, independent of other established CHD risk factors. It may be prudent for American Indians to reduce their fat intake early in life to reduce the risk of dying from CHD.",success
7405884,False,"Comparative Study;Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"A study of base-line nutrient intakes of 8218 urban and rural Puerto Rican man aged 45 to 64 years was undertaken in relation to subsequent six year coronary heart disease (CHD) incidence. Urban dietary intakes were significantly higher in total fat and lower in carbohydrate, particularly starch. Average cholesterol intakes were 83 mg/day higher in urban than rural men. Urban serum cholesterol values were significantly higher than rural values. Urban men who developed myocardial infarction or CHD death had significantly lower calorie and carbohydrate intakes i.e., chiefly those derived from rice and legumes. The same association was found in the rural group but failed to reach statistical significance. A very low intake of alcohol was noted in the 73 rural CHD cases. Dietary sucrose intake showed no relationship to CHD incidence. Multivariate analysis, taking relative weight, hematocrit, blood pressure, serum cholesterol, alcohol intake, cigarette smoking, area, and age into account, demonstrated an independent inverse relation of carbohydrate intake from legumes to CHD incidence. The apparent protective effect of complex carbohydrate merits further investigation.",success
15166397,False,"Journal Article;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, Non-P.H.S.",,,,,,,,True,"A traditional diet that is poor in animal products is thought to explain the high rate of stroke in Asian populations. The purpose of the present study was to examine the effect of a diet rich in animal protein, animal fat, and cholesterol on the risk of cerebral infarction mortality in a Japanese population. A prospective study of 3731 Japanese men and women aged 35 to 89 years was conducted from 1984 to 2001. Nutrient intake was estimated at baseline from the responses to a 24-hour diary. During the follow-up period, cases of cerebral infarction deaths (as entered on death certificates) were monitored. During the follow-up period, 60 deaths were attributed to cerebral infarction. A high intake of animal fat and cholesterol was significantly associated with a reduced risk of cerebral infarction death. The risk was reduced by 62% (CI, 82% to 18%) for those in the third tertile of animal fat intake, compared with those in the first tertile, with a significant linear dose-response relationship (P=0.0073). The risk of death from infarction was reduced by 63% (CI, 82% to 22%) in the high cholesterol consumption group, compared with the low consumption group. A significant linear dose-response relationship was observed. Animal protein was not significantly associated with infarction mortality after adjustment for animal fat and cholesterol. This study suggests that in Japan, where animal product intake is lower than in Western countries, a high consumption of animal fat and cholesterol was associated with a reduced risk of cerebral infarction death.",success
2983212,False,"Comparative Study;Journal Article;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"In a prospective epidemiologic study of 1001 middle-aged men, we examined the relation between dietary information collected approximately 20 years ago and subsequent mortality from coronary heart disease. The men were initially enrolled in three cohorts: one of men born and living in Ireland, another of those born in Ireland who had emigrated to Boston, and the third of those born in the Boston area of Irish immigrants. There were no differences in mortality from coronary heart disease among the three cohorts. In within-population analyses, those who died of coronary heart disease had higher Keys (P = 0.06) and modified Hegsted (P = 0.02) dietary scores than did those who did not (a high score indicates a high intake of saturated fatty acids and cholesterol and a relatively low intake of polyunsaturated fatty acids). These associations were significant (P = 0.03 for the Keys and P = 0.04 for the modified Hegsted scores) after adjustment for other risk factors for coronary heart disease. Fiber intake (P = 0.04) and a vegetable-foods score, which rose with increased intake of fiber, vegetable protein, and starch (P = 0.02), were lower among those who died from coronary heart disease, though not significantly so after adjustment for other risk factors. A higher Keys score carried an increased risk of coronary heart disease (relative risk, 1.60), and a higher fiber intake carried a decreased risk (relative risk, 0.57). Overall, these results tend to support the hypothesis that diet is related, albeit weakly, to the development of coronary heart disease.",success
7442730,False,"Journal Article;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Over twenty years ago, we evaluated diet, serum cholesterol, and other variables in 1900 middle-aged men and repeated the evaluation one year later. No therapeutic suggestions were made. Vital status was determined at the 20th anniversary of the initial examination. Scores summarizing each participant's dietary intake of cholesterol, saturated fatty acids, and polyunsaturated fatty acids were calculated according to the formulas of Keys and Hegsted and their co-workers. The two scores were highly correlated, and results were similar for both: there was a positive association between diet score and serum cholesterol concentration at the initial examination, a positive association between change in diet score and change in serum cholesterol concentration from the initial to the second examination, and a positive association prospectively between mean base-line diet score and the 19-year risk of death from coronary heart disease. These associations persisted after adjustment for potentially confounding factors. The results support the conclusion that lipid composition of the diet affects serum cholesterol concentration and risk of coronary death in middle-aged American men.",success
2566743,False,"Comparative Study;Journal Article;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"In a cohort of 1824 middle-aged men followed for 25 years, intake of dietary cholesterol was associated with risk of death from ischaemic heart disease, from other cardiovascular diseases combined, from all cardiovascular diseases combined, and from all causes combined. The relative hazard of death from all cardiovascular diseases combined, associated with the difference between the mean of the first and fifth quintiles of cholesterol intake (a difference of 184 mg cholesterol/1000 kcal intake) was 1.46 (95% confidence interval 1.10-1.94) after adjustment for age, intake of other dietary lipids, and other coronary risk factors (including serum cholesterol). When stratified into three groups according to serum cholesterol (less than 220 mg/dl, 220-259 mg/dl, and 260 mg/dl or above), the corresponding relative hazards were 1.58, 1.50, and 1.41, respectively. These results are further evidence for the concepts that dietary cholesterol is atherogenic in man, and that the effect is partly independent of total serum cholesterol. They reinforce the recommendation that intake of dietary cholesterol should be low in people without overt hyperlipidaemia as well as those with raised serum cholesterol.",success
26109578,False,"Journal Article;Meta-Analysis;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, Non-P.H.S.;Systematic Review",,,,,,,,True,"Dietary cholesterol has been suggested to increase the risk of cardiovascular disease (CVD), which has led to US recommendations to reduce cholesterol intake. The authors examine the effects of dietary cholesterol on CVD risk in healthy adults by using systematic review and meta-analysis. MEDLINE, Cochrane Central, and Commonwealth Agricultural Bureau Abstracts databases were searched through December 2013 for prospective studies that quantified dietary cholesterol. Investigators independently screened citations and verified extracted data on study and participant characteristics, outcomes, and quality. Random-effect models meta-analysis was used when at least 3 studies reported the same CVD outcome. Forty studies (17 cohorts in 19 publications with 361,923 subjects and 19 trials in 21 publications with 632 subjects) published between 1979 and 2013 were eligible for review. Dietary cholesterol was not statistically significantly associated with any coronary artery disease (4 cohorts; no summary RR), ischemic stroke (4 cohorts; summary RR: 1.13; 95% CI: 0.99, 1.28), or hemorrhagic stroke (3 cohorts; summary RR: 1.09; 95% CI: 0.79, 1.50). Dietary cholesterol statistically significantly increased both serum total cholesterol (17 trials; net change: 11.2 mg/dL; 95% CI: 6.4, 15.9) and low-density lipoprotein (LDL) cholesterol (14 trials; net change: 6.7 mg/dL; 95% CI: 1.7, 11.7 mg/dL). Increases in LDL cholesterol were no longer statistically significant when intervention doses exceeded 900 mg/d. Dietary cholesterol also statistically significantly increased serum high-density lipoprotein cholesterol (13 trials; net change: 3.2 mg/dL; 95% CI: 0.9, 9.7 mg/dL) and the LDL to high-density lipoprotein ratio (5 trials; net change: 0.2; 95% CI: 0.0, 0.3). Dietary cholesterol did not statistically significantly change serum triglycerides or very-low-density lipoprotein concentrations. Reviewed studies were heterogeneous and lacked the methodologic rigor to draw any conclusions regarding the effects of dietary cholesterol on CVD risk. Carefully adjusted and well-conducted cohort studies would be useful to identify the relative effects of dietary cholesterol on CVD risk.",success
10217054,False,"Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Reduction in egg consumption has been widely recommended to lower blood cholesterol levels and prevent coronary heart disease (CHD). Epidemiologic studies on egg consumption and risk of CHD are sparse. To examine the association between egg consumption and risk of CHD and stroke in men and women. Two prospective cohort studies, the Health Professionals Follow-up Study (1986-1994) and the Nurses' Health Study (1980-1994). A total of 37851 men aged 40 to 75 years at study outset and 80082 women aged 34 to 59 years at study outset, free of cardiovascular disease, diabetes, hypercholesterolemia, or cancer. Incident nonfatal myocardial infarction, fatal CHD, and stroke corresponding to daily egg consumption as determined by a food-frequency questionnaire. We documented 866 incident cases of CHD and 258 incident cases of stroke in men during 8 years of follow-up and 939 incident cases of CHD and 563 incident cases of stroke in women during 14 years of follow-up. After adjustment for age, smoking, and other potential CHD risk factors, we found no evidence of an overall significant association between egg consumption and risk of CHD or stroke in either men or women. The relative risks (RRs) of CHD across categories of intake were less than 1 per week (1.0), 1 per week (1.06), 2 to 4 per week (1.12), 5 to 6 per week (0.90), and > or =1 per day (1.08) (P for trend = .75) for men; and less than 1 per week (1.0), 1 per week (0.82), 2 to 4 per week (0.99), 5 to 6 per week (0.95), and > or =1 per day (0.82) (P for trend = .95) for women. In subgroup analyses, higher egg consumption appeared to be associated with increased risk of CHD only among diabetic subjects (RR of CHD comparing more than 1 egg per day with less than 1 egg per week among diabetic men, 2.02 [95% confidence interval, 1.05-3.87; P for trend = .04], and among diabetic women, 1.49 [0.88-2.52; P for trend = .008]). These findings suggest that consumption of up to 1 egg per day is unlikely to have substantial overall impact on the risk of CHD or stroke among healthy men and women. The apparent increased risk of CHD associated with higher egg consumption among diabetic participants warrants further research.",success
22207512,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Few dietary protein sources have been studied prospectively in relation to stroke. We examined the relation between foods that are major protein sources and risk of stroke. We prospectively followed 84 010 women aged 30 to 55 years at baseline and 43 150 men aged 40 to 75 years at baseline without diagnosed cancer, diabetes, or cardiovascular disease. Diet was assessed repeatedly by a standardized and validated questionnaire. We examined the association between protein sources and incidence of stroke using a proportional hazard model adjusted for stroke risk factors. During 26 and 22 years of follow-up in women and men, respectively, we documented 2633 and 1397 strokes, respectively. In multivariable analyses, higher intake of red meat was associated with an elevated risk of stroke, whereas a higher intake of poultry was associated with a lower risk. In models estimating the effects of exchanging different protein sources, compared with 1 serving/day of red meat, 1 serving/day of poultry was associated with a 27% (95% CI, 12%-39%) lower risk of stroke, nuts with a 17% (95% CI. 4%-27%) lower risk, fish with a 17% (95% CI, 0%-30%) lower risk, low-fat dairy with an 11% (95% CI, 5%-17%) lower risk, and whole-fat dairy with a 10% (95% CI, 4%-16%) lower risk. We did not see significant associations with exchanging legumes or eggs for red meat. These data suggest that stroke risk may be reduced by replacing red meat with other dietary sources of protein.",success
12913025,False,"Journal Article;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, Non-P.H.S.",,,,,,,,True,"To determine whether intake of animal products was associated with a reduced risk of stroke mortality in a large-scale population-based cohort in Japan. A self-administered questionnaire, including questions on dietary habits, was mailed to the members of the Life Span Study, a cohort of people exposed and non-exposed to atomic bomb radiation, who were alive as of 1 September 1979. Animal products included frequency intake of beef/pork, chicken, ham/sausage, milk, dairy products, eggs, fish, and broiled fish. Responses were obtained from 40 349 people (72%): 15 350 men (mean age 54 years) and 24 999 women (mean age 58 years). The subjects were followed for 16 years, and deaths were ascertained by linkage to the nationwide family registration system of Japan. The associations between diet and stroke mortality were examined using a Cox proportional hazard model. During the follow-up period, 1462 stroke deaths occurred. Four animal products comprising eggs, dairy products, fish, and broiled fish were independently associated with a decreased risk of stroke mortality; while beef/pork, chicken, ham/ sausage, and milk consumption were not associated with stroke death. A composite measure of eggs, dairy products, fish, and broiled fish intake was calculated, and the highest tertile was significantly inversely associated with total stroke mortality (Hazards Ratio [HR] = 0.80, 95% CI: 0.68, 0.93) compared with the lowest tertile. The protective effect of animal product intake on total stroke death was largely confined to intracerebral haemorrhage death; the RH of intracerebral haemorrhage death for the highest tertile of consumption was 0.72 (95% CI: 0.53-0.98) compared with the lowest tertile; animal products intake was not related to cerebral infarction mortality (HR = 0.84; 95% CI: 0.67-1.06). Intake of animal products such as eggs, dairy products, and fish may be protective against intracerebral haemorrhage, but is not related to cerebral infarction mortality.",success
17092383,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Limited egg consumption is often recommended to reduce serum cholesterol concentration for the prevention of CHD. We examined the association of egg consumption and total cholesterol concentration with the risk of CHD. A total of 90 735 subjects (19 856 men and 21 408 women, aged 40-59 years in cohort I; 23 463 men and 26 008 women, aged 40-69 years in cohort II) were followed from 1990-4 to the end of 2001 under the Japan Public Health Center-based prospective study. Total cholesterol was obtained in 36 % of the subjects. Men and women were combined for the analyses. The subjects were categorised into four groups according to egg consumption. Subjects with total cholesterol >or=2200 mg/l were less frequent in frequent egg consumption groups in both cohorts (trend P<0.0001). Subjects with <1 d/week of egg consumption were more likely to avoid a cholesterol-rich diet. Egg consumption was not associated with the risk of CHD, although total cholesterol was significantly related to the risk of CHD. The multivariate hazard ratio of CHD in subjects with total cholesterol >or=2400 v. <1800 mg/l was 2.17 (95 % CI 1.22, 3.85; trend P=0.0018). In conclusion, eating eggs more frequently, up to almost daily, was not associated with an increase in CHD incidence for middle-aged Japanese men and women. Subjects with hypercholesterolaemia were less frequently in frequent egg consumption groups, probably because they avoided eating eggs.",success
18400720,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"A reduction in dietary cholesterol is recommended to prevent cardiovascular disease (CVD). Although eggs are important sources of cholesterol and other nutrients, limited and inconsistent data are available on the effects of egg consumption on the risk of CVD and mortality. We aimed to examine the association between egg consumption and the risk of CVD and mortality. In a prospective cohort study of 21,327 participants from Physicians' Health Study I, egg consumption was assessed with an abbreviated food questionnaire. Cox regression was used to estimate relative risks. In an average follow-up of 20 y, 1550 new myocardial infarctions (MIs), 1342 incident strokes, and 5169 deaths occurred. Egg consumption was not associated with incident MI or stroke in a multivariate Cox regression. In contrast, adjusted hazard ratios (95% CI) for mortality were 1.0 (reference), 0.94 (0.87, 1.02), 1.03 (0.95, 1.11), 1.05 (0.93, 1.19), and 1.23 (1.11, 1.36) for the consumption of <1, 1, 2-4, 5-6, and > or = 7 eggs/wk, respectively (P for trend < 0.0001). This association was stronger among diabetic subjects, in whom the risk of death in a comparison of the highest with the lowest category of egg consumption was twofold (hazard ratio: 2.01; 95% CI: 1.26, 3.20; P for interaction = 0.09). Infrequent egg consumption does not seem to influence the risk of CVD in male physicians. In addition, egg consumption was positively related to mortality, more strongly so in diabetic subjects, in the study population.",success
18195171,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"Reduction in dietary cholesterol is widely recommended for the prevention of cardiovascular disease. Although eggs are important sources of dietary cholesterol and other nutrients, little is known about the association between egg consumption and heart failure (HF) risk. In a prospective cohort study of 21 275 participants from the Physicians' Health Study I, we examined the association between egg consumption and the risk of HF. Egg consumption was assessed with the use of a simple abbreviated food questionnaire, and we used Cox regression to estimate relative risks of HF. After an average follow-up of 20.4 years, a total of 1084 new HF cases occurred in this cohort. Although egg consumption up to 6 times per week was not associated with incident HF, egg consumption of > or = 7 per week was associated with an increased risk of HF. Compared with subjects who reported egg consumption of < 1 per week, hazard ratios (95% confidence intervals) for HF were 1.28 (1.02 to 1.61) and 1.64 (1.08 to 2.49) for egg consumption of 1 per day and > or = 2 per day, respectively, after adjustment for age, body mass index, smoking, alcohol consumption, exercise, and history of atrial fibrillation, hypertension, valvular heart disease, and hypercholesterolemia. Similar results were obtained for HF without antecedent myocardial infarction. Our data suggest that infrequent egg consumption is not associated with the risk of HF. However, egg consumption of > or = 1 per day is related to an increased risk of HF among US male physicians.",success
18954578,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"Prospective studies evaluating associations between food intake and risk of heart failure (HF) in diverse populations are needed. Relationships between incident HF (death or hospitalization) and intake of seven food categories (whole grains, fruits/vegetables, fish, nuts, high-fat dairy, eggs, red meat) were investigated in an observational cohort of 14,153 African-American and white adults, age 45 to 64 years, sampled from four US communities. Between baseline (1987-1989) and Exam 3 (1993-1995), dietary intake was based on responses to a 66-item food frequency questionnaire administered at baseline; thereafter, intake was based on averaged baseline and Exam 3 responses. Hazard ratios (HR [95% CI]) for HF were calculated per 1-daily serving difference in food group intake. During a mean of 13 years, 1,140 HF hospitalizations were identified. After multivariable adjustment (energy intake, demographics, lifestyle factors, prevalent cardiovascular disease, diabetes, hypertension), HF risk was lower with greater whole-grain intake (0.93 [0.87, 0.99]), but HF risk was higher with greater intake of eggs (1.23 [1.08, 1.41]) and high-fat dairy (1.08 [1.01, 1.16]). These associations remained significant independent of intakes of the five other food categories, which were not associated with HF. In this large, population-based sample of African-American and white adults, whole-grain intake was associated with lower HF risk, whereas intake of eggs and high-fat dairy were associated with greater HF risk after adjustment for several confounders.",success
25303709,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Prospective data examining the relationship between dietary protein intake and incident coronary heart disease (CHD) are inconclusive. Most evidence is derived from homogenous populations such as health professionals. Large community-based analyses in more diverse samples are lacking. We studied the association of protein type and major dietary protein sources and risk for incident CHD in 12,066 middle-aged adults (aged 45-64 at baseline, 1987-1989) from four U.S. communities enrolled in the Atherosclerosis Risk in Communities (ARIC) Study who were free of diabetes mellitus and cardiovascular disease at baseline. Dietary protein intake was assessed at baseline and after 6 years of follow-up by food frequency questionnaire. Our primary outcome was adjudicated coronary heart disease events or deaths with following up through December 31, 2010. Cox proportional hazard models with multivariable adjustment were used for statistical analyses. During a median follow-up of 22 years, there were 1,147 CHD events. In multivariable analyses total, animal and vegetable protein were not associated with an increased risk for CHD before or after adjustment. In food group analyses of major dietary protein sources, protein intake from red and processed meat, dairy products, fish, nuts, eggs, and legumes were not significantly associated with CHD risk. The hazard ratios [with 95% confidence intervals] for risk of CHD across quintiles of protein from poultry were 1.00 [ref], 0.83 [0.70-0.99], 0.93 [0.75-1.15], 0.88 [0.73-1.06], 0.79 [0.64-0.98], P for trend  = 0.16). Replacement analyses evaluating the association of substituting one source of dietary protein for another or of decreasing protein intake at the expense of carbohydrates or total fats did not show any statistically significant association with CHD risk. Based on a large community cohort we found no overall relationship between protein type and major dietary protein sources and risk for CHD.",success
26399866,False,"Journal Article;Observational Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"Some studies have found that egg consumption is associated with a higher risk of ischemic heart disease in patients with diabetes. Epidemiologic studies of egg consumption in relation to risk of heart failure (HF) and stroke types are scarce. The aim of this study was to examine whether egg consumption is associated with incidence of HF, myocardial infarction (MI), or stroke types. In prospective cohorts of 37,766 men (Cohort of Swedish Men) and 32,805 women (Swedish Mammography Cohort) who were free of cardiovascular disease (CVD), egg consumption was assessed at baseline with a food-frequency questionnaire. Incident CVD cases were identified through linkage with the Swedish National Patient and Cause of Death Registers. The data were analyzed with the use of a Cox proportional hazards regression model. During 13 y of follow-up, we ascertained 1628 HFs, 3262 MIs, 2039 ischemic strokes, and 405 hemorrhagic strokes in men and 1207 HFs, 1504 MIs, 1561 ischemic strokes, and 294 hemorrhagic strokes in women. There was no statistically significant association between egg consumption and risk of MI or any stroke type in either men or women or HF in women. In men, consumption of ≤6 eggs/wk was not associated with HF risk; however, daily egg consumption (≥1/d) was associated with a 30% higher risk of HF (RR: 1.30; 95% CI: 1.01, 1.67). Egg consumption was not associated with any CVD outcome in individuals with diabetes. Daily egg consumption was not associated with risk of MI or any stroke type in either men or women or with HF in women. Consumption of eggs ≥1 time/d, but not less frequent consumption, was associated with an elevated risk of HF in men.",success
28109460,False,Comparative Study;Journal Article,,,,,,,,True,"Dietary protein comes from foods with greatly different compositions that may not relate equally with mortality risk. Few cohort studies from non-Western countries have examined the association between various dietary protein sources and cause-specific mortality. Therefore, the associations between dietary protein sources and all-cause, cardiovascular disease, and cancer mortality were evaluated in the Golestan Cohort Study in Iran. Among 42,403 men and women who completed a dietary questionnaire at baseline, 3,291 deaths were documented during 11 years of follow up (2004-2015). Cox proportional hazards models estimated age-adjusted and multivariate-adjusted hazard ratios (HRs) and 95% CIs for all-cause and disease-specific mortality in relation to dietary protein sources. Data were analyzed from 2015 to 2016. Comparing the highest versus the lowest quartile, egg consumption was associated with lower all-cause mortality risk (HR=0.88, 95% CI=0.79, 0.97, p<sub>trend</sub>=0.03). In multivariate analysis, the highest versus the lowest quartile of fish consumption was associated with reduced risk of total cancer (HR=0.79, 95% CI=0.64, 0.98, p<sub>trend</sub>=0.03) and gastrointestinal cancer (HR=0.75, 95% CI=0.56, 1.00, p<sub>trend</sub>=0.02) mortality. The highest versus the lowest quintile of legume consumption was associated with reduced total cancer (HR=0.72, 95% CI=0.58, 0.89, p<sub>trend</sub>=0.004), gastrointestinal cancer (HR=0.76, 95% CI=0.58, 1.01, p<sub>trend</sub>=0.05), and other cancer (HR=0.66, 95% CI=0.47, 0.93, p<sub>trend</sub>=0.04) mortality. Significant associations between total red meat and poultry intake and all-cause, cardiovascular disease, or cancer mortality rate were not observed among all participants. These findings support an association of higher fish and legume consumption with lower cancer mortality, and higher egg consumption with lower all-cause mortality.",success
29288244,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Egg intake was associated with serum total cholesterol adjusted for age (aTCH) and total mortality in women, but not in men, using data from NIPPON DATA (ND) 80 which followed up for 14 years. Re-evaluation of these associations in a different cohort is needed. We analyzed the associations of egg intake with aTCH and cause-specific and total mortality using the ND90 data set with a 15-year follow-up. A nutritional examination was done at the baseline in 1990 using the food-frequency method and by weighed food records. We followed 4686 female participants (ages ≥30 years), with no history of stroke or myocardial infarction (mean age 52.8 years) for 15 years. The participants were divided into 5 egg intake groups (<1/w, 1-2/w, 1/2d, 1/d, and ≥2/d). There were 203, 1462, 1594, 1387, and 40 women in each group, respectively. Egg intake was not associated with aTCH (P = 0.886). There were 183 cardiovascular disease (CVD), 210 cancer, and 599 total mortality cases during follow-up. Cox analysis, adjusted for background factors, found egg intake was directly associated with total and cancer mortality (HR in the ≥2/d vs. the 1 egg/d group: total, 2.05 (95% CI: 1.20-3.52); cancer, 3.20 (1.51-6.76)), and that cancer mortality in the 1-2/w group was significantly less than that in the 1 egg/d group (0.68 (0.47-0.97)). Egg intake was not associated with CVD mortality. Egg intake was associated with cancer and total mortality. Reducing egg intake may have some definitive health benefits in women in Japan, at least.",success
27448949,False,Journal Article,,,ISRCTN35739639,,,,,True,"Eggs are a major source of dietary cholesterol and their consumption has been sometimes discouraged. A relationship between egg consumption and the incidence of cardiovascular disease (CVD) has been suggested to be present exclusively among patients with type2 diabetes. To assess the association between egg consumption and CVD in a large Mediterranean cohort where approximately 50% of participants had type 2 diabetes. We prospectively followed 7216 participants (55-80 years old) at high cardiovascular risk from the PREDIMED (PREvención con DIeta MEDiterránea) study for a mean of 5.8 years. All participants were initially free of CVD. Yearly repeated measurements of dietary information with a validated 137-item food-frequency questionnaire were used to assess egg consumption and other dietary exposures. The endpoint was the rate of major cardiovascular events (myocardial infarction, stroke or death from cardiovascular causes). A major cardiovascular event occurred in 342 participants. Baseline egg consumption was not significantly associated with cardiovascular events in the total population. Non-diabetic participants who ate on average >4 eggs/week had a hazard ratio (HR) of 0.96 (95% confidence interval, 0.33-2.76) in the fully adjusted multivariable model when compared with non-diabetic participants who reported the lowest egg consumption (<2 eggs/week). Among diabetic participants, the HR was 1.33 (0.72-2.46). There was no evidence of interaction by diabetic status. HRs per 500 eggs of cumulative consumption during follow-up were 0.94 (0.66-1.33) in non-diabetics and 1.18 (0.90-1.55) in diabetics. Low to moderated egg consumption was not associated with an increased CVD risk in diabetic or non-diabetic individuals at high cardiovascular risk. This trial was registered at controlled-trials.com as ISRCTN35739639.",success
26864369,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"In general populations, the effects of dietary cholesterol on blood cholesterol concentrations are modest. However, the relation is stronger in those with an ɛ4 allele in the apolipoprotein E gene (APOE). There is little information on the association between cholesterol intake and the risk of coronary artery disease (CAD) among those with the ApoE4 phenotype. We investigated the associations of intakes of cholesterol and eggs, a major source of dietary cholesterol, with carotid intima-media thickness and the risk of incident CAD in middle-aged and older men from eastern Finland. The study included 1032 men aged 42-60 y in 1984-1989 at the baseline examinations of the prospective, population-based Kuopio Ischaemic Heart Disease Risk Factor Study. Data on common carotid artery intima-media thickness (CCA-IMT) were available for 846 men. Dietary intakes were assessed with 4-d food records. Associations with incident CAD and baseline CCA-IMT were analyzed by using Cox regression and ANCOVA, respectively. The ApoE4 phenotype was found in 32.5% of the men. During the average follow-up of 20.8 y, 230 CAD events occurred. Egg or cholesterol intakes were not associated with the risk of CAD. Each 1 additional egg (55 g)/d was associated with a multivariable-adjusted HR of 1.17 (95% CI: 0.85, 1.61) in the ApoE4 noncarriers and an HR of 0.93 (95% CI: 0.50, 1.72) in the ApoE4 carriers (P-interaction = 0.34). Each 100-mg/d higher cholesterol intake was associated with an HR of 1.04 (95% CI: 0.89, 1.22) in the ApoE4 noncarriers and an HR of 0.95 (95% CI: 0.73, 1.25) in the ApoE4 carriers (P-interaction = 0.81). Egg or cholesterol intakes were also not associated with increased CCA-IMT. Egg or cholesterol intakes were not associated with increased CAD risk, even in ApoE4 carriers (i.e., in highly susceptible individuals).",success
21427738,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Egg consumption has been associated with the risk of cardiovascular diseases (CVDs), but evidence is scarce and inconsistent. Our aim was to examine the association between egg consumption and incidence of CVD in a prospective dynamic Mediterranean cohort of 14,185 university graduates. Egg intake was assessed using a 136-item-validated food-frequency questionnaire. Baseline consumption was categorized into no consumption or <1 egg/week, 1 egg/week, 2-4 eggs/week and >4 eggs/week. The presence of cardiovascular risk factors was assessed by questionnaire at baseline, and the incidence of CVD was assessed using biennial assessments. The median follow-up was 6.1 years. Cox regression models were fitted to estimate multivariable-adjusted hazard ratios (HRs) for CVD (myocardial infarction, revascularization procedures or stroke). Outcomes were confirmed by review of medical records. During a median follow-up of 6.1 years, 91 new confirmed cases of CVD were observed. No association was found between egg consumption and the incidence of CVD (HR: 1.10, 95% confidence interval: 0.46-2.63) for the highest versus the lowest category of egg consumption after adjusting for age, sex, total energy intake, adherence to the Mediterranean food pattern and other cardiovascular risk factors. Results were robust to different analytical scenarios. No association between egg consumption and the incidence of CVD was found in this Mediterranean cohort.",success
23880191,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"To verify the association between egg consumption and coronary atherosclerotic burden. Observational study. Cardiac catheterization laboratory. Adult patients referred for coronary angiography. Socio-demographic data (age, education level, and occupation), cardiovascular risk factors (smoking, systemic hypertension, dyslipidemia, diabetes, and family history of coronary artery disease), and egg-eating habits were assessed using a research questionnaire. Egg consumption was divided into three categories: less than one egg a week; one egg a week; and more than one egg a week. Coronary atherosclerotic burden was assessed by a blinded interventional cardiologist using the Friesinger Score (FS) obtained from the coronary angiography. This score varies from 0 to 15 and evaluated each of the three main coronary arteries separately. For this analysis, the FS was divided into three categories: 0-4, 5-9, and 10-15. The study sample was composed of 382 adult patients; 241 patients (63.3%) were male. The average age was 60.3 ± 10.8 years (range 23-89 years). The egg-eating category was inversely associated with dyslipidemia (p < 0.05) but not with the other cardiovascular risk factors. A significant association was found between egg consumption and FS (p < 0.05), showing that patients who ate more than one egg a week had a lower coronary atherosclerotic burden. By multivariate analysis, the atherosclerotic burden was independently associated with sex, age, hypertension and egg consumption. In this observational study of patients undergoing coronary angiography, the consumption of more than one egg per week was associated with a lower coronary atherosclerotic burden.",success
24887016,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"The evidence supporting recommendations to limit intake of cholesterol rich foods is inconclusive. We aimed to examine the association between egg consumption and carotid atherosclerosis phenotypes, and the association with clinical vascular events in a prospective, urban, multi-ethnic population. The Northern Manhattan Study is a population based cohort to determine stroke incidence, risk factors and prognosis. A sub-cohort of 1429 NOMAS participants with both carotid ultrasounds and comprehensive dietary information was evaluated (mean ± SD age of participants 65.80 ± 8.80, 40% male, 18% white, 20% black, 60% Hispanic). The association between egg consumption and carotid intima media thickness (cIMT) was assessed with linear regression. Logistic and quantile regression was used to examine the association between egg consumption and carotid plaque presence, thickness, and area. The relation between egg consumption and clinical vascular events (N = 2669) was examined with Cox models. The mean total cIMT was 0.91 ± 0.08 mm and 58% had carotid plaque present. Increasing egg consumption was inversely associated with cIMT, plaque presence, thickness, and area, in models adjusted for demographics, vascular risk factors and diet. For every additional egg consumed per week, the risk of plaque decreased by 11% (95% CI 3%-18%). No association was detected between egg consumption and risk of clinical vascular outcomes, over a mean follow up of 11 years and after adjustment for covariates. Frequency of egg consumption in the low to moderate range was inversely related to several markers of carotid atherosclerosis. No association with clinical vascular events, including stroke, was detected. Our findings do not support current vascular health guidelines suggesting the extreme limitation or avoidance of egg consumption due to its cholesterol content.",success
25642410,False,Journal Article,,,,,,,,True,"Eggs are a ubiquitous and important source of dietary cholesterol and nutrients, yet their relationship to coronary heart disease (CHD) remains unclear. While some data have suggested a positive association between egg consumption and CHD, especially among diabetic subjects, limited data exist on the influence of egg consumption on subclinical disease. Thus, we sought to examine whether egg consumption is associated with calcified atherosclerotic plaques in the coronary arteries. In a cross-sectional design, we studied 1848 participants of the NHLBI Family Heart Study without known CHD. Egg consumption was assessed by a semi-quantitative food frequency questionnaire and coronary-artery calcium (CAC) was measured by cardiac CT. We defined prevalent CAC using an Agatston score of at least 100 and fitted generalized estimating equations to calculate prevalence odds ratios of CAC. Mean age was 56.5 years and 41% were male. Median consumption of eggs was 1/week. There was no association between frequency of egg consumption and prevalent CAC. Odds ratios (95% CI) for CAC were 1.0 (reference), 0.95 (0.66-1.38), 0.94 (0.63-1.40), and 0.90 (0.57-1.42) for egg consumption of almost never, 1-3 times per month, once per week, and 2+ times per week, respectively (p for trend 0.66), adjusting for age, sex, BMI, smoking, alcohol, physical activity, income, field center, total calories, and bacon. Additional control for hypertension and diabetes mellitus, or restricting the analysis to subjects with diabetes mellitus or fasting glucose >126 mg/dL did not alter the findings. These data do not provide evidence for an association between egg consumption and prevalent CAC in adult men and women.",success
26062990,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"The association of egg consumption with subclinical coronary atherosclerosis remains unknown. Our aim was to examine the association between egg consumption and prevalence of coronary artery calcium (CAC). Cross-sectional study of 23,417 asymptomatic adult men and women without a history of cardiovascular disease (CVD) or hypercholesterolemia, who underwent a health screening examination including cardiac computed tomography for CAC scoring and completed a validated food frequency questionnaire at the Kangbuk Samsung Hospital Total Healthcare Centers, South Korea (March 2011-April 2013). The prevalence of detectable CAC (CAC score > 0) was 11.2%. In multivariable-adjusted models, CAC score ratio (95% confidence interval [CI]) comparing participants eating ≥ 7 eggs/wk to those eating < 1 egg/wk was 1.80 (1.14-2.83; P for trend = 0.003). The multivariable CAC score ratio (95% CI) associated with an increase in consumption of 1 egg/day was 1.54 (1.11-2.14). The positive association seemed to be more pronounced among participants with low vegetable intake (P for interaction = 0.02) and those with high BMI (P for interaction = 0.05). The association was attenuated and no longer significant after further adjustment for dietary cholesterol. Egg consumption was associated with an increased prevalence of subclinical coronary atherosclerosis and with a greater degree of coronary calcification in asymptomatic Korean adults, which may be mediated by dietary cholesterol. The association was particularly pronounced among individuals with low vegetable intake and those with high BMI.",success
30874756,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Cholesterol is a common nutrient in the human diet and eggs are a major source of dietary cholesterol. Whether dietary cholesterol or egg consumption is associated with cardiovascular disease (CVD) and mortality remains controversial. To determine the associations of dietary cholesterol or egg consumption with incident CVD and all-cause mortality. Individual participant data were pooled from 6 prospective US cohorts using data collected between March 25, 1985, and August 31, 2016. Self-reported diet data were harmonized using a standardized protocol. Dietary cholesterol (mg/day) or egg consumption (number/day). Hazard ratio (HR) and absolute risk difference (ARD) over the entire follow-up for incident CVD (composite of fatal and nonfatal coronary heart disease, stroke, heart failure, and other CVD deaths) and all-cause mortality, adjusting for demographic, socioeconomic, and behavioral factors. This analysis included 29 615 participants (mean [SD] age, 51.6 [13.5] years at baseline) of whom 13 299 (44.9%) were men and 9204 (31.1%) were black. During a median follow-up of 17.5 years (interquartile range, 13.0-21.7; maximum, 31.3), there were 5400 incident CVD events and 6132 all-cause deaths. The associations of dietary cholesterol or egg consumption with incident CVD and all-cause mortality were monotonic (all P values for nonlinear terms, .19-.83). Each additional 300 mg of dietary cholesterol consumed per day was significantly associated with higher risk of incident CVD (adjusted HR, 1.17 [95% CI, 1.09-1.26]; adjusted ARD, 3.24% [95% CI, 1.39%-5.08%]) and all-cause mortality (adjusted HR, 1.18 [95% CI, 1.10-1.26]; adjusted ARD, 4.43% [95% CI, 2.51%-6.36%]). Each additional half an egg consumed per day was significantly associated with higher risk of incident CVD (adjusted HR, 1.06 [95% CI, 1.03-1.10]; adjusted ARD, 1.11% [95% CI, 0.32%-1.89%]) and all-cause mortality (adjusted HR, 1.08 [95% CI, 1.04-1.11]; adjusted ARD, 1.93% [95% CI, 1.10%-2.76%]). The associations between egg consumption and incident CVD (adjusted HR, 0.99 [95% CI, 0.93-1.05]; adjusted ARD, -0.47% [95% CI, -1.83% to 0.88%]) and all-cause mortality (adjusted HR, 1.03 [95% CI, 0.97-1.09]; adjusted ARD, 0.71% [95% CI, -0.85% to 2.28%]) were no longer significant after adjusting for dietary cholesterol consumption. Among US adults, higher consumption of dietary cholesterol or eggs was significantly associated with higher risk of incident CVD and all-cause mortality in a dose-response manner. These results should be considered in the development of dietary guidelines and updates.",success
31006335,True,"Journal Article;Multicenter Study;Observational Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"There is uncertainty about the relevance of animal foods to the pathogenesis of ischemic heart disease (IHD). We examined meat, fish, dairy products, and eggs and risk for IHD in the pan-European EPIC cohort (European Prospective Investigation Into Cancer and Nutrition). In this prospective study of 409 885 men and women in 9 European countries, diet was assessed with validated questionnaires and calibrated with 24-hour recalls. Lipids and blood pressure were measured in a subsample. During a mean of 12.6 years of follow-up, 7198 participants had a myocardial infarction or died of IHD. The relationships of animal foods with risk were examined with Cox regression with adjustment for other animal foods and relevant covariates. The hazard ratio (HR) for IHD was 1.19 (95% CI, 1.06-1.33) for a 100-g/d increment in intake of red and processed meat, and this remained significant after exclusion of the first 4 years of follow-up (HR, 1.25 [95% CI, 1.09-1.42]). Risk was inversely associated with intakes of yogurt (HR, 0.93 [95% CI, 0.89-0.98] per 100-g/d increment), cheese (HR, 0.92 [95% CI, 0.86-0.98] per 30-g/d increment), and eggs (HR, 0.93 [95% CI, 0.88-0.99] per 20-g/d increment); the associations with yogurt and eggs were attenuated and nonsignificant after exclusion of the first 4 years of follow-up. Risk was not significantly associated with intakes of poultry, fish, or milk. In analyses modeling dietary substitutions, replacement of 100 kcal/d from red and processed meat with 100 kcal/d from fatty fish, yogurt, cheese, or eggs was associated with ≈20% lower risk of IHD. Consumption of red and processed meat was positively associated with serum non-high-density lipoprotein cholesterol concentration and systolic blood pressure, and consumption of cheese was inversely associated with serum non-high-density lipoprotein cholesterol. Risk for IHD was positively associated with consumption of red and processed meat and inversely associated with consumption of yogurt, cheese, and eggs, although the associations with yogurt and eggs may be influenced by reverse causation bias. It is not clear whether the associations with red and processed meat and cheese reflect causality, but they were consistent with the associations of these foods with plasma non-high-density lipoprotein cholesterol and for red and processed meat with systolic blood pressure, which could mediate such effects.",success
30596814,False,"Journal Article;Meta-Analysis;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"Elevated low-density lipoprotein (LDL) cholesterol is a major risk factor for cardiovascular disease. Dietary guidance recommends reducing saturated fatty acid, trans fatty acid, and cholesterol intakes to reduce circulating LDL cholesterol. Cholesterol intake may also affect high-density lipoprotein (HDL)-cholesterol concentrations, but its impact has not been fully quantified. The aims of this study were to investigate the dose-response relation between changes in dietary cholesterol intake and changes in lipoprotein-cholesterol markers for cardiovascular disease risk and to provide a reference for clinicians on how changes in dietary cholesterol intake affect circulating cholesterol concentrations, after accounting for intakes of fatty acids. We used a Bayesian approach to meta-regression analysis, which uses Markov chain Monte Carlo techniques, to assess the relation between the change in dietary cholesterol (adjusted for dietary fatty acids) and changes in LDL and HDL cholesterol based on the use of data from randomized dietary intervention trials. Fifty-five studies (2652 subjects) were included in the analysis. The nonlinear Michaelis-Menten (MM) and Hill models best described the data across the full spectrum of dietary cholesterol changes studied (0-1500 mg/d). Mean predicted changes in LDL cholesterol for an increase of 100 mg dietary cholesterol/d were 1.90, 4.46, and 4.58 mg/dL for the linear, nonlinear MM, and Hill models, respectively. The change in dietary cholesterol was positively associated with the change in LDL-cholesterol concentration. The linear and MM models indicate that the change in dietary cholesterol is modestly inversely related to the change in circulating HDL-cholesterol concentrations in men but is positively related in women. The clinical implications of HDL-cholesterol changes associated with dietary cholesterol remain uncertain.",success
12716665,False,"Journal Article;Meta-Analysis;Research Support, Non-U.S. Gov't",,,,,,,,True,"The effects of dietary fats on the risk of coronary artery disease (CAD) have traditionally been estimated from their effects on LDL cholesterol. Fats, however, also affect HDL cholesterol, and the ratio of total to HDL cholesterol is a more specific marker of CAD than is LDL cholesterol. The objective was to evaluate the effects of individual fatty acids on the ratis of total to HDL cholesterol and on serum lipoproteins. We performed a meta-analysis of 60 selected trials and calculated the effects of the amount and type of fat on total:HDL cholesterol and on other lipids. The ratio did not change if carbohydrates replaced saturated fatty acids, but it decreased if cis unsaturated fatty acids replaced saturated fatty acids. The effect on total:HDL cholesterol of replacing trans fatty acids with a mix of carbohydrates and cis unsaturated fatty acids was almost twice as large as that of replacing saturated fatty acids. Lauric acid greatly increased total cholesterol, but much of its effect was on HDL cholesterol. Consequently, oils rich in lauric acid decreased the ratio of total to HDL cholesterol. Myristic and palmitic acids had little effect on the ratio, and stearic acid reduced the ratio slightly. Replacing fats with carbohydrates increased fasting triacylglycerol concentrations. The effects of dietary fats on total:HDL cholesterol may differ markedly from their effects on LDL. The effects of fats on these risk markers should not in themselves be considered to reflect changes in risk but should be confirmed by prospective observational studies or clinical trials. By that standard, risk is reduced most effectively when trans fatty acids and saturated fatty acids are replaced with cis unsaturated fatty acids. The effects of carbohydrates and of lauric acid-rich fats on CAD risk remain uncertain.",success
3163364,True,"Clinical Trial;Controlled Clinical Trial;Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"In a controlled feeding situation, male subjects were assigned to one of four treatment groups: low fat (31% of total kcal)/low cholesterol (193 mg/d) (LFLC), low fat/usual cholesterol (504 mg/d) (LFUC), usual fat (46% of total kcal)/low cholesterol (UFLC) and usual fat/usual cholesterol (UFUC) intake. For the first 2 wk of the 10-wk study all subjects consumed the UFUC diet. Subjects consumed experimental diets during wk 3-7 and resumed their customary intake during wk 8-10. Plasma total, high-density-lipoprotein (HDL), low-density-lipoprotein and very-low-density-lipoprotein cholesterol and triglycerides were determined weekly. A significant effect (P less than 0.05) of dietary fat on plasma total and HDL cholesterol was observed between the end of wk 2 and 7. Low fat intake resulted in 17 +/- 2 mg/dL lower total cholesterol and 10 +/- 1 mg/dL lower HDL cholesterol than the usual fat intake. Plasma lipids were not affected either by dietary cholesterol or by any interaction of dietary fat with cholesterol.",success
7310532,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"The effect of changes in dietary cholesterol and fat on serum lipids was studied in 32 healthy men (mean age = 24.8 years). Subjects were fed a controlled diet for 10 days providing 42 to 45% of the total calories from fat, a P/S ratio of 0.3 to 0.5 and two eggs per day. During the next eight weeks, 16 subjects received each of the following diets for four weeks in a crossover design: 1) a control diet with two eggs per day or 2) the control diet with eggs replaced by a cholesterol-free egg substitute. The remaining 16 subjects received each of the following diets in a similar crossover design: 1) a modified-fat diet containing 35% of the total calories from fat, a P/S ratio greater than or equal to 1.0 and two eggs per day or 2) the same modified-fat diet with the egg substitute replacing the eggs. The two-week cycle of menus repeated throughout the study included a wide variety of foods commonly consumed in this country. Although the response of individual subjects varied, analysis of variance showed a significant decrease in serum total cholesterol related to replacement of eggs with the egg substitute and to modification in the type and amount of dietary fat. A significant diet-treatment interaction or sequencing effect was not found. Change in cholesterol intake related to addition or deletion of two eggs in the daily diet had no significant effect on serum triglycerides, high density lipoprotein cholesterol, or relative lipoprotein concentrations.",success
14201552,False,Journal Article,,,,,,,,False,,success
7860745,True,"Clinical Trial;Comparative Study;Controlled Clinical Trial;Journal Article;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"The individual effects of dietary cholesterol and fat saturation on plasma lipoprotein concentrations were determined in an ethnically diverse population of normolipidemic young men (52 Caucasian, 32 non-Caucasian). The experimental diets contained approximately 200 or 600 mg/d of cholesterol, 36-38% of calories as fat, and high or low proportions of saturated and polyunsaturated fat (polyunsaturated/saturated fat ratio approximately 0.8 vs 0.3). At the lower cholesterol intake, the high saturated fat diet had only a modest effect on LDL cholesterol in Caucasians (+ 6 mg/dl-1) and none in non-Caucasians. 600 mg cholesterol with high saturated fat led to a substantial mean increase in LDL cholesterol, which was significantly greater in Caucasian than in non-Caucasian subjects (+ 31 mg/dl vs 16 mg/dl, P < 0.005). 600 mg cholesterol with increased polyunsaturated fat gave a mean LDL increase of 16 mg/dl, lower than found when the same high cholesterol intake was coupled with increased saturated fat. Variation in cholesterol rather than the proportions of saturated and polyunsaturated fat had the most influence on LDL-cholesterol levels. Among non-Caucasians it was the only significant factor.",success
6940435,True,"Clinical Trial;Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",,,,,,,,True,"Twenty-three young adult males were fed diets containing either 400 or 1400 mg of cholesterol per day under controlled conditions for 4 wk. There were minimal differences between the two diets in total protein, carbohydrate, fat, and the P/S fatty acid ratio. In both diets 400 mg of cholesterol was supplied from nonegg food sources; the additional 1000 mg of cholesterol was from four whole eggs. Blood samples were collected after a 12- to 14-h fast at the beginning of the study, weekly throughout the experimental period, and 1 wk after completion of the study. Plasma total cholesterol and triglycerides and high-density, low-density, and very low-density lipoprotein cholesterol levels were measured. No significant differences in plasma total cholesterol, triglycerides, and lipoprotein cholesterol levels were observed between groups at any time. However, plasma cholesterol and cholesterol content of individual lipoproteins varied considerably among the individual subjects fed the high cholesterol diet. The importance of changes in the properties and metabolic activity of individual lipoproteins induced by dietary cholesterol with or without gross changes in the cholesterol levels remains to be determined.",success
7749822,True,"Clinical Trial;Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"We studied the effects of dietary cholesterol intake on lipid and lipoprotein levels in healthy young women (n = 13) who were otherwise eating an American Heart Association (AHA) diet. The study used a randomized, three-way crossover design to determine the effects of 0, 1, or 3 eggs added per day (dietary cholesterol range, 108 to 667 mg/d). Each of the three diets was eaten for 8 weeks, with a washout period between diets. Three fasting blood samples were obtained during the last 3 weeks of each diet period to observe changes in fasting plasma lipid levels associated with the menstrual cycle. We also obtained blood just before and 4 and 8 hours after the subjects ingested a standard high-fat formula. During the menstrual cycle, total cholesterol and LDL cholesterol levels fell by 0.051 mmol/L (1.99 mg/dL) and 0.064 mmol/L (2.48 mg/dL) per week, respectively. HDL cholesterol concentrations increased by 0.060 mmol/L (2.3 mg/dL) per week during the first half of the cycle and then fell by 0.050 mmol/L (1.94 mg/dL) per week during the second half. Therefore, all statistical analyses were performed on values adjusted to midcycle. Total fasting cholesterol concentrations increased by 0.073 mmol/L (2.81 mg/dL) per 100 mg dietary cholesterol added to the diet per day (P = .001). LDL cholesterol increased by 0.054 mmol/L (2.08 mg/dL) per 100 mg/d dietary cholesterol (P = .003); this accounted for about 75% of the rise in total cholesterol. HDL cholesterol concentrations increased by 0.015 mmol/L (0.57 mg/dL) per 100 mg/d dietary cholesterol (P < .04). There was a wide range of responses among the women. Plasma apoB levels increased significantly, 0.93 mg/dL per 100 mg/d dietary cholesterol (P = .025), whereas apoA-I levels tended to rise (1.35 mg/dL per 100 mg/d, P = .056). Increases in dietary cholesterol did not produce any observable effects on fasting plasma cholesteryl ester transfer protein levels and had no effect on the response to a standard high-fat formula. Although menstrual-cycle changes in plasma total, LDL, and HDL cholesterol levels were observed, the effects of the diets were similar in the follicular and luteal phases of the menstrual cycle. Additionally, despite changes associated with the menstrual cycle, within-subject variation in plasma total cholesterol was actually smaller in this study than in our study of young men.",success
8148356,True,"Clinical Trial;Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Despite many previous studies, controversy remains concerning the effects of dietary cholesterol on plasma cholesterol concentrations. In addition, the focus of previous studies has been fasting lipid and lipoprotein concentrations; there are no published studies with postprandial measurements. We studied the effects of four levels of dietary cholesterol intake on fasting lipid, lipoprotein, and apoprotein levels, as well as postprandial lipid levels, in a group of young, healthy men who were otherwise eating a low-fat, American Heart Association step 1 diet. Twenty young, healthy men completed a randomized, four-way crossover design study to test the effects of an American Heart Association step 1 diet containing 0, 1, 2, or 4 eggs per day. Dietary cholesterol ranged from 128 to 858 mg cholesterol per day. Each diet was eaten for 8 weeks, with a break between diets. Three fasting blood samples were obtained at the end of each diet period. In addition, blood samples were obtained just before and 2, 4, and 6 hours after ingestion of a standard lunch containing the various amounts of egg cholesterol. We also obtained blood 4 and 8 hours after the subjects ingested a standard, high-fat formula. Fasting plasma total cholesterol concentrations increased by 1.47 mg/dL (0.038 mmol/L) for every 100 mg dietary cholesterol added to the diet (P < .001). Low-density lipoprotein (LDL) cholesterol increased in parallel. Responsiveness varied but appeared to be normally distributed. Fasting plasma apoprotein B concentrations increased approximately 10% between the 0- and 4-egg diets and were correlated with changes in total and LDL cholesterol concentrations. Although there was a trend toward a greater response in men with an apoprotein E4 allele, this was not statistically significant. Fasting plasma cholesteryl ester transfer protein levels were higher only on the 4-egg diet, and changes in cholesteryl ester transfer protein levels between the 0- and 4-egg diets correlated with changes in total and LDL cholesterol. There were no differences in the postlunch or post-fat-formula responses of plasma lipids across the diets. Incubation of the 4-hour postlunch serum with J774 macrophages did not affect cell cholesteryl ester content at any level of dietary cholesterol. Cellular free cholesterol levels were slightly higher on each of the egg-containing diets versus the 0-egg diet. In summary, increases in dietary cholesterol resulted in linear increases in fasting total and LDL cholesterol in young, healthy men.(ABSTRACT TRUNCATED AT 400 WORDS)",success
6650444,True,"Clinical Trial;Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",,,,,,,,True,"The plasma total cholesterol (TC) and lipoprotein cholesterol concentrations of sedentary young men (n = 23) were determined during 4 wk of controlled feeding and 6 wk of supervised aerobic conditioning. Subjects were assigned to dietary treatments of 400 mg cholesterol per day (M) or 1400 mg cholesterol per day (H); both diets had a P/S ratio of about 0.6. Dietary groups M and H were subdivided into exercise (MX and HX) and sedentary (MS and HS) groups. Compared to the sedentary groups, MX and HX exhibited significant (p less than 0.01) improvements in cardiorespiratory fitness. After 2 and 4 wk of high cholesterol feeding, group HS exhibited significant (p less than 0.05) elevations in TC (+30 +/- 7 and +32 +/- 9 mg/dl) with nonsignificant increases in very low-density lipoprotein cholesterol and low-density lipoprotein cholesterol. Group HX exhibited consistent weekly increases in high-density lipoprotein cholesterol (HDL-C) (from 46 +/- 3 mg/dl, the base level, to 53 +/- 4 mg/dl at wk 4) with aerobic conditioning. By combining exercise and sedentary group data at each level of dietary cholesterol it was shown that TC and HDL-C levels significantly (p less than 0.05) increased by the 4th wk of high cholesterol feeding. The TC/HDL-C ratio significantly (p less than 0.05) increased for the sedentary subjects as compared to all the exercising subjects by wk 4 of controlled feeding.",success
11319723,True,"Clinical Trial;Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Questions remain concerning the effect of variations in cholesterol intake on plasma cholesterol concentration, as well as on the role of factors modulating the metabolic impact of this dietary intervention. To define the impact of wide variations in dietary cholesterol intake on plasma total and low-density lipoprotein (LDL) cholesterol concentrations, as well as testing the hypothesis that resistance to insulin-mediated glucose disposal would accentuate the increase in plasma total and LDL cholesterol concentrations in response to a given increment in dietary cholesterol intake, we performed a prospective, randomized study comparing diets varying in cholesterol content in 65 healthy, postmenopausal women, 31 defined as insulin-resistant and 34 as insulin-sensitive. The changes in total and LDL cholesterol in response to increments in dietary cholesterol of up to approximately 800 mg/day were modest in magnitude, without evidence of a statistically significant diet-induced increase in cholesterol concentration, or of any difference in the responses of insulin-resistant as compared with insulin-sensitive women. These results indicate that relatively large increments in dietary cholesterol intake had little effect on total or LDL cholesterol concentrations in healthy, postmenopausal women, irrespective of whether they were insulin-resistant or insulin-sensitive.",success
16002815,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Endothelial dysfunction is one of the mechanisms linked to an increased risk of cardiovascular disease. We assessed the association between several diet-quality scores and plasma concentrations of markers of inflammation and endothelial dysfunction. Diet-quality scores on the Healthy Eating Index (HEI), Alternate Healthy Eating Index (AHEI), Diet Quality Index Revised (DQI-R), Recommended Food Score (RFS), and the alternate Mediterranean Diet Index (aMED) were calculated by using a food-frequency questionnaire that was administered in 1990 to 690 women in the Nurses' Health Study (ages 43-69 y, no cardiovascular disease or diabetes). Blood collection was completed in the same year. We used regression analysis to assess the associations between these diet-quality scores and plasma concentrations of C-reactive protein, interleukin 6, E-selectin, soluble intercellular cell adhesion molecule 1, and soluble vascular cell adhesion molecule 1. The various diet-quality scores were significantly correlated with each other; correlation coefficients ranged from 0.56 to 0.80 (all P values < 0.0001). After adjustment for age, body mass index, alcohol intake, physical activity, smoking status, and energy intake, the HEI and DQI-R were not significantly associated with any of the biomarkers, whereas the AHEI and aMED scores were associated with significantly lower concentrations of most biomarkers. The RFS was significantly associated with a lower concentration of E-selectin only. C-reactive protein concentrations were 30% (P < 0.05) and 24% (P < 0.05) lower in the top than in the bottom quintile of the AHEI and of the aMED, respectively Higher AHEI and aMED scores were associated with lower concentrations of biomarkers of inflammation and endothelial dysfunction and therefore may be useful as guidelines for reducing the risk of diseases involving such biological pathways.",success
9099655,True,"Clinical Trial;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"It is known that obesity, sodium intake, and alcohol consumption factors influence blood pressure. In this clinical trial, Dietary Approaches to Stop Hypertension, we assessed the effects of dietary patterns on blood pressure. We enrolled 459 adults with systolic blood pressures of less than 160 mm Hg and diastolic blood pressures of 80 to 95 mm Hg. For three weeks, the subjects were fed a control diet that was low in fruits, vegetables, and dairy products, with a fat content typical of the average diet in the United States. They were then randomly assigned to receive for eight weeks the control diet, a diet rich in fruits and vegetables, or a ""combination"" diet rich in fruits, vegetables, and low-fat dairy products and with reduced saturated and total fat. Sodium intake and body weight were maintained at constant levels. At base line, the mean (+/-SD) systolic and diastolic blood pressures were 131.3+/-10.8 mm Hg and 84.7+/-4.7 mm Hg, respectively. The combination diet reduced systolic and diastolic blood pressure by 5.5 and 3.0 mm Hg more, respectively, than the control diet (P<0.001 for each); the fruits-and-vegetables diet reduced systolic blood pressure by 2.8 mm Hg more (P<0.001) and diastolic blood pressure by 1.1 mm Hg more than the control diet (P=0.07). Among the 133 subjects with hypertension (systolic pressure, > or =140 mm Hg; diastolic pressure, > or =90 mm Hg; or both), the combination diet reduced systolic and diastolic blood pressure by 11.4 and 5.5 mm Hg more, respectively, than the control diet (P<0.001 for each); among the 326 subjects without hypertension, the corresponding reductions were 3.5 mm Hg (P<0.001) and 2.1 mm Hg (P=0.003). A diet rich in fruits, vegetables, and low-fat dairy foods and with reduced saturated and total fat can substantially lower blood pressure. This diet offers an additional nutritional approach to preventing and treating hypertension.",success
28408026,False,Journal Article;Review,,,,,,,,True,"Cardiovascular disease (CVD) presents a great burden for elderly patients, their caregivers, and health systems. Structural and functional alterations of vessels accumulate throughout life, culminating in increased risk of developing CVD. The growing elderly population worldwide highlights the need to understand how aging promotes CVD in order to develop new strategies to confront this challenge. This review provides examples of some major unresolved clinical problems encountered in daily cardiovascular practice as we care for elderly patients. Next, the authors summarize the current understanding of the mechanisms implicated in cardiovascular aging, and the potential for targeting novel pathways implicated in endothelial dysfunction, mitochondrial oxidative stress, chromatin remodeling, and genomic instability. Lastly, the authors consider critical aspects of vascular repair, including autologous transplantation of bone marrow-derived stem cells in elderly patients.",success
26673558,False,Journal Article,,,,,,,,False,,success
23746838,False,"Journal Article;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"Aging is characterized by a progressive loss of physiological integrity, leading to impaired function and increased vulnerability to death. This deterioration is the primary risk factor for major human pathologies, including cancer, diabetes, cardiovascular disorders, and neurodegenerative diseases. Aging research has experienced an unprecedented advance over recent years, particularly with the discovery that the rate of aging is controlled, at least to some extent, by genetic pathways and biochemical processes conserved in evolution. This Review enumerates nine tentative hallmarks that represent common denominators of aging in different organisms, with special emphasis on mammalian aging. These hallmarks are: genomic instability, telomere attrition, epigenetic alterations, loss of proteostasis, deregulated nutrient sensing, mitochondrial dysfunction, cellular senescence, stem cell exhaustion, and altered intercellular communication. A major challenge is to dissect the interconnectedness between the candidate hallmarks and their relative contributions to aging, with the final goal of identifying pharmaceutical targets to improve human health during aging, with minimal side effects.",success
12806071,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"This paper develops a method for appraising health status in elderly people. A frailty index was defined as the proportion of accumulated deficits (symptoms, signs, functional impairments, and laboratory abnormalities). It serves as an individual state variable, reflecting severity of illness and proximity to death. In a representative database of elderly Canadians we found that deficits accumulated at 3% per year, and show a gamma distribution, typical for systems with redundant components that can be used in case of failure of a given subsystem. Of note, the slope of the index is insensitive to the individual nature of the deficits, and serves as an important prognostic factor for life expectancy. The formula for estimating an individual's life span given the frailty index value is presented. For different patterns of cognitive impairments the average within-group index value increases with the severity of the cognitive impairment, and the relative variability of the index is significantly reduced. Finally, the statistical distribution of the frailty index sharply differs between well groups (gamma distribution) and morbid groups (normal distribution). This pattern reflects an increase in uncompensated deficits in impaired organisms, which would lead to illness of various etiologies, and ultimately to increased mortality. The accumulation of deficits is as an example of a macroscopic variable, i.e., one that reflects general properties of aging at the level of the whole organism rather than any given functional deficiency. In consequence, we propose that it may be used as a proxy measure of aging.",success
21527153,False,Journal Article,,,,,,,,False,,success
17493201,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"Geriatricians have embraced the term ""geriatric syndrome,"" using it extensively to highlight the unique features of common health conditions in older people. Geriatric syndromes, such as delirium, falls, incontinence, and frailty, are highly prevalent, multifactorial, and associated with substantial morbidity and poor outcomes. Nevertheless, this central geriatric concept has remained poorly defined. This article reviews criteria for defining geriatric syndromes and proposes a balanced approach of developing preliminary criteria based on peer-reviewed evidence. Based on a review of the literature, four shared risk factors-older age, baseline cognitive impairment, baseline functional impairment, and impaired mobility-were identified across five common geriatric syndromes (pressure ulcers, incontinence, falls, functional decline, and delirium). Understanding basic mechanisms involved in geriatric syndromes will be critical to advancing research and developing targeted therapeutic options, although given the complexity of these multifactorial conditions, attempts to define relevant mechanisms will need to incorporate more-complex models, including a focus on synergistic interactions between different risk factors. Finally, major barriers have been identified in translating research advances, such as preventive strategies of proven effectiveness for delirium and falls, into clinical practice and policy initiatives. National strategic initiatives are required to overcome barriers and to achieve clinical, research, and policy advances that will improve quality of life for older persons.",success
27067230,False,Journal Article,,,,,,,,True,"The incidence and prevalence of most cardiovascular disorders increase with age, and cardiovascular disease is the leading cause of death and major disability in adults ≥75 years of age; however, despite the large impact of cardiovascular disease on quality of life, morbidity, and mortality in older adults, patients aged ≥75 years have been markedly underrepresented in most major cardiovascular trials, and virtually all trials have excluded older patients with complex comorbidities, significant physical or cognitive disabilities, frailty, or residence in a nursing home or assisted living facility. As a result, current guidelines are unable to provide evidence-based recommendations for diagnosis and treatment of older patients typical of those encountered in routine clinical practice. The objectives of this scientific statement are to summarize current guideline recommendations as they apply to older adults, identify critical gaps in knowledge that preclude informed evidence-based decision making, and recommend future research to close existing knowledge gaps. To achieve these objectives, we conducted a detailed review of current American College of Cardiology/American Heart Association and American Stroke Association guidelines to identify content and recommendations that explicitly targeted older patients. We found that there is a pervasive lack of evidence to guide clinical decision making in older patients with cardiovascular disease, as well as a paucity of data on the impact of diagnostic and therapeutic interventions on key outcomes that are particularly important to older patients, such as quality of life, physical function, and maintenance of independence. Accordingly, there is a critical need for a multitude of large population-based studies and clinical trials that include a broad spectrum of older patients representative of those seen in clinical practice and that incorporate relevant outcomes important to older patients in the study design. The results of these studies will provide the foundation for future evidence-based guidelines applicable to older patients, thereby enhancing patient-centered evidence-based care of older people with cardiovascular disease in the United States and around the world.",success
29747836,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, Non-P.H.S.;Review",,,,,,,,True,"Multimorbidity occurs in adults of all ages, but the number and complexity of comorbid conditions commonly increase with advancing age such that cardiovascular disease (CVD) in older adults typically occurs in a context of multimorbidity. Current clinical practice and research mainly target single disease-specific care that does not embrace the complexities imposed by concurrent conditions. In this paper, emerging concepts regarding CVD in combination with multimorbidity are reviewed, including recommendations for incorporating multimorbidity into clinical decision making, critical knowledge gaps, and research priorities to optimize care of complex older patients.",success
29453307,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Review",,,,,,,,False,,success
17456647,False,"Comparative Study;Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"An accurate assessment of the prevalence of cognitive impairment in patients scheduled for coronary artery bypass graft (CABG) surgery is necessary if valid assumptions regarding cognitive change are to be made. Such an assessment requires the use of a healthy control group free of cardiovascular disease. In a retrospective observational study, 349 patients scheduled for CABG surgery underwent neuropsychological testing. We compared the results with those from a group of 170 healthy controls without cardiovascular disease and containing more female patients who were matched for age and IQ score. Cognitive impairment was defined as test scores > or =2 sd less than the controls on two or more of the seven tests. The CABG surgery patients performed significantly worse than the control group on all tests except the Grooved Pegboard test (nondominant). When analyzed by group, performance on the verbal learning test was the most impaired. Cognitive impairment was present in 122 (35%) of CABG surgery patients before their procedure. Prior myocardial infarction, age, and IQ were independent predictors of cognitive impairment. Cognitive impairment is prevalent in patients presenting for CABG surgery. Impaired cognition before surgery must be considered when assessing the effects of CABG surgery on cognitive performance.",success
23331439,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"Despite the fact that 80% of patients with heart failure are aged more than 65 years, recognition of cognitive impairment by physicians in this population has received relatively little attention. The current study evaluated physician documentation (as a measure of recognition) of cognitive impairment at the time of discharge in a cohort of older adults hospitalized for heart failure. We performed a prospective cohort study of older adults hospitalized with a primary diagnosis of heart failure. Cognitive status was evaluated with the Folstein Mini-Mental State Examination at the time of hospitalization. A score of 21 to 24 was used to indicate mild cognitive impairment, and a score of ≤20 was used to indicate moderate to severe impairment. To evaluate physician documentation of cognitive impairment, we used a standardized form with a targeted keyword strategy to review hospital discharge summaries. We calculated the proportion of patients with cognitive impairment documented as such by physicians and compared characteristics between groups with and without documented cognitive impairment. We then analyzed the association of cognitive impairment and documentation of cognitive impairment with 6-month mortality or readmission using Cox proportional hazards regression. A total of 282 patients completed the cognitive assessment. Their mean age was 80 years of age, 18.8% were nonwhite, and 53.2% were female. Cognitive impairment was present in 132 of 282 patients (46.8% overall; 25.2% mild, 21.6% moderate-severe). Among those with cognitive impairment, 30 of 132 (22.7%) were documented as such by physicians. Compared with patients whose cognitive impairment was documented by physicians, those whose impairment was not documented were younger (81.3 vs 85.2 years, P<.05) and had less severe impairment (median Mini-Mental State Examination score 22.0 vs 18.0, P<.01). After multivariable adjustment, patients whose cognitive impairment was not documented were significantly more likely to experience 6-month mortality or hospital readmission than patients without cognitive impairment. Cognitive impairment is common in older adults hospitalized for heart failure, yet it is frequently not documented by physicians. Implementation of strategies to improve recognition and documentation of cognitive impairment may improve the care of these patients, particularly at the time of hospital discharge.",success
26139023,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"Delirium and dementia are two of the most common causes of cognitive impairment in older populations, yet their interrelation remains poorly understood. Previous studies have shown that dementia is the leading risk factor for delirium and that delirium is an independent risk factor for subsequent development of dementia. However, a major area of controversy is whether delirium is simply a marker of vulnerability to dementia, whether the effect of delirium is solely related to its precipitating factors, or whether delirium itself can cause permanent neuronal damage and lead to dementia. Ultimately, all of these hypotheses are likely to be true. Emerging evidence from epidemiological, clinicopathological, neuroimaging, biomarker, and experimental studies lends support to a strong relation between delirium and dementia, and to both shared and distinct pathological mechanisms. New preventive and therapeutic approaches that target delirium might offer a sought-after opportunity for early intervention, preservation of cognitive reserve, and prevention of irreversible cognitive decline in ageing.",success
29064263,True,Journal Article;Multicenter Study;Observational Study,NCT02004665,databank,NCT02004665,NCT02004665,NCT02004665,NCT02004665|databank,NCT02004665|databank,True,"Delirium is a frequent in-hospital complication in elderly patients, and is associated with poor clinical outcome. Its clinical impact, however, has not yet been fully addressed in the setting of the cardiac intensive care unit (CICU). The present study is a prospective, two-centre registry aimed at assessing the incidence, prevalence and significance of delirium in elderly patients with acute cardiac diseases. Between January 2014 and March 2015, all consecutive patients aged 65 years or older admitted to the CICU of our institutions were enrolled and followed for 6 months. Delirium was defined according to the confusion assessment method. During the study period, 726 patients were screened for delirium. The mean age was 79.1±7.8 years. A total of 111 individuals (15.3%) were diagnosed with delirium; of them, 46 (41.4%) showed prevalent delirium (PD), while 65 (58.6%) developed incident delirium (ID). Patients 85 years or older showed a delirium rate of 52.3%. Hospital stay was longer in delirious versus non-delirious patients. Patients with delirium showed higher in-hospital, 30-day and 6-month mortality compared to non-delirious patients, irrespective of the onset time (overall, ID or PD). Six-month re-hospitalisation was significantly higher in overall delirium and the PD group, as compared to non-delirious patients. Kaplan-Meier analysis showed a significant reduction of 6-month survival in patients with delirium compared to those without, irrespective of delirium onset time (i.e. ID or PD). A positive confusion assessment method was an independent predictor of short and long-term mortality. Delirium is a common complication in elderly CICU patients, and is associated with a longer and more complicated hospital stay and increased short and long-term mortality. Our findings suggest the usefulness of a protocol for the early identification of delirium in the CICU. Clinicaltrials.gov: NCT02004665.",success
26041151,False,"Journal Article;Meta-Analysis;Research Support, Non-U.S. Gov't;Systematic Review",,,,,,,,True,"To determine the relation between delirium in critically ill patients and their outcomes in the short term (in the intensive care unit and in hospital) and after discharge from hospital. Systematic review and meta-analysis of published studies. PubMed, Embase, CINAHL, Cochrane Library, and PsychINFO, with no language restrictions, up to 1 January 2015. Reports were eligible for inclusion if they were prospective observational cohorts or clinical trials of adults in intensive care units who were assessed with a validated delirium screening or rating system, and if the association was measured between delirium and at least one of four clinical endpoints (death during admission, length of stay, duration of mechanical ventilation, and any outcome after hospital discharge). Studies were excluded if they primarily enrolled patients with a neurological disorder or patients admitted to intensive care after cardiac surgery or organ/tissue transplantation, or centered on sedation management or alcohol or substance withdrawal. Data were extracted on characteristics of studies, populations sampled, identification of delirium, and outcomes. Random effects models and meta-regression analyses were used to pool data from individual studies. Delirium was identified in 5280 of 16,595 (31.8%) critically ill patients reported in 42 studies. When compared with control patients without delirium, patients with delirium had significantly higher mortality during admission (risk ratio 2.19, 94% confidence interval 1.78 to 2.70; P<0.001) as well as longer durations of mechanical ventilation and lengths of stay in the intensive care unit and in hospital (standard mean differences 1.79 (95% confidence interval 0.31 to 3.27; P<0.001), 1.38 (0.99 to 1.77; P<0.001), and 0.97 (0.61 to 1.33; P<0.001), respectively). Available studies indicated an association between delirium and cognitive impairment after discharge. Nearly a third of patients admitted to an intensive care unit develop delirium, and these patients are at increased risk of dying during admission, longer stays in hospital, and cognitive impairment after discharge.",success
23269131,False,"Consensus Development Conference;Journal Article;Practice Guideline;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"To revise the ""Clinical Practice Guidelines for the Sustained Use of Sedatives and Analgesics in the Critically Ill Adult"" published in Critical Care Medicine in 2002. The American College of Critical Care Medicine assembled a 20-person, multidisciplinary, multi-institutional task force with expertise in guideline development, pain, agitation and sedation, delirium management, and associated outcomes in adult critically ill patients. The task force, divided into four subcommittees, collaborated over 6 yr in person, via teleconferences, and via electronic communication. Subcommittees were responsible for developing relevant clinical questions, using the Grading of Recommendations Assessment, Development and Evaluation method (http://www.gradeworkinggroup.org) to review, evaluate, and summarize the literature, and to develop clinical statements (descriptive) and recommendations (actionable). With the help of a professional librarian and Refworks database software, they developed a Web-based electronic database of over 19,000 references extracted from eight clinical search engines, related to pain and analgesia, agitation and sedation, delirium, and related clinical outcomes in adult ICU patients. The group also used psychometric analyses to evaluate and compare pain, agitation/sedation, and delirium assessment tools. All task force members were allowed to review the literature supporting each statement and recommendation and provided feedback to the subcommittees. Group consensus was achieved for all statements and recommendations using the nominal group technique and the modified Delphi method, with anonymous voting by all task force members using E-Survey (http://www.esurvey.com). All voting was completed in December 2010. Relevant studies published after this date and prior to publication of these guidelines were referenced in the text. The quality of evidence for each statement and recommendation was ranked as high (A), moderate (B), or low/very low (C). The strength of recommendations was ranked as strong (1) or weak (2), and either in favor of (+) or against (-) an intervention. A strong recommendation (either for or against) indicated that the intervention's desirable effects either clearly outweighed its undesirable effects (risks, burdens, and costs) or it did not. For all strong recommendations, the phrase ""We recommend …"" is used throughout. A weak recommendation, either for or against an intervention, indicated that the trade-off between desirable and undesirable effects was less clear. For all weak recommendations, the phrase ""We suggest …"" is used throughout. In the absence of sufficient evidence, or when group consensus could not be achieved, no recommendation (0) was made. Consensus based on expert opinion was not used as a substitute for a lack of evidence. A consistent method for addressing potential conflict of interest was followed if task force members were coauthors of related research. The development of this guideline was independent of any industry funding. These guidelines provide a roadmap for developing integrated, evidence-based, and patient-centered protocols for preventing and treating pain, agitation, and delirium in critically ill patients.",success
28422280,False,Journal Article,,,,,,,,True,"Although the field of frailty research has expanded rapidly, it is still a nascent concept within the clinical specialties. Frailty, conceptualized as greater vulnerability to stressors because of significant depletion of physiological reserves, predicts poorer outcomes in several medical specialties, including cardiology, human immunodeficiency virus care, and nephrology, and in the behavioral and social sciences. Lack of a consensus definition, proliferation of measurement tools, inadequate understanding of the biology of frailty, and lack of validated clinical algorithms for frail individuals hinders incorporation of frailty assessment and frailty research into the specialties. In 2015, the American Geriatrics Society, the National Institute on Aging (NIA), and the Alliance for Academic Internal Medicine held a conference for awardees of the NIA-sponsored Grants for Early Medical/Surgical Specialists Transition into Aging Research program to review the current state of knowledge regarding frailty in the subspecialties and to highlight examples of integrating frailty research into the medical specialties. Research questions to advance frailty research into specialty medicine are proposed.",success
23395245,False,Journal Article;Review,,,,,,,,True,"Frailty is the most problematic expression of population ageing. It is a state of vulnerability to poor resolution of homoeostasis after a stressor event and is a consequence of cumulative decline in many physiological systems during a lifetime. This cumulative decline depletes homoeostatic reserves until minor stressor events trigger disproportionate changes in health status. In landmark studies, investigators have developed valid models of frailty and these models have allowed epidemiological investigations that show the association between frailty and adverse health outcomes. We need to develop more efficient methods to detect frailty and measure its severity in routine clinical practice, especially methods that are useful for primary care. Such progress would greatly inform the appropriate selection of elderly people for invasive procedures or drug treatments and would be the basis for a shift in the care of frail elderly people towards more appropriate goal-directed care.",success
28143778,False,Journal Article;Review,,,,,,,,True,"Frailty is common and associated with poorer outcomes in the elderly, but its role as potential cardiovascular disease (CVD) risk factor requires clarification. We thus aimed to meta-analytically evaluate the evidence of frailty and pre-frailty as risk factors for CVD. Two reviewers selected all studies comparing data about CVD prevalence or incidence rates between frail/pre-frail vs. robust. The association between frailty status and CVD in cross-sectional studies was explored by calculating and pooling crude and adjusted odds ratios (ORs) ±95% confidence intervals (CIs); the data from longitudinal studies were pooled using the adjusted hazard ratios (HRs). Eighteen cohorts with a total of 31,343 participants were meta-analyzed. Using estimates from 10 cross-sectional cohorts, both frailty and pre-frailty were associated with higher odds of CVD than robust participants. Longitudinal data were obtained from 6 prospective cohort studies. After a median follow-up of 4.4 years, we identified an increased risk for faster onset of any-type CVD in the frail (HR=1.70 [95%CI, 1.18-2.45]; I<sup>2</sup>=66%) and pre-frail (HR=1.23 [95%CI, 1.07-1.36]; I<sup>2</sup>=67%) vs. robust groups. Similar results were apparent for time to CVD mortality in the frail and pre-frail groups. In conclusion, frailty and pre-frailty constitute addressable and independent risk factors for CVD in older adults.",success
24291279,False,Journal Article;Review,,,,,,,,True,"Due to the aging and increasingly complex nature of our patients, frailty has become a high-priority theme in cardiovascular medicine. Despite the recognition of frailty as a pivotal element in the evaluation of older adults with cardiovascular disease (CVD), there has yet to be a road map to facilitate its adoption in routine clinical practice. Thus, we sought to synthesize the existing body of evidence and offer a perspective on how to integrate frailty into clinical practice. Frailty is a biological syndrome that reflects a state of decreased physiological reserve and vulnerability to stressors. Upward of 20 frailty assessment tools have been developed, with most tools revolving around the core phenotypic domains of frailty-slow walking speed, weakness, inactivity, exhaustion, and shrinking-as measured by physical performance tests and questionnaires. The prevalence of frailty ranges from 10% to 60%, depending on the CVD burden, as well as the tool and cutoff chosen to define frailty. Epidemiological studies have consistently demonstrated that frailty carries a relative risk of >2 for mortality and morbidity across a spectrum of stable CVD, acute coronary syndromes, heart failure, and surgical and transcatheter interventions. Frailty contributes valuable prognostic insights incremental to existing risk models and assists clinicians in defining optimal care pathways for their patients. Interventions designed to improve outcomes in frail elders with CVD such as multidisciplinary cardiac rehabilitation are being actively tested. Ultimately, frailty should not be viewed as a reason to withhold care but rather as a means of delivering it in a more patient-centered fashion.",success
31475601,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Background Frailty is a predictor of adverse outcomes after acute myocardial infarction (AMI). Methods and Results We estimated the prevalence of frailty among adults age ≥75 years admitted with AMI and examined the relationship between frailty, interventions, and mortality. We used the Premier Healthcare Database to identify older adults with primary diagnoses of AMI. We classified individuals as frail or not using the validated Claims-based Frailty Index. We described patients' characteristics and receipt of percutaneous coronary intervention stratified by frailty status. The primary outcome was hospital mortality. From 2000 to 2016, we identified 469 390 encounters for older patients admitted with AMI. The median age was 82 years, 53% were women, and 75% were white. The prevalence of frailty was 19%. Frail patients were less likely to receive percutaneous coronary intervention than nonfrail (15% versus 33%, P<0.001) and much less likely to receive coronary artery bypass surgery (1% versus 9%, P<0.001). There were far fewer interventions in individuals over age 85 years. Frailty was associated with higher mortality during AMI admission (unadjusted odds ratio [OR] 1.43, CI 1.39-1.46). While there was a differential benefit of the interventions because of frailty, frail patients had reduced hospital mortality with percutaneous coronary intervention (frail: OR 0.59, CI 0.55-0.63; nonfrail: OR 0.49, CI 0.47-0.50, P for interaction <0.001) and with coronary artery bypass surgery (frail: OR 0.77, CI 0.65-0.93; nonfrail: OR 0.74, CI 0.71-0.77, P for interaction <0.001) relative to no intervention. Conclusions In the United States, frailty is common among older patients admitted with AMI. While these vulnerable patients are at an increased risk for mortality, judicial use of revascularization with percutaneous coronary intervention in frail older patients still confers immediate survival benefit.",success
28728570,False,Journal Article;Meta-Analysis;Systematic Review,,,,,,,,True,"Mild or pre-frailty is common and associated with increased risks of hospitalisation, functional decline, moves to long-term care, and death. Little is known about the effectiveness of health promotion in reducing these risks. This systematic review aimed to synthesise randomised controlled trials (RCTs) evaluating home and community-based health promotion interventions for older people with mild/pre-frailty. We searched 20 bibliographic databases and 3 trials registers (January 1990 - May 2016) using mild/pre-frailty and associated terms. We included randomised controlled and crossover trials of health promotion interventions for community-dwelling older people (65+ years) with mild/pre-frailty and excluded studies focussing on populations in hospital, long term care facilities or with a specific condition. Risk of bias was assessed by two reviewers using the Cochrane Risk of Bias tool. We pooled study results using standardised mean differences (SMD) where possible and used narrative synthesis where insufficient outcome data were available. We included 10 articles reporting on seven trials (total n = 506 participants) and included five trials in a meta-analysis. Studies were predominantly small, of limited quality and six studies tested group exercise alone. One study additionally investigated a nutrition and exercise intervention and one evaluated telemonitoring. Interventions of exercise in groups showed mixed effects on functioning (no effects on self-reported functioning SMD 0.19 (95% CI -0.57 to 0.95) n = 3 studies; positive effects on performance-based functioning SMD 0.37 (95% CI 0.07 to 0.68) n = 3 studies). No studies assessed moves to long-term care or hospitalisations. Currently the evidence base is of insufficient size, quality and breadth to recommend specific health promotion interventions for older people with mild or pre- frailty. High quality studies of rigorously developed interventions are needed. CRD42014010370 (Review 2).",success
28579766,False,Journal Article;Systematic Review,,,,,,,,True,"Frailty is an aging syndrome caused by exceeding a threshold of decline across multiple organ systems leading to a decreased resistance to stressors. Treatment for frailty focuses on multi-domain interventions to target multiple affected functions in order to decrease the adverse outcomes of frailty. No systematic reviews on the effectiveness of multi-domain interventions exist in a well-defined frail population. This systematic review aimed to determine the effect of multi-domain compared to mono-domain interventions on frailty status and score, cognition, muscle mass, strength and power, functional and social outcomes in (pre)frail elderly (≥65 years). It included interventions targeting two or more domains (physical exercise, nutritional, pharmacological, psychological, or social interventions) in participants defined as (pre)frail by an operationalized frailty definition. The databases PubMed, EMBASE, CINAHL, PEDro, CENTRAL, and the Cochrane Central register of Controlled Trials were searched from inception until September 14, 2016. Additional articles were searched by citation search, author search, and reference lists of relevant articles. The protocol for this review was registered on PROSPERO (CRD42016032905). Twelve studies were included, reporting a large diversity of interventions in terms of content, duration, and follow-up period. Overall, multi-domain interventions tended to be more effective than mono-domain interventions on frailty status or score, muscle mass and strength, and physical functioning. Results were inconclusive for cognitive, functional, and social outcomes. Physical exercise seems to play an essential role in the multi-domain intervention, whereby additional interventions can lead to further improvement (eg, nutritional intervention). Evidence of beneficial effects of multi-domain compared to mono-domain interventions is limited but increasing. Additional studies are needed, focusing on a well-defined frail population and with specific attention to the design and the individual contribution of mono-domain interventions. This will contribute to the development of more effective interventions for frail elderly.",success
30540612,False,"Journal Article;Observational Study;Research Support, N.I.H., Extramural",NCT00981474,databank,NCT00981474;NCT02587039,NCT00981474;NCT02587039,NCT00981474;NCT02587039,NCT00981474|databank;NCT02587039|databank,NCT00981474|databank;NCT02587039|databank,True,"Frailty is a geriatric syndrome thought to identify the most vulnerable older adults, and morbidity and mortality has been reported to be higher for frail patients after cardiac surgery compared to nonfrail patients. However, the cognitive consequences of frailty after cardiac surgery have not been well described. In this study, we examined the hypothesis that baseline frailty would be associated with postoperative delirium and cognitive change at 1 and 12 months after cardiac surgery. This study was nested in 2 trials, each of which was conducted by the same research team with identical measurement of exposures and outcomes. Before surgery, patients were assessed with the validated ""Fried"" frailty scale, which evaluates 5 domains (shrinking, weakness, exhaustion, low physical activity, and slowed walking speed) and classifies patients as nonfrail, prefrail, and frail. The primary outcome was postoperative delirium during hospitalization, which was assessed using the Confusion Assessment Method, Confusion Assessment Method for the Intensive Care Unit, and validated chart review. Neuropsychological testing was a secondary outcome and was generally performed within 2 weeks of surgery and then 4-6 weeks and 1 year after surgery, and the outcome of interest was change in composite Z-score of the test battery. Associations were analyzed using logistic and linear regression models, with adjustment for variables considered a priori (age, gender, race, education, and logistic European System for Cardiac Operative Risk Evaluation). Multiple imputation was used to account for missing data at the 12-month follow-up. Data were available from 133 patients with baseline frailty assessments. Compared to nonfrail patients (13% delirium incidence), the incidence of delirium was higher in prefrail (48% delirium incidence; risk difference, 35%; 95% CI, 10%-51%) and frail patients (48% delirium incidence; risk difference, 35%; 95% CI, 7%-53%). In both univariable and multivariable models, the odds of delirium were significantly higher for prefrail (adjusted odds ratio, 6.43; 95% CI, 1.31-31.64; P = .02) and frail patients (adjusted odds ratio, 6.31; 95% CI, 1.18-33.74; P = .03) compared to nonfrail patients. The adjusted decline in composite cognitive Z-score was greater from baseline to 1 month only in frail patients compared to nonfrail patients. By 1 year after surgery, there were no differences in the association of baseline frailty with change in cognition. Compared to nonfrail patients, both prefrail and frail patients were at higher risk for the primary outcome of delirium after cardiac surgery. Frail patients were also at higher risk for the secondary outcome of greater decline in cognition from baseline to 1 month, but not baseline to 1 year, after surgery.",success
30663607,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Some people with substantial Alzheimer's disease pathology at autopsy had shown few characteristic clinical symptoms or signs of the disease, whereas others with little Alzheimer's disease pathology have been diagnosed with Alzheimer's dementia. We aimed to examine whether frailty, which is associated with both age and dementia, moderates the relationship between Alzheimer's disease pathology and Alzheimer's dementia. We did a cross-sectional analysis of data from participants of the Rush Memory and Aging Project, a clinical-pathological cohort study of older adults (older than 59 years) without known dementia at baseline, living in Illinois, USA. Participants in the cohort study underwent annual neuropsychological and clinical evaluations. In the present cross-sectional analysis, we included those participants who did not have any form of dementia or who had Alzheimer's dementia at the time of their last clinical assessment and who had died and for whom complete autopsy data were available. Alzheimer's disease pathology was quantified by a summary measure of neurofibrillary tangles and neuritic and diffuse plaques. Clinical diagnosis of Alzheimer's dementia was based on clinician consensus. Frailty was operationalised retrospectively using health variable information obtained at each clincial evaluation using the deficit accumulation approach (41-item frailty index). Logistic regression and moderation modelling were used to assess relationships between Alzheimer's disease pathology, frailty, and Alzheimer's dementia. All analyses were adjusted for age, sex, and education. Up to data cutoff (Jan 20, 2017), we included 456 participants (mean age at death 89·7 years [SD 6·1]; 316 [69%] women). 242 (53%) had a diagnosis of possible or probable Alzheimer's dementia at their last clinical assessment. Frailty (odds ratio 1·76, 95% CI 1·54-2·02; p<0·0001) and Alzheimer's disease pathology (4·81, 3·31-7·01; p<0·0001) were independently associated with Alzheimer's dementia, after adjusting for age, sex, and education. When frailty was added to the model for the relationship between Alzheimer's disease pathology and Alzheimer's dementia, model fit improved (p<0·0001). There was a significant interaction between frailty and Alzheimer's disease pathology (odds ratio 0·73, 95% CI 0·57-0·94; p<sub>interaction</sub>=0·015). People with an increased frailty score had a weakened direct link between Alzheimer's disease pathology and Alzheimer's dementia; that is, people with a low amount of frailty were better able to tolerate Alzheimer's disease pathology, whereas those with higher amounts of frailty were more likely both to have more Alzheimer's disease pathology and for it to be expressed as dementia. The degree of frailty among people of the same age modifies the association between Alzheimer's disease pathology and Alzheimer's dementia. That frailty is related to both odds of Alzheimer's dementia and disease expression has implications for clinical management, since individuals with even a low level of Alzheimer's disease pathology might be at risk for dementia if they have high amounts of frailty. Further research should assess how frailty and cognition change over time to better elucidate this complex relationship. None.",success
26338685,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"To examine the relationship between physical frailty and risk of disability, and to identify the component(s) of frailty with the most impact on disability in community-dwelling older adults. Prospective cohort study. A Japanese community. 4341 older adults aged ≥65 living in the community participated in a baseline assessment from 2011 to 2012 and were followed for 2 years. Care-needs certification in the national long-term care insurance (LTCI) system of Japan, type of physical frailty (robust, prefrail, frail) and subitems (slowness, weakness, exhaustion, low activity, weight loss), adjusted for several potential confounders such as demographic characteristics, analysed with Kaplan-Meier survival curves for incidence of disability by frailty phenotype. During the 2-year follow-up period, 168 participants (3.9%) began using the LTCI system for incidence of disability. Participants classified as frail (HR 4.65, 95% CI 2.63 to 8.22) or prefrail (2.52, 1.56 to 4.07) at the baseline assessment had an increased risk of disability incidence compared with robust participants. Analyses for subitems of frailty showed that slowness (2.32, 1.62 to 3.33), weakness (1.90, 1.35 to 2.68) and weight loss (1.61, 1.13 to 2.31) were related to increased risk of disability incidence. In stratified analyses, participants who were classified as frail and who had lower cognitive function had the highest percentage (30.3%) of disability incidence during the 2 years after baseline assessment. Physical frailty, even being prefrail, had a strong impact on the risk of future disability. Some components of frailty, such as slowness, weakness and weight loss, are strongly associated with incident disability in community-dwelling older adults.",success
16129869,False,"Journal Article;Research Support, Non-U.S. Gov't;Validation Study",,,,,,,,True,"There is no single generally accepted clinical definition of frailty. Previously developed tools to assess frailty that have been shown to be predictive of death or need for entry into an institutional facility have not gained acceptance among practising clinicians. We aimed to develop a tool that would be both predictive and easy to use. We developed the 7-point Clinical Frailty Scale and applied it and other established tools that measure frailty to 2305 elderly patients who participated in the second stage of the Canadian Study of Health and Aging (CSHA). We followed this cohort prospectively; after 5 years, we determined the ability of the Clinical Frailty Scale to predict death or need for institutional care, and correlated the results with those obtained from other established tools. The CSHA Clinical Frailty Scale was highly correlated (r = 0.80) with the Frailty Index. Each 1-category increment of our scale significantly increased the medium-term risks of death (21.2% within about 70 mo, 95% confidence interval [CI] 12.5%-30.6%) and entry into an institution (23.9%, 95% CI 8.8%-41.2%) in multivariable models that adjusted for age, sex and education. Analyses of receiver operating characteristic curves showed that our Clinical Frailty Scale performed better than measures of cognition, function or comorbidity in assessing risk for death (area under the curve 0.77 for 18-month and 0.70 for 70-month mortality). Frailty is a valid and clinically important construct that is recognizable by physicians. Clinical judgments about frailty can yield useful predictive information.",success
27274775,False,Journal Article,,,,,,,,True,"Multimorbidity affects more than two thirds of older individuals and the vast majority of patients with chronic cardiovascular disease. Patients with multimorbidity have high resource utilization, poor mobility, and poor health status and are at an increased risk for death. The presence of multimorbidity imposes numerous management challenges in caring for patients with chronic cardiovascular disease. It complicates decision-making, promotes fragmented care, and imposes an immense burden on the patient and their social support system. Novel models of care, such as the cardiovascular patient-centered medical home, are needed to provide high-quality, efficient, effective care to this growing population.",success
16091574,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Clinical practice guidelines (CPGs) have been developed to improve the quality of health care for many chronic conditions. Pay-for-performance initiatives assess physician adherence to interventions that may reflect CPG recommendations. To evaluate the applicability of CPGs to the care of older individuals with several comorbid diseases. The National Health Interview Survey and a nationally representative sample of Medicare beneficiaries (to identify the most prevalent chronic diseases in this population); the National Guideline Clearinghouse (for locating evidence-based CPGs for each chronic disease). Of the 15 most common chronic diseases, we selected hypertension, chronic heart failure, stable angina, atrial fibrillation, hypercholesterolemia, diabetes mellitus, osteoarthritis, chronic obstructive pulmonary disease, and osteoporosis, which are usually managed in primary care, choosing CPGs promulgated by national and international medical organizations for each. Two investigators independently assessed whether each CPG addressed older patients with multiple comorbid diseases, goals of treatment, interactions between recommendations, burden to patients and caregivers, patient preferences, life expectancy, and quality of life. Differences were resolved by consensus. For a hypothetical 79-year-old woman with chronic obstructive pulmonary disease, type 2 diabetes, osteoporosis, hypertension, and osteoarthritis, we aggregated the recommendations from the relevant CPGs. Most CPGs did not modify or discuss the applicability of their recommendations for older patients with multiple comorbidities. Most also did not comment on burden, short- and long-term goals, and the quality of the underlying scientific evidence, nor give guidance for incorporating patient preferences into treatment plans. If the relevant CPGs were followed, the hypothetical patient would be prescribed 12 medications (costing her 406 dollars per month) and a complicated nonpharmacological regimen. Adverse interactions between drugs and diseases could result. This review suggests that adhering to current CPGs in caring for an older person with several comorbidities may have undesirable effects. Basing standards for quality of care and pay for performance on existing CPGs could lead to inappropriate judgment of the care provided to older individuals with complex comorbidities and could create perverse incentives that emphasize the wrong aspects of care for this population and diminish the quality of their care. Developing measures of the quality of the care needed by older patients with complex comorbidities is critical to improving their care.",success
24073682,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, U.S. Gov't, P.H.S.;Review",,,,,,,,True,"Polypharmacy, defined as the use of multiple drugs or more than are medically necessary, is a growing concern for older adults. MEDLINE and EMBASE databases were searched from January 1, 1986 to June 30, 2013) to identify relevant articles in people aged > 65 years. We present information about: i) prevalence of polypharmacy and unnecessary medication use; ii) negative consequences of polypharmacy; and iii) interventions to improve polypharmacy. International research shows that polypharmacy is common in older adults with the highest number of drugs taken by those residing in nursing homes. Nearly 50% of older adults take one or more medications that are not medically necessary. Research has clearly established a strong relationship between polypharmacy and negative clinical consequences. Moreover, well-designed interprofessional (often including clinical pharmacist) intervention studies that focus on enrolling high-risk older patients with polypharmacy have shown that they can be effective in reducing aspects of unnecessary prescribing with mixed results on distal health outcomes.",success
23475597,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Systematic Review",,,,,,,,True,"Overuse of unnecessary medications in frail older adults with limited life expectancy remains an understudied challenge. To identify intervention studies that reduced use of unnecessary medications in frail older adults. A secondary goal was to identify and review studies focusing on patients approaching end of life. We examined criteria for identifying unnecessary medications, intervention processes for medication reduction, and intervention effectiveness. A systematic review of English articles using MEDLINE, EMBASE, and International Pharmaceutical Abstracts from January 1966 to September 2012. Additional studies were identified by searching bibliographies. Search terms included prescription drugs, drug utilization, hospice or palliative care, and appropriate or inappropriate. A manual review of 971 identified abstracts for the inclusion criteria (study included an intervention to reduce chronic medication use; at least 5 participants; population included patients aged at least 65 years, hospice enrollment, or indication of frailty or risk of functional decline-including assisted living or nursing home residence, inpatient hospitalization) yielded 60 articles for full review by 3 investigators. After exclusion of review articles, interventions targeting acute medications, or studies exclusively in the intensive care unit, 36 articles were retained (including 13 identified by bibliography review). Articles were extracted for study design, study setting, intervention description, criteria for identifying unnecessary medication use, and intervention outcomes. The studies included 15 randomized controlled trials, 4 non-randomized trials, 6 pre-post studies, and 11 case series. Control groups were used in over half of the studies (n = 20). Study populations varied and included residents of nursing homes and assisted living facilities (n = 16), hospitalized patients (n = 14), hospice/palliative care patients (n = 3), home care patients (n = 2), and frail or disabled community-dwelling patients (n = 1). The majority of studies (n = 21) used implicit criteria to identify unnecessary medications (including drugs without indication, unnecessary duplication, and lack of effectiveness); only one study incorporated patient preference into prescribing criteria. Most (25) interventions were led by or involved pharmacists, 4 used academic detailing, 2 used audit and feedback reports targeting prescribers, and 5 involved physician-led medication reviews. Overall intervention effect sizes could not be determined due to heterogeneity of study designs, samples, and measures. Very little rigorous research has been conducted on reducing unnecessary medications in frail older adults or patients approaching end of life.",success
21862745,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Patients discharged from acute care hospitals may be at risk for unintentional discontinuation of medications prescribed for chronic diseases. The intensive care unit (ICU) may pose an even greater risk because of the focus on acute events and the presence of multiple transitions in care. To evaluate rates of potentially unintentional discontinuation of medications following hospital or ICU admission. A population-based cohort study using administrative records from 1997 to 2009 of all hospitalizations and outpatient prescriptions in Ontario, Canada; it included 396,380 patients aged 66 years or older with continuous use of at least 1 of 5 evidence-based medication groups prescribed for long-term use: (1) statins, (2) antiplatelet/anticoagulant agents, (3) levothyroxine, (4) respiratory inhalers, and (5) gastric acid-suppressing drugs. Rates of medication discontinuation were compared across 3 groups: patients admitted to the ICU, patients hospitalized without ICU admission, and nonhospitalized patients (controls). Odds ratios (ORs) were calculated and adjusted for patient demographics, clinical factors, and health services use. The primary outcome was failure to renew the prescription within 90 days after hospital discharge. Patients admitted to the hospital (n = 187,912) were more likely to experience potentially unintentional discontinuation of medications than controls (n = 208,468) across all medication groups examined. The adjusted ORs (AORs) ranged from 1.18 (95% CI, 1.14-1.23) for discontinuing levothyroxine in 12.3% of hospitalized patients (n = 6831) vs 11.0% of controls (n = 7114) to an AOR of 1.86 (95% CI, 1.77-1.97) for discontinuing antiplatelet/anticoagulant agents in 19.4% of hospitalized patients (n = 5564) vs 11.8% of controls (n = 2535). With ICU exposure, the AORs ranged from 1.48 (95% CI, 1.39-1.57) for discontinuing statins in 14.6% of ICU patients (n = 1484) to an AOR of 2.31 (95% CI, 2.07-2.57) for discontinuing antiplatelet/anticoagulant agents in 22.8% of ICU patients (n = 522) vs the control group. Admission to an ICU was associated with an additional risk of medication discontinuation in 4 of 5 medication groups vs hospitalizations without an ICU admission. One-year follow-up of patients who discontinued medications showed an elevated AOR for the secondary composite outcome of death, emergency department visit, or emergent hospitalization of 1.07 (95% CI, 1.03-1.11) in the statins group and of 1.10 (95% CI, 1.03-1.16) in the antiplatelet/anticoagulant agents group. Patients prescribed medications for chronic diseases were at risk for potentially unintentional discontinuation after hospital admission. Admission to the ICU was generally associated with an even higher risk of medication discontinuation.",success
8765105,False,Journal Article,,,,,,,,True,"A study was undertaken to determine the potential for adverse drug interactions (ADIs) and drug-disease interactions (DDIs) in a high-risk population of emergency department (ED) patients and to characterize drug-drug and drug-disease interactions in terms of percentage of patients at risk from existing drug regimens, percentage of patients at risk from ED treatment, relation between number of drugs and potential for interactions, types of drugs and diseases posing greatest potential for interaction, and the differences in a general versus community hospital population with respect to these parameters. Records of 205 consecutive patients, 111 from a general hospital teaching facility ED (Facility 1) and 94 from a community hospital ED (Facility 2) were retrospectively reviewed. The records of all patients receiving three or more medications and all patients older than 50 years of age receiving two or more medications were analyzed by two computer programs for the presence of potential drug-drug and drug-disease interactions. A total of 226 potential ADIs were found in 89 patients (47%), with 50% of ADIs being related to ED treatment. A total of 94 potential DDIs were found in 44 patients (21%), with 34% of DDIs being related to ED treatment. The risk of an ADI rose from 13% for patients taking 2 medications to 82% for patients taking 7 or more medications. Eleven medications and four disease categories were identified as having particular potential for interactions. No significant differences were found between the general and the community hospital populations in these respects. ED patients taking three or more medications and patients older than 50 years of age taking two or more medications are at substantial risk for adverse drug-drug and drug-disease interactions. The risk is increased in patients taking particular drugs or having particular disease states.",success
24637848,False,"Journal Article;Observational Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"Beers criteria and screening tool of older person's prescriptions (STOPP) criteria are widely used to assess potentially inappropriate drug use (PIDU). the aims of the present study are (i) to assess the prevalence of PIDU based on 2012 Beers criteria and STOPP criteria and (ii) to determine the impact of PIDU, as defined by these criteria, on health outcomes among older in-hospital patients. prospective observational study. a total of 871 in-hospital patients participating to the CRIteria to Assess Appropriate Medication Use among Elderly Complex Patients project. outcome measures were (i) adverse drug reactions (ADR); (ii) decline in functional status; (iii) combined outcome (ADR or declined in functional status). the prevalence of PIDU was 58.4% applying Beers criteria, 50.4% applying STOPP criteria and 75.0% combining both sets of criteria. PIDU defined based on STOPP criteria was significantly associated with ADR [odds ratio (OR) 2.36; 95% confidence interval (CI) 1.10-5.06], and decline in physical function (OR: 2.00; 95% CI: 1.10-3.64), while, despite a positive trend, no significant association was observed for Beers criteria or the combination of both criteria. The combined outcome was significantly associated with PIDU defined based on Beers (OR: 1.74; 95% CI: 1.06-2.85), STOPP criteria (OR: 2.14; 95% CI: 1.32-3.47) or both (OR 2.02; 95% CI: 1.06-3.84). PIDU is common in hospitalised older adults and the combination of Beers and STOPP criteria might lead to the identification of a larger number of cases of PIDU than the application of a single set of criteria. STOPP criteria significantly predict all in-hospital outcomes considered, while Beers criteria were significantly associated with the combined outcome only.",success
21670372,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, Non-P.H.S.",,,,,,,,False,,success
14678335,False,Journal Article;Review,,,,,,,,True,"Advancing age is characterized by impairment in the function of the many regulatory processes that provide functional integration between cells and organs. Therefore, there may be a failure to maintain homeostasis under conditions of physiological stress. The reduced homeostatic ability affects different regulatory systems in different subjects, thus explaining at least partly the increased interindividual variability occurring as people get older. Important pharmacokinetic and pharmacodynamic changes occur with advancing age. Pharmacokinetic changes include a reduction in renal and hepatic clearance and an increase in volume of distribution of lipid soluble drugs (hence prolongation of elimination half-life) whereas pharmacodynamic changes involve altered (usually increased) sensitivity to several classes of drugs such as anticoagulants, cardiovascular and psychotropic drugs. This review focuses on the main age-related physiological changes affecting different organ systems and their implications for pharmacokinetics and pharmacodynamics of drugs.",success
19664166,False,Journal Article;Review,,,,,,,,True,"As the mortality from critical illness has improved in recent years, there has been increasing focus on patient outcomes after hospital discharge. Neuromuscular weakness acquired in the intensive care unit (ICU) is common, persistent, and often severe. Immobility due to prolonged bed rest in the ICU may play an important role in the development of ICU-acquired weakness. Studies in other patient populations have demonstrated that moderate exercise is beneficial in altering the inflammatory milieu associated with immobility, and in improving muscle strength and physical function. Recent studies have demonstrated that early mobility in the ICU is safe and feasible, with a potential reduction in short-term physical impairment. However, early mobility requires a significant change in ICU practice, with reductions in heavy sedation and bed rest. Further research is required to determine whether early mobility in the ICU can improve patients' short-term and long-term outcomes.",success
29976568,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Older adults undergoing aortic valve replacement (AVR) are at risk for malnutrition. The association between preprocedural nutritional status and midterm mortality has yet to be determined. The FRAILTY-AVR (Frailty in Aortic Valve Replacement) prospective multicenter cohort study was conducted between 2012 and 2017 in 14 centers in 3 countries. Patients ≥70 years of age who underwent transcatheter or surgical AVR were eligible. The Mini Nutritional Assessment-Short Form was assessed by trained observers preprocedure, with scores ≤7 of 14 considered malnourished and 8 to 11 of 14 considered at risk for malnutrition. The Short Performance Physical Battery was simultaneously assessed to measure physical frailty, with scores ≤5 of 12 considered severely frail and 6 to 8 of 12 considered mildly frail. The primary outcome was 1-year all-cause mortality, and the secondary outcome was 30-day composite mortality or major morbidity. Multivariable regression models were used to adjust for potential confounders. There were 1158 patients (727 transcatheter AVR and 431 surgical AVR), with 41.5% females, a mean age of 81.3 years, a mean body mass index of 27.5 kg/m<sup>2</sup>, and a mean Society of Thoracic Surgeons-Predicted Risk of Mortality of 5.1%. Overall, 8.7% of patients were classified as malnourished and 32.8% were at risk for malnutrition. Mini Nutritional Assessment-Short Form scores were modestly correlated with Short Performance Physical Battery scores (Spearman R=0.31, P<0.001). There were 126 deaths in the transcatheter AVR group (19.1 per 100 patient-years) and 30 deaths in the surgical AVR group (7.5 per 100 patient-years). Malnourished patients had a nearly 3-fold higher crude risk of 1-year mortality compared with those with normal nutritional status (28% versus 10%, P<0.001). After adjustment for frailty, Society of Thoracic Surgeons-Predicted Risk of Mortality, and procedure type, preprocedural nutritional status was a significant predictor of 1-year mortality (odds ratio, 1.08 per Mini Nutritional Assessment-Short Form point; 95% CI, 1.01-1.16) and of the 30-day composite safety end point (odds ratio, 1.06 per Mini Nutritional Assessment-Short Form point; 95% CI, 1.001-1.12). Preprocedural nutritional status is associated with mortality in older adults undergoing AVR. Clinical trials are needed to determine whether pre- and postprocedural nutritional interventions can improve clinical outcomes in these vulnerable patients.",success
28583157,False,Journal Article;Consensus Development Conference,,,,,,,,True,"Nutrition support is a necessary therapy for critically ill cardiac surgery patients. However, conclusive evidence for this population, consisting of well-conducted clinical trials is lacking. To clarify optimal strategies to improve outcomes, an international multidisciplinary group of 25 experts from different clinical specialties from Germany, Canada, Greece, USA and Russia discussed potential approaches to identify patients who may benefit from nutrition support, when best to initiate nutrition support, and the potential use of pharmaco-nutrition to modulate the inflammatory response to cardiopulmonary bypass. Despite conspicuous knowledge and evidence gaps, a rational nutritional support therapy is presented to benefit patients undergoing cardiac surgery.",success
19661454,False,"Comparative Study;Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Inactivity is a recognized compounding factor in sarcopenia and muscle weakness in old age. However, while the negative effects of unloading on skeletal muscle in young individuals are well elucidated, only little is known about the consequence of immobilization and the regenerative capacity in elderly individuals. Thus the aim of this study was to examine the effect of aging on changes in muscle contractile properties, specific force, and muscle mass characteristics in 9 old (61-74 yr) and 11 young men (21-27 yr) after 2 wk of immobilization and 4 wk of retraining. Both young and old experienced decreases in maximal muscle strength, resting twitch peak torque and twitch rate of force development, quadriceps muscle volume, pennation angle, and specific force after 2 wk of immobilization (P < 0.05). The decline in quadriceps volume and pennation angle was smaller in old compared with young (P < 0.05). In contrast, only old men experienced a decrease in quadriceps activation. After retraining, both young and old regained their initial muscle strength, but old had smaller gains in quadriceps volume compared with young, and pennation angle increased in young only (P < 0.05). The present study is the first to demonstrate that aging alters the neuromuscular response to short-term disuse and recovery in humans. Notably, immobilization had a greater impact on neuronal motor function in old individuals, while young individuals were more affected at the muscle level. In addition, old individuals showed an attenuated response to retraining after immobilization compared with young individuals.",success
15084522,True,"Clinical Trial;Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Skeletal muscle atrophy occurs as a consequence of injury, illness, surgery, and muscle disuse, impacting appreciably on health care costs and patient quality of life, particularly in the absence of appropriate rehabilitation. The molecular mechanisms that regulate muscle mass during atrophy and rehabilitation in humans have not been elucidated, despite several robust candidate pathways being identified. Here, we induced skeletal muscle atrophy in healthy volunteers using two weeks of limb immobilization, and then stimulated the restoration of muscle mass with six weeks of supervised exercise rehabilitation. We determined muscle mass and function and performed targeted gene expression analysis at prescribed time points during immobilization and rehabilitation. For the first time, we have identified novel changes in gene expression following immobilization-induced atrophy and during a program of rehabilitative exercise that restored muscle mass and function. Furthermore, we have shown that exercise performed immediately following immobilization induces profound changes in the expression of a number of genes in favor of the restoration of muscle mass, within 24 h. This information will be of considerable importance to our understanding of how immobilization and contraction stimulate muscle atrophy and hypertrophy, respectively, and to the development of novel therapeutic strategies aimed at maintaining or restoring muscle mass.",success
19898232,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"To highlight the losses in muscle mass, strength, power, and functional capacity incurred in older adults during bed rest-mediated inactivity and to provide practical recommendations for both the prevention and rehabilitation of these losses. In addition to sarcopenic muscle loss, older adults lose lean tissue more rapidly than the young during prolonged periods of physical inactivity. Amino acid or protein supplementation has the potential to maintain muscle protein synthesis and may reduce inactivity-induced muscle loss, but should ideally be part of an integrated countermeasure regimen consisting of nutrition, exercise, and, when appropriate, pharmacologic interventions. In accordance with recent mechanistic advances, we recommend an applied, broad-based two-phase approach to limit inactivity-mediated losses of muscle mass and function in older adults: (i) Lifestyle: consume a moderate amount (25-30 g) of high-quality protein with each meal and incorporate habitual exercise in close temporal proximity to protein-containing meals; (ii) Crises: react aggressively to combat the accelerated loss of muscle mass and function during acute catabolic crises and periods of reduced physical activity. As a base strategy, this should include nutritional support such as targeted protein or amino acid supplementation and integrated physical therapy.",success
17456818,False,"Letter;Research Support, N.I.H., Extramural",,,,,,,,False,,success
24703814,False,Journal Article;Review,,,,,,,,True,"Elderly patients are a population not only at particularly high risk of venous thromboembolism including pulmonary embolism (PE), but also at high risk of adverse clinical outcomes and treatment-related complications. Major progresses have been achieved in the diagnosis and treatment of PE over the last two decades. Nevertheless, some of elderly patients' specificities still represent important challenges in the management of PE in this population, from its suspicion to its diagnosis and treatment, and are discussed in this review. Perspectives for the future are from a diagnostic point of view the potential implementation of age-adjusted d-dimer cut-offs that will allow ruling out PE in a greater proportion of elderly patients without the need for thoracic imaging. From a therapeutic point of view, acquisition of post-marketing clinical experience with the use of new oral anticoagulants is still necessary, and in the meantime, these drugs should be prescribed with great caution in thoroughly selected elderly patients.",success
19638747,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Bed rest is a common intervention for critically ill adults. Associated with both benefits and adverse effects, bed rest is undergoing increasing scrutiny as a therapeutic option in the intensive care unit. Bed rest has molecular and systemic effects, ultimately affecting functional outcomes in healthy individuals as well as in those with acute and critical illnesses. Using empirical sources, the purpose of this article was to describe the consequences of bed rest and immobility, especially consequences with implications for critically ill adults in the intensive care unit. This review uses body systems to cluster classic and current results of bed rest studies, beginning with cardiovascular and including pulmonary, renal, skin, nervous, immune, gastrointestinal/ metabolic, and skeletal systems. It concludes with effects on muscles, a system profoundly affected by immobility and bed rest.",success
12594312,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"As more patients survive the acute respiratory distress syndrome, an understanding of the long-term outcomes of this condition is needed. We evaluated 109 survivors of the acute respiratory distress syndrome 3, 6, and 12 months after discharge from the intensive care unit. At each visit, patients were interviewed and underwent a physical examination, pulmonary-function testing, a six-minute-walk test, and a quality-of-life evaluation. Patients who survived the acute respiratory distress syndrome were young (median age, 45 years) and severely ill (median Acute Physiology, Age, and Chronic Health Evaluation score, 23) and had a long stay in the intensive care unit (median, 25 days). Patients had lost 18 percent of their base-line body weight by the time they were discharged from the intensive care unit and stated that muscle weakness and fatigue were the reasons for their functional limitation. Lung volume and spirometric measurements were normal by 6 months, but carbon monoxide diffusion capacity remained low throughout the 12-month follow-up. No patients required supplemental oxygen at 12 months, but 6 percent of patients had arterial oxygen saturation values below 88 percent during exercise. The median score for the physical role domain of the Medical Outcomes Study 36-item Short-Form General Health Survey (a health-related quality-of-life measure) increased from 0 at 3 months to 25 at 12 months (score in the normal population, 84). The distance walked in six minutes increased from a median of 281 m at 3 months to 422 m at 12 months; all values were lower than predicted. The absence of systemic corticosteroid treatment, the absence of illness acquired during the intensive care unit stay, and rapid resolution of lung injury and multiorgan dysfunction were associated with better functional status during the one-year follow-up. Survivors of the acute respiratory distress syndrome have persistent functional disability one year after discharge from the intensive care unit. Most patients have extrapulmonary conditions, with muscle wasting and weakness being most prominent.",success
16783553,False,"Journal Article;Meta-Analysis;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Systematic Review",,,,,,,,True,"To summarize long-term quality of life (QOL) and the degree of variation in QOL estimates across studies of acute respiratory distress (ARDS) survivors. A systematic review of studies evaluating QOL in ARDS survivors was conducted. Medline, EMBASE, CINAHL, pre-CINAHL, and the Cochrane Library were searched, and reference lists from relevant articles were evaluated. Two authors independently selected studies reporting QOL in adult survivors of ARDS or acute lung injury at least 30 days after intensive care unit discharge and extracted data on study design, patient characteristics, methods, and results. Thirteen independent observational studies (557 patients) met inclusion criteria. Eight of these studies used eight different QOL instruments, allowing only qualitative synthesis of results. The five remaining studies (330 patients) measured QOL using the Medical Outcomes Study 36-Item Short Form survey (SF-36). Mean QOL scores were similar across these studies, falling within a range of 20 points for all domains. Pooled domain-specific QOL scores in ARDS survivors 6 months or later after discharge ranged from 45 (role physical) to 66 (social functioning), or 15-26 points lower than population norms, in all domains except mental health (11 points) and role physical (39 points). Corresponding confidence intervals were no wider than +/-9 points. Six studies all found stable or improved QOL over time, but only one found significant improvement beyond 6 months after discharge. ARDS survivors in different clinical settings experience similar decrements in QOL. The precise magnitude of these decrements helps clarify the long-term prognosis for ARDS survivors.",success
15803303,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, Non-P.H.S.;Systematic Review",,,,,,,,True,"To determine how the quality of life (QOL) of intensive care unit (ICU) survivors compares with the general population, changes over time, and is predicted by baseline characteristics. Systematic literature review including MEDLINE, EMBASE, CINAHL and Cochrane Library. Eligible studies measured QOL > or = 30 days after ICU discharge using the Medical Outcomes Study 36-item Short Form (SF-36), EuroQol-5D, Sickness Impact Profile, or Nottingham Health Profile in representative populations of adult ICU survivors. Disease-specific studies were excluded. Of 8,894 citations identified, 21 independent studies with 7,320 patients were reviewed. Three of three studies found that ICU survivors had significantly lower QOL prior to admission than did a matched general population. During post-discharge follow-up, ICU survivors had significantly lower QOL scores than the general population in each SF-36 domain (except bodily pain) in at least four of seven studies. Over 1-12 months of follow-up, at least two of four studies found clinically meaningful improvement in each SF-36 domain except mental health and general health perceptions. A majority of studies found that age and severity of illness predicted physical functioning. Compared with the general population, ICU survivors report lower QOL prior to ICU admission. After hospital discharge, QOL in ICU survivors improves but remains lower than general population levels. Age and severity of illness are predictors of physical functioning. This systematic review provides a general understanding of QOL following critical illness and can serve as a standard of comparison for QOL studies in specific ICU subpopulations.",success
25886997,False,Journal Article;Review,,,,,,,,True,"The results of recent large-scale clinical trials have led us to review our understanding of the metabolic response to stress and the most appropriate means of managing nutrition in critically ill patients. This review presents an update in this field, identifying and discussing a number of areas for which consensus has been reached and others where controversy remains and presenting areas for future research. We discuss optimal calorie and protein intake, the incidence and management of re-feeding syndrome, the role of gastric residual volume monitoring, the place of supplemental parenteral nutrition when enteral feeding is deemed insufficient, the role of indirect calorimetry, and potential indications for several pharmaconutrients.",success
24581949,False,Journal Article,,,,,,,,True,"To study the mortality and outcome of critically ill elderly patients in a developing country with focus on nutritional and socioeconomic status. A prospective study of 109 patients (215 screened) admitted consecutively to the intensive care unit from 2011 to 2012. Demographics, Acute Physiology and Chronic Health Evaluation (APACHE) II score, mechanical ventilation, Malnutrition Universal Screening Tool score, socioeconomic category, functional status, delirium, and length of stay were recorded. Telephonic assessment of outcome was done at 1 year. Appropriate statistical tests compared differences between subgroups. Multivariate analysis was performed on significant variables (P<.1) affecting mortality. At 12 months after discharge, 46.8% of patients (mean age, 76.5±9.6 years; APACHEII, 22.7±6.4; and intensive care unit stay, 7.8±3.4 days) had died. Risk factors for mortality at 12 months were APACHE II score (P<.001; odds ratio [OR], 1.2; 95% confidence interval [CI], 1.1-1.3), severe malnutrition (P=.006; OR, 0.08; 95% CI, 0.01-0.48), and delirium (P=.03; OR, 0.32; 95% CI, 0.11-0.9). Risk factors for short-term mortality (at 28 days) were APACHE II score (P=.02; OR, 1.1 [1.0-1.2]) and premorbid functional status (P=.03; OR, 0.2 [0.1-0.8]). Kaplan-Meier survival analysis showed a significant association with malnutrition (log-rank test, P=.012) but not with socioeconomic category. Most (72%) of the survivors had a favorable functional status. Malnutrition, delirium, and APACHEII were risk factors for long-term mortality. Survivors had a good functional outcome. Appropriate quality of life tools for this population need to be developed.",success
22167076,False,Journal Article,,,,,,,,True,"Optimal nutrition for patients in the intensive care unit has been proposed to be the provision of energy as determined by indirect calorimetry and the provision of protein of at least 1.2 g/kg. Prospective observational cohort study in a mixed medical-surgical intensive care unit in an academic hospital. In total, 886 consecutive mechanically ventilated patients were included. Nutrition was guided by indirect calorimetry and protein provision of at least 1.2 g/kg. Cumulative intakes were calculated for the period of mechanical ventilation. Cox regression was used to analyze the effect of protein + energy target achieved or energy target achieved versus neither target achieved on 28-day mortality, with adjustments for sex, age, body mass index, Acute Physiology and Chronic Health Evaluation II, diagnosis, and hyperglycemic index. Patients' mean age was 63 ± 16 years; body mass index, 26 ± 6; and Acute Physiology and Chronic Health Evaluation II, 23 ± 8. For neither target, energy target, and protein + energy target, energy intake was 75% ± 15%, 96% ± 5%, and 99% ± 5% of target, and protein intake was 72% ± 20%, 89% ± 10%, and 112% ± 12% of target, respectively. Hazard ratios (95% confidence interval) for energy target and protein + energy target were 0.83 (0.67-1.01) and 0.47 (0.31-0.73) for 28-day mortality. Optimal nutritional therapy in mechanically ventilated, critically ill patients, defined as protein and energy targets reached, is associated with a decrease in 28-day mortality by 50%, whereas only reaching energy targets is not associated with a reduction in mortality.",success
22209678,False,Journal Article,,,,,,,,True,"Adequacy of nutritional support in intensive care patients is still a matter of investigation. This study aimed to relate mortality to provision, measured requirements and balances for energy and protein in ICU patients. Prospective observational cohort study of 113 ICU patients in a tertiary referral hospital. Death occurred earlier in the tertile of patients with the lowest provision of protein and amino acids. The results were confirmed in Cox regression analyses which showed a significantly decreased hazard ratio of death with increased protein provision, also when adjusted for baseline prognostic variables (APACHE II, SOFA scores and age). Provision of energy, measured resting energy expenditure or energy and nitrogen balance was not related to mortality. The possible cause-effect relationship is discussed after a more detailed analysis of the initial part of the admission. In these severely ill ICU patients, a higher provision of protein and amino acids was associated with a lower mortality. This was not the case for provision of energy or measured resting energy expenditure or energy or nitrogen balances. The hypothesis that higher provision of protein improves outcome should be tested in a randomised trial.",success
17980023,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Undernutrition among older people is a continuing source of concern, particularly among acutely hospitalized patients. The purpose of the current study is to compare malnourished elderly patients with those at nutritional risk and identify factors contributing to the variability between the groups. The study was carried out at the Soroka University Medical Center in the south of Israel. From September 2003 through December 2004, all patients 65 years-of-age or older admitted to any of the internal medicine departments, were screened within 72 hours of admission to determine nutritional status using the short version of the Mini Nutritional Assessment (MNA-SF). Patients at nutritional risk were entered the study and were divided into malnourished or 'at risk' based on the full version of the MNA. Data regarding medical, nutritional, functional, and emotional status were obtained by trained interviewers. Two hundred fifty-nine elderly patients, 43.6% men, participated in the study; 18.5% were identified as malnourished and 81.5% were at risk for malnutrition according to the MNA. The malnourished group was less educated, had a higher depression score and lower cognitive and physical functioning. Higher prevalence of chewing problems, nausea, and vomiting was detected among malnourished patients. There was no difference between the groups in health status indicators except for subjective health evaluation which was poorer among the malnourished group. Lower dietary score indicating lower intake of vegetables fruits and fluid, poor appetite and difficulties in eating distinguished between malnourished and at-risk populations with the highest sensitivity and specificity as compare with the anthropometric, global, and self-assessment of nutritional status parts of the MNA. In a multivariate analysis, lower cognitive function, education <12 years and chewing problems were all risk factors for malnutrition. Our study indicates that low food consumption as well as poor appetite and chewing problems are associated with the development of malnutrition. Given the critical importance of nutritional status in the hospitalized elderly, further intervention trials are required to determine the best intervention strategies to overcome these problems.",success
29430446,False,Journal Article;Review,,,,,,,,True,"Skeletal muscle weakness is common in the intensive care units (ICU). Approximately 50% of patients under mechanical ventilation for more than 7 days show signs of ICU-acquired muscle weakness. In these patients, muscle weakness may be the result of axonal polyneuropathy, myopathy or a combination of both. The commonest risk factors in patients with ICU-acquired weakness (AW) are the severity and duration of the systemic inflammatory response, duration of the stay in the ICU and of mechanical ventilation, hyperglycemia, hypoalbuminemia, parenteral nutrition, and administration of corticosteroids and of neuromuscular blocking agents. Loss of thick filaments (myosin), atrophy of the myofibers, necrosis, and regeneration features has been consistently shown in muscle samples during critical illness. Moreover, a slow-to-fast fiber type shift, reduced muscle fiber cross-sectional area of the myofibers, alterations in muscle contractility, reduced aerobic capacity and protein synthesis, and the electromechanical properties of the nerve-muscle interface are also relevant features in skeletal muscles of critically ill patients and experimental models. Several diagnostic tools are currently available to identify patients at risk of ICU-AW. Early rehabilitation in combination with nutritional support constitutes the basis of the therapeutic strategies to be implemented in ICU. Future research will need to shed light on additional cellular processes that could also be targeted pharmacologically. An overview of all these aspects has been provided during the Second International Symposium on Acute Pulmonary Injury Translational Research organized by Hospital Universitario de Getafe (Madrid, Spain) in November 2017 and it is being described in the present review.",success
30260486,False,"Journal Article;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"Current randomized trials and observational studies evaluating higher versus lower protein doses in critically ill patients yield inconclusive results. Because of few studies and methodologic limitations, clinical guidelines suggest a wide range of protein intake based on weak evidence. Clinical equipoise about protein dosing exists. The purpose of the current manuscript is to provide the rationale and protocol for a randomized controlled trial (RCT) of 4000 critically ill patients randomly allocated to receive a higher or lower protein dose. We propose a global, volunteer-driven, registry-based RCT involving >100 intensive care units (ICUs). We will enroll mechanically ventilated patients with high nutrition risk, identified by low (≤25) or high (≥35) body mass index, moderate to severe malnutrition, frailty, sarcopenia, or when >96-hour duration of mechanical ventilation is expected. Exclusion criteria include patients who are >96 hours since initiation of mechanical ventilation, moribund, or pregnant, and where the clinician lacks clinical equipoise regarding protein dose. The intervention consists of higher (≥2.2 g/kg/d) or lower (≤1.2 g/kg/d) protein dose, achieved by enteral nutrition, parenteral nutrition, or both. The primary outcome will be 60-day mortality. Key secondary outcomes include time-to-discharge alive from hospital, ICU and hospital survival, and length of stay. As this is research based on existing medical practice, we will apply for a waiver of informed consent, where possible. The large sample size is a reflection of the small signal we expect to see in this large, pragmatic trial.",success
25978160,False,"Editorial;Research Support, N.I.H., Extramural;Comment",,,,,,,,False,,success
25654178,False,"Journal Article;Meta-Analysis;Research Support, N.I.H., Extramural;Systematic Review",,,,,,,,True,"To conduct a systematic review and metaanalysis of the prevalence, risk factors, and prevention/treatment strategies for posttraumatic stress disorder symptoms in critical illness survivors. PubMed, Embase, CINAHL, PsycINFO, and Cochrane Library from inception through March 5, 2014. Eligible studies met the following criteria: 1) adult general/nonspecialty ICU, 2) validated posttraumatic stress disorder instrument greater than or equal to 1 month post-ICU, and 3) sample size greater than or equal to 10 patients. Duplicate independent review and data abstraction from all eligible titles/abstracts/full-text articles. The search identified 2,817 titles/abstracts, with 40 eligible articles on 36 unique cohorts (n = 4,260 patients). The Impact of Event Scale was the most common posttraumatic stress disorder instrument. Between 1 and 6 months post-ICU (six studies; n = 456), the pooled mean (95% CI) Impact of Event Scale score was 20 (17-24), and the pooled prevalences of clinically important posttraumatic stress disorder symptoms (95% CI) were 25% (18-34%) and 44% (36-52%) using Impact of Event Scale thresholds greater than or equal to 35 and greater than or equal to 20, respectively. Between 7 and 12 months post-ICU (five studies; n = 698), the pooled mean Impact of Event Scale score was 17 (9-24), and pooled prevalences of posttraumatic stress disorder symptoms were 17% (10-26%) and 34% (22-50%), respectively. ICU risk factors for posttraumatic stress disorder symptoms included benzodiazepine administration and post-ICU memories of frightening ICU experiences. Posttraumatic stress disorder symptoms were associated with worse quality of life. In European-based studies: 1) an ICU diary was associated with a significant reduction in posttraumatic stress disorder symptoms, 2) a self-help rehabilitation manual was associated with significant posttraumatic stress disorder symptom reduction at 2 months, but not 6 months; and 3) a nurse-led ICU follow-up clinic did not reduce posttraumatic stress disorder symptoms. Clinically important posttraumatic stress disorder symptoms occurred in one fifth of critical illness survivors at 1-year follow-up, with higher prevalence in those who had comorbid psychopathology, received benzodiazepines, and had early memories of frightening ICU experiences. In European studies, ICU diaries reduced posttraumatic stress disorder symptoms.",success
22922434,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"The goal of comparative effectiveness research (CER) is to explain the differential benefits and harms of alternate methods to prevent, diagnose, treat, and monitor a clinical condition or to improve the delivery of care. To inform decision making, information from the patient's perspective that reflects outcomes that patients care about are needed and can be collected rigorously using appropriate patient-reported outcomes (PRO). It can be challenging to select the most appropriate PRO measure given the proliferation of such questionnaires over the past 20 years. In this paper, we discuss the value of PROs within CER, types of measures that are likely to be useful in the CER context, PRO instrument selection, and key challenges associated with using PROs in CER. We delineate important considerations for defining the CER context, selecting the appropriate measures, and for the analysis and interpretation of PRO data. Emerging changes that may facilitate CER using PROs as an outcome are also reviewed including implementation of electronic and personal health records, hospital and population-based registries, and the use of PROs in national monitoring initiatives. The potential benefits of linking the information derived from PRO endpoints in CER to decision making is also reviewed. The recommendations presented for incorporating PROs in CER are intended to provide a guide to researchers, clinicians, and policy makers to ensure that information derived from PROs is applicable and interpretable for a given CER context. In turn, CER will provide information that is necessary for clinicians, patients, and families to make informed care decisions.",success
30009806,False,"Journal Article;Research Support, N.I.H., Extramural;Review",,,,,,,,True,"Current studies in cardiothoracic clinical research frequently fail to use end points that are most meaningful to patients, including measures associated with quality of life. Patient-reported outcomes (PROs) represent an underused but important component of high-quality patient-centered care. Our objective was to highlight important principles of PRO measurement, describe current use in cardiothoracic operations, and discuss the potential for and challenges associated with integration of PROs into large clinical databases. We performed a literature review by using the PubMed/EMBASE databases. Clinical articles that focused on the use of PROs in cardiothoracic surgical outcomes measurement or clinical research were included in this review. PROs measure the outcomes that matter most to patients and facilitate the delivery of patient-centered care. When effectively used, PRO measures have provided detailed and nuanced quality-of-life data for comparative effectiveness research. However, further steps are needed to better integrate PROs into routine clinical care. Incorporation of PROs into routine clinical practice is essential for delivering high-quality patient-centered care. Future integration of PROs into prospectively collected registries and databases, including that The Society of Thoracic Surgeons National Database, has the potential to enrich comparative effectiveness research in cardiothoracic surgery.",success
23463810,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,False,,success
30359923,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"The purposes of the study were to provide richer context for families' quantitative assessments of the quality of ICU care, and to describe further quality areas of importance for family members. Free-text comments from 1077 family members of 920 patients focusing on family evaluation of ICU quality of care were analyzed using content analysis. Twenty-one Danish and Dutch ICUs participated from October 2014 to June 2015. Four themes emerged as important to families: information, clinician skills, ICU environment, and discharge from the ICU. Families highlighted the importance of receiving information that was accessible, understandable and honest. They indicated that quality care was ensured by having clinicians who were both technically and interpersonally competent. The ICU environment and the circumstances of the transfer out of the ICU were described as contributing to quality of care. The comments identified room for improvement within all themes. The study highlights the importance of including both technical and emotional care for patients and families and the consequent need to focus on clinicians' mastery of interpersonal skills.",success
30071357,False,Journal Article;Review,,,,,,,,True,"Use of the frailty index to measure an accumulation of deficits has been proven a valuable method for identifying elderly people at risk for increased vulnerability, disease, injury, and mortality. However, complementary molecular frailty biomarkers or ideally biomarker panels have not yet been identified. We conducted a systematic search to identify biomarker candidates for a frailty biomarker panel. Gene expression databases were searched (http://genomics.senescence.info/genes including GenAge, AnAge, LongevityMap, CellAge, DrugAge, Digital Aging Atlas) to identify genes regulated in aging, longevity, and age-related diseases with a focus on secreted factors or molecules detectable in body fluids as potential frailty biomarkers. Factors broadly expressed, related to several ""hallmark of aging"" pathways as well as used or predicted as biomarkers in other disease settings, particularly age-related pathologies, were identified. This set of biomarkers was further expanded according to the expertise and experience of the authors. In the next step, biomarkers were assigned to six ""hallmark of aging"" pathways, namely (1) inflammation, (2) mitochondria and apoptosis, (3) calcium homeostasis, (4) fibrosis, (5) NMJ (neuromuscular junction) and neurons, (6) cytoskeleton and hormones, or (7) other principles and an extensive literature search was performed for each candidate to explore their potential and priority as frailty biomarkers. A total of 44 markers were evaluated in the seven categories listed above, and 19 were awarded a high priority score, 22 identified as medium priority and three were low priority. In each category high and medium priority markers were identified. Biomarker panels for frailty would be of high value and better than single markers. Based on our search we would propose a core panel of frailty biomarkers consisting of (1) CXCL10 (C-X-C motif chemokine ligand 10), IL-6 (interleukin 6), CX3CL1 (C-X3-C motif chemokine ligand 1), (2) GDF15 (growth differentiation factor 15), FNDC5 (fibronectin type III domain containing 5), vimentin (VIM), (3) regucalcin (RGN/SMP30), calreticulin, (4) PLAU (plasminogen activator, urokinase), AGT (angiotensinogen), (5) BDNF (brain derived neurotrophic factor), progranulin (PGRN), (6) α-klotho (KL), FGF23 (fibroblast growth factor 23), FGF21, leptin (LEP), (7) miRNA (micro Ribonucleic acid) panel (to be further defined), AHCY (adenosylhomocysteinase) and KRT18 (keratin 18). An expanded panel would also include (1) pentraxin (PTX3), sVCAM/ICAM (soluble vascular cell adhesion molecule 1/Intercellular adhesion molecule 1), defensin α, (2) APP (amyloid beta precursor protein), LDH (lactate dehydrogenase), (3) S100B (S100 calcium binding protein B), (4) TGFβ (transforming growth factor beta), PAI-1 (plasminogen activator inhibitor 1), TGM2 (transglutaminase 2), (5) sRAGE (soluble receptor for advanced glycosylation end products), HMGB1 (high mobility group box 1), C3/C1Q (complement factor 3/1Q), ST2 (Interleukin 1 receptor like 1), agrin (AGRN), (6) IGF-1 (insulin-like growth factor 1), resistin (RETN), adiponectin (ADIPOQ), ghrelin (GHRL), growth hormone (GH), (7) microparticle panel (to be further defined), GpnmB (glycoprotein nonmetastatic melanoma protein B) and lactoferrin (LTF). We believe that these predicted panels need to be experimentally explored in animal models and frail cohorts in order to ascertain their diagnostic, prognostic and therapeutic potential.",success
24659054,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Metabolome analysis has emerged as a powerful technique for detecting and define specific physio-pathological phenotypes. In this investigation the diagnostic potential of metabolomics has been applied to better characterize the multiple biochemical alterations that concur in the definition of the frailty phenotype observed in elderly breast cancer patients. The study included 89 women with breast cancer (range 70-97 years) classified as Fit (n = 49), Unfit (n = 23), or Frail (n = 17) according to comprehensive geriatric assessment. The serum metabolomic profile was performed by tandem mass spectrometry and included different classes of metabolites such as amino acids, acylcarnitines, sphingo-, and glycerol-phospolipids. ANOVA was applied to identify the metabolites differing significantly among Fit, Unfit, and Frail patients. In patients carrying the frail phenotype, the amino acid perturbations involve serine, tryptophan, hydroxyproline, histidine, its derivate 3-methyl-hystidine, cystine, and β-aminoisobutyric acid. With regard to lipid metabolism, the frailty phenotype was characterized by a decrease of a wide number of glycerol- and sphingo-phospholipid metabolites. These metabolomics biomarkers may give a further insight into the biochemical processes involved in the development of frailty in breast cancer patients. Moreover, they might be useful to refine the comprehensive geriatric assessment model.",success
27914496,False,Journal Article,,,,,,,,True,"To determine the prevalence of low skeletal muscle mass in patients undergoing transcatheter aortic valve replacement (TAVR) and whether skeletal muscle mass measured from preoperative computed tomography (CT) images provides value in predicting postoperative length of stay (LOS). There are limited data on the use of body composition as a frailty measure in TAVR patients and no studies have determined if this measure predicts LOS. We studied 104 consecutive patients who underwent TAVR at Tallahassee Memorial Hospital from 2012 to 2016. Patient demographics, standard frailty measures (hand grip, albumin, and 5-m walk test), clinical comorbidities, echocardiographic data, and Valve Academic Research Consortium II major complications were recorded prospectively. Skeletal muscle index (SMI) [skeletal muscle mass cross-sectional area at L3/height<sup>2</sup>] was measured from CT images using Slice-O-Matic software (Tomovision, Montreal, Quebec, Canada). Clinical outcomes were assessed and multivariate methods used to determine predictors of LOS. Sarcopenia was prevalent in men (83%) and women (56%). Patients who suffered from a major complication had significantly longer length of stay (13 vs 4.6days, P<.0001). Skeletal muscle index correlated with age, sex, body mass index, handgrip strength, and previous coronary artery bypass graft surgery, but not major complications. A multivariate model including all univariate predictors of LOS showed SMI, major complications, transapical access, atrial fibrillation, and chronic obstructive pulmonary syndrome as independent predictors of LOS. For every 14-cm<sup>2</sup>/m<sup>2</sup> increase in SMI, there was a 1-day reduction in LOS. None of the standard measures of frailty predicted LOS. Skeletal muscle index, a measure of sarcopenia readily determined from pre-TAVR CT scans, independently predicts TAVR LOS better than standard frailty testing. Further evaluation of SMI as a frailty measure after TAVR and other cardiovascular procedures is warranted.",success
27863730,False,Journal Article,,,,,,,,True,"Frailty assessment can help predict which older adults will experience adverse events after cardiac surgical procedures. Low muscle mass is a core component of frailty that is suboptimally captured by self-reported weight loss; refined measures using computed tomographic (CT) images have emerged and are predictive of outcomes in noncardiac surgical procedures. The objective of this study was to evaluate the association between CT muscle area and length of stay (LOS) after cardiac surgical procedures. Frail patients who had a perioperative abdominal or thoracic CT scan were identified. The CT scans were analyzed to measure cross-sectional lean muscle area at the L4 vertebra (psoas muscle area [PMA], lumbar muscle area [LMA]) and the T4 vertebra (thoracic muscle area [TMA]). The associations of PMA, LMA, and TMA with frailty markers and postoperative LOS were investigated. Eighty-two patients were included; the mean age was 69.2 ± 9.97 years. Low muscle area was correlated with lower handgrip strength and short physical performance battery (SPPB) scores indicative of physical frailty. Postoperative LOS was correlated with PMA (R = -0.47, p = 0.004), LMA (R = -0.41, p = 0.01), and TMA (R = -0.29, p = 0.03). After adjustment for the predicted risk of prolonged LOS, age, sex, and body surface area, PMA remained significantly associated with LOS (β = -2.35, 95% CI -4.48 to -0.22). The combination of low PMA and handgrip strength, indicative of sarcopenia, yielded the greatest incremental value in predicting LOS. Low PMA is a marker of physical frailty associated with increased LOS in older adults undergoing cardiac surgical procedures. Further research is necessary to validate PMA as a prognostic marker and therapeutic target in this vulnerable population.",success
12515756,False,Journal Article;Review,,,,,,,,False,,success
12538439,False,Journal Article;Review,,,,,,,,False,,success
12551876,False,Journal Article;Review,,,,,,,,False,,success
21809160,False,Journal Article;Review,,,,,,,,True,"Important changes occur in the cardiovascular system with advancing age, even in apparently healthy individuals. Thickening and stiffening of the large arteries develop due to collagen and calcium deposition and loss of elastic fibers in the medial layer. These arterial changes cause systolic blood pressure to rise with age, while diastolic blood pressure generally declines after the sixth decade. In the left ventricle, modest concentric wall thickening occurs due to cellular hypertrophy, but cavity size does not change. Although left ventricular systolic function is preserved across the age span, early diastolic filling rate declines 30-50% between the third and ninth decades. Conversely, an age-associated increase in late diastolic filling due to atrial contraction preserves end-diastolic volume. Aerobic exercise capacity declines approximately 10% per decade in cross-sectional studies; in longitudinal studies, however, this decline is accelerated in the elderly. Reductions in peak heart rate and peripheral oxygen utilization but not stroke volume appear to mediate the age-associated decline in aerobic capacity. Deficits in both cardiac β-adrenergic receptor density and in the efficiency of postsynaptic β-adrenergic signaling contribute significantly to the reduced cardiovascular performance during exercise in older adults. Although these cardiovascular aging changes are considered ""normative"", they lower the threshold for the development of cardiovascular disease, which affects the majority of older adults.",success
29802146,False,"Journal Article;Research Support, U.S. Gov't, P.H.S.;Validation Study",,,,,,,,True,"Intensive care unit (ICU) use for initially stable patients presenting with non-ST-segment-elevation myocardial infarction (NSTEMI) varies widely across hospitals and minimally correlates with severity of illness. We aimed to develop a bedside risk score to assist in identifying high-risk patients with NSTEMI for ICU admission. Using the Acute Coronary Treatment and Intervention Outcomes Network (ACTION) Registry linked to Medicare data, we identified patients with NSTEMI aged ≥65 years without cardiogenic shock or cardiac arrest on presentation. Complications requiring ICU care were defined as subsequent development of cardiac arrest, shock, high-grade atrioventricular block, respiratory failure, stroke, or death during the index hospitalization. We developed and validated a model and integer risk score (Acute Coronary Treatment and Intervention Outcomes Network (ACTION) ICU risk score) that uses variables present at hospital admission to predict requirement for ICU care. Of 29 973 patients with NSTEMI, 4282 (14%) developed a complication requiring ICU-level care, yet 12 879 (43%) received care in an ICU. Signs or symptoms of heart failure, initial heart rate, initial systolic blood pressure, initial troponin, initial serum creatinine, prior revascularization, chronic lung disease, ST-segment depression, and age had statistically significant associations with requirement for ICU care after adjusting for other risk factors. The ACTION ICU risk score had a C-statistic of 0.72. It identified 11% of patients as having very high risk (>30%) of developing complications requiring ICU care and 49% as having low likelihood (<10%) of requiring an ICU. The ACTION ICU risk score quantifies the risk of initially stable patients with NSTEMI developing a complication requiring ICU care, and could be used to more effectively allocate limited ICU resources.",success
24561498,False,"Journal Article;Research Support, Non-U.S. Gov't;Validation Study",,,,,,,,True,"Risk scores are recommended in guidelines to facilitate the management of patients who present with acute coronary syndromes (ACS). Internationally, such scores are not systematically used because they are not easy to apply and some risk indicators are not available at first presentation. We aimed to derive and externally validate a more accurate version of the Global Registry of Acute Coronary Events (GRACE) risk score for predicting the risk of death or death/myocardial infarction (MI) both acutely and over the longer term. The risk score was designed to be suitable for acute and emergency clinical settings and usable in electronic devices. The GRACE risk score (2.0) was derived in 32 037 patients from the GRACE registry (14 countries, 94 hospitals) and validated externally in the French registry of Acute ST-elevation and non-ST-elevation MI (FAST-MI) 2005. Patients presenting with ST-elevation and non-ST elevation ACS and with long-term outcomes. The GRACE Score (2.0) predicts the risk of short-term and long-term mortality, and death/MI, overall and in hospital survivors. For key independent risk predictors of death (1 year), non-linear associations (vs linear) were found for age (p<0.0005), systolic blood pressure (p<0.0001), pulse (p<0.0001) and creatinine (p<0.0001). By employing non-linear algorithms, there was improved model discrimination, validated externally. Using the FAST-MI 2005 cohort, the c indices for death exceeded 0.82 for the overall population at 1 year and also at 3 years. Discrimination for death or MI was slightly lower than for death alone (c=0.78). Similar results were obtained for hospital survivors, and with substitutions for creatinine and Killip class, the model performed nearly as well. The updated GRACE risk score has better discrimination and is easier to use than the previous score based on linear associations. GRACE Risk (2.0) performed equally well acutely and over the longer term and can be used in a variety of clinical settings to aid management decisions.",success
10938172,True,"Clinical Trial;Clinical Trial, Phase III;Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",,,,,,,,True,"Patients with unstable angina/non-ST-segment elevation myocardial infarction (MI) (UA/NSTEMI) present with a wide spectrum of risk for death and cardiac ischemic events. To develop a simple risk score that has broad applicability, is easily calculated at patient presentation, does not require a computer, and identifies patients with different responses to treatments for UA/NSTEMI. Two phase 3, international, randomized, double-blind trials (the Thrombolysis in Myocardial Infarction [TIMI] 11B trial [August 1996-March 1998] and the Efficacy and Safety of Subcutaneous Enoxaparin in Unstable Angina and Non-Q-Wave MI trial [ESSENCE; October 1994-May 1996]). A total of 1957 patients with UA/NSTEMI were assigned to receive unfractionated heparin (test cohort) and 1953 to receive enoxaparin in TIMI 11B; 1564 and 1607 were assigned respectively in ESSENCE. The 3 validation cohorts were the unfractionated heparin group from ESSENCE and both enoxaparin groups. The TIMI risk score was derived in the test cohort by selection of independent prognostic variables using multivariate logistic regression, assignment of value of 1 when a factor was present and 0 when it was absent, and summing the number of factors present to categorize patients into risk strata. Relative differences in response to therapeutic interventions were determined by comparing the slopes of the rates of events with increasing score in treatment groups and by testing for an interaction between risk score and treatment. Outcomes were TIMI risk score for developing at least 1 component of the primary end point (all-cause mortality, new or recurrent MI, or severe recurrent ischemia requiring urgent revascularization) through 14 days after randomization. The 7 TIMI risk score predictor variables were age 65 years or older, at least 3 risk factors for coronary artery disease, prior coronary stenosis of 50% or more, ST-segment deviation on electrocardiogram at presentation, at least 2 anginal events in prior 24 hours, use of aspirin in prior 7 days, and elevated serum cardiac markers. Event rates increased significantly as the TIMI risk score increased in the test cohort in TIMI 11B: 4.7% for a score of 0/1; 8.3% for 2; 13. 2% for 3; 19.9% for 4; 26.2% for 5; and 40.9% for 6/7 (P<.001 by chi(2) for trend). The pattern of increasing event rates with increasing TIMI risk score was confirmed in all 3 validation groups (P<.001). The slope of the increase in event rates with increasing numbers of risk factors was significantly lower in the enoxaparin groups in both TIMI 11B (P =.01) and ESSENCE (P =.03) and there was a significant interaction between TIMI risk score and treatment (P =. 02). In patients with UA/NSTEMI, the TIMI risk score is a simple prognostication scheme that categorizes a patient's risk of death and ischemic events and provides a basis for therapeutic decision making. JAMA. 2000;284:835-842",success
28208030,False,Comparative Study;Journal Article,,,,,,,,True,"Admission to an intensive care unit (ICU) may be beneficial to patients with pneumonia with uncertain ICU needs; however, evidence regarding the association between ICU admission and mortality for other common conditions is largely unknown. To estimate the relationship between ICU admission and outcomes for hospitalized patients with exacerbation of chronic obstructive pulmonary disease (COPD), exacerbation of heart failure (HF), or acute myocardial infarction (AMI). We performed a retrospective cohort study of all acute care hospitalizations from 2010 to 2012 for U.S. fee-for-service Medicare beneficiaries aged 65 years and older admitted with COPD exacerbation, HF exacerbation, or AMI. We used multivariable adjustment and instrumental variable analysis to assess each condition separately. The instrumental variable analysis used differential distance to a high ICU use hospital (defined separately for each condition) as an instrument for ICU admission to examine marginal patients whose likelihood of ICU admission depended on the hospital to which they were admitted. The primary outcome was 30-day mortality. Secondary outcomes included hospital costs. Among 1,555,798 Medicare beneficiaries with COPD exacerbation, HF exacerbation, or AMI, 486,272 (31%) were admitted to an ICU. The instrumental variable analysis found that ICU admission was not associated with significant differences in 30-day mortality for any condition. ICU admission was associated with significantly greater hospital costs for HF ($11,793 vs. $9,185, P < 0.001; absolute increase, $2,608 [95% confidence interval, $1,377-$3,840]) and AMI ($19,513 vs. $14,590, P < 0.001; absolute increase, $4,922 [95% confidence interval, $2,665-$7,180]), but not for COPD. ICU admission did not confer a survival benefit for patients with uncertain ICU needs hospitalized with COPD exacerbation, HF exacerbation, or AMI. These findings suggest that the ICU may be overused for some patients with these conditions. Identifying patients most likely to benefit from ICU admission may improve health care efficiency while reducing costs.",success
23856021,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"The classification of myocardial infarction into 5 types was introduced in 2007 as an important component of the universal definition. In contrast to the plaque rupture-related type 1 myocardial infarction, type 2 myocardial infarction is considered to be caused by an imbalance between demand and supply of oxygen in the myocardium. However, no specific criteria for type 2 myocardial infarction have been established. We prospectively studied unselected hospital patients who had cardiac troponin I measured on clinical indication. The diagnosis and classification of myocardial infarction were established, and the frequency and features of type 2 myocardial infarction were investigated by use of novel developed criteria. From January 2010 to January 2011, a total of 7230 consecutive patients who had cardiac troponin I measured were evaluated, and 4499 patients qualified for inclusion. The diagnosis of myocardial infarction was established in 553 patients, of whom 386 (72%) had a type 1 myocardial infarction and 144 (26%) had a type 2 myocardial infarction. Patients in the group with type 2 myocardial infarction were older and more likely to be female, and had more comorbidities. The proportion of patients without significant coronary artery disease was higher in those with type 2 myocardial infarction (45%) than in those with type 1 myocardial infarction (12%) (P < .001). Tachyarrhythmias, anemia, and respiratory failure were the most prevalent mechanisms causing type 2 myocardial infarction. In a cohort of patients with myocardial infarction who were admitted consecutively through 1 year, the category of type 2 myocardial infarction comprised one fourth when diagnosed by the use of newly developed criteria. Approximately half of patients with type 2 myocardial infarction had no significant coronary artery disease.",success
24462011,False,Journal Article;Review,,,,,,,,True,"The Task Force for the Universal Definition of Myocardial Infarction recently published updated guidelines for the clinical and research diagnosis of myocardial infarction under a variety of circumstances and in a variety of categories. A type 1 myocardial infarction (MI) is usually the result of atherosclerotic coronary artery disease with thrombotic coronary arterial obstruction secondary to atherosclerotic plaque rupture, ulceration, fissuring, or dissection, causing coronary arterial obstruction with resultant myocardial ischemia and necrosis. Patients with a type 2 MI do not have atherosclerotic plaque rupture. In this latter group of patients, myocardial necrosis occurs because of an increase in myocardial oxygen demand or a decrease in myocardial blood flow. Type 2 MI has been the subject of considerable clinical discussion and confusion. This review by knowledgeable members of the Task Force seeks to help clinicians resolve the confusion surrounding type 2 MI.",success
17923572,True,"Journal Article;Multicenter Study;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Acute myocardial infarction may be accompanied by acute, severe, concomitant, noncardiac conditions, but their prevalence and prognostic importance is not well defined. We sought to evaluate the prevalence of acute, severe, noncardiac conditions present at the time of hospital admission with acute myocardial infarction and to assess the association of these conditions with in-hospital mortality. A total of 3907 patients admitted with an acute myocardial infarction were prospectively enrolled in 19 US centers between January 2003 and June 2004. Acute noncardiac conditions present at admission with imminent threat to life were identified from medical record review within 24 hours of admission. Using multivariable analyses, we evaluated the relationship between these conditions and in-hospital mortality. We documented a concomitant acute, severe, noncardiac condition in 6.8% (n=267) of the study sample. The most common concomitant conditions were severe pneumonia (potentially requiring intubation; 18.4%), severe gastrointestinal bleeding/anemia (15.7%), stroke (9.7%), and sepsis (9.4%). These patients were less likely to be ideal for or to receive evidence-based therapies at the time of admission. The in-hospital mortality was 21.3% (57 of 267) for patients with concomitant conditions versus 2.7% (100 of 3640) for those without these conditions. The presence of an acute noncardiac condition was associated with an increased risk of in-hospital mortality after adjustment for demographic and clinical characteristics and disease severity (odds ratio, 5.0; 95% confidence interval, 3.3 to 7.7). Concomitant, acute, noncardiac conditions are common and associated with a marked increase in the risk of in-hospital mortality.",success
29509764,False,"Journal Article;Observational Study;Research Support, Non-U.S. Gov't",NCT03037255,databank,NCT03037255,NCT03037255,NCT03037255,NCT03037255|databank,NCT03037255|databank,True,"There is limited knowledge of the scale and impact of multimorbidity for patients who have had an acute myocardial infarction (AMI). Therefore, this study aimed to determine the extent to which multimorbidity is associated with long-term survival following AMI. This national observational study included 693,388 patients (median age 70.7 years, 452,896 [65.5%] male) from the Myocardial Ischaemia National Audit Project (England and Wales) who were admitted with AMI between 1 January 2003 and 30 June 2013. There were 412,809 (59.5%) patients with multimorbidity at the time of admission with AMI, i.e., having at least 1 of the following long-term health conditions: diabetes, chronic obstructive pulmonary disease or asthma, heart failure, renal failure, cerebrovascular disease, peripheral vascular disease, or hypertension. Those with heart failure, renal failure, or cerebrovascular disease had the worst outcomes (39.5 [95% CI 39.0-40.0], 38.2 [27.7-26.8], and 26.6 [25.2-26.4] deaths per 100 person-years, respectively). Latent class analysis revealed 3 multimorbidity phenotype clusters: (1) a high multimorbidity class, with concomitant heart failure, peripheral vascular disease, and hypertension, (2) a medium multimorbidity class, with peripheral vascular disease and hypertension, and (3) a low multimorbidity class. Patients in class 1 were less likely to receive pharmacological therapies compared with class 2 and 3 patients (including aspirin, 83.8% versus 87.3% and 87.2%, respectively; β-blockers, 74.0% versus 80.9% and 81.4%; and statins, 80.6% versus 85.9% and 85.2%). Flexible parametric survival modelling indicated that patients in class 1 and class 2 had a 2.4-fold (95% CI 2.3-2.5) and 1.5-fold (95% CI 1.4-1.5) increased risk of death and a loss in life expectancy of 2.89 and 1.52 years, respectively, compared with those in class 3 over the 8.4-year follow-up period. The study was limited to all-cause mortality due to the lack of available cause-specific mortality data. However, we isolated the disease-specific association with mortality by providing the loss in life expectancy following AMI according to multimorbidity phenotype cluster compared with the general age-, sex-, and year-matched population. Multimorbidity among patients with AMI was common, and conferred an accumulative increased risk of death. Three multimorbidity phenotype clusters that were significantly associated with loss in life expectancy were identified and should be a concomitant treatment target to improve cardiovascular outcomes. ClinicalTrials.gov NCT03037255.",success
30172472,False,Journal Article;Observational Study,,,,,,,,True,"To examine age-specific differences in the frequency and impact of cardiac and non-cardiac conditions among patients aged 65 years and older hospitalized with acute myocardial infarction (AMI). Study population consisted of 3863 adults hospitalized with AMI at 11 medical centers in central Massachusetts on a biennial basis between 2001 and 2011. The presence of 11 chronic conditions (five cardiac and six non-cardiac) was based on the review of hospital medical records. Participants' median age was 79 years, 49% were men, and had an average of three chronic conditions (average of cardiac conditions: 2.6 and average of non-cardiac conditions: 1.0). Approximately one in every two patients presented with two or more cardiac related conditions whereas one in every three patients presented with two or more non-cardiac related conditions. The most prevalent chronic conditions in our study population were hypertension, diabetes, heart failure, chronic kidney disease, and peripheral vascular disease. Patients across all age groups with a greater number of previously diagnosed cardiac or non-cardiac conditions were at higher risk for developing important clinical complications or dying during hospitalization as compared to those with 0-1 condition. The prevalence of multimorbidity among older adults hospitalized with AMI is high and associated with worse outcomes that should be considered in the management of this vulnerable population.",success
29860244,False,"Journal Article;Observational Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"Myocardial infarction (MI) patients are increasingly older, and common risk scores include chronological age, but do not consider chronic comorbidity or biological age. Frailty status reflects these variables and may be independently correlated with prognosis in this setting. This study investigated the impact of frailty on the prognosis of elderly patients admitted due to MI. This prospective and observational study included patients ≥75 years admitted to three tertiary hospitals in Spain due to MI. Frailty assessment was performed at admission using the Survey of Health, Ageing and Retirement in Europe Frailty Index (SHARE-FI) tool. The primary endpoint was the composite of death or non-fatal reinfarction during a follow-up of 1 year. Overall mortality, reinfarction, the composite of death, reinfarction and stroke, major bleeding, and readmission rates were also explored. A total of 285 patients were enrolled. Frail patients (109, 38.2%) were older, with a higher score in the Charlson Comorbidity Index and with a higher risk score addressed in the GRACE and CRUSADE indexes. On multivariate analysis including GRACE, CRUSADE, maximum creatinine level, culprit lesion revascularization, complete revascularization, and dual antiplatelet therapy at discharge, frailty was an independent predictor of the composite of death and reinfarction (2.81, 95% CI 1.16-6.78) and overall mortality (3.07, 95% CI 1.35-6.98). Frailty is an independent prognostic marker of the composite of mortality and reinfarction and of overall mortality in patients aged ≥75 years admitted due to MI.",success
22689718,False,Journal Article;Systematic Review,,,,,,,,True,"Cognitive impairment in cardiac patients may interfere with disease management. This review describes studies examining specific cognitive impairments in cardiac patients and studies that investigate the link between echocardiographic and cognitive measures. Executive function impairments were frequently reported in different patient groups. Also, lower cardiac output and worse left ventricular diastolic function are linked to executive function deficits. In cardiac patients, special attention should be paid to these executive function impairments in view of their role in disease management and independent living. Interventions that stimulate executive function should be encouraged and integrated in cardiac treatment protocols.",success
27168733,False,Journal Article,,,,,,,,False,,success
12727150,True,"Clinical Trial;Comparative Study;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"The SHould we emergently revascularize Occluded Coronaries in cardiogenic shocK (SHOCK) Trial showed no benefit of early revascularization in patients aged >/=75 years with acute myocardial infarction and cardiogenic shock. We examined the effect of age on treatment and outcomes of patients with cardiogenic shock in the SHOCK Trial Registry. We compared clinical and treatment factors in patients in the SHOCK Trial Registry with shock due to pump failure aged <75 years (n=588) and >/=75 years (n=277), and 30-day mortality of patients treated with early revascularization <18 hours since onset of shock and those undergoing a later or no revascularization procedure. After excluding early deaths covariate-adjusted relative risk and 95% confidence intervals were calculated to compare the revascularization strategies within the two age groups. Older patients more often had prior myocardial infarction, congestive heart failure, renal insufficiency, other comorbidities, and severe coronary anatomy. In-hospital mortality in the early vs. late or no revascularization groups was 45 vs. 61% for patients aged <75 years (p=0.002) and 48 vs. 81% for those aged >/=75 years (p=0.0003). After exclusion of 65 early deaths and covariate adjustment, the relative risk was 0.76 (0.59, 0.99; p=0.045) in patients aged <75 years and 0.46 (0.28, 0.75; p=0.002) in patients aged >/=75 years. Elderly patients with myocardial infarction complicated by cardiogenic shock are less likely to be treated with invasive therapies than younger patients with shock. Covariate-adjusted modeling reveals that elderly patients selected for early revascularization have a lower mortality rate than those receiving a revascularization procedure later or never.",success
30999991,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Older adults ≥75 years of age carry an increased risk of mortality after ST-segment elevation myocardial infarction (STEMI) complicated by cardiogenic shock. The purpose of this study was to examine the use of percutaneous coronary intervention (PCI) in older adults with STEMI and shock and its influence on in-hospital mortality. We used a large publicly available all-payer inpatient health care database sponsored by the Agency for Healthcare Research and Quality between 1999 and 2013. The primary outcome was in-hospital mortality. The influence of PCI on in-hospital mortality was assessed by quintiles of propensity score (PS). Of the 317,728 encounters with STEMI and shock in the United States, 111,901 (35%) were adults age ≥75 years. Of these, 53% were women and 83% were Caucasians. The median number of chronic conditions was 8 (interquartile range: 6 to 10). The diagnosis of STEMI and cardiogenic shock in older patients decreased significantly over time (proportion of older adults with STEMI and shock: 1999: 42% vs. 2013: 29%). Concomitantly, the rate of PCI utilization in older adults increased (1999: 27% vs. 2013: 56%, p < 0.001), with declining in-hospital mortality rates (1999: 64% vs. 2013: 46%; p < 0.001). Utilizing PS matching methods, PCI was associated with a lower risk of in-hospital mortality across quintiles of propensity score (Mantel-Haenszel odds ratio: 0.48; 95% confidence interval [CI]: 0.45 to 0.51). This reduction in hospital mortality risk was seen across the 4 different U.S. census bureau regions (adjusted odds ratio: Northeast: 0.41; 95% CI: 0.36 to 0.47; Midwest: 0.49; 95% CI: 0.42 to 0.57; South: 0.51; 95% CI: 0.46 to 0.56; West: 0.46; 95% CI: 0.41 to 0.53). This large and contemporary analysis shows that utilization of PCI in older adults with STEMI and cardiogenic shock is increasing and paralleled by a substantial reduction in mortality. Although clinical judgment is critical, older adults should not be excluded from early revascularization based on age in the absence of absolute contraindications.",success
29684242,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"To compare timely access to reperfusion therapy and outcomes according to age of older adults with ST-segment elevation myocardial infarction (STEM) managed within an integrated regional system of care. Ongoing, prospective, regional, hospital-based clinical registry. Twenty-three public and private hospitals in the Northern Alps in France. Individuals presenting with STEMI evolving for less than 12 hours from symptom onset between January 2009 and December 2015 (N=4,813; 3,716 (77.2%) <75, 782 (16.2%) 75-84, 315 (6.5%) ≥85). Delivery of any reperfusion therapy (primary percutaneous coronary intervention (PCI), intravenous fibrinolysis), primary PCI, and timely reperfusion therapy and in-hospital outcomes. The percentages of patients receiving any reperfusion therapy were 92.9% for those younger than 75, 89.0% for those aged 75 to 84, and 78.7% for those aged 85 and older (P < .001). The percentages of patients undergoing primary PCI were 63.7%, 70.3%, 72.4% (P < .001); and the percentages of patients receiving timely delivery of reperfusion therapy were 44.6%, 36.8%, 29.9% (P < .001). In-hospital all-cause mortality was 3.4% for those younger than 75, 10.2% for those aged 75 to 84, and 19.8% for those aged 85 and older (P <.001). In multivariable analysis adjusting for baseline characteristics, timely delivery of reperfusion therapy was associated with lower in-hospital mortality (adjusted odds ratio=0.63, 95% confidence interval=0.46-0.85) with no significant heterogeneity between age groups (P-value for interaction = .45). Older adults meeting contemporary eligibility criteria for reperfusion therapy continue to receive delayed reperfusion therapy and experience higher mortality than their younger counterparts.",success
26757786,False,Journal Article,NCT01305785,databank,NCT01305785,NCT01305785,NCT01305785,NCT01305785|databank,NCT01305785|databank,True,"To determine whether treatment and outcomes of older acute coronary syndrome (ACS) patients changed over time. We analysed the use of guideline-recommended therapies and in-hospital outcomes of 13 662 ACS patients ≥70 years enrolled in the prospective Acute Myocardial Infarction in Switzerland (AMIS) cohort between 2001 and 2012 according to 4-year periods (2001-2004, 2005-2008, and 2009-2012). Between first and last 4-year period, percutaneous coronary intervention (PCI) use increased from 43.8 to 69.6% of older ACS patients ( ITALIC! P < 0.001). Use of guideline-recommended drugs as well increased. At the same time, in-hospital mortality of the overall population decreased from 11.6% in the first to 10.0% in the last 4-year period ( ITALIC! P = 0.020), and in-hospital major adverse cardiac and cerebrovascular events from 14.4 to 11.3% ( ITALIC! P < 0.001). Percutaneous coronary intervention was used in increasingly older and co-morbid patients over time (mean age of patients treated with PCI 76.2 years in 2001-2004 and 78.1 years in 2009-2012, ITALIC! P < 0.001; Charlson score ≥2 was found for 27.6% of patients treated with PCI in 2001-2004 and for 32.1% in 2009-2012, ITALIC! P = 0.003). Percutaneous coronary intervention use was associated with similar odds ratios (ORs) of in-hospital mortality over time (adjusted OR 0.29, 95% confidence interval, CI, 0.22-0.40, in 2001-2004; and, adjusted OR 0.26, 95% CI 0.20-0.35, in 2009-2012). Use of guideline-recommended therapies for ACS increased and in-hospital outcomes improved over the observed 12-year period. Though PCI was used in increasingly older and co-morbid patients, PCI use was associated with similar ORs of in-hospital mortality over time. This study suggests that increasing use of guideline-recommended therapies was appropriate. ClinicalTrials.gov Identifier: NCT01305785.",success
31010297,False,"Letter;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,False,,success
26794722,True,"Comparative Study;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",NCT01255540,databank,NCT01255540,NCT01255540,NCT01255540,NCT01255540|databank,NCT01255540|databank,True,"Non-ST-elevation myocardial infarction (NSTEMI) and unstable angina pectoris are frequent causes of hospital admission in the elderly. However, clinical trials targeting this population are scarce, and these patients are less likely to receive treatment according to guidelines. We aimed to investigate whether this population would benefit from an early invasive strategy versus a conservative strategy. In this open-label randomised controlled multicentre trial, patients aged 80 years or older with NSTEMI or unstable angina admitted to 16 hospitals in the South-East Health Region of Norway were randomly assigned to an invasive strategy (including early coronary angiography with immediate assessment for percutaneous coronary intervention, coronary artery bypass graft, and optimum medical treatment) or to a conservative strategy (optimum medical treatment alone). A permuted block randomisation was generated by the Centre for Biostatistics and Epidemiology with stratification on the inclusion hospitals in opaque concealed envelopes, and sealed envelopes with consecutive inclusion numbers were made. The primary outcome was a composite of myocardial infarction, need for urgent revascularisation, stroke, and death and was assessed between Dec 10, 2010, and Nov 18, 2014. An intention-to-treat analysis was used. This study is registered with ClinicalTrials.gov, number NCT01255540. During a median follow-up of 1·53 years of participants recruited between Dec 10, 2010, and Feb 21, 2014, the primary outcome occurred in 93 (40·6%) of 229 patients assigned to the invasive group and 140 (61·4%) of 228 patients assigned to the conservative group (hazard ratio [HR] 0·53 [95% CI 0·41-0·69], p=0·0001). Five patients dropped out of the invasive group and one from the conservative group. HRs for the four components of the primary composite endpoint were 0·52 (0·35-0·76; p=0·0010) for myocardial infarction, 0·19 (0·07-0·52; p=0·0010) for the need for urgent revascularisation, 0·60 (0·25-1·46; p=0·2650) for stroke, and 0·89 (0·62-1·28; p=0·5340) for death from any cause. The invasive group had four (1·7%) major and 23 (10·0%) minor bleeding complications whereas the conservative group had four (1·8%) major and 16 (7·0%) minor bleeding complications. In patients aged 80 years or more with NSTEMI or unstable angina, an invasive strategy is superior to a conservative strategy in the reduction of composite events. Efficacy of the invasive strategy was diluted with increasing age (after adjustment for creatinine and effect modification). The two strategies did not differ in terms of bleeding complications. Norwegian Health Association (ExtraStiftelsen) and Inger and John Fredriksen Heart Foundation.",success
28985265,True,"Comparative Study;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",NCT01255540,databank,NCT01255540,NCT01255540,NCT01255540,NCT01255540|databank,NCT01255540|databank,True,"in the After Eighty study (ClinicalTrials.gov.number, NCT01255540), patients aged 80 years or more, with non-ST-elevation myocardial infarction (NSTEMI), and unstable angina pectoris (UAP), were randomised to either an invasive or conservative management approach. We sought to compare the effects of these management strategies on health related quality of life (HRQOL) after 1 year. the After Eighty study was a prospective randomised controlled multicenter trial. In total, 457 patients aged 80 or over, with NSTEMI or UAP, were randomised to either an invasive strategy (n = 229, mean age: 84.7 years), involving early coronary angiography, with immediate evaluation for percutaneous coronary intervention, coronary artery bypass graft, optimal medical therapy, or to a conservative strategy (n = 228, mean age: 84.9 years). The Short Form 36 health survey (SF-36) was used to assess HRQOL at baseline, and at the 1-year follow-up. baseline SF-36 completion was achieved for 208 and 216 patients in the invasive and conservative groups, respectively. A total of 137 in the invasive group and 136 patients in the conservative group completed the SF-36 form at follow-up. When comparing the changes from follow-up to baseline (delta) no significant changes in quality-of-life scores were observed between the two strategies in any of the domains, expect for a small but statistically significant difference in bodily pain. This difference in only one of the SF-36 subscales may not necessarily be clinically significant. from baseline to the 1 year follow-up, only minor differences in change of HRQOL as measured by SF-36 were seen by comparing an invasive and conservative strategy. NCT01255540.",success
26856210,True,Journal Article;Multicenter Study;Randomized Controlled Trial,,,,,,,,True,"Older adults presenting with acute myocardial infarction (MI) often have multivessel coronary artery disease amenable to percutaneous coronary intervention (PCI), yet the risks of multivessel intervention may outweigh potential benefits in these patients. We sought to determine if nonculprit intervention during the index PCI is associated with better outcomes among older patients with acute MI and multivessel disease. We examined 19,271 ST-segment elevation MI (STEMI) and 31,361 non-STEMI (NSTEMI) patients 65years or older with multivessel disease in a linked CathPCI Registry-Medicare database, excluding patients with prior coronary artery bypass grafting, left main disease, or cardiogenic shock. Using inverse probability-weighted propensity adjustment, we compared mortality between patients receiving culprit-only vs multivessel intervention during the index PCI procedure. Most older MI patients (91% STEMI and 74% NSTEMI) received culprit-only intervention during the index PCI. Among STEMI patients, multivessel intervention during the index PCI was associated with higher 30-day mortality (8.3% vs 6.3%, adjusted hazard ratio [HR] 1.36, 95% CI 1.14-1.62) than culprit-only intervention, and this trend persisted at 1year (13.8% vs 12.2%, adjusted HR 1.14, 95% CI 0.99-1.31). No significant mortality differences were observed among NSTEMI patients at 30days (3.4% vs 4.1%, adjusted HR 1.01, 95% CI 0.88-1.15) or at 1year (10.1% vs 10.8%, adjusted HR 0.99, 95% CI 0.91-1.08). Nonculprit intervention during the index PCI was associated with worse outcomes among STEMI patients, but not NSTEMI patients.",success
28982673,True,Comparative Study;Journal Article;Multicenter Study;Observational Study,,,,,,,,True,"Among patients with acute myocardial infarction (MI) who have multivessel disease, it is unclear if multivessel percutaneous coronary intervention (PCI) improves clinical and quality-of-life outcomes compared with culprit-only intervention. We sought to compare clinical and quality-of-life outcomes between multivessel and culprit-only PCI. Among 6061 patients with acute MI who have multivessel disease in the TRANSLATE-ACS (Treatment With Adenosine Diphosphate Receptor Inhibitors: Longitudinal Assessment of Treatment Patterns and Events After Acute Coronary Syndrome) study, we used inverse probability-weighted propensity adjustment to study the associations between multivessel and culprit-only intervention during the index PCI and major adverse cardiovascular events, unplanned all-cause readmission, and angina frequency at 6 weeks and 1 year. Multivessel PCI was performed in 1208 (20%) of patients with MI who had multivessel disease. Relative to the culprit-only intervention, patients receiving multivessel PCI were similarly aged and more likely to be seen with non-ST-segment elevation MI or cardiogenic shock. At 6 weeks, the initial multivessel PCI strategy was associated with lower major adverse cardiovascular events and unplanned readmission risks, whereas angina frequency was not significantly different between multivessel and culprit-only PCI. At 1 year, major adverse cardiovascular event risk was persistently lower in the multivessel PCI group (adjusted hazard ratio, 0.84; 95% confidence interval, 0.72-0.99), whereas long-term readmission risk (adjusted hazard ratio, 0.94; 95% confidence interval, 0.84-1.04) and angina frequency were similar between groups (adjusted odds ratio, 1.01; 95% confidence interval, 0.82-1.24). Similar associations were seen when patients with ST-segment elevation MI and non-ST-segment elevation MI were examined separately. Among patients with acute MI who have multivessel disease, multivessel PCI was associated with lower risk of all-cause readmission at 6 weeks and lower risk of major adverse cardiovascular events at 6 weeks and 1 year. However, similar short- and long-term angina frequencies were noted.",success
30137259,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, U.S. Gov't, Non-P.H.S.",,,,,,,,True,"We evaluated the burden of adverse events caused by β-blocker use after acute myocardial infarction (AMI) in frail, older nursing home (NH) residents. This retrospective cohort study used national Medicare claims linked to Minimum Data Set assessments. The study population was individuals aged ≥65 years who resided in a U.S. NH for ≥30 days, had a hospitalized AMI between May 2007 and March 2010, and returned to the NH. Exposure was new use of β-blockers versus nonuse post-AMI. Orthostasis, general hypotension, falls, dizziness, syncope, and breathlessness outcomes were measured over 90 days of follow-up. Odds ratios (ORs) with 95% confidence intervals (CIs) for outcomes were estimated using multinomial logistic regression models after 1:1 propensity score-matching of β-blocker users to nonusers. Among the 10,992 NH propensity score-matched residents with an AMI, the mean age was 84 years and 70.9% were female. β-blocker users were more likely than nonusers to be hospitalized for hypotension (OR = 1.20, 95% CI 1.03-1.39) or experience breathlessness (OR = 1.10, 95% CI 1.01-1.20) after AMI. With the exception of falls, other outcome estimates, though imprecise, were compatible with a potential elevated risk of orthostasis (OR = 1.14, 95% CI 0.96-1.35), syncope, (OR = 1.24, 95% CI 0.55-2.77), and dizziness (OR = 1.28, 95% CI 0.82-1.99) among β-blocker users. Considered alongside prior evidence that β-blockers may worsen functional outcomes in NH residents with poor baseline functional and cognitive status, our results suggest that providers should exercise caution when prescribing for these vulnerable groups, balancing the mortality benefit against the potential for causing adverse events.",success
29230546,False,Journal Article;Observational Study,,,,,,,,True,"Patients with ST-segment elevation myocardial infarction (STEMI) and consecutive cardiogenic shock (CS) represent a challenge in clinical practice. Only few 'real-world' data on therapeutic management and outcome exist. The present analysis focuses on changes of clinical management of STEMI-patients with CS and analyzes predictors of outcome using the Bremen-STEMI registry. Out of 7865 patients with STEMI, 981 patients (13%) presented with CS. Most CS patients (88%) underwent an early percutaneous intervention (PCI). Intraaortic balloon pumps (IABP) were less implanted since 2013 (p < 0.001), the rate of drug-eluting stents and periprocedural prasugrel or ticagrelor therapy increased over the years. Overall in-hospital mortality of patients with CS was 37%, 1 year mortality was 50%. A significantly reduced 1-year mortality (2006-2009: 55%, 2010-2013: 50%; 2014-2015: 43%, p = 0.027) was observed. In a multivariate analysis significant predictors of an increased 1-year mortality were acute renal failure (OR 3.6; 95% CI 1.9-7.0), atrial fibrillation (OR 2.8; 95% CI 1.3-6.0), three-vessel disease (OR 2.5; 95% CI 1.3-4.7), age ≥ 75 years (OR 2.4, 95% CI 1.3-4.4) and anemia (OR 1.9; 95% CI 1.1-3.3). A successful performed PCI (OR 0.5, 95% CI 0.2-0.9) was associated with a significantly reduced 1-year mortality. management of patients with CS changed with a steep decrease of IABP implantations. Mortality of patients with CS decreased over the last 10 years. Especially, performance of successful PCI was associated with a reduction of mortality, indicating the crucial role of early revascularization to improve prognosis in this high-risk cohort of STEMI-patients.",success
29083953,True,"Comparative Study;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",NCT01927549,databank,NCT01927549,NCT01927549,NCT01927549,NCT01927549|databank,NCT01927549|databank,True,"In patients who have acute myocardial infarction with cardiogenic shock, early revascularization of the culprit artery by means of percutaneous coronary intervention (PCI) improves outcomes. However, the majority of patients with cardiogenic shock have multivessel disease, and whether PCI should be performed immediately for stenoses in nonculprit arteries is controversial. In this multicenter trial, we randomly assigned 706 patients who had multivessel disease, acute myocardial infarction, and cardiogenic shock to one of two initial revascularization strategies: either PCI of the culprit lesion only, with the option of staged revascularization of nonculprit lesions, or immediate multivessel PCI. The primary end point was a composite of death or severe renal failure leading to renal-replacement therapy within 30 days after randomization. Safety end points included bleeding and stroke. At 30 days, the composite primary end point of death or renal-replacement therapy had occurred in 158 of the 344 patients (45.9%) in the culprit-lesion-only PCI group and in 189 of the 341 patients (55.4%) in the multivessel PCI group (relative risk, 0.83; 95% confidence interval [CI], 0.71 to 0.96; P=0.01). The relative risk of death in the culprit-lesion-only PCI group as compared with the multivessel PCI group was 0.84 (95% CI, 0.72 to 0.98; P=0.03), and the relative risk of renal-replacement therapy was 0.71 (95% CI, 0.49 to 1.03; P=0.07). The time to hemodynamic stabilization, the risk of catecholamine therapy and the duration of such therapy, the levels of troponin T and creatine kinase, and the rates of bleeding and stroke did not differ significantly between the two groups. Among patients who had multivessel coronary artery disease and acute myocardial infarction with cardiogenic shock, the 30-day risk of a composite of death or severe renal failure leading to renal-replacement therapy was lower among those who initially underwent PCI of the culprit lesion only than among those who underwent immediate multivessel PCI. (Funded by the European Union 7th Framework Program and others; CULPRIT-SHOCK ClinicalTrials.gov number, NCT01927549 .).",success
30145971,True,"Comparative Study;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",NCT01927549,databank,NCT01927549,NCT01927549,NCT01927549,NCT01927549|databank,NCT01927549|databank,True,"Among patients with acute myocardial infarction, cardiogenic shock, and multivessel coronary artery disease, the risk of a composite of death from any cause or severe renal failure leading to renal-replacement therapy at 30 days was found to be lower with percutaneous coronary intervention (PCI) of the culprit lesion only than with immediate multivessel PCI. We evaluated clinical outcomes at 1 year. We randomly assigned 706 patients to either culprit-lesion-only PCI or immediate multivessel PCI. The results for the primary end point of death or renal-replacement therapy at 30 days have been reported previously. Prespecified secondary end points at 1 year included death from any cause, recurrent myocardial infarction, repeat revascularization, rehospitalization for congestive heart failure, the composite of death or recurrent infarction, and the composite of death, recurrent infarction, or rehospitalization for heart failure. As reported previously, at 30 days, the primary end point had occurred in 45.9% of the patients in the culprit-lesion-only PCI group and in 55.4% in the multivessel PCI group (P=0.01). At 1 year, death had occurred in 172 of 344 patients (50.0%) in the culprit-lesion-only PCI group and in 194 of 341 patients (56.9%) in the multivessel PCI group (relative risk, 0.88; 95% confidence interval [CI], 0.76 to 1.01). The rate of recurrent infarction was 1.7% with culprit-lesion-only PCI and 2.1% with multivessel PCI (relative risk, 0.85; 95% CI, 0.29 to 2.50), and the rate of a composite of death or recurrent infarction was 50.9% and 58.4%, respectively (relative risk, 0.87; 95% CI, 0.76 to 1.00). Repeat revascularization occurred more frequently with culprit-lesion-only PCI than with multivessel PCI (in 32.3% of the patients vs. 9.4%; relative risk, 3.44; 95% CI, 2.39 to 4.95), as did rehospitalization for heart failure (5.2% vs. 1.2%; relative risk, 4.46; 95% CI, 1.53 to 13.04). Among patients with acute myocardial infarction and cardiogenic shock, the risk of death or renal-replacement therapy at 30 days was lower with culprit-lesion-only PCI than with immediate multivessel PCI, and mortality did not differ significantly between the two groups at 1 year of follow-up. (Funded by the European Union Seventh Framework Program and others; CULPRIT-SHOCK ClinicalTrials.gov number, NCT01927549 .).",success
29223432,True,Journal Article;Multicenter Study,,,,,,,,True,"Major bleeding is a frequent complication for patients with acute myocardial infarction (AMI) and is associated with significant morbidity and mortality. To develop a contemporary model for inhospital major bleeding that can both support clinical decision-making and serve as a foundation for assessing hospital quality. An inhospital major bleeding model was developed using the Acute Coronary Treatment and Intervention Outcomes Network Registry-Get With the Guidelines (ACTION Registry-GWTG) database. Patients hospitalized with AMI between January 1, 2012 and December 31, 2013 across 657 hospitals were used to create a derivation cohort (n=144,800) and a validation cohort (n=96,684). Multivariable hierarchal logistic regression was used to identify significant predictors of major bleeding. A simplified risk score was created to enable prospective risk stratification for clinical care. The rate of major bleeding in the overall population was 7.53%. There were 8 significant, independent factors associated with major bleeding: presentation after cardiac arrest (OR 2.99 [2.77-3.22]); presentation in cardiogenic shock (OR 2.22 [2.05-2.40]); STEMI (OR 1.72 [1.65-1.80]); presentation in heart failure (OR 1.55 [1.47-1.63]); baseline hemoglobin less than 12 g/dL (1.55 [1.48-1.63]); heart rate (per 10 beat per minute increase) (OR 1.13 [1.12-1.14]); weight (per 10 kilogram decrease) (OR 1.12 [1.11-1.14]); creatinine clearance (per 5-mL decrease) (OR 1.07 [1.07-1.08]). The model discriminated well in the derivation (C-statistic = 0.74) and validation (C-statistic = 0.74) cohorts. In the validation cohort, a risk score for major bleeding corresponded well with observed bleeding: very low risk (2.2%), low risk (5.1%), moderate risk (10.1%), high risk (16.3%), and very high risk (25.2%). The new ACTION Registry-GWTG inhospital major bleeding risk model and risk score offer a robust, parsimonious, and contemporary risk-adjustment method to support clinical decision-making and enable hospital quality assessment. Strategies to mitigate risk should be developed and tested as a means to lower costs and improve outcomes in an era of alternative payment models.",success
23684677,False,Journal Article;Review,,,,,,,,True,"Over the past decade, myocardial structure, cardiomyocyte function, and intramyocardial signaling were shown to be specifically altered in heart failure with preserved ejection fraction (HFPEF). A new paradigm for HFPEF development is therefore proposed, which identifies a systemic proinflammatory state induced by comorbidities as the cause of myocardial structural and functional alterations. The new paradigm presumes the following sequence of events in HFPEF: 1) a high prevalence of comorbidities such as overweight/obesity, diabetes mellitus, chronic obstructive pulmonary disease, and salt-sensitive hypertension induce a systemic proinflammatory state; 2) a systemic proinflammatory state causes coronary microvascular endothelial inflammation; 3) coronary microvascular endothelial inflammation reduces nitric oxide bioavailability, cyclic guanosine monophosphate content, and protein kinase G (PKG) activity in adjacent cardiomyocytes; 4) low PKG activity favors hypertrophy development and increases resting tension because of hypophosphorylation of titin; and 5) both stiff cardiomyocytes and interstitial fibrosis contribute to high diastolic left ventricular (LV) stiffness and heart failure development. The new HFPEF paradigm shifts emphasis from LV afterload excess to coronary microvascular inflammation. This shift is supported by a favorable Laplace relationship in concentric LV hypertrophy and by all cardiac chambers showing similar remodeling and dysfunction. Myocardial remodeling in HFPEF differs from heart failure with reduced ejection fraction, in which remodeling is driven by loss of cardiomyocytes. The new HFPEF paradigm proposes comorbidities, plasma markers of inflammation, or vascular hyperemic responses to be included in diagnostic algorithms and aims at restoring myocardial PKG activity.",success
28433667,False,Journal Article;Meta-Analysis;Systematic Review,,,,,,,,True,"Cognitive impairment and dementia are associated with a range of cardiovascular conditions, including hypertension, coronary artery disease, and atrial fibrillation. We aimed to describe the association with heart failure, summarizing published data to give estimates of prevalence, incidence, and relative risk of cognitive impairment/dementia in heart failure. We searched multidisciplinary databases including MEDLINE (OVID), EMBASE (OVID), CINAHL (EBSCO), PsychINFO (EBSCO), Web of Science (Thomson Reuters), and CENTRAL (Cochrane Library) from inception until May 31, 2015. All relevant studies looking at cognitive impairment/dementia in heart failure were included. Studies were selected by 2 independent reviewers using prespecified inclusion/exclusion criteria. Where data allowed, we performed meta-analysis and pooled results using random effects models. From 18,000 titles, 37 studies were eligible (n = 8411 participants). Data from 4 prospective cohorts (n = 2513 participants) suggest greater cognitive decline in heart failure compared with non-heart failure over the longer term. These data were not suitable for meta-analysis. In case control studies describing those with and without heart failure (n = 4 papers, 1414 participants) the odds ratio for cognitive impairment in the heart failure population was 1.67 (95% confidence interval 1.15-2.42). Prevalence of cognitive impairment in heart failure cohorts (n = 26 studies, 4176 participants) was 43% (95% confidence interval 30-55). This review suggests a substantial proportion of patients with heart failure have concomitant cognitive problems. This has implications for planning treatment and services. These data do not allow us to comment on causation, and further work is needed to describe the underlying pathophysiology.",success
27072307,False,"Journal Article;Observational Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"The aim of this study was to evaluate the prevalence, clinical features, and the independent impact of frailty-a geriatric syndrome characterized by the decline of physiological systems-and its components, on prognosis after heart failure (HF) hospitalization. FRAIL-HF is a prospective cohort study including 450 non-dependent patients ≥70 years old hospitalized for HF. Frailty was screened according to the biological phenotype criteria (low physical activity, weight loss, slow walking speed, weak grip strength, and exhaustion). The independent influence of frailty on mortality, functional decline, and readmission risks was calculated adjusted for HF characteristics and co-morbidities. Mean age was 80 ± 6 years; 76% fulfilled frailty criteria. Frail patients were older, more often female, but showed no differences in chronic co-morbidities, LVEF, and NT-proBNP levels. Slow walking speed was the most discriminative component between frail (89.2%) and non-frail patients (26%). Overall, 1-year survival was 89% in the non-frail group and 75% in frail subjects (P = 0.003). After adjusting for age, gender, chronic and acute co-morbidities, NYHA, and NT-proBNP, frail patients showed higher risks for 30-day functional decline [odds ratio (OR) 2.20, 95% confidence interval (CI) 1.19-4.08], 1-year all-cause mortality [hazard ratio (HR) 2.13, 95% CI 1.07-4.23], and 1-year readmission (OR 1.96, 95% CI 1.14-3.34). The association of individual components with 1-year adjusted mortality risk was HR 2.14, 95% CI 1.05-4.39 for low physical activity and HR 1.77, 95% CI 0.95-3.29 for slow walking speed. Frailty is highly prevalent even among non-dependent elderly HF patients, and is an independent predictor of early disability, long-term mortality, and readmission. Individual frailty components may be useful for risk prediction.",success
30219550,False,Journal Article;Observational Study,,,,,,,,True,"Frailty reflects decreased resilience to physiological stressors; its prevalence and prognosis are not fully defined in heart failure with preserved ejection fraction (HFpEF). The Short Physical Performance Battery (SPPB) was prospectively obtained in 114 outpatients with HFpEF. The SPPB tests gait speed, tandem balance, and timed chair rises, each scored from 0 to 4 points. Severe and mild frailty were respectively defined as an SPPB score ≤6 and 7-9 points. We used risk-adjusted logistic, Poisson, and negative binominal regression, respectively, to assess the relationship between SPPB score and risk of death or all-cause hospitalization, number of hospitalizations, and days hospitalized or dead longer than 6 months. Patients were similar to other HFpEF cohorts (age 68 ± 13 years, 58% female, body mass index 36 ± 8 kg/m<sup>2</sup>, multiple comorbidities). Mean SPPB score was 6.9 ± 3.2, and 80% of patients were at least mildly frail. Over a 6-month period, the SPPB score independently predicted death or all-cause hospitalization (odds ratio 0.81 per point, 95% confidence interval [CI] 0.69-0.94, P = .006), number of hospitalizations (incidence rate ratio 0.92 per point, 95% CI 0.86-0.97, P = .006), and days hospitalized or dead (incidence rate ratio 0.85 per point, 95% CI 0.73-0.99, P = .04). Lower extremity function, as measured by the SPPB, independently predicts hospitalization burden in outpatients with HFpEF. Additional studies are warranted to explore shared mechanisms and treatment implications of frailty in HFpEF.",success
28794121,False,Comparative Study;Journal Article,,,,,,,,True,"Early reports suggest the number of cardiac intensive care unit (CICU) patients with primary noncardiac diagnoses is rising in the United States, but no national data currently exist. We examined changes in primary noncardiac diagnoses among elderly patients admitted to a CICU during the past decade. Using 2003 to 2013 Medicare data, we grouped elderly patients admitted to CICUs into 2 categories based on principal diagnosis at discharge: (1) primary noncardiac diagnoses and (2) primary cardiac diagnoses. We examined changes in patient demographics, comorbidities, procedure use, and risk-adjusted in-hospital mortality. Among 3.4 million admissions with a CICU stay, primary noncardiac diagnoses rose in prevalence from 38.0% to 51.7% between 2003 and 2013. The fastest rising primary noncardiac diagnoses were infectious diseases (7.8%-15.1%) and respiratory diseases (6.0%-7.6%; <i>P</i><0.001 for both), whereas the fastest declining primary cardiac diagnosis was coronary artery disease (32.3%-19.0%; <i>P</i><0.001). Simultaneously, the prevalence of both cardiovascular and noncardiovascular comorbidities rose: heart failure (13.9%-34.4%), pulmonary vascular disease (1.2%-7.1%), valvular heart disease (5.0%-9.8%), and renal failure (7.1%-19.6%; <i>P</i><0.001 for all). As compared with those with primary cardiac diagnoses, elderly CICU patients with primary noncardiac diagnoses had higher rates of noncardiac procedure use and risk-adjusted in-hospital mortality (<i>P</i><0.001 for all). Risk-adjusted in-hospital mortality declined slightly in the overall cohort from 9.3% to 8.9% (<i>P</i><0.001). More than half of all elderly patients with a CICU stay across the United States now have primary noncardiac diagnoses at discharge. These patients receive different types of care and have worse outcomes than patients with primary cardiac diagnoses. Our work has important implications for the development of appropriate training and staffing models for the future critical care workforce.",success
27914806,True,Journal Article;Multicenter Study,,,,,,,,True,"International registries have reported a wide variation in coronary care unit (CCU) admission rates for patients hospitalized with acute coronary syndrome (ACS) or heart failure (HF). Little is known about variation in Canadian interprovincial use and outcomes. Canadian Institute of Health Information data were used to identify hospitalized patients admitted to a CCU with a primary diagnosis of ACS or HF between April 1, 2007 and March 31, 2013. We examined interprovincial differences in CCU admission rates, use of CCU restricted therapies in the first 2 days of admission, and the association between CCU admission rate and risk-adjusted in-hospital mortality at the provincial level. The CCU admission rate among 220,759 patients hospitalized with ACS and HF was 33%, and this varied significantly across provinces (interprovincial range [IPR] 17%-50%; P < 0.001). A majority (59%; IPR, 48%-84%; P < 0.001) of patients admitted to the CCU did not receive critical care restricted therapies within 2 days. In-hospital mortality also varied across provinces (10%; IPR, 5%-13%; P < 0.001). Although statistically significant (P < 0.001), the correlation between CCU admission rates and provincial risk-adjusted in-hospital mortality was low (r = -0.30). These findings highlight the need for national CCU admission criteria designed to reduce variability and improve health care resource use and outcomes.",success
28973065,True,Journal Article;Multicenter Study;Randomized Controlled Trial,NCT01508819,databank,NCT01508819,NCT01508819,NCT01508819,NCT01508819|databank,NCT01508819|databank,True,"The high mortality rate in critically ill elderly patients has led to questioning of the beneficial effect of intensive care unit (ICU) admission and to a variable ICU use among this population. To determine whether a recommendation for systematic ICU admission in critically ill elderly patients reduces 6-month mortality compared with usual practice. Multicenter, cluster-randomized clinical trial of 3037 critically ill patients aged 75 years or older, free of cancer, with preserved functional status (Index of Independence in Activities of Daily Living ≥4) and nutritional status (absence of cachexia) who arrived at the emergency department of one of 24 hospitals in France between January 2012 and April 2015 and were followed up until November 2015. Centers were randomly assigned either to use a program to promote systematic ICU admission of patients (n=1519 participants) or to follow standard practice (n=1518 participants). The primary outcome was death at 6 months. Secondary outcomes included ICU admission rate, in-hospital death, functional status, and quality of life (12-Item Short Form Health Survey, ranging from 0 to 100, with higher score representing better self-reported health) at 6 months. One patient withdrew consent, leaving 3036 patients included in the trial (median age, 85 [interquartile range, 81-89] years; 1361 [45%] men). Patients in the systematic strategy group had an increased risk of death at 6 months (45% vs 39%; relative risk [RR], 1.16; 95% CI, 1.07-1.26) despite an increased ICU admission rate (61% vs 34%; RR, 1.80; 95% CI, 1.66-1.95). After adjustments for baseline characteristics, patients in the systematic strategy group were more likely to be admitted to an ICU (RR, 1.68; 95% CI, 1.54-1.82) and had a higher risk of in-hospital death (RR, 1.18; 95% CI, 1.03-1.33) but had no significant increase in risk of death at 6 months (RR, 1.05; 95% CI, 0.96-1.14). Functional status and physical quality of life at 6 months were not significantly different between groups. Among critically ill elderly patients in France, a program to promote systematic ICU admission increased ICU use but did not reduce 6-month mortality. Additional research is needed to understand the decision to admit elderly patients to the ICU. clinicaltrials.gov Identifier: NCT01508819.",success
28266167,False,"Journal Article;Review;Research Support, N.I.H., Extramural",,,,,,,,True,"Frailty, a clinical syndrome that typically occurs in older adults, implies a reduced ability to tolerate biological stressors. Frailty accompanies many age-related diseases but can also occur without overt evidence of end-organ disease. The condition is associated with circulating inflammatory cytokines and sarcopenia, features that are shared with heart failure (HF). However, the biological underpinnings of frailty remain unclear and the interaction with HF is complex. Here, we describe the inflammatory pathophysiology that is associated with frailty and speculate that the inflammation that occurs with frailty shares common origins with HF. We discuss the limitations in investigating the pathophysiology of frailty due to few relevant experimental models. Leveraging current therapies for advanced HF and current known therapies to address frailty in humans may enable translational studies to better understand the inflammatory interactions between frailty and HF.",success
21295193,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Comorbidity, disability, and polypharmacy commonly complicate the care of patients with heart failure. These factors can change biological response to therapy, reduce patient ability to adhere to recommendations, and alter patient preference for treatment and outcome. Yet, a comprehensive understanding of the complexity of patients with heart failure is lacking. Our objective was to assess trends in demographics, comorbidity, physical function, and medication use in a nationally representative, community-based heart failure population. Using data from the National Health and Nutrition Examination Survey, we analyzed trends across 3 survey periods (1988-1994, 1999-2002, 2003-2008). We identified 1395 participants with self-reported heart failure (n=581 in 1988-1994, n=280 in 1999-2002, n=534 in 2003-2008). The proportion of patients with heart failure who were ≥80 years old increased from 13.3% in 1988-1994 to 22.4% in 2003-2008 (P <.01). The proportion of patients with heart failure who had 5 or more comorbid chronic conditions increased from 42.1% to 58.0% (P <.01). The mean number of prescription medications increased from 4.1 to 6.4 prescriptions (P <.01). The prevalence of disability did not increase but was substantial across all years. The phenotype of patients with heart failure changed substantially over the last 2 decades. Most notably, more recent patients have a higher percentage of very old individuals, and the number of comorbidities and medications increased markedly. Functional disability is prevalent, although it has not changed. These changes suggest a need for new research and practice strategies that accommodate the increasing complexity of this population.",success
23741057,False,Consensus Development Conference;Journal Article,,,,,,,,False,,success
24594551,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"In older adults hospitalized for heart failure, a poor score on a comprehensive geriatric assessment (CGA) is associated with worse prognosis during hospitalization and at 1 month after discharge. However, the association between the CGA score and long-term mortality is uncertain. This is a prospective study of 487 patients aged ≥75 years admitted for decompensated heart failure. At discharge, a CGA score (range, 0-10) was calculated based on limitation in activities of daily living, mobility limitation, comorbidity, cognitive decline, and previous medication use. The analysis of the association between the CGA score and 2-year subsequent mortality was performed with Cox regression and adjusted for the main confounders. A 1-point increase in the CGA score was associated with a 19% higher mortality (hazard ratio, 1.19; 95% confidence interval, 1.11-1.27). Results were similar regardless of age, sex, left ventricular ejection fraction, and the coexistence of atrial fibrillation, ischemic heart disease, or hypertensive cardiopathy. All components of the CGA score showed a consistent association with higher death risk: the hazard ratio (95% confidence interval) of mortality was 1.78 (1.25-2.54) with ≥3 versus 0 limitations in activities of daily living, 1.36 (1.0-1.86) with moderate or severe versus no or mild limitation in mobility, 1.98 (1.29-3.03) with a ≥5 versus ≤1 score on the Charlson index, 2.48 (1.84-3.34) with previous cognitive decline, and 1.77 (0.99-3.18) in those using ≥8 versus ≤3 medications. The score on a simple CGA is associated with long-term mortality in older patients hospitalized for heart failure.",success
26920682,False,Journal Article;Meta-Analysis;Systematic Review,,,,,,,,True,"Recent studies have suggested that undernutrition as defined using multidimensional nutritional evaluation tools may affect clinical outcomes in heart failure (HF). The evidence supporting this correlation is unclear. Therefore, we conducted this systematic review to critically appraise the use of multidimensional evaluation tools in the prediction of clinical outcomes in HF. We performed descriptive analyses of all identified articles involving qualitative analyses. We used STATA to conduct meta-analyses when at least three studies that tested the same type of nutritional assessment or screening tools and used the same outcome were identified. Sensitivity analyses were conducted to validate our positive results. We identified 17 articles with qualitative analyses and 11 with quantitative analysis after comprehensive literature searching and screening. We determined that the prevalence of malnutrition is high in HF (range 16-90 %), particularly in advanced and acute decompensated HF (approximate range 75-90 %). Undernutrition as identified by multidimensional evaluation tools may be significantly associated with hospitalization, length of stay and complications and is particularly strongly associated with high mortality. The meta-analysis revealed that compared with other tools, Mini Nutritional Assessment (MNA) scores were the strongest predictors of mortality in HF [HR (4.32, 95 % CI 2.30-8.11)]. Our results remained reliable after conducting sensitivity analyses. The prevalence of malnutrition is high in HF, particularly in advanced and acute decompensated HF. Moreover, undernutrition as identified by multidimensional evaluation tools is significantly associated with unfavourable prognoses and high mortality in HF.",success
26542502,False,Journal Article;Observational Study,,,,,,,,True,"Delirium is one of the most frequent complications of hospitalization in elderly patients. Its influence on prognosis in patients admitted for acute cardiac diseases is not well known. The objective of this study is to assess the incidence of delirium and its impact on clinical and functional outcomes in older patients hospitalized for acute cardiac diseases. We prospectively analyzed 203 patients aged 75years or older admitted to a cardiology unit. Delirium was diagnosed with the Confusion Assessment Method. Logistic regression analysis was used to assess independent predictors of in-hospital delirium and to examine the independent risk of mortality, readmission, functional decline, and need for new help at discharge, at 1month and 12months associated with the development of delirium, after adjusting for age, comorbidity, and initial diagnosis. The incidence of delirium was 17.2%. Patients with delirium were older (83±5 vs 81±5years, P=.016) and showed a higher prevalence of major geriatric syndromes (82.9% vs 54.5%, P=.002). Aggressive ventilation modes, urinary catheters, prolonged fluid therapy, night treatments, longer immobilization, and physical restrain were associated with the incidence of delirium. Patients with delirium presented longer stays (8.9±6.2 vs 6.5±4.0days, P=.016) and a greater adjusted risk of functional decline at discharge (odds ratio 2.94, 95% CI 1.10-7.86, P=.032) and of 12-month mortality (odds ratio 4.20, 95% CI 1.81-9.74, P=.001). Delirium is a common preventable complication in older patients with acute cardiac diseases. It is associated with poorer in-hospital functional and clinical outcomes, and increased postdischarge mortality.",success
25122628,True,"Clinical Trial;Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"The exact relationship between the bed rest-induced loss of skeletal muscle and reductions in muscle strength and physical performance in the older individuals is still unclear. We examined the effect of 10 days of bed rest on changes in regional body composition, muscle strength, and functional status, and the relationship between these variables in older individuals. Regional body composition was measured using dual energy x-ray absorptiometry. We also determined changes in leg strength and several indices of functional status, including walking speed. Body weight, body mass index, and total and lower extremity lean mass decreased with bed rest. There were also significant reductions in knee extension one repetition maximum, isometric knee extension, knee extension 60° concentric, stair ascent time, stair ascent power, stair descent time, VO2 max, floor transfer test, 5-minute walk time, and chair stand. The overall change in total and lower extremity lean mass was also directly related to bed rest-induced reductions in one repetition maximum knee extension. Bed rest promoted overall declines in muscle mass, muscle strength, and physical function in older individuals. The changes in lean tissue were closely correlated with the bed rest-induced decline of muscle strength.",success
26773077,False,Journal Article;Practice Guideline,,,,,,,,False,,success
22881367,False,Journal Article;Systematic Review,,,,,,,,True,"To systematically compare and pool the prevalence of frailty, including prefrailty, reported in community-dwelling older people overall and according to sex, age, and definition of frailty used. Systematic review of the literature using the key words elderly, aged, frailty, prevalence, and epidemiology. Cross-sectional data from community-based cohorts. Community-dwelling adults aged 65 and older. In the studies that were found, frailty and prefrailty were measured according to physical phenotype and broad phenotype, the first defining frailty as a purely physical condition and the second also including psychosocial aspects. Reported prevalence in the community varies enormously (range 4.0-59.1%). The overall weighted prevalence of frailty was 10.7% (95% confidence interval (CI) = 10.5-10.9; 21 studies; 61,500 participants). The weighted prevalence was 9.9% for physical frailty (95% CI = 9.6-10.2; 15 studies; 44,894 participants) and 13.6% for the broad phenotype of frailty (95% CI = 13.2-14.0; 8 studies; 24,072 participants) (chi-square (χ(2) ) = 217.7, degrees of freedom (df)=1, P < .001). Prevalence increased with age (χ(2) = 6067, df = 1, P < .001) and was higher in women (9.6%, 95% CI = 9.2-10.0%) than in men (5.2%, 95% CI = 4.9-5.5%; χ(2) = 298.9 df = 1, P < .001). Frailty is common in later life, but different operationalization of frailty status results in widely differing prevalence between studies. Improving the comparability of epidemiological and clinical studies constitutes an important step forward.",success
17087693,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"To characterize physiological variation in hospitalized older adults with severe coronary artery disease (CAD) and evaluate the prevalence of frailty in this sample, to determine whether single-item performance measures are good indicators of multidimensional frailty, and to estimate the association between frailty and 6-month mortality. Observational cohort study. Inpatient hospital cardiology ward. Three hundred nine consecutive inpatients aged 70 and older admitted to a cardiology service (n = 309; 70% male, 84% white) with minimum two-vessel CAD determined using cardiac catheterization. Two standard frailty phenotypes (Composite A and Composite B), usual gait speed, grip strength, chair stands, cardiology clinical variables, and 6-month mortality. Prevalence of frailty was 27% for Composite A versus 63% for Composite B. Utility of single-item measures for identifying frailty was greatest for gait speed (receiver operating characteristic curve c statistic = 0.89 for Composite A, 0.70 for Composite B) followed by chair-stands (c = 0.83, 0.66) and grip strength (c = 0.78, 0.57). After adjustment, composite scores and single-item measures were individually associated with higher mortality at 6 months. Slow gait speed (< or =0.65 m/s) and poor grip strength (< or =25 kg) were stronger predictors of 6-month mortality than either composite score (gait speed odds ratio (OR)=3.8, 95% confidence interval (CI) = 1.1-13.1; grip strength OR = 2.7, 95% CI = 0.7-10.0; Composite A OR = 1.9, 95% CI = 0.60-6.1; chair-stand OR = 1.5, 95% CI = 0.5-5.1; Composite B OR = 1.3, 95% CI = 0.3-5.2). Gait speed frailty was the strongest predictor of mortality in a population with CAD and may add to traditional risk assessments when predicting outcomes in this population.",success
17350971,True,"Journal Article;Multicenter Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"To identify the proportion and characteristics of patients with severe symptomatic mitral regurgitation (MR) who are denied surgery. In the Euro Heart Survey on valvular heart disease, 396 patients had severe symptomatic MR as assessed by Doppler-echocardiography (grade > or =3/4) and New York Heart Association class II or greater. Patient characteristics were analysed according to the decision to operate or not. A decision not to operate was taken in 193 patients (49%). In multivariable analysis, decreased left ventricular ejection fraction (LVEF) [OR = 1.39 per 10% decrease, 95% CI (1.17-1.66), P = 0.0002], non-ischaemic aetiology [OR = 4.44, 95% CI (1.96-10.76), P = 0.0006], older age [OR = 1.40 per 10-year increase, 95% CI (1.15-1.72), P = 0.001], increased Charlson comorbidity index [OR = 1.38 per 1 point increase, 95% CI (1.12-1.72), P = 0.004], and grade 3 MR [OR = 2.23, 95% CI (1.28-3.29), P = 0.005] were associated with the decision not to operate. One-year survival was 96.0 +/- 1.4% in patients with a positive decision for intervention vs. 89.5 +/- 2.3% in those with a negative decision (P = 0.02). Surgery was denied in 49% of patients with severe symptomatic MR. Impaired LVEF, older age, and comorbidity were the most striking characteristics of patients who were denied surgery. The weight of age and LVEF in the decision do not seem justified according to current knowledge.",success
20031890,True,"Journal Article;Multicenter Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"Some patients with severe symptomatic aortic stenosis (AS) do not undergo aortic valve replacement (AVR) despite demonstrated symptomatic and survival advantages and despite unequivocal guideline recommendations for surgical evaluation. In 3 large tertiary care institutions (university, Veterans Affairs, and private practice) in Washtenaw County, Mich, patients were identified with unrefuted echocardiography/Doppler evidence of severe AS during calendar year 2005. Medical records were retrospectively reviewed for symptoms, referral for AVR, calculated operative risk for AVR, and rationale as to why patients did not undergo valve replacement. Of 369 patients with severe AS, 191 (52%) did not undergo AVR. Of these, 126 (66%, 34% of total) had symptoms consistent with AS. The most common reasons cited for absent intervention were comorbidities with high operative risk (61 patients [48%]), patent refusal (24 patients [19%]), and symptoms unrelated to AS (24 patients [19%]). Operated patients had a lower Society of Thoracic Surgery-calculated perioperative mortality risk than unoperated patients (1.8% [interquartile range, 1.0 to 3.0%] versus 2.7% [interquartile range, 1.6 to 5.5%], P<0.001). However, 28 (24%) of 126 unoperated symptomatic patients had a calculated perioperative risk less than the median risk for patients who underwent AVR. Only 57 (30%) of 191 unoperated patients were evaluated by a cardiac surgeon. There were similar rates of intervention across practice settings, and similar rates of unoperated patients despite symptoms and low operative risk. One third of patients with severe AS are symptomatic but do not undergo AVR, with similar findings in multiple practice environments. For most unoperated patients, objectively calculated operative risks did not appear prohibitive. Despite this, a minority of unoperated patients were referred for surgical consultation. Some patients with severe symptomatic AS may be inappropriately denied access to potentially life-saving therapy.",success
27956264,True,Journal Article;Multicenter Study,,,,,,,,True,"The Society of Thoracic Surgeons (STS)/American College of Cardiology Transcatheter Valve Therapy (TVT) Registry captures all procedures with Food and Drug Administration-approved transcatheter valve devices performed in the United States, and is mandated as a condition of reimbursement by the Centers for Medicaid & Medicare Services. This annual report focuses on patient characteristics, trends, and outcomes of transcatheter aortic and mitral valve catheter-based valve procedures in the United States. We reviewed data for all patients receiving commercially approved devices from 2012 through December 31, 2015, that are entered in the TVT Registry. The 54,782 patients with transcatheter aortic valve replacement demonstrated decreases in expected risk of 30-day operative mortality (STS Predicted Risk of Mortality [PROM]) of 7% to 6% and transcatheter aortic valve replacement PROM (TVT PROM) of 4% to 3% (both p < 0.0001) from 2012 to 2015. Observed in-hospital mortality decreased from 5.7% to 2.9%, and 1-year mortality decreased from 25.8% to 21.6%. However, 30-day post-procedure pacemaker insertion increased from 8.8% in 2013 to 12.0% in 2015. The 2,556 patients who underwent transcatheter mitral leaflet clip in 2015 were similar to patients from 2013 to 2014, with hospital mortality of 2% and with mitral regurgitation reduced to grade ≤2 in 87% of patients (p < 0.0001). The 349 patients who underwent mitral valve-in-valve and mitral valve-in-ring procedures were high risk, with an STS PROM for mitral valve replacement of 11%. The observed hospital mortality was 7.2%, and 30-day post-procedure mortality was 8.5%. The TVT Registry is an innovative registry that that monitors quality, patient safety and trends for these rapidly evolving new technologies.",success
19564568,False,Journal Article;Review,,,,,,,,False,,success
28886619,False,Journal Article;Practice Guideline,,,,,,,,False,,success
24589853,False,Journal Article;Practice Guideline,,,,,,,,False,,success
29191323,True,Journal Article;Multicenter Study,,,,,,,,True,"Limited data exist about safety and efficacy of transcatheter aortic valve replacement (TAVR) in patients with pure native aortic regurgitation (AR). This study sought to compare the outcomes of TAVR with early- and new-generation devices in symptomatic patients with pure native AR. From the pure native AR TAVR multicenter registry, procedural and clinical outcomes were assessed according to VARC-2 criteria and compared between early- and new-generation devices. A total of 331 patients with a mean STS score of 6.7 ± 6.7 underwent TAVR. The early- and new-generation devices were used in 119 patients (36.0%) and 212 patients (64.0%), respectively. STS score tended to be lower in the new-generation device group (6.2 ± 6.7 vs. 7.6 ± 6.7; p = 0.08), but transfemoral access was more frequently used in the early-generation device group (87.4% vs. 60.8%; p < 0.001). Compared with the early-generation devices, the new-generation devices were associated with a significantly higher device success rate (81.1% vs. 61.3%; p < 0.001) due to lower rates of second valve implantation (12.7% vs. 24.4%; p = 0.007) and post-procedural AR ≥ moderate (4.2% vs. 18.8%; p < 0.001). There were no significant differences in major 30-day endpoints between the 2 groups. The cumulative rates of all-cause and cardiovascular death at 1-year follow-up were 24.1% and 15.6%, respectively. The 1-year all-cause mortality rate was significantly higher in the patients with post-procedural AR ≥ moderate compared with those with post-procedural AR ≤ mild (46.1% vs. 21.8%; log-rank p = 0.001). On multivariable analysis, post-procedural AR ≥ moderate was independently associated with 1-year all-cause mortality (hazard ratio: 2.85; 95% confidence interval: 1.52 to 5.35; p = 0.001). Compared with the early-generation devices, TAVR using the new-generation devices was associated with improved procedural outcomes in treating patients with pure native AR. In patients with pure native AR, significant post-procedural AR was independently associated with increased mortality.",success
28566471,True,Journal Article;Multicenter Study,,,,,,,,True,"The optimal treatment of patients with acute and severe decompensation of aortic stenosis is unclear due to recent advances in transcatheter interventions and supportive therapies. Our aim was to assess the early outcome of emergency transcatheter aortic valve implantation (eTAVI) versus emergency balloon aortic valvuloplasty (eBAV) followed by TAVI under elective circumstances. Emergency conditions were defined as: cardiogenic shock with requirement of catecholamine therapy, severe acute dyspnoea (NYHA IV), cardiac resuscitation or mechanic respiratory support. The data were collected according to the Valve Academic Research Consortium 2 (VARC-2) criteria. In five German centres, 23 patients (logistic Euroscore 37.7%±18.1) underwent eTAVI and 118 patients underwent eBAV (logistic Euroscore 35.3%±20.8). In the eTAVI group, immediate procedural mortality was 8.7%, compared with 20.3% for the eBAV group (p=0.19). After 30 days, cardiovascular mortality for the eTAVI group was 23.8% and for the eBAV group 33.0% (p=0.40). Analyses adjusting for potential confounders did not provide evidence of a difference between groups. Of note, the elective TAVI performed after eBAV (n=32, logistic Euroscore 25.9%±13.9) displayed an immediate procedural mortality of 9.4% and a cardiovascular mortality after 30 days of 15.6%. Major vascular complications were significantly more likely to occur after eTAVI (p=0.01) as well as stroke (p=0.01). In this multicentre cohort, immediate procedural and 30-day mortality of eTAVI and eBAV were high, and mortality of secondary TAVI subsequent to eBAV was higher than expected. Randomised study data are required to define the role of emergency TAVI in tertiary care centres with current device generations.",success
22443478,True,"Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",NCT00530894,databank,NCT00530894,NCT00530894,NCT00530894,NCT00530894|databank,NCT00530894|databank,True,"Transcatheter aortic-valve replacement (TAVR) is the recommended therapy for patients with severe aortic stenosis who are not suitable candidates for surgery. The outcomes beyond 1 year in such patients are not known. We randomly assigned patients to transfemoral TAVR or to standard therapy (which often included balloon aortic valvuloplasty). Data on 2-year outcomes were analyzed. A total of 358 patients underwent randomization at 21 centers. The rates of death at 2 years were 43.3% in the TAVR group and 68.0% in the standard-therapy group (P<0.001), and the corresponding rates of cardiac death were 31.0% and 62.4% (P<0.001). The survival advantage associated with TAVR that was seen at 1 year remained significant among patients who survived beyond the first year (hazard ratio, 0.58; 95% confidence interval [CI], 0.36 to 0.92; P=0.02 with the use of the log-rank test). The rate of stroke was higher after TAVR than with standard therapy (13.8% vs. 5.5%, P=0.01), owing, in the first 30 days, to the occurrence of more ischemic events in the TAVR group (6.7% vs. 1.7%, P=0.02) and, beyond 30 days, to the occurrence of more hemorrhagic strokes in the TAVR group (2.2% vs. 0.6%, P=0.16). At 2 years, the rate of rehospitalization was 35.0% in the TAVR group and 72.5% in the standard-therapy group (P<0.001). TAVR, as compared with standard therapy, was also associated with improved functional status (P<0.001). The data suggest that the mortality benefit after TAVR may be limited to patients who do not have extensive coexisting conditions. Echocardiographic analysis showed a sustained increase in aortic-valve area and a decrease in aortic-valve gradient, with no worsening of paravalvular aortic regurgitation. Among appropriately selected patients with severe aortic stenosis who were not suitable candidates for surgery, TAVR reduced the rates of death and hospitalization, with a decrease in symptoms and an improvement in valve hemodynamics that were sustained at 2 years of follow-up. The presence of extensive coexisting conditions may attenuate the survival benefit of TAVR. (Funded by Edwards Lifesciences; ClinicalTrials.gov number, NCT00530894.).",success
10985712,True,"Clinical Trial;Comparative Study;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Our objective was to define the outcomes of patients with cardiogenic shock (CS) due to severe mitral regurgitation (MR) complicating acute myocardial infarction (AMI). Methods for early identification and optimal treatment of such patients have not been defined. The SHOCK Trial Registry enrolled 1,190 patients with CS complicating AMI. We compared 1) the cohort with severe mitral regurgitation (MR, n = 98) to the cohort with predominant left ventricular failure (LVF, n = 879), and 2) the MR patients who underwent valve surgery (n = 43) to those who did not (n = 51). Shock developed early after MI in both the MR (median 12.8 h) and LVF (median 6.2 h) cohorts. The MR patients were more often female (52% vs. 37%, p = 0.004) and less likely to have ST elevation at shock diagnosis (41% vs. 63%, p < 0.001). The MR index MI was more frequently inferior (55% vs. 44%, p = 0.039) or posterior (32% vs. 17%, p = 0.002) than that of LVF and much less frequently anterior (34% vs. 59%, p < 0.001). Despite having higher mean LVEF (0.37 vs. 0.30, p = 0.001) the MR cohort had similar in-hospital mortality (55% vs. 61%, p = 0.277). The majority of MR patients did not undergo mitral valve surgery. Those undergoing surgery exhibited higher mean LVEF than those not undergoing surgery; nevertheless, 39% died in hospital. The data highlight opportunities for early identification and intervention to potentially decrease the devastating mortality and morbidity of severe post-myocardial infarction MR.",success
28607001,False,Case Reports;Journal Article;Video-Audio Media,,,,,,,,False,,success
19379882,False,Journal Article,,,,,,,,True,"With the advent of percutaneous valve implantation, an increasing amount of interest is being expressed in outcomes of conventional aortic valve replacement (AVR) in elderly patients. We evaluated characteristics and outcomes of elderly patients undergoing isolated AVR with a particular focus on the European System for Cardiac Operative Risk Evaluation (EuroSCORE) risk stratification. All patients aged 80 years or older (n = 282) undergoing isolated AVR between November 1995 and June 2006 at our institution were reviewed according to logistic EuroSCORE (ES(log)) risk stratification. Surgical risk was defined as low risk (ES(log) < or = 10% [n = 107]), moderate risk (10% < ES(log) < 20% [n = 103]), and high risk (ES(log) > or = 20% [n = 72]). Patient age was 82 +/- 2 years (low risk), 82.7 +/- 2.7 years (moderate risk), and 83.6 +/- 3.1 years (high risk), respectively (p < 0.05). Mean ES(log) predicted risk of mortality was 7.3% +/- 1.4% (low risk), 13.7% +/- 2.5% (moderate risk), and 33.0% +/- 11.5% (high risk; p < 0.05). Follow-up was 99.7% complete. In-hospital mortality was 7.5% (low risk), 12.6% (moderate risk), and 12.5% (high risk; p = 0.4). One-year survival was 90%, 78%, and 69% (p = 0.002); 5-year survival was 70%, 53%, and 38% (p = 0.05); and 8-year survival was 38%, 33%, and 21% (p = 0.017), for low-, moderate-, and high-risk patients, respectively. Independent predictors for in-hospital mortality were pulmonary hypertension and urgent indication for surgery. Cox regression predictors of medium-term survival were congestive heart failure, urgent timing, previous stroke or transient ischemic attack, and EuroSCORE stratum. Aortic valve replacement can be performed in the elderly population with acceptable outcomes. EuroSCORE risk stratification is imprecise for prediction of perioperative mortality among octogenarian AVR patients, but may be useful for predicting mortality during medium-term follow-up.",success
20048216,False,Journal Article,,,,,,,,True,"Age >90 years represents in many centers an absolute contraindication to cardiac surgery. Nonagenarians are a rapidly growing subset of the population posing an expanding clinical problem. To provide helpful information in regard to this complex decision, we analyzed the operative and 5-year results of coronary and valvular surgical procedures in these patients. We retrospectively reviewed 127 patients aged >or=90 years who underwent cardiac surgery within our hospital group in the period 1998 to 2008. Kaplan-Meier and multiple logistic regression analyses were performed. A longer follow-up than most published studies and the largest series published thus far are presented. Mean age was 92 years (range, 90 to 103 years). Mean logistic EuroSCORE was 21.3+/-6.1. Sixty patients had valvular surgery (including 11 valve repairs), 49 patients had coronary artery bypass grafting, and 18 had valvular plus coronary artery bypass grafting surgery (55 left mammary artery grafts implanted). Forty-five patients (35.4%) were operated on nonelectively. Operative mortality was 13.4% (17 cases). Fifty-four patients (42.5%) had a complicated postoperative course. There were no statistically significant differences in the rate and type of complications between patient strata on the basis of type of surgery performed. Nonelective priority predicted a complicated postoperative course. Predictors of operative mortality were nonelective priority and previous myocardial infarction. Kaplan-Meier survival estimates at 5 years were comparable between patient groups on the basis of procedure performed. Although the rate of postoperative complications remains high, cardiac surgery in nonagenarians can achieve functional improvement at the price of considerable operative and follow-up mortality rates. Cardiac operations in these very elderly subjects are supported if appropriate selection is made and if the operation is performed earlier and electively. Our results should contribute to the development of guidelines for cardiac operations in nonagenarians.",success
24958751,True,Journal Article;Multicenter Study;Validation Study,NCT00530894,databank,NCT00530894,NCT00530894,NCT00530894,NCT00530894|databank,NCT00530894|databank,True,"Transcatheter aortic valve replacement (TAVR) is a less invasive option for treatment of high-risk patients with severe aortic stenosis. We sought to identify patients at high risk for poor outcome after TAVR using a novel definition of outcome that integrates quality of life with mortality. Among 2137 patients who underwent TAVR in the PARTNER (Placement of Aortic Transcatheter Valve) trial or its associated continued access registry, quality of life was assessed with the Kansas City Cardiomyopathy Questionnaire-Overall Summary Scale (KCCQ-OS; range 0-100, where a higher score equates to a better quality of life) at baseline and at 1, 6, and 12 months after TAVR. A poor 6-month outcome (defined as death, KCCQ-OS score <45, or ≥10-point decrease in KCCQ-OS score compared with baseline) occurred in 704 patients (33%). Using a split-sample design, we developed a multivariable model to identify a parsimonious set of covariates to identify patients at high risk for poor outcome. The model demonstrated moderate discrimination (c-index=0.66) and good calibration with the observed data, performed similarly in the separate validation cohort (c-index=0.64), and identified 211 patients (10% of the population) with a ≥50% likelihood of a poor outcome after TAVR. A second model that explored predictors of poor outcome at 1 year identified 1102 patients (52%) with ≥50% likelihood and 178 (8%) with ≥70% likelihood of a poor 1-year outcome after TAVR. Using a large, multicenter cohort, we have developed and validated predictive models that can identify patients at high risk for a poor outcome after TAVR. Although model discrimination was moderate, these models may help guide treatment choices and offer patients realistic expectations of outcomes based on their presenting characteristics. http://www.clinicaltrials.gov. Unique identifier: NCT00530894.",success
27765189,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"A series of models have been developed to identify patients at high risk for poor outcomes after transcatheter aortic valve replacement (TAVR) to help guide treatment choices, offer patients realistic expectations of long-term outcomes, and support decision making. This study examined the performance of the previously developed TAVR Poor Outcome risk models in an external dataset and explored the incremental contribution of geriatric domains to model performance. Poor outcome after TAVR was defined as death, poor quality of life (QOL), or decline in QOL, as assessed using the Kansas City Cardiomyopathy Questionnaire. We tested 4 TAVR Poor Outcome risk models: 6-month and 1-year full and clinical (reduced) models. We examined each model's discrimination and calibration in the CoreValve trial dataset, and then tested the incremental contribution of frailty and disability markers to the model's discrimination using the incremental discrimination index. Among 2,830 patients who underwent TAVR in the CoreValve US Pivotal Extreme and High Risk trials and associated continued access registries, 31.2% experienced a poor outcome at 6 months following TAVR (death, 17.6%; very poor QOL, 11.6%; QOL decline, 2.0%) and 50.8% experienced a poor outcome at 1 year (death, 30.2%; poor QOL, 19.6%; QOL, decline 1.0%). The models demonstrated similar discrimination as in the Placement of Aortic Transcatheter Valves Trial cohorts (c-indexes, 0.637 to 0.665) and excellent calibration. Adding frailty as a syndrome increased the c-indexes by 0.000 to 0.004 (incremental discrimination index, p < 0.01 for all except the 1-year clinical model), with the most important individual components being disability and unintentional weight loss. Although discrimination of the TAVR Poor Outcome risk models was generally moderate, calibration was excellent among patients with different risk profiles and treated with a different TAVR device. These findings demonstrated the value of these models for individualizing outcome predictions in high-risk patients undergoing TAVR.",success
23628298,False,Journal Article;Meta-Analysis,,,,,,,,True,"Coronary artery disease (CAD) negatively affects prognosis in patients undergoing surgical aortic valve replacement, being currently evaluated in the most common used risk score. Our meta-analysis aims to clarify the prognostic role of CAD on mid-term survival in patients undergoing TAVI. Studies reporting multivariate predictors of adverse outcomes in patients undergoing TAVI were systematically searched for and pooled, when appropriate, using a random-effect method. 960 citations were first screened and finally 7 studies (2472 patients) were included. Diagnosis of CAD was reported in 52%(42-65) of patients and 1169 Edwards SAPIEN and 1303 CoreValve prostheses were implanted. After a median follow up of 452 days (357-585) 24% of patients (19-33) died, and 23 (14-32) for cardiovascular death. At pooled analysis of multivariate approach, diagnosis of coronary artery disease did not increase risk of death (OR 1.0, 95% CI, confidence interval, 0.67-1.50 I(2) 0%). CAD does not affect mid-term TAVI outcome: this finding should be weighted to accurately evaluate risk and strategies for patients with severe aortic stenosis.",success
27931592,False,Journal Article;Practice Guideline;Review,,,,,,,,True,"Transcatheter aortic valve replacement (TAVR) is an effective, nonsurgical treatment option for patients with severe aortic stenosis. The optimal treatment strategy for treating concomitant coronary artery disease (CAD) has not been tested prospectively in a randomized clinical trial. Nevertheless, it is standard practice in the United States to perform coronary angiography and percutaneous coronary intervention for significant CAD at least 1 month before TAVR. All existing clinical trials were designed using this strategy. Therefore, it is wrong to extrapolate current American College of Cardiology/American Heart Association Appropriate Use Criteria against invasive procedures in asymptomatic patients to the TAVR population when evaluating the quality of care by cardiologists or hospitals. In this statement from the Interventional Section Leadership Council of the ACC, it is recommended that percutaneous coronary intervention should be considered in all patients with significant proximal coronary stenosis in major coronary arteries before TAVR, even though the indication is not covered in current guidelines.",success
11642893,False,Journal Article,,,,,,,,False,,success
28747535,False,Journal Article;Review,,,,,,,,True,"Valvular heart disease (VHD), particularly aortic valve disease, is prevalent with increasing incidence. When surgery is not possible, or when risks outweigh benefits, percutaneous treatment options may offer effective alternatives. However, procedures may not always go as planned, and frail patients or those whose symptoms are caused by other comorbidities may not benefit from valve intervention at all. Significant effort should be made to assess frailty, comorbidities and patient goals prior to intervention. Palliative care (PC) should play a critical role in the care of patients with severe valve disease. PC is specialised medical care that aims to optimise health-related quality of life by managing symptoms and clarifying patient values and goals of care. It should be implemented at the time of diagnosis and continue throughout the disease course. Because of the paucity of studies dedicated to the provision of PC to patients with advanced VHD, further research is needed.",success
29879568,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Little is known about the effects of early mobilization in older adults in the Cardiovascular Intensive Care Unit (CICU). We reviewed consecutive patients ≥60 years of age admitted to the CICU at an academic tertiary care center from 2016 to 2017. The level of function (LOF) was assessed prehospital, at CICU admission, and at CICU transfer using a graded scale ranging from LOF 1 (bedbound) to 4 (walk > 50 ft). The prehospital frailty status was assessed using Rockwood's Clinical Frailty Scale. We sought to determine whether the mean change of LOF during CICU admission differed based on frailty status. There were 264 patients in the cohort (77.1 ± 9.3 years old; 40% female; 34% frail). Frail patients were more likely to have lower prehospital, CICU admission, day of transfer LOFs (all P < 0.001). The mean LOF improvement during CICU stay was 0.5 ± 0.8 and did not differ based on frailty status. Frailty was not predictive of EM responsiveness in the adjusted analysis. EM is feasible in older adults admitted to the CICU. Functional status improved in both frail and non-frail older adults during CICU admission. Prospective studies are needed to determine whether frail older adults may benefit from EM.",success
21810861,False,Journal Article;Review,,,,,,,,True,"Acute aortic syndrome (AAS) is a modern term to describe interrelated emergency aortic conditions with similar clinical characteristics and challenges. These conditions include aortic dissection, intramural haematoma (IMH), and penetrating atherosclerotic ulcer (PAU and aortic rupture); trauma to the aorta with intimal laceration may also be considered. The common denominator of AAS is disruption of the media layer of the aorta with bleeding within IMH, along the aortic media resulting in separation of the layers of the aorta (dissection), or transmurally through the wall in the case of ruptured PAU or trauma. Population-based studies suggest that the incidence of acute dissection ranges from 2 to 3.5 cases per 100 000 person-years; hypertension and a variety of genetic disorders with altered connective tissues are the most prevalent risk conditions. Patients with AAS often present in a similar fashion, regardless of the underlying condition of dissection, IMH, PAU, or contained aortic rupture. Pain is the most commonly presenting symptom of acute aortic dissection and should prompt immediate attention including diagnostic imaging modalities (such as multislice computed tomography, transoesophageal ultrasound, or magnetic resonance imaging). Prognosis is clearly related to undelayed diagnosis and appropriate surgical repair in the case of proximal involvement of the aorta; affection of distal segments of the aorta may call for individualized therapeutic approaches favouring endovascular in the presence of malperfusion or imminent rupture, or medical management.",success
12204498,False,Evaluation Study;Journal Article,,,,,,,,True,"We sought to evaluate the clinical characteristics, management, and outcomes of elderly patients with acute type A aortic dissection. Few data exist on the clinical manifestations and outcomes of acute type A aortic dissection in an elderly patient cohort. We categorized 550 patients with type A aortic dissection enrolled in the International Registry of Acute Aortic Dissection into two age strata (<70 and >or=70 years) and compared their clinical features, management, and in-hospital events. Thirty-two percent of patients with type A dissection were aged >or=70 years. Marfan syndrome was exclusively associated with dissection in the young, whereas hypertension, atherosclerosis and iatrogenic dissection predominated in older patients. Typical symptoms (abrupt onset of chest or back pain) and signs (aortic regurgitation murmur or pulse deficits) of dissection were less common among the elderly. Fewer elderly patients were managed surgically than younger patients (64% vs. 86%, p < 0.0001). Hypotension occurred more frequently (46% vs. 32%, p = 0.002) and focal neurologic deficits less frequently (18% vs. 26%, p = 0.04) among the elderly. In-hospital mortality was higher among older patients (43% vs. 28%, p = 0.0006). Logistic regression analysis identified age >or=70 years as an independent predictor of hospital death for acute type A aortic dissection (odds ratio 1.7, 95% confidence interval 1.1-2.8; p = 0.03). Our study shows significant differences between older (age >or=70 years) and younger (age <70 years) patients with acute type A aortic dissection in their clinical characteristics, management, and hospital outcomes. Future research should evaluate strategies to improve outcomes in this high-risk elderly cohort.",success
23657079,True,"Comparative Study;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",,,,,,,,True,"To determine the association between age and clinical presentation, management and surgical outcomes in a large contemporary, prospective cohort of patients with acute aortic dissection type A (AADA). AADA is one of the most life-threatening cardiovascular diseases, and delayed surgery or overly conservative management can result in sudden death. The perioperative and intraoperative conditions of 2137 patients prospectively reported to the multicenter German Registry for Acute Aortic Dissection Type A were analyzed. Of all patients with AADA, 640 (30%) were 70 years or older and 160 patients (7%) were younger than 40 years. The probability of aortic dissection extension to the supra-aortic vessels and abdominal aorta decreased with age (P < 0.0001 and P = 0.0017, respectively). In 1447 patients (69%), the aortic root was preserved and supracoronary replacement of the ascending aorta was done. The probability of this procedure increased with age (P < 0.0001). The incidence of new postoperative neurological disorders was not influenced by age. The lowest probability of 30-day mortality was noted in the youngest patients (11%-14% for patients aged between 20 and 40 years) and rose progressively with age, peaking at 25% in octogenarians. This study reflects current results after surgical treatment of AADA in relation to patient age. Current survival rates are acceptable, even in very elderly patients. The contemporary surgical mortality rate among young patients is lower than that previously reported in the literature. The postoperative stroke incidence does not increase with age.",success
27563539,False,Journal Article;Review,,,,,,,,True,"The results of surgical treatment of type A aortic dissection (AAD) in the elderly are controversial and aggravated by a higher operative mortality rate. The studies published in this subset of patients are mainly retrospective analyses or small samples from international registries. We sought to investigate this topic by conducting a contemporary meta-analysis of the most recent observational studies. A systematic literature search was conducted for any study published in the last five years on aortic dissection treated surgically in patients 70 years and older. A pooled risk-ratio meta-analysis has been conducted three main post-operative outcomes: short-term mortality, stroke and acute kidney injury. A total of 11 retrospective observational studies have been included in the quantitative meta-analysis. Pooled meta-analysis showed an increased risk of short term mortality for the elderly population [relative risk (RR) =2.25; 95% CI, 1.79-2.83; I (2)=0%; P<0.0001], and this has been confirmed in a sub-analysis of patients 80 years and older. The risk of having stroke (RR =1.15; 95% CI, 0.89-1.5; I (2)=0%; P=0.28) and acute kidney injury (RR =0.79; 95% CI, 0.5-1.25, I (2)=14%, P=0.31) after surgery were comparable to the younger cohort of patients. Although affected by an increased risk of short-term mortality in the elderly, surgical repair remains the treatment of choice for AAD. The main post-operative outcomes are comparable to younger patients and the mid-term survival rates are acceptable.",success
20176372,True,"Comparative Study;Journal Article;Multicenter Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"The increasing life expectancy of the population will likely be accompanied by a rise in the incidence of acute type A aortic dissection. However, because of an increased risk of cardiac surgery in an elderly population, it is important to define when, if at all, the risks of aortic repair outweigh the risk of death from unoperated type A aortic dissection. We analyzed 936 patients with type A aortic dissection enrolled in the International Registry of Acute Aortic Dissection from 1996 to 2004. Patients with type A aortic dissection were categorized according to patient age by decade and by surgical versus medical management, and outcomes of both management types were investigated in the different age groups. The rate of surgical aortic repair decreased progressively with age, whereas surgical mortality significantly increased with age. Age 70 years or more was an independent predictor for mortality (38.2% vs 26.0%; P < .0001, odds ratio 1.73). The in-hospital mortality rate was significantly lower after surgical management compared with medical management until the age of 80 years. For patients aged 80 to 90 years, the in-hospital mortality appeared to be lower after surgical management (37.9% vs 55.2%; P = .188); however, this failed to reach clinical significance owing to the limited patient number in this age group. Although the surgical mortality significantly increased with increased age, surgical management was still associated with significantly lower in-hospital mortality rates compared with medical management until the age of 80 years. Surgery may decrease the in-hospital mortality rate for octogenarians with type A aortic dissection and might be considered in all patients with type A aortic dissection regardless of age.",success
23267524,False,Comparative Study;Journal Article,,,,,,,,True,"Surgery in octogenarians with acute type A aortic dissection is commonly avoided or denied because of the high surgical morbidity and mortality reported in elderly patients. We sought to compare clinical and quality of life outcomes between octogenarians and those aged less than 80 years who underwent surgical repair at New York Medical College. A total of 101 cases of acute type A aortic dissection repair between July 2005 and December 2011 were retrospectively analyzed, comparing 21 octogenarians with 80 concurrent patients aged less than 80 years. All patients underwent corrective surgery (ascending/hemiarch replacement in 71; Bentall in 22; David procedure in 2; Wheat procedure in 4; total arch replacement in 2) using deep hypothermic circulatory arrest. During follow-up, the RAND 36-Item Short Form Health Survey Questionnaire was used to assess quality of life. Octogenarians (average, 85 years; range, 80-91 years) were compared with the younger group (average, 60 years; range, 30-79 years). The 2 groups had similar preoperative characteristics, but the younger group experienced more malperfusion (40% vs 9%, P = .002), were more likely to have undergone a Bentall procedure (26% vs 5%, P = .04), and had longer circulatory arrest times (20 ± 7 minutes vs 16 ± 9 minutes, P = .03). The overall hospital mortality was 9% (9/101). Among octogenarians, there were no hospital deaths, no late deaths during follow-up (mean, 17 months; range, 1-59 months), and emotional health scores were better than those of the younger patients (P = .04). Surgery for acute type A aortic dissection should be offered to octogenarians because excellent surgical and quality of life outcomes can be achieved even in this elderly population.",success
23228401,False,Journal Article;Observational Study,,,,,,,,True,"We sought to evaluate surgical outcomes of type A acute aortic dissection in elderly patients. Between January 2004 and July 2011, 422 patients underwent emergency open surgery for type A acute aortic dissection at our institution. Of those, 124 patients who were ≥75 years (mean age, 78.6 ± 3.4 years) were reviewed. We also reviewed 26 patients (≥75 years old) who were diagnosed with acute aortic dissection at our institution during the same period but who did not undergo surgery. We analyzed early and late outcomes of surgical and nonsurgical patients. The operative mortality was 4.8% (6/124), and the incidences of stroke and prolonged hospital stay (>30 days) were 17.7% (22/124) and 20.1% (25/124), respectively. The actuarial survivals at 1, 3, and 5 years were 89.3%, 84.7%, and 79.1%, respectively. Predictors of stroke are preoperative cardiopulmonary resuscitation (odds ratio, 17.5; 95% confidence interval, 3.1-98.9; P = .001) and previous cardiac surgery (odds ratio, 14.0; 95% confidence interval, 1.2-164.7; P = .036). The 30-day or in-hospital mortality of patients who were indicated for surgery but refused surgery was 63.6% (7/11). Emergency open surgery for type A acute aortic dissection in elderly patients resulted in a low mortality but high incidences of stroke and prolonged hospital stay. Preoperative cardiopulmonary resuscitation and previous cardiac surgery were significant predictors of stroke. Emergency surgery is still the primary option for most elderly patients with acute aortic dissection.",success
27460914,False,Journal Article,,,,,,,,True,"The number of elderly patients undergoing emergency operation for acute type A aortic dissection is increasing in the aging society. We examined the early and late outcomes of operation for acute type A aortic dissection in elderly patients (≥80 years old). From January 2001 to December 2015, 345 consecutive patients underwent surgical treatment for acute type A aortic dissection at our institution. Of these, 63 elderly patients (≥80 years old; 28 men; mean age, 83.7 ± 3.0 years) were reviewed and compared with nonelderly patients (≤79 years old). The hospital death was 9/63 (14.3%) and 25/282 (8.9%) in patients 80 years and older but 79 years or younger, respectively (p = 0.28). Multivariate analysis showed age 80 years or older was a significant risk factor for hospital mortality (odds ratio 3.27, 95% confidence interval: 1.22 to 8.76, p = 0.02). During follow-up period (mean, 51.3 ± 40.9 months; range, 1 to 162 months), the 5-year survival of the elderly patients discharged from the hospital was 58.6% ± 8.7%. At postoperative 6 months and the latest follow-up (mean, 44.3 ± 25.6 months) of the elderly patients excluding late death, 90.2% (46/51) and 88% (22/25) of elderly patients had totally or almost independent daily life, respectively. Although age 80 years or older was the risk factor for hospital mortality in operation for acute type A aortic dissection, the long-term survival of the hospital survivors and the level of activity of daily life were acceptable. Aggressive surgical treatment could be a reasonable option for selected elderly patients.",success
28962505,False,Journal Article,,,,,,,,True,"The objectives are to (i) report characteristics and outcomes of patients with inoperable acute type A aortic dissection, (ii) describe proximal aortic morphology and (iii) identify potential for endovascular treatment of the entry tear. Fifty-three (7.7%) of 686 patients with acute type A dissection between 2005 and 2015 were deemed inoperable. Chart review and active follow-up were performed for clinical characteristics and outcomes. Specific attention was directed at determining the reasons for inoperability. Twenty-four patients had computed tomography scans available for 3D reconstruction and imaging analysis. Measurements included diameter and cross-sectional area at multiple levels; plus lengths along the centreline, greater and lesser curves and outer wall of dissection. The entry tear location was identified. Entry tears between the sinotubular junction and innominate artery, or distal to the left subclavian artery, were considered amenable to endovascular repair. The reasons for inoperability were characterized as very high-risk 35 (66%) or prohibitive 18 (34%). Prohibitive risk factors included dementia, severe stroke, malperfusion and advanced malignancy. Thirty-day mortality occurred in 35 (66%). On imaging analysis, the sinotubular junction was <45 mm in 18 (75%). The false lumen was located along the greater curve in 16 (67%), lesser curve 2 (8%), anteriorly in 5 (21%) and posteriorly in 1 (4%). The entry tear was potentially amenable to coverage in 19 (79%) patients-between the sinotubular junction and innominate artery in 18 patients and distal to the left subclavian artery in 1 patient. The entry tear was in the aortic root and arch in 1 patient (4%) each and not visible in 3 patients (13%). Only one-third of inoperable patients are prohibitive risk for any intervention. The entry tears in most patients are potentially coverable with endovascular devices. Additional imaging and engineering analysis will guide the design of disease specific devices.",success
30086279,False,Comparative Study;Journal Article,,,,,,,,True,"Although frailty is used to predict morbidity and mortality, its effect on the outcomes of acute type A aortic dissection has not been examined. Therefore, the objective of this study was to evaluate the role of frailty in predicting postoperative morbidity and mortality of patients with acute type A aortic dissection. A retrospective analysis of a prospectively maintained database was undertaken for all patients (n = 310) undergoing aortic surgery between May 2004 and March 2017. Frailty was evaluated using an index consisting of age more than 70 years, body mass index less than 18.5 kg/m<sup>2</sup>, serum creatinine greater than 1.2 mg/dL, anemia, history of stroke, hypoalbuminemia, and the psoas muscle area index. One point was given for each criterion met, for a frailty score between 0 and 7. Frailty was defined as a score of 3 or more. Of all patients, 106 (34.2%) were defined as frail. Inhospital mortality rates of frail versus nonfrail patients were not significantly different (10.4% versus 8.3%, respectively; p = 0.54). Incidences of postoperative major morbidities without reexploration for bleeding were also not statistically different. Five-year survival rates were significantly worse for frail patients than for nonfrail patients (57.7% versus 85.1%, respectively; p = 0.0001). A frailty score of 3 or greater was associated with late mortality, and long-term outcomes were clearly stratified by frailty score. Frailty, as defined using a seven-component frailty index, can serve as an independent predictor of the risk of late mortality for patients undergoing surgery for acute type A aortic dissection. Such frailty markers, all of which are easily assessed preoperatively, may provide valuable information for patient counseling and risk stratification before aortic surgery.",success
24070705,True,"Comparative Study;Journal Article;Multicenter Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"Complicated acute type B aortic dissection (cABAD) generally requires urgent intervention. Advanced age is a risk factor for mortality after thoracic aortic intervention, including surgery for aortic dissection. The purpose of this study was to investigate the exact impact of increasing age on the management and outcomes of cABAD. We analyzed the outcomes of 583 patients with cABAD enrolled in the International Registry of Acute Aortic Dissection (IRAD) between 1996 and 2012. All patients with cABAD were categorized according to age by decade and management type (medical, surgical, or endovascular treatment), and outcomes were subsequently investigated in the different age groups. The mean age of the cohort was 63.4 ± 14.2 years, 36% of patients (n = 209) were greater than 70 years of age and 64% (n = 374) were less than 70 years. The utilization of surgery and endovascular techniques progressively decreased with patient age, while the rate of medical management significantly increased with age (p < 0.001). The in-hospital mortality rates for complicated patients younger than 70 years versus 70 years or more were 10.1% versus 30.0% for endovascular treatment (p = 0.001), 17.2% versus 34.2% for surgical treatment (p = 0.027), and 14.2% versus 32.2% for medical treatment (p = 0.001). Age 70 years or greater was a predictor of in-hospital mortality in multivariate analysis (odds ratio 2.37, 95% confidence interval: 1.23 to 4.54, p = 0.010). Advanced age has a dramatic impact on the management and outcomes of patients with cABAD. A nonsignificant trend toward lower mortality after endovascular management was observed, both for younger patients and for elderly patients.",success
15111153,False,"Comparative Study;Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"The clinical features and outcomes of elderly patients with acute type B aortic dissection (ABAD) are less well known. Accordingly, we sought to evaluate the clinical features and outcomes and derive a simple risk stratification rule for elderly with ABAD. We categorized 383 patients with ABAD enrolled in the International Registry of Acute Aortic Dissection into two strata (aged less than 70 years and aged 70 years or more) and compared their clinical features and in-hospital outcomes. Further, we developed a clinical decision rule to risk-stratify elderly with ABAD. Forty-two percent (161 of 383) of patients with ABAD were aged 70 years or more. Hypertension, diabetes, history of prior aortic aneurysm, and arteriosclerosis were more common in the elderly patients, whereas Marfan syndrome and cocaine abuse were less common. The in-hospital complication of hypotension/shock was more common among elderly, and malperfusion of a visceral organ less frequent among elderly patients. In-hospital mortality was higher in the elderly cohort compared with the younger patients (16% versus 10%, p = 0.07). A classification tree identified that elderly patients with hypotension/shock had the highest risk of death (56%). In absence of this, any branch vessel involvement was associated with the next highest mortality rate (28.6%) followed by presence of periaortic hematoma (10.5%). In contrast, elderly patients without any of these three risk factors had an extremely low mortality rate (1.3%). Our study highlights important differences between older and younger patients with ABAD in their clinical characteristics, management, and outcomes. We also propose a simple decision rule that allows stepwise risk-stratification in elderly patients with ABAD.",success
27883977,False,Journal Article,,,,,,,,True,"Risk models that use a single aortic diameter threshold have failed to successfully predict acute type B aortic dissection (TBAD). We sought to identify meaningful age-indexed anatomical variables to predict TBAD risk. A geometric deformable model, consisting of virtual elastic balloons that inflate inside a vessel lumen, was developed to quantify thoracic aorta geometry. In the presence of TBAD, true and total artery lumen morphology were assessed. A stepwise logistic model was built to predict TBAD risk. Initial covariates included age, gender, body mass index and all anatomic variables not directly related to the dissected segment. Patients with acute TBAD (n=34, 62±12years old, 57% male gender) were compared with subjects with symptoms of dissection, but with a subsequent negative diagnosis (n=51, 62±12years old, 76% male gender). Patient risk factors did not differ between groups. Most aortic anatomical variables were age-dependent. Aortic size was larger in every segment of the dissected with respect to non-dissected aortas (p<0.001). Variables entering the TBAD risk prediction model were aortic arch diameter, thoracic aorta length and age (predictability=0.9764, r=0.85), confirmed by a bootstrap internal validation. In dissected aortas, the true lumen volume was correlated to age (r=0.72). TBAD probability increases with a larger aortic arch diameter and a longer thoracic aorta, whereas threshold values increase with age. The aortic morphology was age-dependent. After dissection, true lumen volume correlated to age. The use of threshold values indexed to age should be encouraged to better prevent and eventually treat TBAD.",success
12218969,False,Journal Article,,,,,,,,True,"Advanced age has been reported as a predictor of increased morbidity and mortality in patients who undergo major cardiovascular reconstructive surgery. In this study, we evaluated the outcome of patients aged 79 years or older after thoracoabdominal and descending thoracic aortic aneurysm repair. From February 1991 to May 2001, 854 patients underwent operation for thoracoabdominal or descending thoracic aortic aneurysm. Fifty-six patients were between the ages of 79 and 88 years at the time of surgery, and these patients were included in this study. Risk factors were analyzed for their impact on mortality and morbidity in these elderly patients with univariate analysis. In patients at low risk, the 30-day mortality rate was 7/42 (17%), compared with 7/14 (50%) in patients at high risk with emergency presentation, congestive heart failure, or diabetes (P <.03). Four patients (7%; 4/56) had neurologic deficits develop. No single preoperative risk factor was significantly associated with increased mortality or neurologic deficits. Thoracoabdominal and descending thoracic aortic aneurysm repair in elderly patients can be undertaken with acceptable mortality and morbidity, provided that patients are selected appropriately.",success
9521222,False,"Journal Article;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"The incidence of venous thromboembolism has not been well described, and there are no studies of long-term trends in the incidence of venous thromboembolism. To estimate the incidence of deep vein thrombosis and pulmonary embolism and to describe trends in incidence. We performed a retrospective review of the complete medical records from a population-based inception cohort of 2218 patients who resided within Olmsted County, Minnesota, and had an incident deep vein thrombosis or pulmonary embolism during the 25-year period from 1966 through 1990. The overall average age- and sex-adjusted annual incidence of venous thromboembolism was 117 per 100000 (deep vein thrombosis, 48 per 100000; pulmonary embolism, 69 per 100000), with higher age-adjusted rates among males than females (130 vs 110 per 100000, respectively). The incidence of venous thromboembolism rose markedly with increasing age for both sexes, with pulmonary embolism accounting for most of the increase. The incidence of pulmonary embolism was approximately 45% lower during the last 15 years of the study for both sexes and all age strata, while the incidence of deep vein thrombosis remained constant for males across all age strata, decreased for females younger than 55 years, and increased for women older than 60 years. Venous thromboembolism is a major national health problem, especially among the elderly. While the incidence of pulmonary embolism has decreased over time, the incidence of deep vein thrombosis remains unchanged for men and is increasing for older women. These findings emphasize the need for more accurate identification of patients at risk for venous thromboembolism, as well as a safe and effective prophylaxis.",success
26409636,False,Journal Article,,,,,,,,True,"Little is known about national trends of pulmonary embolism (PE) hospitalizations and outcomes in older adults in the context of recent diagnostic and therapeutic advances. Therefore, we conducted a retrospective cohort study of 100% Medicare fee-for-service beneficiaries hospitalized from 1999 to 2010 with a principal discharge diagnosis code for PE. The adjusted PE hospitalization rate increased from 129/100,000 person-years in 1999 to 302/100,000 person-years in 2010, a relative increase of 134% (p <0.001). Black patients had the highest rate of increase (174 to 548/100,000 person-years) among all age, gender, and race categories. The mean (standard deviation) length of hospital stay decreased from 7.6 (5.7) days in 1999 to 5.8 (4.4) days in 2010, and the proportion of patients discharged to home decreased from 51.1% (95% confidence interval [CI] 50.5 to 51.6) to 44.1% (95% CI 43.7 to 44.6), whereas more patients were discharged with home health care and to skilled nursing facilities. The in-hospital mortality rate decreased from 8.3% (95% CI 8.0 to 8.6) in 1999 to 4.4% (95% CI 4.2 to 4.5) in 2010, as did adjusted 30-day (from 12.3% [95% CI 11.9 to 12.6] to 9.1% [95% CI 8.5 to 9.7]) and 6-month mortality rates (from 23.0% [95% CI 22.5 to 23.4] to 19.6% [95% CI 18.8 to 20.5]). There were no significant racial differences in mortality rates by 2010. There was no change in the adjusted 30-day all-cause readmission rate from 1999 to 2010. In conclusion, PE hospitalization rates increased substantially from 1999 to 2010, with a higher rate for black patients. All mortality rates decreased but remained high. The increase in hospitalization rates and continued high mortality and readmission rates confirm the significant burden of PE for older adults.",success
10227218,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Pulmonary embolism (PE) remains poorly understood. Rates of clinical outcomes such as death and recurrence vary widely among trials. We therefore established the International Cooperative Pulmonary Embolism Registry (ICOPER), with the aim of identifying factors associated with death. 2454 consecutive eligible patients with acute PE were registered from 52 hospitals in seven countries in Europe and North America. The primary outcome measure was all-cause mortality at 3 months. The prognostic effect of baseline factors on survival was assessed with multivariate analyses. 2110 (86.0%) patients had PE proven by necropsy, high-probability lung scan, pulmonary angiography, or venous ultrasonography plus high clinical suspicion; ICOPER accepted without independent review diagnoses and interpretation of imaging provided by participating centres; 3-month follow-up was completed in 98.0% of patients. The overall crude mortality rate at 3 months was 17.4% (426 of 2454 deaths, including 52 patients lost to follow-up): 179 of 397 (45.1%) deaths were ascribed to PE and 70 of 397 (17.6%) to cancer, and no information on the cause of death was available for 29 patients. After exclusion of 61 patients in whom PE was first discovered at necropsy, the mortality rate at 3 months was 15.3% (365 of 2393 deaths). On multiple-regression modelling, age over 70 years (hazard ratio 1.6 [95% CI 1.1-2.3]), cancer (2.3 [1.5-3.5]), congestive heart failure (2.4 [1.5-3.7]), chronic obstructive pulmonary disease (1.8 [1.2-2.7]), systolic arterial hypotension (2.9 [1.7-5.0]), tachypnoea (2.0 [1.2-3.2]), and right-ventricular hypokinesis on echocardiography (2.0 [1.3-2.9]) were identified as significant prognostic factors. PE remains an important clinical problem with a high mortality rate. Data from ICOPER provide rates and highlight adverse prognostic categories that will help in planning of future trials of high-risk PE patients.",success
16241944,True,"Journal Article;Multicenter Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"The diagnostic value of clinical presentation of pulmonary embolism (PE) is uncertain in the elderly, who often have concomitant cardiopulmonary diseases that may mimic PE. The aim of our study was to assess the differential value of risk factors, symptoms and clinical signs of venous thromboembolism, results of electrocardiogram and chest X-ray for the diagnosis of PE in suspected patients according to age. We analyzed data from two outcome studies which enrolled 1721 consecutive patients presenting in the emergency department with clinically suspected PE defined as acute onset of new or worsening shortness of breath or chest pain without any other obvious etiology. All patients underwent a sequential diagnostic work-up and a 3-month follow-up. The proportion of confirmed PE was 24.2% (416 of 1721). Strength of the association with PE did not differ according to age group for history of venous thromboembolism (VTE), recent surgery, tachypnea at admission or right ventricular strain on electrocardiogram. Active malignancy, hemoptysis, tachycardia, hemidiaphragmatic elevation and pleural effusion at chest X-ray were no more associated with PE in the patients aged of 75 years or more. Finally, symptoms and signs of deep venous thrombosis, and an alternative diagnosis less probable than PE were associated with PE in all age groups, but the strength of this association decreased significantly with advancing age. Some risk factors, symptoms and signs of VTE are less strongly or even not at all associated with PE in the elderly. Physicians should take this into account when attending elderly patients suspected of PE and when assessing their clinical probability of PE.",success
23590273,False,Journal Article,,,,,,,,True,"The nonspecific clinical presentation of pulmonary embolism (PE) frequently leads to delay in its diagnosis. This study aimed to assess the impact of delay in presentation on the diagnostic management and clinical outcome of patients with suspected PE. In 4,044 consecutive patients with suspected PE, patients presenting more than 7 days from the onset of symptoms were contrasted with those presenting within 7 days as regards the safety of excluding PE on the basis of a clinical decision rule combined with D-dimer testing. Patients were followed for 3 months to assess the rates of recurrent venous thromboembolism and mortality. A delayed presentation (presentation >7 d) was present in 754 (18.6%) of the patients. The failure rate of an unlikely clinical probability and normal D-dimer test was 0.5% (95% confidence interval [CI], 0.01-2.7) for patients with and 0.5% (95% CI, 0.2-1.2) for those without diagnostic delay. D-dimer testing yielded a sensitivity of 99% (95% CI, 96-99%) and 98% (95% CI, 97-99%) in these groups, respectively. Patients with PE with diagnostic delay more frequently had centrally located PE (41% vs. 26%; P < 0.001). The cumulative rates of recurrent venous thromboembolism (4.6% vs. 2.7%; P = 0.14) and mortality (7.6% vs. 6.6%; P = 0.31) were not different for patients with and without delayed presentation. PE can be safely excluded based on a clinical decision rule and D-dimer testing in patients with a delayed clinical presentation. A delayed presentation for patients who survived acute PE was associated with a more central PE location, although this did not affect the clinical outcome at 3 months.",success
15935031,False,Journal Article;Review,,,,,,,,True,"Pulmonary embolism (PE) is a potentially fatal disease if left untreated. The prevalence of PE increases markedly with age, and its diagnosis in elderly people is difficult because many cardiopulmonary conditions may mimic clinical presentation of PE, and age may unfavorably influence the characteristics of diagnostic tests for PE. The modern approach to PE is based on sequential diagnostic strategies based on clinical probability, D-dimer measurement, lower limb compression ultrasonography, ventilation-perfusion lung scan, and helical computed tomography (hCT). Pulmonary angiogram is rarely necessary because the noninvasive diagnostic evaluation is usually conclusive. Age reduces the clinical usefulness of D-dimer and ventilation-perfusion lung scan. D-dimer allows excluding PE in only 5% of patients aged 80 and older, compared with 60% younger than 40. Similarly, the rate of inconclusive ventilation-perfusion lung scans is almost twice as high (58%) in patients older than 70 and in patients younger than 40 (32%). In contrast, aging does not change the diagnostic accuracy of clinical probability assessment, whether empirical or as determined by prediction rules, nor appear to influence the diagnostic characteristics of lower limb compression ultrasonography and hCT. Therefore, a rational diagnostic approach to PE in older people should rest mainly on the sequential use of those tests that have demonstrated strong diagnostic yield, accuracy, and safety in this population.",success
11020391,True,Journal Article;Multicenter Study,,,,,,,,True,"The diagnosis of pulmonary embolism in the elderly is often difficult because of comorbid medical conditions, and perhaps also because diagnostic tests have a lower yield. We analyzed the diagnostic performance of common diagnostic tests for pulmonary embolism in different age groups. We analyzed data from two large studies that enrolled 1,029 consecutive patients presenting to the emergency department with clinically suspected pulmonary embolism. The clinical probability of pulmonary embolism (high [>/=80%], intermediate, or low [</=20%]) was estimated by the treating physician. All patients underwent a sequential diagnostic protocol, including ventilation-perfusion lung scan, measurement of plasma D-dimer level, lower limb venous compression ultrasonography, and pulmonary angiography if the noninvasive work-up was inconclusive. The prevalence of pulmonary embolism increased progressively, from 12% in patients <40 years of age to 44% in those >/=80 years of age. The positive predictive value of a high clinical probability of pulmonary embolism was greater in the elderly (71% to 78% in those >/=60 years old versus 40% to 64% in those </=59 years old). The sensitivity of D-dimer testing was 100% in all age groups, but its specificity decreased markedly with age, from 67% in those </=40 years old to 10% in those >/=80 years old. The diagnostic yield of lower limb compression ultrasonography was greater in the elderly. The proportion of lung scans that were diagnostic (normal, near-normal, or high probability) decreased from 68% to 42% with increasing age. Age affects the performance of common diagnostic tests for pulmonary embolism and should be kept in mind when evaluating patients suspected of having this condition.",success
28173757,False,Journal Article,,,,,,,,True,"The AMI code is a regional network enhancing a rapid and widespread access to reperfusion therapy (giving priority to primary angioplasty) in patients with acute ST-segment elevation myocardial infarction (STEMI). We aimed to assess the long-term control of conventional cardiovascular risk factors after a STEMI among patients included in the AMI code registry. Four hundred and fifty-four patients were prospectively included between June-2009 and April-2013. Clinical characteristics were collected at baseline. The long-term control of cardiovascular risk factors and cardiovascular morbidity/mortality was assessed among the 6-months survivors. A total of 423 patients overcame the first 6 months after the STEMI episode, of whom 370 (87%) underwent reperfusion therapy (363, 98% of them, with primary angioplasty). At 1-year follow-up, only 263 (62%) had adequate blood pressure control, 123 (29%) had LDL-cholesterol within targeted levels, 126/210 (60%) smokers had withdrawn from their habit and 40/112 (36%) diabetic patients had adequate glycosylated hemoglobin levels. During a median follow-up of 20 (11-30) months, cumulative mortality of 6 month-survivors was 6.1%, with 9.9% of hospital cardiovascular readmissions. The lack of assessment of LDL and HDL-cholesterol were significantly associated with higher mortality and cardiovascular readmission rates. Whereas implementation of the AMI code resulted in a widespread access to rapid reperfusion therapy, its long-term therapeutic benefit may be partially counterbalanced by a manifestly suboptimal control of cardiovascular risk factors. Further efforts should be devoted to secondary prevention strategies after STEMI.",success
20351550,True,"Comparative Study;Journal Article;Multicenter Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"Guideline-recommended pharmacotherapy after myocardial infarction (MI) has been shown to reduce cardiovascular morbidity and mortality. Our objectives were to determine factors of, and to measure outcomes associated with nonadherence after MI. Multicentre, prospective, observational study (Acute Coronary Syndromes Registry). We analyzed data of 11,823 consecutive hospital survivors of acute MI and evaluated their discharge medication with the five following drugs: acetyl salicylic acid, clopidogrel, β-blocker, angiotensin-converting enzyme inhibitor/sartan and statin. Patients receiving less than four drugs (group 1, n=3439, 29.1%) were compared with those receiving 4-5 drugs (group 2, n=8384, 70.9%). The impact of clinical, demographic and treatment factors on not prescribing each of these five drugs at discharge was investigated by using multiple logistic regression models. Patients of group 1 were older, had more comorbidities, more frequently suffered a nonST elevation MI and less often received reperfusion therapy. In the multivariate analysis, group 1 was associated with an increased risk for death at 1-year follow-up [odds ratio (OR): 1.6, 95% confidence interval (CI): 1.4-1.9]. After adjustment for confounding variables chronic oral anticoagulation was the strongest predictor for not receiving acetyl salicylic acid (OR: 19.6, 95% CI: 15.9-24.0) at discharge, no percutaneous coronary intervention within 48 h for not receiving statin (OR: 2.1, 95% CI: 1.9-2.4) and clopidogrel (OR: 10.4, 95% CI: 9.4-11.5), chronic obstructive lung disease for not receiving β-blocker (OR: 4.2, 95% CI: 3.6-4.9) and chronic renal insufficiency for not receiving angiotensin-converting enzyme inhibitor/sartan (OR: 2.8, 95% CI: 2.2-3.5). In clinical practice guideline-adherent secondary prevention drug therapy is linked with an improved 1-year survival. Comorbidities and no interventional treatment were strong negative predictors for guideline-adherent discharge medication.",success
27864615,False,Journal Article;Meta-Analysis;Systematic Review,,,,,,,,True,"Early active mobilisation and rehabilitation in the intensive care unit (ICU) is being used to prevent the long-term functional consequences of critical illness. This review aimed to determine the effect of active mobilisation and rehabilitation in the ICU on mortality, function, mobility, muscle strength, quality of life, days alive and out of hospital to 180 days, ICU and hospital lengths of stay, duration of mechanical ventilation and discharge destination, linking outcomes with the World Health Organization International Classification of Function Framework. A PRISMA checklist-guided systematic review and meta-analysis of randomised and controlled clinical trials. Fourteen studies of varying quality including a total of 1753 patients were reviewed. Active mobilisation and rehabilitation had no impact on short- or long-term mortality (p > 0.05). Meta-analysis showed that active mobilisation and rehabilitation led to greater muscle strength (body function) at ICU discharge as measured using the Medical Research Council Sum Score (mean difference 8.62 points, 95% confidence interval (CI) 1.39-15.86), greater probability of walking without assistance (activity limitation) at hospital discharge (odds ratio 2.13, 95% CI 1.19-3.83), and more days alive and out of hospital to day 180 (participation restriction) (mean difference 9.69, 95% CI 1.7-17.66). There were no consistent effects on function, quality of life, ICU or hospital length of stay, duration of mechanical ventilation or discharge destination. Active mobilisation and rehabilitation in the ICU has no impact on short- and long-term mortality, but may improve mobility status, muscle strength and days alive and out of hospital to 180 days. CRD42015029836.",success
29730622,False,Journal Article;Meta-Analysis;Systematic Review,,,,,,,,True,"We examined the effectiveness of early rehabilitation for the prevention of postintensive care syndrome (PICS), characterised by an impaired physical, cognitive or mental health status, among survivors of critical illness. We performed a systematic literature search of several databases (Medline, Embase and Cochrane Central Register of Controlled Trials) and a manual search to identify randomised controlled trials (RCTs) comparing the effectiveness of early rehabilitation versus no early rehabilitation or standard care for the prevention of PICS. The primary outcomes were short-term physical-related, cognitive-related and mental health-related outcomes assessed during hospitalisation. The secondary outcomes were the standardised, long-term health-related quality of life scores (EuroQol 5 Dimension (EQ5D) and the Medical Outcomes Study 36-Item Short Form Health Survey Physical Function Scale (SF-36 PF)). We used the Grading of Recommendations Assessment, Development and Evaluation approach to rate the quality of evidence (QoE). Six RCTs selected from 5105 screened abstracts were included. Early rehabilitation significantly improved short-term physical-related outcomes, as indicated by an increased Medical Research Council scale score (standardised mean difference (SMD): 0.38, 95% CI 0.10 to 0.66, p=0.009) (QoE: low) and a decreased incidence of intensive care unit-acquired weakness (OR 0.42, 95% CI 0.22 to 0.82, p=0.01, QoE: low), compared with standard care or no early rehabilitation. However, the two groups did not differ in terms of cognitive-related delirium-free days (SMD: -0.02, 95% CI -0.23 to 0.20, QoE: low) and the mental health-related Hospital Anxiety and Depression Scale score (OR: 0.79, 95% CI 0.29 to 2.12, QoE: low). Early rehabilitation did not improve the long-term outcomes of PICS as characterised by EQ5D and SF-36 PF. Early rehabilitation improved only short-term physical-related outcomes in patients with critical illness. Additional large RCTs are needed.",success
29558969,False,Journal Article;Review,,,,,,,,True,Please change the first sentence to: This article is one of ten reviews selected from the Annual Update in Intensive Care and Emergency Medicine 2018. Other selected articles can be found online at https://www.biomedcentral.com/collections/annualupdate2018 . Further information about the Annual Update in Intensive Care and Emergency Medicine is available from http://www.springer.com/series/8901 .,success
28098628,False,Journal Article,,,,,,,,True,"Over the past 20 years, critical care has matured in a myriad of ways resulting in dramatically higher survival rates for our sickest patients. For millions of new survivors comes de novo suffering and disability called ""the postintensive care syndrome."" Patients with postintensive care syndrome are robbed of their normal cognitive, emotional, and physical capacity and cannot resume their previous life. The ICU Liberation Collaborative is a real-world quality improvement initiative being implemented across 76 ICUs designed to engage strategically the ABCDEF bundle through team- and evidence-based care. This article explains the science and philosophy of liberating ICU patients and families from harm that is both inherent to critical illness and iatrogenic. ICU liberation is an extensive program designed to facilitate the implementation of the pain, agitation, and delirium guidelines using the evidence-based ABCDEF bundle. Participating ICU teams adapt data from hundreds of peer-reviewed studies to operationalize a systematic and reliable methodology that shifts ICU culture from the harmful inertia of sedation and restraints to an animated ICU filled with patients who are awake, cognitively engaged, and mobile with family members engaged as partners with the ICU team at the bedside. In doing so, patients are ""liberated"" from iatrogenic aspects of care that threaten his or her sense of self-worth and human dignity. The goal of this 2017 plenary lecture at the 47th Society of Critical Care Medicine Congress is to provide clinical ICU teams a synthesis of the literature that led to the creation of ICU liberation philosophy and to explain how this patient- and family-centered, quality improvement program is novel, generalizable, and practice changing.",success
20116842,True,"Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",NCT00466492,databank,NCT00466492,NCT00466492,NCT00466492,NCT00466492|databank,NCT00466492|databank,True,"Standard treatment of critically ill patients undergoing mechanical ventilation is continuous sedation. Daily interruption of sedation has a beneficial effect, and in the general intesive care unit of Odense University Hospital, Denmark, standard practice is a protocol of no sedation. We aimed to establish whether duration of mechanical ventilation could be reduced with a protocol of no sedation versus daily interruption of sedation. Of 428 patients assessed for eligibility, we enrolled 140 critically ill adult patients who were undergoing mechanical ventilation and were expected to need ventilation for more than 24 h. Patients were randomly assigned in a 1:1 ratio (unblinded) to receive: no sedation (n=70 patients); or sedation (20 mg/mL propofol for 48 h, 1 mg/mL midazolam thereafter) with daily interruption until awake (n=70, control group). Both groups were treated with bolus doses of morphine (2.5 or 5 mg). The primary outcome was the number of days without mechanical ventilation in a 28-day period, and we also recorded the length of stay in the intensive care unit (from admission to 28 days) and in hospital (from admission to 90 days). Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00466492. 27 patients died or were successfully extubated within 48 h, and, as per our study design, were excluded from the study and statistical analysis. Patients receiving no sedation had significantly more days without ventilation (n=55; mean 13.8 days, SD 11.0) than did those receiving interrupted sedation (n=58; mean 9.6 days, SD 10.0; mean difference 4.2 days, 95% CI 0.3-8.1; p=0.0191). No sedation was also associated with a shorter stay in the intensive care unit (HR 1.86, 95% CI 1.05-3.23; p=0.0316), and, for the first 30 days studied, in hospital (3.57, 1.52-9.09; p=0.0039), than was interrupted sedation. No difference was recorded in the occurrences of accidental extubations, the need for CT or MRI brain scans, or ventilator-associated pneumonia. Agitated delirium was more frequent in the intervention group than in the control group (n=11, 20%vs n=4, 7%; p=0.0400). No sedation of critically ill patients receiving mechanical ventilation is associated with an increase in days without ventilation. A multicentre study is needed to establish whether this effect can be reproduced in other facilities. Danish Society of Anesthesiology and Intensive Care Medicine, the Fund of Danielsen, the Fund of Kirsten Jensa la Cour, and the Fund of Holger og Ruth Hess.",success
26975647,True,"Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",NCT01151865,databank,NCT01151865,NCT01151865,NCT01151865,NCT01151865|databank,NCT01151865|databank,True,"Effective therapy has not been established for patients with agitated delirium receiving mechanical ventilation. To determine the effectiveness of dexmedetomidine when added to standard care in patients with agitated delirium receiving mechanical ventilation. The Dexmedetomidine to Lessen ICU Agitation (DahLIA) study was a double-blind, placebo-controlled, parallel-group randomized clinical trial involving 74 adult patients in whom extubation was considered inappropriate because of the severity of agitation and delirium. The study was conducted at 15 intensive care units in Australia and New Zealand from May 2011 until December 2013. Patients with advanced dementia or traumatic brain injury were excluded. Bedside nursing staff administered dexmedetomidine (or placebo) initially at a rate of 0.5 µg/kg/h and then titrated to rates between 0 and 1.5 µg/kg/h to achieve physician-prescribed sedation goals. The study drug or placebo was continued until no longer required or up to 7 days. All other care was at the discretion of the treating physician. Ventilator-free hours in the 7 days following randomization. There were 21 reported secondary outcomes that were defined a priori. Of the 74 randomized patients (median age, 57 years; 18 [24%] women), 2 withdrew consent later and 1 was found to have been randomized incorrectly, leaving 39 patients in the dexmedetomidine group and 32 patients in the placebo group for analysis. Dexmedetomidine increased ventilator-free hours at 7 days compared with placebo (median, 144.8 hours vs 127.5 hours, respectively; median difference between groups, 17.0 hours [95% CI, 4.0 to 33.2 hours]; P = .01). Among the 21 a priori secondary outcomes, none were significantly worse with dexmedetomidine, and several showed statistically significant benefit, including reduced time to extubation (median, 21.9 hours vs 44.3 hours with placebo; median difference between groups, 19.5 hours [95% CI, 5.3 to 31.1 hours]; P < .001) and accelerated resolution of delirium (median, 23.3 hours vs 40.0 hours; median difference between groups, 16.0 hours [95% CI, 3.0 to 28.0 hours]; P = .01). Using hierarchical Cox modeling to adjust for imbalanced baseline characteristics, allocation to dexmedetomidine was significantly associated with earlier extubation (hazard ratio, 0.47 [95% CI, 0.27-0.82]; P = .007). Among patients with agitated delirium receiving mechanical ventilation in the intensive care unit, the addition of dexmedetomidine to standard care compared with standard care alone (placebo) resulted in more ventilator-free hours at 7 days. The findings support the use of dexmedetomidine in patients such as these. clinicaltrials.gov Identifier: NCT01151865.",success
22436955,True,"Comparative Study;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",NCT00479661,databank,NCT00479661;NCT00481312,NCT00479661;NCT00481312,NCT00479661;NCT00481312,NCT00479661|databank;NCT00481312|databank,NCT00479661|databank;NCT00481312|databank,True,"Long-term sedation with midazolam or propofol in intensive care units (ICUs) has serious adverse effects. Dexmedetomidine, an α(2)-agonist available for ICU sedation, may reduce the duration of mechanical ventilation and enhance patient comfort. To determine the efficacy of dexmedetomidine vs midazolam or propofol (preferred usual care) in maintaining sedation; reducing duration of mechanical ventilation; and improving patients' interaction with nursing care. Two phase 3 multicenter, randomized, double-blind trials carried out from 2007 to 2010. The MIDEX trial compared midazolam with dexmedetomidine in ICUs of 44 centers in 9 European countries; the PRODEX trial compared propofol with dexmedetomidine in 31 centers in 6 European countries and 2 centers in Russia. Included were adult ICU patients receiving mechanical ventilation who needed light to moderate sedation for more than 24 hours (midazolam, n = 251, vs dexmedetomidine, n = 249; propofol, n = 247, vs dexmedetomidine, n = 251). Sedation with dexmedetomidine, midazolam, or propofol; daily sedation stops; and spontaneous breathing trials. For each trial, we tested whether dexmedetomidine was noninferior to control with respect to proportion of time at target sedation level (measured by Richmond Agitation-Sedation Scale) and superior to control with respect to duration of mechanical ventilation. Secondary end points were patients' ability to communicate pain (measured using a visual analogue scale [VAS]) and length of ICU stay. Time at target sedation was analyzed in per-protocol population (midazolam, n = 233, vs dexmedetomidine, n = 227; propofol, n = 214, vs dexmedetomidine, n = 223). Dexmedetomidine/midazolam ratio in time at target sedation was 1.07 (95% CI, 0.97-1.18) and dexmedetomidine/propofol, 1.00 (95% CI, 0.92-1.08). Median duration of mechanical ventilation appeared shorter with dexmedetomidine (123 hours [IQR, 67-337]) vs midazolam (164 hours [IQR, 92-380]; P = .03) but not with dexmedetomidine (97 hours [IQR, 45-257]) vs propofol (118 hours [IQR, 48-327]; P = .24). Patients' interaction (measured using VAS) was improved with dexmedetomidine (estimated score difference vs midazolam, 19.7 [95% CI, 15.2-24.2]; P < .001; and vs propofol, 11.2 [95% CI, 6.4-15.9]; P < .001). Length of ICU and hospital stay and mortality were similar. Dexmedetomidine vs midazolam patients had more hypotension (51/247 [20.6%] vs 29/250 [11.6%]; P = .007) and bradycardia (35/247 [14.2%] vs 13/250 [5.2%]; P < .001). Among ICU patients receiving prolonged mechanical ventilation, dexmedetomidine was not inferior to midazolam and propofol in maintaining light to moderate sedation. Dexmedetomidine reduced duration of mechanical ventilation compared with midazolam and improved patients' ability to communicate pain compared with midazolam and propofol. More adverse effects were associated with dexmedetomidine. clinicaltrials.gov Identifiers: NCT00481312, NCT00479661.",success
27542303,True,"Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",,,,,,,,True,"Delirium is a postoperative complication that occurs frequently in patients older than 65 years, and presages adverse outcomes. We investigated whether prophylactic low-dose dexmedetomidine, a highly selective α<sub>2</sub> adrenoceptor agonist, could safely decrease the incidence of delirium in elderly patients after non-cardiac surgery. We did this randomised, double-blind, placebo-controlled trial in two tertiary-care hospitals in Beijing, China. We enrolled patients aged 65 years or older, who were admitted to intensive care units after non-cardiac surgery, with informed consent. We used a computer-generated randomisation sequence (in a 1:1 ratio) to randomly assign patients to receive either intravenous dexmedetomidine (0·1 μg/kg per h, from intensive care unit admission on the day of surgery until 0800 h on postoperative day 1), or placebo (intravenous normal saline). Participants, care providers, and investigators were all masked to group assignment. The primary endpoint was the incidence of delirium, assessed twice daily with the Confusion Assessment Method for intensive care units during the first 7 postoperative days. Analyses were done by intention-to-treat and safety populations. This study is registered with Chinese Clinical Trial Registry, www.chictr.org.cn, number ChiCTR-TRC-10000802. Between Aug 17, 2011, and Nov 20, 2013, of 2016 patients assessed, 700 were randomly assigned to receive either placebo (n=350) or dexmedetomidine (n=350). The incidence of postoperative delirium was significantly lower in the dexmedetomidine group (32 [9%] of 350 patients) than in the placebo group (79 [23%] of 350 patients; odds ratio [OR] 0·35, 95% CI 0·22-0·54; p<0·0001). Regarding safety, the incidence of hypertension was higher with placebo (62 [18%] of 350 patients) than with dexmedetomidine (34 [10%] of 350 patients; 0·50, 0·32-0·78; p=0·002). Tachycardia was also higher in patients given placebo (48 [14%] of 350 patients) than in patients given dexmedetomidine (23 [7%] of 350 patients; 0·44, 0·26-0·75; p=0·002). Occurrence of hypotension and bradycardia did not differ between groups. For patients aged over 65 years who are admitted to the intensive care unit after non-cardiac surgery, prophylactic low-dose dexmedetomidine significantly decreases the occurrence of delirium during the first 7 days after surgery. The therapy is safe. Braun Anaesthesia Scientific Research Fund and Wu Jieping Medical Foundation, Beijing, China. Study drugs were manufactured and supplied by Jiangsu Hengrui Medicine Co, Ltd, Jiangsu, China.",success
29318004,False,Journal Article,,,,,,,,True,"The aim of this study was to evaluate efficacy and safety of poly-de-prescribing (PDP) based on the Garfinkel method in older people with polypharmacy. A longitudinal, prospective, nonrandomized study in Israel was carried out between 2009 and 2016. Comprehensive geriatric assessments were performed at home in people age ⩾66 years consuming ⩾6 prescription drugs. Exclusion criteria were life expectancy <6 months and a seeming unwillingness to cooperate (poor compliance). PDP of ⩾3 prescription drugs was recommended. Follow up was at ⩾3 years. Between April 2015 and April 2016 Likert scale questionnaires were filled by all participants/families to evaluate overall satisfaction and clinical outcomes. The outcome measures were change in functional, mental and cognitive status, sleep quality, appetite, continence; major complication, hospitalizations, mortality, and family doctor's cooperation. Poly-de-prescribing of ⩾3 drugs was eventually achieved by 122 participants (PDP group); ⩽2 drugs stopped by 55 'nonresponders' (NR group). The average age was 83.4 ± 5.3 in the PDP group, and 80.8 ± 6.3 in the NR group (<i>p</i> = 0.0045). Follow up was 43.6 ± 14 months (PDP) and 39.5 ± 16.6 months (NR) (<i>p</i> = 0.09). The prevalence of most diseases/symptoms was comparable except for a higher prevalence for dementia, incontinence and functional decline in the PDP group. The main barrier to de-prescribing was the family doctor's unwillingness to adopt PDP recommendations (<i>p</i> < 0.0001). The baseline median number of medications taken by both groups was 10 (IQR 8 to 12) (<i>p</i> = 0.55). On the last follow up, the drug count was 11 (IQR 8 to 12) in the NR group and 4 (IQR 2 to 5) in the PDP group (<i>p</i> =0.0001). The PDP group showed significantly less deterioration (sometimes improvement) in general satisfaction, functional, mental and cognitive status, sleep quality, appetite, sphincter control, and the number of major complications was significantly reduced (<i>p</i> < 0.002 in all). The rate of hospitalizations and mortality was comparable. Health improvement occurred within 3 months after de-prescribing in 83%, and persisted for ⩾2 years in 68%. This self-selected sample longitudinal research strongly suggests that the negative, usually invisible effects of polypharmacy are reversible. PDP is well tolerated and associated with improved clinical outcomes, in comparison with outcomes of older people who adhere to all clinical guidelines and take all medications conventionally. Future double-blind studies will probably prove beneficial economic outcomes as well.",success
28369729,False,Journal Article,,,,,,,,True,"Medications can pose considerable risk in older adults. This article annotates four articles addressing this concern from 2016. The first provides national data on the use of specific prescription, over-the-counter and dietary supplements in older adults and their change over time. The second discusses the opportunity of deprescribing ineffective/unnecessary stool softeners (i.e., docusate) routinely given to older hospital patients. The third national study examines common adverse drug events in older emergency room patients. Finally, a study published demonstrating a potential association between melatonin and fractures is discussed. This manuscript is intended to provide a narrative review of key publications in medication safety for clinicians and researchers committed to improving medication safety in older adults.",success
27006985,False,"Journal Article;Research Support, Non-U.S. Gov't;Systematic Review",,,,,,,,True,"The aim of this study was to identify what definitions have been published for the term 'deprescribing', and determine whether a unifying definition could be reached. A secondary aim was to uncover patterns between the published definitions which could explain any variation. Systematic literature searches were performed (earliest records to February 2014) in MEDLINE, Embase, CINAHL, Informit, Scopus and Google Scholar. The terms deprescrib* or de-prescrib* were employed as a keyword search in all fields. Conventional content analysis and word frequencies were used to identify characteristics of the definitions. Network analysis was conducted to visualize characteristic distribution across authors and articles. Following removal of duplicates, 231 articles were retrieved, 37 of which included a definition. Eight characteristics of the definitions were identified: use of the term stop/withdraw/cease/discontinue (35 articles), aspect of prescribing included e.g. long term therapy/inappropriate medications (n = 18), use of the term 'process' or 'structured' (n = 13), withdrawal is planned/supervised/judicious (n = 11), involving multiple steps (n = 7), includes dose reduction/substitution (n = 7), desired goals/outcomes described (n = 5) and involves tapering (n = 4). Network analysis did not reveal patterns responsible for variations in previously used definitions. These findings show that there is lack of consensus on the definition of deprescribing. This article proposes the following definition: 'Deprescribing is the process of withdrawal of an inappropriate medication, supervised by a health care professional with the goal of managing polypharmacy and improving outcomes'. This definition has not yet been externally validated and further work is required to develop an internationally accepted and appropriate definition.",success
26596509,False,Journal Article;Observational Study,,,,,,,,True,"The purpose was to determine if the implementation of an evidence-based nonpharmacologic protocol reduced the percentage of time patients spent delirious in a medical intensive care unit (MICU) that already uses a sedation and mobility protocol. This was a prospective, pre-post quality improvement project of MICU patients conducted from September 2013 to April 2014. Evidence-based effective nonpharmacologic interventions with nursing education were bundled into the project protocol: music, opening/closing of blinds, reorientation/cognitive stimulation, and eye/ear care. Patients were evaluated between September 2013 and April 2014, with 230 and 253 patients being included in the each phase. There was a 50.6% reduction (16.1% vs 9.6%, P < .001) in time spent delirious in the MICU. Incidence of delirium developed was decreased (15.7% vs 9.4%, P = .04). The protocol reduced the odds of developing delirium by 57% (odds ratio, 0.43; P = .005) after controlling for age, Acute Physiology and Chronic Health Evaluation II, mechanical ventilation, and dementia. The implementation of a nonpharmacologic delirium prevention protocol resulted in a significant decrease in the percentage of time spent delirious in the MICU while reducing the risk of delirium development. Additional studies with more rigorous study designs need to be completed to further the research of nonpharmacologic interventions with appropriate sedation and mobility protocols.",success
27791223,False,Journal Article;Review,,,,,,,,True,"The ONTOP project aims to undertake a literature search of systematic reviews concerning evidence-based non-pharmacological interventions of prevalent medical conditions affecting older people, including delirium. To develop explicit and transparent recommendations for non-pharmacological interventions in older subjects at risk of developing delirium, as well as in older subjects with delirium, based on the Grading of Recommendations, Assessment, Development and Evaluation (GRADE) approach to rating the quality of evidence and the strength of recommendations. A multidisciplinary panel was constituted comprising geriatricians, research nurse and a clinical epidemiologist. The panel developed a systematic overview of non-pharmacological interventions to prevent or treat delirium. The GRADE approach was used to rate the evidence and to formulate recommendations. The critical outcomes were delirium incidence, for delirium prevention, and delirium improvement and functional status, for delirium treatment. The non-pharmacological interventions were identified and categorized as multicomponent and single component. Strong recommendations in favor of multicomponent interventions to prevent delirium, in surgical or medicals wards, were formulated. In the latter case the evidence applied to older patients at intermediate - high risk of developing delirium. Weak recommendations, to prevent delirium, were formulated for multicomponent interventions provided by family members (medical ward), staff education (medical ward), ear plugs (intensive care unit), reorientation protocol (intensive care unit), and the use of a software to perform drug review. Weak recommendations were provided for the use of multicomponent interventions to prevent delirium in medical wards in patients not selected according to the risk of delirium. Strong recommendations not to use bright light therapy to prevent delirium in intensive care unit settings were articulated. Weak recommendations not to use music therapy to prevent delirium for patients undergoing surgical interventions were specified. The ability to make strong recommendations was limited by the low quality of evidence and the presence of uncertainty. Moreover, weak recommendations were provided for the use of multicomponent interventions to treat delirium of older patients (medical wards). Overall, the panel developed 12 recommendations for the delivery of non-pharmacological interventions to older patients at risk of developing or, with delirium.",success
28254205,True,Journal Article;Randomized Controlled Trial,,,,,,,,True,"Family members could play an important role in preventing and reducing the development of delirium in Intensive Care Units (ICU) patients. This study sought to assess the feasibility of design and recruitment, and acceptability for family members and nurses of a family delivered intervention to reduce delirium in ICU patients. A single centre randomised controlled trial in an Australian medical/surgical ICU was conducted. Sixty-one family members were randomised (29 in intervention and 32 in non-intervention group). Following instructions, the intervention comprised the family members providing orientation or memory clues (family photographs, orientation to surroundings) to their relative each day. In addition, family members conducted sensory checks (vision and hearing with glasses and hearing aids); and therapeutic or cognitive stimulation (discussing family life, reminiscing) daily. Eleven ICU nurses were interviewed to gain insight into the feasibility and acceptability of implementing the intervention from their perspective. Recruitment rate was 28% of eligible patients (recruited n=90, attrition n=1). Following instruction by the research nurse the family member delivered the intervention which was assessed to be feasible and acceptable by family members and nurses. Protocol adherence could be improved with alternative data collection methods. Nurses considered the activities acceptable. The study was able to recruit, randomise and retain family member participants. Further strategies are required to assess intervention fidelity and improve data collection.",success
21926572,False,"Comparative Study;Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Critically ill patients are at high risk of malnutrition. Insufficient nutritional support still remains a widespread problem despite guidelines. The aim of this study was to measure the clinical impact of a two-step interdisciplinary quality nutrition program. Prospective interventional study over three periods (A, baseline; B and C, intervention periods). Mixed intensive care unit within a university hospital. Five hundred seventy-two patients (age 59 ± 17 yrs) requiring >72 hrs of intensive care unit treatment. Two-step quality program: 1) bottom-up implementation of feeding guideline; and 2) additional presence of an intensive care unit dietitian. The nutrition protocol was based on the European guidelines. Anthropometric data, intensive care unit severity scores, energy delivery, and cumulated energy balance (daily, day 7, and discharge), feeding route (enteral, parenteral, combined, none-oral), length of intensive care unit and hospital stay, and mortality were collected. Altogether 5800 intensive care unit days were analyzed. Patients in period A were healthier with lower Simplified Acute Physiologic Scale and proportion of ""rapidly fatal"" McCabe scores. Energy delivery and balance increased gradually: impact was particularly marked on cumulated energy deficit on day 7 which improved from -5870 kcal to -3950 kcal (p < .001). Feeding technique changed significantly with progressive increase of days with nutrition therapy (A: 59% days, B: 69%, C: 71%, p < .001), use of enteral nutrition increased from A to B (stable in C), and days on combined and parenteral nutrition increased progressively. Oral energy intakes were low (mean: 385 kcal*day, 6 kcal*kg*day ). Hospital mortality increased with severity of condition in periods B and C. A bottom-up protocol improved nutritional support. The presence of the intensive care unit dietitian provided significant additional progression, which were related to early introduction and route of feeding, and which achieved overall better early energy balance.",success
19446324,True,Journal Article;Multicenter Study;Randomized Controlled Trial,NCT00322010,databank,NCT00322010,NCT00322010,NCT00322010,NCT00322010|databank,NCT00322010|databank,True,"Long-term complications of critical illness include intensive care unit (ICU)-acquired weakness and neuropsychiatric disease. Immobilisation secondary to sedation might potentiate these problems. We assessed the efficacy of combining daily interruption of sedation with physical and occupational therapy on functional outcomes in patients receiving mechanical ventilation in intensive care. Sedated adults (>/=18 years of age) in the ICU who had been on mechanical ventilation for less than 72 h, were expected to continue for at least 24 h, and who met criteria for baseline functional independence were eligible for enrolment in this randomised controlled trial at two university hospitals. We randomly assigned 104 patients by computer-generated, permuted block randomisation to early exercise and mobilisation (physical and occupational therapy) during periods of daily interruption of sedation (intervention; n=49) or to daily interruption of sedation with therapy as ordered by the primary care team (control; n=55). The primary endpoint-the number of patients returning to independent functional status at hospital discharge-was defined as the ability to perform six activities of daily living and the ability to walk independently. Therapists who undertook patient assessments were blinded to treatment assignment. Secondary endpoints included duration of delirium and ventilator-free days during the first 28 days of hospital stay. Analysis was by intention to treat. This trial is registered with ClinicalTrials.gov, number NCT00322010. All 104 patients were included in the analysis. Return to independent functional status at hospital discharge occurred in 29 (59%) patients in the intervention group compared with 19 (35%) patients in the control group (p=0.02; odds ratio 2.7 [95% CI 1.2-6.1]). Patients in the intervention group had shorter duration of delirium (median 2.0 days, IQR 0.0-6.0 vs 4.0 days, 2.0-8.0; p=0.02), and more ventilator-free days (23.5 days, 7.4-25.6 vs 21.1 days, 0.0-23.8; p=0.05) during the 28-day follow-up period than did controls. There was one serious adverse event in 498 therapy sessions (desaturation less than 80%). Discontinuation of therapy as a result of patient instability occurred in 19 (4%) of all sessions, most commonly for perceived patient-ventilator asynchrony. A strategy for whole-body rehabilitation-consisting of interruption of sedation and physical and occupational therapy in the earliest days of critical illness-was safe and well tolerated, and resulted in better functional outcomes at hospital discharge, a shorter duration of delirium, and more ventilator-free days compared with standard care. None.",success
29582429,False,"Journal Article;Research Support, Non-U.S. Gov't;Systematic Review",,,,,,,,True,"Survivors of critical illness often experience a multitude of problems that begin in the intensive care unit (ICU) or present and continue after discharge. These can include muscle weakness, cognitive impairments, psychological difficulties, reduced physical function such as in activities of daily living (ADLs), and decreased quality of life. Early interventions such as mobilizations or active exercise, or both, may diminish the impact of the sequelae of critical illness. To assess the effects of early intervention (mobilization or active exercise), commenced in the ICU, provided to critically ill adults either during or after the mechanical ventilation period, compared with delayed exercise or usual care, on improving physical function or performance, muscle strength and health-related quality of life. We searched CENTRAL, MEDLINE, Embase and CINAHL. We searched conference proceedings, reference lists of retrieved articles, databases of trial registries and contacted experts in the field on 31 August 2017. We did not impose restrictions on language or location of publications. We included all randomized controlled trials (RCTs) or quasi-RCTs that compared early intervention (mobilization or active exercise, or both), delivered in the ICU, with delayed exercise or usual care delivered to critically ill adults either during or after the mechanical ventilation period in the ICU. Two researchers independently screened titles and abstracts and assessed full-text articles against the inclusion criteria of this review. We resolved any disagreement through discussion with a third review author as required. We presented data descriptively using mean differences or medians, risk ratios and 95% confidence intervals. A meta-analysis was not possible due to the heterogeneity of the included studies. We assessed the quality of evidence with GRADE. We included four RCTs (a total of 690 participants), in this review. Participants were adults who were mechanically ventilated in a general, medical or surgical ICU, with mean or median age in the studies ranging from 56 to 62 years. Admitting diagnoses in three of the four studies were indicative of critical illness, while participants in the fourth study had undergone cardiac surgery. Three studies included range-of-motion exercises, bed mobility activities, transfers and ambulation. The fourth study involved only upper limb exercises. Included studies were at high risk of performance bias, as they were not blinded to participants and personnel, and two of four did not blind outcome assessors. Three of four studies reported only on those participants who completed the study, with high rates of dropout. The description of intervention type, dose, intensity and frequency in the standard care control group was poor in two of four studies.Three studies (a total of 454 participants) reported at least one measure of physical function. One study (104 participants) reported low-quality evidence of beneficial effects in the intervention group on return to independent functional status at hospital discharge (59% versus 35%, risk ratio (RR) 1.71, 95% confidence interval (CI) 1.11 to 2.64); the absolute effect is that 246 more people (95% CI 38 to 567) per 1000 would attain independent functional status when provided with early mobilization. The effects on physical functioning are uncertain for a range measures: Barthel Index scores (early mobilization: median 75 control: versus 55, low quality evidence), number of ADLs achieved at ICU (median of 3 versus 0, low quality evidence) or at hospital discharge (median of 6 versus 4, low quality evidence). The effects of early mobilization on physical function measured at ICU discharge are uncertain, as measured by the Acute Care Index of Function (ACIF) (early mobilization mean: 61.1 versus control: 55, mean difference (MD) 6.10, 95% CI -11.85 to 24.05, low quality evidence) and the Physical Function ICU Test (PFIT) score (5.6 versus 5.4, MD 0.20, 95% CI -0.98 to 1.38, low quality evidence). There is low quality evidence that early mobilization may have little or no effect on physical function measured by the Short Physical Performance Battery score at ICU discharge from one study of 184 participants (mean 1.6 in the intervention group versus 1.9 in usual care, MD -0.30, 95% CI -1.10 to 0.50), or at hospital discharge (MD 0, 95% CI -1.00 to 0.90). The fourth study, which examined postoperative cardiac surgery patients did not measure physical function as an outcome.Adverse effects were reported across the four studies but we could not combine the data. Our certainty in the risk of adverse events with either mobilization strategy is low due to the low rate of events. One study reported that in the intervention group one out of 49 participants (2%) experienced oxygen desaturation less than 80% and one of 49 (2%) had accidental dislodgement of the radial catheter. This study also found cessation of therapy due to participant instability occurred in 19 of 498 (4%) of the intervention sessions. In another study five of 101 (5%) participants in the intervention group and five of 109 (4.6%) participants in the control group had postoperative pulmonary complications deemed to be unrelated to intervention. A third study found one of 150 participants in the intervention group had an episode of asymptomatic bradycardia, but completed the exercise session. The fourth study reported no adverse events. There is insufficient evidence on the effect of early mobilization of critically ill people in the ICU on physical function or performance, adverse events, muscle strength and health-related quality of life at this time. The four studies awaiting classification, and the three ongoing studies may alter the conclusions of the review once these results are available. We assessed that there is currently low-quality evidence for the effect of early mobilization of critically ill adults in the ICU due to small sample sizes, lack of blinding of participants and personnel, variation in the interventions and outcomes used to measure their effect and inadequate descriptions of the interventions delivered as usual care in the studies included in this Cochrane Review.",success
25565021,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"Use of physical and/or occupational therapy in the intensive care unit (ICU) is safe, feasible, and demonstrates improvements in functional status with early administration. Access to physical and/or occupational therapy in the ICU is variable, with little known regarding its use in community ICUs. Determine what proportion of hospitals across Washington State report use of physical activity in mechanically ventilated patients and investigate process of care factors associated with reported activity delivery. Cross-sectional telephone interview survey study of nurse managers in hospitals caring for patients on mechanical ventilation across Washington State in 2013. Survey responses were linked with hospital-level data available in the Washington State Department of Health Comprehensive Hospital Abstract Reporting System database. Chi-square testing was used to explore unadjusted associations between potential process of care factors and report on activity delivery. Two multivariable logistic regression models were developed to explore the association between presence of a mobility protocol and report on delivery of activity. We identified 54 hospitals caring for patients on mechanical ventilation; 47 participated in the survey (response rate, 85.5%). Nurse managers from 36 (76.6%) hospitals reported use of physical activity in patients on mechanical ventilation, with 22 (46.8%) reporting use of high-level physical activity (transferring to chair, standing or ambulating) and 24 (51.1%) reporting use in high-severity patients (patients requiring mechanical ventilation and/or vasopressors). Presence of a written ICU activity protocol (odds ratio [OR], 5.54; 95% confidence interval [CI], 1.60-19.18; P = 0.006), hospital volume (OR, 5.33; 95% CI, 1.54-18.48; P = 0.008), and academic affiliation (OR, 4.40; 95% CI, 1.23-15.63; P = 0.02) were associated with report of higher level activity. Presence of a written ICU activity protocol (OR, 6.00; 95% CI, 1.69-21.14; P = 0.005) and academic affiliation (OR, 4.50; 95% CI, 1.21-16.46; P = 0.02) were associated with report of delivery of physical activity to high-severity patients. Nurse managers at three-fourths (76.6%) of eligible hospitals across Washington State reported use of physical activity in patients on mechanical ventilation. Hospital-level factors including hospital volume, academic affiliation, and presence of a mobility protocol were associated with report of higher level activity and delivery of activity to high-severity patients.",success
25919754,True,"Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",,,,,,,,True,"To evaluate if person-centred care can improve self-efficacy and facilitate return to work or prior activity level in patients after an event of acute coronary syndrome. 199 patients with acute coronary syndrome < 75 years were randomly assigned to person-centred care intervention or treatment as usual and followed for 6 months. In the intervention group a person-centred care process was added to treatment as usual, emphasising the patient as a partner in care. Care was co-created in collaboration between patients, physicians, registered nurses and other health care professionals and documented in a health plan. A team-based partnership across three health care levels included transparent knowledge about the disease and medical state to achieve agreed goals during recovery. Main outcome measure was a composite score of changes in general self-efficacy ≥ 5 units, return to work or prior activity level and re-hospitalisation or death. The composite score showed that more patients (22.3%, n=21) improved in the intervention group at 6 months compared to the control group (9.5%, n=10) (odds ratio, 2.7; 95% confidence interval: 1.2-6.2; P=0.015). The effect was driven by improved self-efficacy ≥ 5 units in the intervention group. Overall general self-efficacy improved significantly more in the intervention group compared with the control group (P=0.026). There was no difference between groups on re-hospitalisation or death, return to work or prior activity level. A person-centred care approach emphasising the partnership between patients and health care professionals throughout the care chain improves general self-efficacy without causing worsening clinical events.",success
28893432,True,Journal Article;Multicenter Study;Randomized Controlled Trial,,,,,,,,True,"To assess the long-term effect of person-centred care (PCC) in patients with acute coronary syndrome (ACS). Patients with ACS were randomly assigned to treatment as usual (control group) or an added PCC intervention for six months. The primary endpoint was a composite score of changes in general self-efficacy≥five units, return to work or to a prior activity level and re-hospitalisation or death. The composite score improved in the PCC intervention group (n=94) at a two-year follow-up compared with the control group (n=105) (18.1%, n=17 vs. 10.5%, n=11; P=0.127). In the per-protocol analysis (n=183) the improvement was significant in favour of the PCC intervention (n=78) compared with usual care (n=105) (21.8%, n=17 vs. 10.5%, n=11; P=0.039). This effect was driven by the finding that more patients in the PCC group improved their general self-efficacy score≥5units (32.2%, n=19 vs. 17.3%, n=14; P=0.046). The composite score improvement was significantly higher in the PCC intervention group without post-secondary education (n=33) in comparison with corresponding patients in the control group (n=50) (30.3%, n=10 vs. 10.0%, n=5; P=0.024). Implementation of PCC results in sustained improvements in health outcome in patients with ACS. PCC can be incorporated into conventional cardiac prevention programmes to improve equity in uptake and patient health outcomes. Swedish registry, Researchweb.org, ID NR 65791.",success
23231540,False,"Journal Article;Research Support, Non-U.S. Gov't;Systematic Review;Validation Study",,,,,,,,True,"To identify person-centred care as an intervention in controlled trials, where patients had been involved as a partner, and to describe the outcomes of these studies. The notion of person-centred care asserts that patients are persons and partners in care and should not be reduced to their disease alone. A systematic literature review. Searches were undertaken in the databases PUBMED and CINAHL. The inclusion criteria were that person-centred care as an intervention was described as a partnership between the caregiver and the patient, and that the studies were randomised controlled trials or quasi-experimental designs. The studies were analysed based on methodology, context and type of intervention, outcomes and effects of the interventions. Eleven trials fulfilled the inclusion criteria. The studies were carried out in a variety of contexts with diverse outcomes. Person-centred care as an intervention was shown to be successful in eight of the studies. The internal and external validity in the studies were generally good. However, as regards the precision of the studies there was a wide variation. The value and efficacy of person-centred care as an intervention have only been studied to a limited extent. Methodological problems in trial design and execution could account for the general lack of research on person-centred care. Evidence that person-centred care is effective is insufficient, more stringent studies are needed. The results suggest that person-centred care may lead to significant improvements, but the implementation and relevant effects needs to be assessed in more studies.",success
26509317,False,Journal Article;Practice Guideline,,,,,,,,True,"Shared decision making is endorsed by critical care organizations; however, there remains confusion about what shared decision making is, when it should be used, and approaches to promote partnerships in treatment decisions. The purpose of this statement is to define shared decision making, recommend when shared decision making should be used, identify the range of ethically acceptable decision-making models, and present important communication skills. The American College of Critical Care Medicine and American Thoracic Society Ethics Committees reviewed empirical research and normative analyses published in peer-reviewed journals to generate recommendations. Recommendations approved by consensus of the full Ethics Committees of American College of Critical Care Medicine and American Thoracic Society were included in the statement. Six recommendations were endorsed: 1) DEFINITION: Shared decision making is a collaborative process that allows patients, or their surrogates, and clinicians to make healthcare decisions together, taking into account the best scientific evidence available, as well as the patient's values, goals, and preferences. 2) Clinicians should engage in a shared decision making process to define overall goals of care (including decisions regarding limiting or withdrawing life-prolonging interventions) and when making major treatment decisions that may be affected by personal values, goals, and preferences. 3) Clinicians should use as their ""default"" approach a shared decision making process that includes three main elements: information exchange, deliberation, and making a treatment decision. 4) A wide range of decision-making approaches are ethically supportable, including patient- or surrogate-directed and clinician-directed models. Clinicians should tailor the decision-making process based on the preferences of the patient or surrogate. 5) Clinicians should be trained in communication skills. 6) Research is needed to evaluate decision-making strategies. Patient and surrogate preferences for decision-making roles regarding value-laden choices range from preferring to exercise significant authority to ceding such authority to providers. Clinicians should adapt the decision-making model to the needs and preferences of the patient or surrogate.",success
24148851,True,"Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",NCT01876173,databank,NCT01876173,NCT01876173,NCT01876173,NCT01876173|databank,NCT01876173|databank,True,"Patients, identified to be at risk for but who have never experienced a potentially lethal cardiac arrhythmia, have the option of receiving an implantable cardioverter defibrillator (ICD) as prophylaxis against sudden cardiac death - a primary prevention indication. In Canada, there is no clear framework to support patients' decision-making for these devices. Decision support, using a decision aid, could moderate treatment-related uncertainty and prepare patients to make well-informed decisions. Patient decision aids provide information on treatment options, risks, and benefits, to help patients clarify their values for outcomes of treatment options. The objectives of this research are: 1) develop a decision aid, 2) evaluate the decision aid, and 3) determine the feasibility of conducting a trial. A development panel comprised of the core investigative team, health service researchers, decision science experts, cardiovascular healthcare practitioners, and ICD patient representatives will collaborate to provide input on the content and format of the aid. To generate probabilities to include in the aid, we will synthesize primary prevention ICD evidence. To obtain anonymous input about the facts and content, we will employ a modified Delphi process. To evaluate the draft decision aid will invite ICD patients and their families (n = 30) to rate its acceptability. After we evaluate the aid, to determine the feasibility, we will conduct a feasibility pilot randomized controlled trial (RCT) in new ICD candidates (n = 80). Participants will be randomized to receive a decision aid prior to specialist consultation versus usual care. Results from the pilot RCT will determine the feasibility of research processes; inform sample size calculation, measure decision quality (knowledge, values, decision conflict) and the influence of health related quality of life on decision-making. Our study seeks to develop a decision aid, for patients offered their first ICD for prophylaxis against sudden cardiac death. This paper outlines the background and methods of a pilot randomized trial which will inform a larger multicenter trial. Ultimately, decision support prior to specialist consultation could enhance the decision-making process between patients, physicians, and families, associated with life-prolonging medical devices like the ICD. ClinicalTrials.gov: NCT01876173.",success
24219117,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Sudden cardiac death is a well-documented public health problem and the implantable cardioverter defibrillator (ICD) has demonstrated benefit in reducing mortality. Prospective patients must identify and evaluate the ICD's pros and cons and produce a personal decision. The purpose of this study was to create and evaluate a measure of patient-evaluated pros and cons of the ICD, and its relationship to patient decision regarding ICD implantation. The ICD-decision analysis scale (ICD-DAS) was created and tested in prospective ICD recipients (N = 104). Factor analysis was performed to evaluate interitem relationships, and subsequently, identified subscales; additional psychosocial measures were used to predict the ICD decision. A two-factor measure for ICD decision making was established with two subscales: ICD Pros and ICD Cons. The subscales have high internal consistency and were strong predictors of intent to choose an ICD. Other psychosocial measures were not significantly predictive of ICD Choice, yet simultaneous entry of ICD Pros and Cons subscales resulted in a significant increase in R(2) , F(2, 59) = 19.36, P < 0.001. The full model was significantly greater than zero, F(11, 70) = 5.017, P < 0.001, R(2)  = 0.48. The ICD-DAS provides the first empirically tested and clinically useful approach to understanding the specific pros and cons for prospective ICD patients. The measure can assist clinicians with patient-centered discussions regarding sudden cardiac arrest treatments. The ICD-DAS will allow for the provision of tailored education or counseling and may be used to predict postdecision outcomes.",success
25438725,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"The Clinical Decision Aid was created to assist in selecting anticoagulant therapies for patients with nonvalvular atrial fibrillation. The aid incorporates a patient's absolute risk for stroke and bleeding, relative stroke risk reduction, and increase in relative bleeding risk to identify the agent with the lowest net risk. We describe theoretical implications of utilizing the aid at a US managed care population level. This retrospective study used claims data from a large US managed care database including enrollees in commercial and Medicare Advantage plans. The distribution of patients across each possible combination of scores on the HAS-BLED scale (evidence of hypertension, abnormal renal or liver function, stroke, bleeding, labile INR, age >65 years, and drugs or alcohol abuse or dependence) and the CHA2DS2-VASc scale (CHADS2 [congestive heart failure, hypertension, age ≥75 years, diabetes mellitus, prior stroke or transient ischemic attack or thromboembolism] with additional nonmajor stroke risk factors, including age 65-74 years, female sex, and vascular disease) was generated. We assessed the correlation between the HAS-BLED and CHA2DS2-VASc scores and derived the optimal treatment options based on various bleeding ratios. Data from 48,260 patients were included in the analysis. The MAPD subset had a higher mean HAS-BLED score (2.17 vs 1.39; P < 0.001) and a higher mean CHA2DS2-VASc score (3.35 vs 2.05; P < 0.001) than did the commercial subset. Pearson coefficients suggested a moderate to strong positive correlation between the HAS-BLED and CHA2DS2-VASc scores among the commercial (0.730; P < 0.001) and MAPD (0.568; P < 0.001) enrollees. Based on a 2:1 bleeding-to-stroke risk ratio, 70.50% of patients would be recommended treatment with apixaban; 25.86%, no treatment; 3.62%, acetylsalicylic acid; and 0.01%, dabigatran 150 mg, if the Clinical Decision Aid were to be used for anticoagulant treatment selection. Evidence-based clinical decision-making tools utilizing risk assessment for recommending a treatment may be valuable for not only health care providers but also health care payers in optimizing care at the population level.",success
27919865,True,Journal Article;Pragmatic Clinical Trial;Randomized Controlled Trial,NCT01969240,databank,NCT01969240,NCT01969240,NCT01969240,NCT01969240|databank,NCT01969240|databank,True,"To compare the effectiveness of shared decision making with usual care in choice of admission for observation and further cardiac testing or for referral for outpatient evaluation in patients with possible acute coronary syndrome.  Multicenter pragmatic parallel randomized controlled trial.  Six emergency departments in the United States.  898 adults (aged >17 years) with a primary complaint of chest pain who were being considered for admission to an observation unit for cardiac testing (451 were allocated to the decision aid and 447 to usual care), and 361 emergency clinicians (emergency physicians, nurse practitioners, and physician assistants) caring for patients with chest pain.  Patients were randomly assigned (1:1) by an electronic, web based system to shared decision making facilitated by a decision aid or to usual care. The primary outcome, selected by patient and caregiver advisers, was patient knowledge of their risk for acute coronary syndrome and options for care; secondary outcomes were involvement in the decision to be admitted, proportion of patients admitted for cardiac testing, and the 30 day rate of major adverse cardiac events.  Compared with the usual care arm, patients in the decision aid arm had greater knowledge of their risk for acute coronary syndrome and options for care (questions correct: decision aid, 4.2 v usual care, 3.6; mean difference 0.66, 95% confidence interval 0.46 to 0.86), were more involved in the decision (observing patient involvement scores: decision aid, 18.3 v usual care, 7.9; 10.3, 9.1 to 11.5), and less frequently decided with their clinician to be admitted for cardiac testing (decision aid, 37% v usual care, 52%; absolute difference 15%; P<0.001). There were no major adverse cardiac events due to the intervention.  Use of a decision aid in patients at low risk for acute coronary syndrome increased patient knowledge about their risk, increased engagement, and safely decreased the rate of admission to an observation unit for cardiac testing.Trial registration ClinicalTrials.gov NCT01969240.",success
22496116,True,"Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",NCT01077037,databank,NCT01077037,NCT01077037,NCT01077037,NCT01077037|databank,NCT01077037|databank,True,"Cardiac stress testing in patients at low risk for acute coronary syndrome is associated with increased false-positive test results, unnecessary downstream procedures, and increased cost. We judged it unlikely that patient preferences were driving the decision to obtain stress testing. The Chest Pain Choice trial was a prospective randomized evaluation involving 204 patients who were randomized to a decision aid or usual care and were followed for 30 days. The decision aid included a 100-person pictograph depicting the pretest probability of acute coronary syndrome and available management options (observation unit admission and stress testing or 24-72 hours outpatient follow-up). The primary outcome was patient knowledge measured by an immediate postvisit survey. Additional outcomes included patient engagement in decision making and the proportion of patients who decided to undergo observation unit admission and cardiac stress testing. Compared with usual care patients (n=103), decision aid patients (n=101) had significantly greater knowledge (3.6 versus 3.0 questions correct; mean difference, 0.67; 95% CI, 0.34-1.0), were more engaged in decision making as indicated by higher OPTION (observing patient involvement) scores (26.6 versus 7.0; mean difference, 19.6; 95% CI, 1.6-21.6), and decided less frequently to be admitted to the observation unit for stress testing (58% versus 77%; absolute difference, 19%; 95% CI, 6%-31%). There were no major adverse cardiac events after discharge in either group. Use of a decision aid in patients with chest pain increased knowledge and engagement in decision making and decreased the rate of observation unit admission for stress testing.",success
27503067,False,Journal Article;Review,,,,,,,,True,"The mission of the American Heart Association/American Stroke Association includes increasing access to high-quality, evidence-based care that improves patient outcomes such as health-related quality of life and is consistent with the patients' values, preferences, and goals. Awareness of and access to palliative care interventions align with the American Heart Association/American Stroke Association mission. The purposes of this policy statement are to provide background on the importance of palliative care as it pertains to patients with advanced cardiovascular disease and stroke and their families and to make recommendations for policy decisions. Palliative care, defined as patient- and family-centered care that optimizes health-related quality of life by anticipating, preventing, and treating suffering, should be integrated into the care of all patients with advanced cardiovascular disease and stroke early in the disease trajectory. Palliative care focuses on communication, shared decision making about treatment options, advance care planning, and attention to physical, emotional, spiritual, and psychological distress with inclusion of the patient's family and care system. Our policy recommendations address the following: reimbursement for comprehensive delivery of palliative care services for patients with advanced cardiovascular disease and stroke; strong payer-provider relationships that involve data sharing to identify patients in need of palliative care, identification of better care and payment models, and establishment of quality standards and outcome measurements; healthcare system policies for the provision of comprehensive palliative care services during hospitalization, including goals of care, treatment decisions, needs of family caregivers, and transition to other care settings; and health professional education in palliative care as part of licensure requirements.",success
27037030,False,Journal Article,,,,,,,,True,"The purpose of this study was to examine hospital mortality, long-term mortality, and health service utilization among critically ill patients. We also determined whether these outcomes differed according to demographic and clinical characteristics. We conducted a retrospective cohort study of adults (age ≥ 18 years) who survived admission to an intensive care unit (ICU) in Ontario, Canada, between 1 April 2002 and 31 March 2012, excluding isolated admissions to step-down or intermediate ICUs, coronary care ICUs, or cardiac surgery ICUs. Adults (age ≥ 18 years) who survived an acute hospitalization that did not include an ICU stay formed the comparator group. The primary outcome was mortality following hospital discharge. Secondary outcomes were healthcare utilization, including emergency room admissions and hospital readmissions during follow-up. Over the study interval, 500,124 patients were admitted to ICUs and 420,187 (84%) survived to hospital discharge. Median follow-up for survivors was 5.3 (interquartile range 2.5, 8.2) years. Patients admitted to an ICU were more likely to subsequently visit the emergency department, be readmitted to the hospital and ICU, receive home care support, require rehabilitation, and be admitted for long-term care. Those requiring more resources within the ICU required more resources after discharge. One-third of patients admitted to the ICU died during long-term follow-up, with overall probabilities of death of 11% and 29% at 1 year and 5 years, respectively. In the adjusted analysis, there was an increasing hazard of death with increasing age, reaching a hazard ratio of 18.08 (95 % confidence interval 16.60-19.68) for those ≥ 85 years of age compared with those aged 18-24 years. Healthcare utilization after hospital discharge was higher among ICU patients, and also among those requiring more healthcare resources during their ICU admission, than among all hospitalized patients as a group. One-third of ICU patients died within the 5 years following discharge, and age was the most influential determinant of outcome. These findings should help target post-ICU discharge services for high-risk groups and better inform goals-of-care discussions for elderly critically ill patients.",success
25706486,False,"Journal Article;Observational Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"Many studies of critical illness outcomes have been restricted to short-term outcomes, selected diagnoses, and patients in one or a few intensive care units (ICUs). Evaluate a range of relevant outcomes in a population-based cohort of patients admitted to ICUs. Among all adult residents of the Canadian province of Manitoba admitted to ICUs over a 9-year period, we assessed ICU, hospital, 30-day, and 180-day mortality rates; ICU and hospital lengths-of-stay; Post-hospital use of hospital care, ICU care, outpatient physician care, medications, and home care; and Post-hospital residence location. We explored data stratified by age, sex, and separate categories of geocoded income for urban and rural residents. For Post-hospital use variables we compared ICU patients with those admitted to hospitals without the need for ICU care. After ICU admission there was a high initial death rate, which declined between 30 and 180 days and thereafter remained at the lower value. Hospital mortality was 19.0%, with 21.7% dying within 6 months of ICU admission. Women had higher hospital mortality than men (20.8 vs. 17.8%; P = 0.0008). Among urban residents there was a steady gradient of declining hospital mortality with rising income (P < 0.0001). Mean ICU length of stay was 3.96 days, increasing 0.11 d/yr over the study period (P = 0.001); median ICU length of stay was 2.33 days and did not change over time. In the year after ICU care, 41% were rehospitalized, 10% were readmitted to an ICU, 98% had outpatient physician visits, 96% used prescription medications, and 27% used home care services. Although most of these parameters were statistically higher than for hospitalizations not requiring ICU care, differences were generally small. Among hospital survivors, 2.7% were discharged to chronic care facilities, with 2.5% living in such facilities 3 months later. Post-hospital medical resource use among ICU survivors is substantial, although similar to that after non-ICU hospitalization. Although the fraction of survivors unable to live independently was small, a larger fraction required home care services. Identifying Post-hospital supports needed by ICU survivors can be useful for policy makers and others responsible for healthcare planning.",success
25727085,False,Journal Article,,,,,,,,True,"Patients admitted to today's cardiac intensive care units (CICUs) have increasingly complex medical conditions; consequently, palliative care is becoming an integral component of their care. Although there is a robust body of literature emanating from other intensive care unit settings, there has been less discussion about the role of palliative care in the CICU. This study examined all admissions to the Mount Sinai Hospital CICU from January 1 through December 31, 2012. Of the 1,368 patients admitted, there were 117 CICU patient deaths. End-of-life discussions were carried out in 85 patients (72.6%) who died during that hospital admission; the primary CICU team led these discussions and helped with decision making in >1/2 of them. For the 85 patients who had goals of care (GOC) discussions, there was a higher rate of redirected GOC toward comfort care or no escalation of care (38.8% vs 3.1%, p <0.001) and withdrawal of life-sustaining treatments, such as mechanical ventilation and vasopressors (23.5% vs 6.3%, p = 0.02) compared with patients for whom no GOC discussions were held. Among patients who had GOC discussions, there was no statistically significant difference for patients who had their mechanical circulatory support, defibrillator, or pacing therapies turned off compared with patients who were not involved in GOC discussions. With the exception of discontinuation of mechanical circulatory support which took place for 6 of the 7 patients in the CICU, end-of-life interventions were split evenly between the palliative care unit and the CICU. There was no difference in CICU length of stay or days to mortality from the time of CICU admission between the 2 groups. In conclusion, our study demonstrates the effect of palliative care and end-of-life decision making in the CICU. As such, we advocate for increased palliative care education and training among clinicians who are involved in cardiac critical care.",success
22980296,False,Journal Article;Review,,,,,,,,True,"BACKGROUND AND APPROACH: There is a growing emphasis on the need for high-quality and patient-centered palliative care for patients with heart failure (HF) near end of life. Accordingly, clinicians require adequate knowledge of patient values and preferences, but this topic has been underreported in the HF literature. In response, we conducted a structured narrative review of available evidence regarding patient preferences for HF care near end of life, focusing on circumstances of death, advance care planning, and preferences for specific HF therapies. Patients had widely varying preferences for sudden (""unaware"") death versus a death that was anticipated (""aware""), which would allow time to make arrangements and time with family; preferences influenced their choice of HF therapies. Patients and physicians rarely discussed advance care planning; physicians were rarely aware of resuscitation preferences. Advance care planning discussions rarely included preferences for limiting implantable cardioverter defibrillator use, and patients were often uninformed of the option of implantable cardioverter defibrillator deactivation. A substantial minority of patients strongly preferred improved quality of life versus extended survival, but preferences of individuals could not be easily predicted. Current evidence regarding preferences of patients with HF near end of life suggests substantial opportunities for improvement of end-of-life HF care. Most notably, the wide distribution of patient preferences highlights the need to tailor approach to patient wishes, avoiding assumptions of patient wishes. A research agenda and implications for health care provider training are proposed.",success
27568873,False,Journal Article;Review,,,,,,,,True,"Advanced heart failure (HF) therapies are focused on extending life and improving function. In contrast, palliative care is a holistic approach that focuses on symptom alleviation and patients' physical, psychosocial, and spiritual needs. HF clinicians can integrate palliative care strategies by incorporating several important components of planning and decision-making for HF patients. Future care planning (FCP) for HF patients should incorporate the basic tenets of shared decision-making (SDM). These include understanding the patient's perspective and care preferences, articulating what is medically feasible, and integrating these considerations into the overall care plan. Use of defined triggers for FCP can stimulate important patient-caregiver conversations. Guidelines advocate an annual review of HF status and future care preferences. Advance directives are important for any individual with a chronic, life-limiting illness and should be integrated into FCP. Nevertheless, use of advance directives by HF patients is extremely low. Consideration of illness trajectories and risk-scoring tools might facilitate prognostication and delivery of appropriate HF care. Decisions about heart transplantation or left ventricular assist device implantation should include planning for potential complications associated with these therapies. Such decisions also should include a discussion of palliative management, as an alternative to intervention and also as an option for managing symptoms or adverse events after intervention. Palliative care, including FCP and SDM, should be integrated into the course of all patients with advanced HF. Clinicians who provide HF care should acquire the skills necessary for conducting FCP and SDM discussions.",success
24862840,False,"Journal Article;Meta-Analysis;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, Non-P.H.S.;Systematic Review",,,,,,,,True,"Nearly 25% of patients hospitalized with heart failure (HF) are readmitted within 30 days. To assess the efficacy, comparative effectiveness, and harms of transitional care interventions to reduce readmission and mortality rates for adults hospitalized with HF. MEDLINE, Cochrane Library, CINAHL, ClinicalTrials.gov, and World Health Organization International Clinical Trials Registry Platform (1 January 1990 to late October 2013). Two reviewers independently selected randomized, controlled trials published in English reporting a readmission or mortality rate within 6 months of an index hospitalization. One reviewer extracted data, and another checked accuracy. Two reviewers assessed risk of bias and graded strength of evidence (SOE). Forty-seven trials were included. Most enrolled adults with moderate to severe HF and a mean age of 70 years. Few trials reported 30-day readmission rates. At 30 days, a high-intensity home-visiting program reduced all-cause readmission and the composite end point (all-cause readmission or death; low SOE). Over 3 to 6 months, home-visiting programs and multidisciplinary heart failure (MDS-HF) clinic interventions reduced all-cause readmission (high SOE). Home-visiting programs reduced HF-specific readmission and the composite end point (moderate SOE). Structured telephone support (STS) interventions reduced HF-specific readmission (high SOE) but not all-cause readmissions (moderate SOE). Home-visiting programs, MDS-HF clinics, and STS interventions produced a mortality benefit. Neither telemonitoring nor primarily educational interventions reduced readmission or mortality rates. Few trials reported 30-day readmission rates. Usual care was heterogeneous and sometimes not adequately described. Home-visiting programs and MDS-HF clinics reduced all-cause readmission and mortality; STS reduced HF-specific readmission and mortality. These interventions should receive the greatest consideration by systems or providers seeking to implement transitional care interventions for persons with HF. Agency for Healthcare Research and Quality.",success
25604605,False,Journal Article,,,,,,,,True,"In patients with heart failure (HF), use of 30-day rehospitalization as a healthcare metric and increased pressure to provide value-based care compel healthcare providers to improve efficiency and to use an integrated care approach. Transition programs are being used to achieve goals. Transition of care in the context of HF management refers to individual interventions and programs with multiple activities that are designed to improve shifts or transitions from one setting to the next, most often from hospital to home. As transitional care programs become the new normal for patients with chronic HF, it is important to understand the current state of the science of transitional care, as discussed in the available research literature. Of transitional care reports, there was much heterogeneity in research designs, methods, study aims, and program targets, or they were not well described. Often, programs used bundled interventions, making it difficult to discuss the efficiency and effectiveness of specific interventions. Thus, further HF transition care research is needed to ensure best practices related to economically and clinically effective and feasible transition interventions that can be broadly applicable. This statement provides an overview of the complexity of HF management and includes patient, hospital, and healthcare provider barriers to understanding end points that best reflect clinical benefits and to achieving optimal clinical outcomes. The statement describes transitional care interventions and outcomes and discusses implications and recommendations for research and clinical practice to enhance patient-centered outcomes.",success
23861483,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Reducing hospital readmission rates is a national priority; however, evidence about hospital strategies that are associated with lower readmission rates is limited. We sought to identify hospital strategies that were associated with lower readmission rates for patients with heart failure. Using data from a Web-based survey of hospitals participating in national quality initiatives to reduce readmission (n=599; 91% response rate) during 2010-2011, we constructed a multivariable linear regression model, weighted by hospital volume, to determine strategies independently associated with risk-standardized 30-day readmission rates (RSRRs) adjusted for hospital teaching status, geographic location, and number of staffed beds. Strategies that were associated with lower hospital RSRRs included the following: (1) partnering with community physicians or physician groups to reduce readmission (0.33% percentage point lower RSRRs; P=0.017), (2) partnering with local hospitals to reduce readmissions (0.34 percentage point; P=0.020), (3) having nurses responsible for medication reconciliation (0.18 percentage point; P=0.002), (4) arranging follow-up appointments before discharge (0.19 percentage point; P=0.037), (5) having a process in place to send all discharge paper or electronic summaries directly to the patient's primary physician (0.21 percentage point; P=0.004), and (6) assigning staff to follow up on test results that return after the patient is discharged (0.26 percentage point; P=0.049). Although statistically significant, the magnitude of the effects was modest with individual strategies associated with less than half a percentage point reduction in RSRRs; however, hospitals that implemented more strategies had significantly lower RSRRs (reduction of 0.34 percentage point for each additional strategy). Several strategies were associated with lower hospital RSRRs for patients with heart failure.",success
22986378,False,"Journal Article;Research Support, U.S. Gov't, P.H.S.;Systematic Review",,,,,,,,True,"Transitional care is a time-limited service to prevent discontinuous care and adverse outcomes, including rehospitalization. To describe transitional care interventions and evidence of benefit or harm in patients hospitalized for acute stroke or myocardial infarction (MI). Cumulative Index to Nursing and Allied Health Literature, MEDLINE, Cochrane Database of Systematic Reviews, and EMBASE, supplemented with manual searches of reference lists of relevant studies and review articles (January 2000 to March 2012). 6 reviewers screened 5857 citations to identify English-language reports of trials or observational studies that compared transitional care with usual care among adults hospitalized for stroke or MI and that reported patient, caregiver, process, or systems outcomes within 1 year of hospital discharge. Data on study design, quality, population, intervention characteristics, and patient- and system-level outcomes were extracted by 3 reviewers and confirmed by 1 additional reviewer. 62 articles representing 44 studies of transitional care for either acute stroke (27 studies) or MI (17 studies). Four intervention types were studied: hospital-initiated support (n = 14), patient and family education (n = 7), community-based support (n = 20), and chronic disease management (n = 3). Most studies (68%) were of fair quality. Overall, moderate-strength evidence showed that hospital-initiated support reduced length of stay for patients who had a stroke, and low-strength evidence showed that it reduced mortality for patients who had an MI. Evidence about benefits of other interventions and harms from transitional care services was insufficient. Few studies had high-quality research designs. The usual care comparator was often poorly defined. Applicability to U.S. clinical practice was limited; only 6 studies were conducted in the United States. Available evidence shows that hospital-initiated transitional care can improve some outcomes in adults hospitalized for stroke or MI. Finding additional transitional care interventions that improve functional outcomes and prevent rehospitalizations and adverse events is a high priority for the growing population of patients who have an MI or a stroke. Agency for Healthcare Research and Quality.",success
28064173,False,"Journal Article;Research Support, Non-U.S. Gov't;Scoping Review",,,,,,,,True,"frailty impacts older adults' ability to recover from an acute illness, injuries and other stresses. Currently, a systematic synthesis of available interventions to prevent or reduce frailty does not exist. Therefore, we conducted a scoping review of interventions and international policies designed to prevent or reduce the level of frailty in community-dwelling older adults. we conducted a scoping review using the framework of Arksey and O'Malley. We systematically searched articles and grey literature to identify interventions and policies that aimed to prevent or reduce the level of frailty. fourteen studies were included: 12 randomised controlled trials and 2 cohort studies (mean number of participants 260 (range 51-610)), with most research conducted in USA and Japan. The study quality was moderate to good. The interventions included physical activity; physical activity combined with nutrition; physical activity plus nutrition plus memory training; home modifications; prehabilitation (physical therapy plus exercise plus home modifications) and comprehensive geriatric assessment (CGA). Our review showed that the interventions that significantly reduced the number of frailty markers present or the prevalence of frailty included the physical activity interventions (all types and combinations), and prehabilitation. The CGA studies had mixed findings. nine of the 14 studies reported that the intervention reduced the level of frailty. The results need to be interpreted with caution, as only 14 studies using 6 different definitions of frailty were retained. Future research could combine interventions targeting more frailty markers including cognitive or psychosocial well-being.",success
29298089,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Review",,,,,,,,False,,success
27243899,True,Journal Article;Randomized Controlled Trial,NCT00715962,databank,NCT00715962,NCT00715962,NCT00715962,NCT00715962|databank,NCT00715962|databank,True,"Low mobility is common during hospitalization and associated with loss or declines in ability to perform activities of daily living (ADL) and limitations in community mobility. To examine the effect of an in-hospital mobility program (MP) on posthospitalization function and community mobility. This single-blind randomized clinical trial used masked assessors to compare a MP with usual care (UC). Patients admitted to the medical wards of the Birmingham Veterans Affairs Medical Center from January 12, 2010, through June 29, 2011, were followed up throughout hospitalization with 1-month posthospitalization telephone follow-up. One hundred hospitalized patients 65 years or older were randomly assigned to the MP or UC groups. Patients were cognitively intact and able to walk 2 weeks before hospitalization. Data analysis was performed from November 21, 2012, to March 14, 2016. Patients in the MP group were assisted with ambulation up to twice daily, and a behavioral strategy was used to encourage mobility. Patients in the UC group received twice-daily visits. Changes in self-reported ADL and community mobility were assessed using the Katz ADL scale and the University of Alabama at Birmingham Study of Aging Life-Space Assessment (LSA), respectively. The LSA measures community mobility based on the distance through which a person reports moving during the preceding 4 weeks. Of 100 patients, 8 did not complete the study (6 in the MP group and 2 in the UC group). Patients (mean age, 73.9 years; 97 male [97.0%]; and 19 black [19.0%]) had a median length of stay of 3 days. No significant differences were found between groups at baseline. For all periods, groups were similar in ability to perform ADL; however, at 1-month after hospitalization, the LSA score was significantly higher in the MP (LSA score, 52.5) compared with the UC group (LSA score, 41.6) (P = .02). For the MP group, the 1-month posthospitalization LSA score was similar to the LSA score measured at admission. For the UC group, the LSA score decreased by approximately 10 points. A simple MP intervention had no effect on ADL function. However, the MP intervention enabled patients to maintain their prehospitalization community mobility, whereas those in the UC group experienced clinically significant declines. Lower life-space mobility is associated with increased risk of death, nursing home admission, and functional decline, suggesting that declines such as those observed in the UC group would be of great clinical importance. clinicaltrials.gov Identifier: NCT00715962.",success
19623052,True,"Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",,,,,,,,True,": To investigate whether a daily exercise session, using a bedside cycle ergometer, is a safe and effective intervention in preventing or attenuating the decrease in functional exercise capacity, functional status, and quadriceps force that is associated with prolonged intensive care unit stay. A prolonged stay in the intensive care unit is associated with muscle dysfunction, which may contribute to an impaired functional status up to 1 yr after hospital discharge. No evidence is available concerning the effectiveness of an early exercise training intervention to prevent these detrimental complications. : Randomized controlled trial. : Medical and surgical intensive care unit at University Hospital Gasthuisberg. : Ninety critically ill patients were included as soon as their cardiorespiratory condition allowed bedside cycling exercise (starting from day 5), given they still had an expected prolonged intensive care unit stay of at least 7 more days. : Both groups received respiratory physiotherapy and a daily standardized passive or active motion session of upper and lower limbs. In addition, the treatment group performed a passive or active exercise training session for 20 mins/day, using a bedside ergometer. : All outcome data are reflective for survivors. Quadriceps force and functional status were assessed at intensive care unit discharge and hospital discharge. Six-minute walking distance was measured at hospital discharge. No adverse events were identified during and immediately after the exercise training. At intensive care unit discharge, quadriceps force and functional status were not different between groups. At hospital discharge, 6-min walking distance, isometric quadriceps force, and the subjective feeling of functional well-being (as measured with ""Physical Functioning"" item of the Short Form 36 Health Survey questionnaire) were significantly higher in the treatment group (p < .05). : Early exercise training in critically ill intensive care unit survivors enhanced recovery of functional exercise capacity, self-perceived functional status, and muscle force at hospital discharge.",success
26771786,False,Journal Article,,,,,,,,False,,success
27687720,False,Journal Article;Review,,,,,,,,True,"Over the past half century, coronary care units have expanded from specialized ischemia arrhythmia monitoring units into intensive care units (ICUs) for acutely ill and medically complex patients with a primary cardiac diagnosis. Patients admitted to contemporary coronary intensive care units (CICUs) are at risk for common and preventable critical care complications, yet many CICUs have not adopted standard-of-care prevention protocols and practices from general ICUs. In this article, we (1) review evidence-based interventions and care bundles that reduce the incidence of ventilator-associated pneumonia, excess sedation during mechanical ventilation, central line infections, stress ulcers, malnutrition, delirium, and medication errors and (2) recommend pragmatic adaptations for common conditions in critically ill patients with cardiac disease, and (3) provide example order sets and practical CICU protocol implementation strategies.",success
10422996,True,"Clinical Trial;Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",,,,,,,,True,"Pharmacist review of medication orders in the intensive care unit (ICU) has been shown to prevent errors, and pharmacist consultation has reduced drug costs. However, whether pharmacist participation in the ICU at the time of drug prescribing reduces adverse events has not been studied. To measure the effect of pharmacist participation on medical rounds in the ICU on the rate of preventable adverse drug events (ADEs) caused by ordering errors. Before-after comparison between phase 1 (baseline) and phase 2 (after intervention implemented) and phase 2 comparison with a control unit that did not receive the intervention. A medical ICU (study unit) and a coronary care unit (control unit) in a large urban teaching hospital. Seventy-five patients randomly selected from each of 3 groups: all admissions to the study unit from February 1, 1993, through July 31, 1993 (baseline) and all admissions to the study unit (postintervention) and control unit from October 1, 1994, through July 7, 1995. In addition, 50 patients were selected at random from the control unit during the baseline period. A senior pharmacist made rounds with the ICU team and remained in the ICU for consultation in the morning, and was available on call throughout the day. Preventable ADEs due to ordering (prescribing) errors and the number, type, and acceptance of interventions made by the pharmacist. Preventable ADEs were identified by review of medical records of the randomly selected patients during both preintervention and postintervention phases. Pharmacists recorded all recommendations, which were then analyzed by type and acceptance. The rate of preventable ordering ADEs decreased by 66% from 10.4 per 1000 patient-days (95% confidence interval [CI], 7-14) before the intervention to 3.5 (95% CI, 1-5; P<.001) after the intervention. In the control unit, the rate was essentially unchanged during the same time periods: 10.9 (95% CI, 6-16) and 12.4 (95% CI, 8-17) per 1000 patient-days. The pharmacist made 366 recommendations related to drug ordering, of which 362 (99%) were accepted by physicians. The presence of a pharmacist on rounds as a full member of the patient care team in a medical ICU was associated with a substantially lower rate of ADEs caused by prescribing errors. Nearly all the changes were readily accepted by physicians.",success
29344376,False,Journal Article;Review,,,,,,,,True,"The pharmacist may play a relevant role in primary and secondary prevention of cardiovascular diseases, mainly through patient education and counselling, drug safety management, medication review, monitoring and reconciliation, detection and control of specific cardiovascular risk factors (eg, blood pressure, blood glucose, serum lipids) and clinical outcomes. Systematic reviews of randomised controlled and observational studies have documented an improved control of hypertension, dyslipidaemia or diabetes, smoking cessation and reduced hospitalisation in patients with heart failure, following a pharmacist's intervention. Limited proof for effectiveness is available for humanistic (patient satisfaction, adherence and knowledge) and economic outcomes. A multidisciplinary approach, including medical input plus a pharmacist, specialist nurse or both, and a greater involvement of community rather than hospital pharmacists, seems to represent the most efficient and modern healthcare delivery model. However, further well-designed research is demanded in order to quantitatively and qualitatively evaluate the impact of pharmacist's interventions on cardiovascular disease and to identify specific areas of impact of collaborative practice. Such research should particularly focus on the demonstration of a sensitivity to community pharmacist's intervention. Since pharmacy services are easily accessible and widely distributed in the community setting, a maximum benefit should be expected from interventions provided in this context.",success
26541925,False,"Journal Article;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"Team-based cardiovascular care, including the use of clinical pharmacists, can efficiently deliver high-quality care. This Joint Council Perspectives paper from the Cardiovascular Team and Prevention Councils of the American College of Cardiology provides background information on the clinical pharmacist's role, training, certification, and potential utilization in a variety of practice models. Selected systematic reviews and meta-analyses, highlighting the benefit of clinical pharmacy services, are summarized. Clinical pharmacists have a substantial effect in a wide variety of roles in inpatient and ambulatory settings, largely through optimization of drug use, avoidance of adverse drug events, and transitional care activities focusing on medication reconciliation and patient education. Expansion of clinical pharmacy services is often impeded by policy, legislation, and compensation barriers. Multidisciplinary organizations, including the American College of Cardiology, should support efforts to overcome these barriers, allowing pharmacists to deliver high-quality patient care to the full extent of their education and training.",success
21666444,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Ventilator-associated pneumonia is the most common intensive care unit-acquired infection. Although there is widespread consensus that evidenced-based interventions reduce the risk of ventilator-associated pneumonia, controversy has surrounded the importance of implementing them as a ""bundle"" of care. This study aimed to determine the effects of implementing such a bundle while controlling for potential confounding variables seen in similar studies. A before-and-after study conducted within the context of an existing, independent, infection surveillance program. An 18-bed, mixed medical-surgical teaching hospital intensive care unit. All patients admitted to intensive care for 48 hrs or more during the periods before and after intervention. A four-element ventilator-associated pneumonia prevention bundle, consisting of head-of-bed elevation, oral chlorhexidine gel, sedation holds, and a weaning protocol implemented as part of the Scottish Patient Safety Program using Institute of Health Care Improvement methods. Compliance with head-of-bed elevation and chlorhexidine gel were 95%-100%; documented compliance with ""wake and wean"" elements was 70%, giving overall bundle compliance rates of 70%. Compared to the preintervention period, there was a significant reduction in ventilator-associated pneumonia in the postintervention period (32 cases per 1,000 ventilator days to 12 cases per 1,000 ventilator days; p<.001). Statistical process control charts showed the decrease was most marked after bundle implementation. Patient cohorts staying ≥6 and ≥14 days had greater reduction in ventilator-associated pneumonia acquisition and also had reduced antibiotic use (reduced by 1 and 3 days; p=.008/.007, respectively). Rates of methicillin-resistant Staphylococcus aureus acquisition also decreased (10% to 3.6%; p<.001). Implementation of a ventilator-associated pneumonia prevention bundle was associated with a statistically significant reduction in ventilator-associated pneumonia, which had not been achieved with earlier ad hoc ventilator-associated pneumonia prevention guidelines in our unit. This occurred despite an inability to meet bundle compliance targets of 95% for all elements. Our data support the systematic approach to achieving high rates of process compliance and suggest systematic introduction can decrease both infection incidence and antibiotic use, especially for patients requiring longer duration of ventilation.",success
24277703,True,"Journal Article;Multicenter Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"Frailty is a multidimensional syndrome characterized by loss of physiologic and cognitive reserves that confers vulnerability to adverse outcomes. We determined the prevalence, correlates and outcomes associated with frailty among adults admitted to intensive care. We prospectively enrolled 421 critically ill adults aged 50 or more at 6 hospitals across the province of Alberta. The primary exposure was frailty, defined by a score greater than 4 on the Clinical Frailty Scale. The primary outcome measure was in-hospital mortality. Secondary outcome measures included adverse events, 1-year mortality and quality of life. The prevalence of frailty was 32.8% (95% confidence interval [CI] 28.3%-37.5%). Frail patients were older, were more likely to be female, and had more comorbidities and greater functional dependence than those who were not frail. In-hospital mortality was higher among frail patients than among non-frail patients (32% v. 16%; adjusted odds ratio [OR] 1.81, 95% CI 1.09-3.01) and remained higher at 1 year (48% v. 25%; adjusted hazard ratio 1.82, 95% CI 1.28-2.60). Major adverse events were more common among frail patients (39% v. 29%; OR 1.54, 95% CI 1.01-2.37). Compared with nonfrail survivors, frail survivors were more likely to become functionally dependent (71% v. 52%; OR 2.25, 95% CI 1.03-4.89), had significantly lower quality of life and were more often readmitted to hospital (56% v. 39%; OR 1.98, 95% CI 1.22-3.23) in the 12 months following enrolment. Frailty was common among critically ill adults aged 50 and older and identified a population at increased risk of adverse events, morbidity and mortality. Diagnosis of frailty could improve prognostication and identify a vulnerable population that might benefit from follow-up and intervention.",success
28336790,False,Journal Article;Review,,,,,,,,True,"Adults are living longer, and cardiovascular disease is endemic in the growing population of older adults who are surviving into old age. Functional capacity is a key metric in this population, both for the perspective it provides on aggregate health and as a vital goal of care. Whereas cardiorespiratory function has long been applied by cardiologists as a measure of function that depended primarily on cardiac physiology, multiple other factors also contribute, usually with increasing bearing as age advances. Comorbidity, inflammation, mitochondrial metabolism, cognition, balance, and sleep are among the constellation of factors that bear on cardiorespiratory function and that become intricately entwined with cardiovascular health in old age. This statement reviews the essential physiology underlying functional capacity on systemic, organ, and cellular levels, as well as critical clinical skills to measure multiple realms of function (eg, aerobic, strength, balance, and even cognition) that are particularly relevant for older patients. Clinical therapeutic perspectives and patient perspectives are enumerated to clarify challenges and opportunities across the caregiving spectrum, including patients who are hospitalized, those managed in routine office settings, and those in skilled nursing facilities. Overall, this scientific statement provides practical recommendations and vital conceptual insights.",success
28898390,False,"Journal Article;Meta-Analysis;Research Support, Non-U.S. Gov't;Systematic Review",,,,,,,,True,"Comprehensive geriatric assessment (CGA) is a multi-dimensional, multi-disciplinary diagnostic and therapeutic process conducted to determine the medical, mental, and functional problems of older people with frailty so that a co-ordinated and integrated plan for treatment and follow-up can be developed. This is an update of a previously published Cochrane review. We sought to critically appraise and summarise current evidence on the effectiveness and resource use of CGA for older adults admitted to hospital, and to use these data to estimate its cost-effectiveness. We searched CENTRAL, MEDLINE, Embase, three other databases, and two trials registers on 5 October 2016; we also checked reference lists and contacted study authors. We included randomised trials that compared inpatient CGA (delivered on geriatric wards or by mobile teams) versus usual care on a general medical ward or on a ward for older people, usually admitted to hospital for acute care or for inpatient rehabilitation after an acute admission. We followed standard methodological procedures expected by Cochrane and Effective Practice and Organisation of Care (EPOC). We used the GRADE approach to assess the certainty of evidence for the most important outcomes. For this update, we requested individual patient data (IPD) from trialists, and we conducted a survey of trialists to obtain details of delivery of CGA. We calculated risk ratios (RRs), mean differences (MDs), or standardised mean differences (SMDs), and combined data using fixed-effect meta-analysis. We estimated cost-effectiveness by comparing inpatient CGA versus hospital admission without CGA in terms of cost per quality-adjusted life year (QALY) gained, cost per life year (LY) gained, and cost per life year living at home (LYLAH) gained. We included 29 trials recruiting 13,766 participants across nine, mostly high-income countries. CGA increases the likelihood that patients will be alive and in their own homes at 3 to 12 months' follow-up (risk ratio (RR) 1.06, 95% confidence interval (CI) 1.01 to 1.10; 16 trials, 6799 participants; high-certainty evidence), results in little or no difference in mortality at 3 to 12 months' follow-up (RR 1.00, 95% CI 0.93 to 1.07; 21 trials, 10,023 participants; high-certainty evidence), decreases the likelihood that patients will be admitted to a nursing home at 3 to 12 months follow-up (RR 0.80, 95% CI 0.72 to 0.89; 14 trials, 6285 participants; high-certainty evidence) and results in little or no difference in dependence (RR 0.97, 95% CI 0.89 to 1.04; 14 trials, 6551 participants; high-certainty evidence). CGA may make little or no difference to cognitive function (SMD ranged from -0.22 to 0.35 (5 trials, 3534 participants; low-certainty evidence)). Mean length of stay ranged from 1.63 days to 40.7 days in the intervention group, and ranged from 1.8 days to 42.8 days in the comparison group. Healthcare costs per participant in the CGA group were on average GBP 234 (95% CI GBP -144 to GBP 605) higher than in the usual care group (17 trials, 5303 participants; low-certainty evidence). CGA may lead to a slight increase in QALYs of 0.012 (95% CI -0.024 to 0.048) at GBP 19,802 per QALY gained (3 trials; low-certainty evidence), a slight increase in LYs of 0.037 (95% CI 0.001 to 0.073), at GBP 6305 per LY gained (4 trials; low-certainty evidence), and a slight increase in LYLAH of 0.019 (95% CI -0.019 to 0.155) at GBP 12,568 per LYLAH gained (2 trials; low-certainty evidence). The probability that CGA would be cost-effective at a GBP 20,000 ceiling ratio for QALY, LY, and LYLAH was 0.50, 0.89, and 0.47, respectively (17 trials, 5303 participants; low-certainty evidence). Older patients are more likely to be alive and in their own homes at follow-up if they received CGA on admission to hospital. We are uncertain whether data show a difference in effect between wards and teams, as this analysis was underpowered. CGA may lead to a small increase in costs, and evidence for cost-effectiveness is of low-certainty due to imprecision and inconsistency among studies. Further research that reports cost estimates that are setting-specific across different sectors of care are required.",success
27385077,False,Journal Article,,,,,,,,True,"To inform the development of a data-driven measure of quality care for individuals with multiple chronic conditions (MCCs) derived from an electronic health record (EHR). Qualitative study using focus groups, interactive webinars, and a modified Delphi process. Research department within an integrated delivery system. The webinars and Delphi process included 17 experts in clinical geriatrics and primary care, health policy, quality assessment, health technology, and health system operations. The focus group included 10 individuals aged 70-87 with three to six chronic conditions selected from a random sample of individuals aged 65 and older with three or more chronic medical conditions. Through webinars and the focus group, input was solicited on constructs representing high-quality care for individuals with MCCs. A working list was created of potential measures representing these constructs. Using a modified Delphi process, experts rated the importance of each possible measure and the feasibility of implementing each measure using EHR data. High-priority constructs reflected processes rather than outcomes of care. High-priority constructs that were potentially feasible to measure included assessing physical function, depression screening, medication reconciliation, annual influenza vaccination, outreach after hospital admission, and documented advance directives. High-priority constructs that were less feasible to measure included goal setting and shared decision-making, identifying drug-drug interactions, assessing social support, timely communication with patients, and other aspects of good customer service. Lower-priority domains included pain assessment, continuity of care, and overuse of screening or laboratory testing. High-quality MCC care should be measured using meaningful process measures rather than outcomes. Although some care processes are currently extractable from electronic data, capturing others will require adapting and applying technology to encourage holistic, person-centered care.",success
29189383,False,Journal Article;Validation Study,,,,,,,,True,"To develop and validate a simple geriatric screening tool that performs as well as more complex assessments BACKGROUND:: Many tools that predict treatment risk in older adults are impractical for routine clinical use. We prospectively conducted comprehensive preoperative evaluations on 1025 patients age ≥75 years who presented to Sinai Hospital of Baltimore for major elective surgery, then retrospectively reviewed patients' medical records for occurrence of postoperative outcomes. Using logistic regression modeling and receiver operating characteristic curve analysis we selected the best combination of simple tests, labeling this the Sinai Abbreviated Geriatric Evaluation (SAGE). The performance of the SAGE was then compared with 3 standard tools in its power to predict postoperative outcomes. The SAGE is a statistically significant predictor of postoperative outcomes. Each unit decrease in SAGE score was significantly associated with a 51% (95% CI 1.30-1.77) increase in odds of a complication, a 2-fold increase in odds of postoperative delirium (95% CI 1.65-2.66), a 27% increase in odds of length of hospital stay >2 days (95% CI 1.10-1.47), a 54% increase in odds of a hospital readmission within 30 days (95% CI 1.25-2.88), and a 38% increase in odds of an unanticipated discharge to higher-level care (95% CI 1.18-1.61). We estimated the receiver operating characteristic curve area under the curve (AUC) for the SAGE of 0.69, 0.77, 0.73, 0.66, and 0.78 for the above outcomes, respectively. The SAGE performed as well in predicting postoperative outcomes as Fried's frailty phenotype, Charlson Comorbidity Index, and American Society of Anesthesiologists Physical Status Class (ASA). The SAGE performs as well as other geriatric evaluations that require equipment or memorization.",success
21946660,False,Comparative Study;Journal Article;Review,,,,,,,,True,"Millions of patients are discharged from intensive care units annually. These intensive care survivors and their families frequently report a wide range of impairments in their health status which may last for months and years after hospital discharge. To report on a 2-day Society of Critical Care Medicine conference aimed at improving the long-term outcomes after critical illness for patients and their families. Thirty-one invited stakeholders participated in the conference. Stakeholders represented key professional organizations and groups, predominantly from North America, which are involved in the care of intensive care survivors after hospital discharge. Invited experts and Society of Critical Care Medicine members presented a summary of existing data regarding the potential long-term physical, cognitive and mental health problems after intensive care and the results from studies of postintensive care unit interventions to address these problems. Stakeholders provided reactions, perspectives, concerns and strategies aimed at improving care and mitigating these long-term health problems. Three major themes emerged from the conference regarding: (1) raising awareness and education, (2) understanding and addressing barriers to practice, and (3) identifying research gaps and resources. Postintensive care syndrome was agreed upon as the recommended term to describe new or worsening problems in physical, cognitive, or mental health status arising after a critical illness and persisting beyond acute care hospitalization. The term could be applied to either a survivor or family member. Improving care for intensive care survivors and their families requires collaboration between practitioners and researchers in both the inpatient and outpatient settings. Strategies were developed to address the major themes arising from the conference to improve outcomes for survivors and families.",success
27525995,False,Journal Article,,,,,,,,True,"The Society of Critical Care Medicine and four other major critical care organizations have endorsed a seven-step process to resolve disagreements about potentially inappropriate treatments. The multiorganization statement (entitled: An official ATS/AACN/ACCP/ESICM/SCCM Policy Statement: Responding to Requests for Potentially Inappropriate Treatments in Intensive Care Units) provides examples of potentially inappropriate treatments; however, no clear definition is provided. This statement was developed to provide a clear definition of inappropriate interventions in the ICU environment. A subcommittee of the Society of Critical Care Medicine Ethics Committee performed a systematic review of empirical research published in peer-reviewed journals as well as professional organization position statements to generate recommendations. Recommendations approved by consensus of the full Society of Critical Care Medicine Ethics Committees and the Society of Critical Care Medicine Council were included in the statement. ICU interventions should generally be considered inappropriate when there is no reasonable expectation that the patient will improve sufficiently to survive outside the acute care setting, or when there is no reasonable expectation that the patient's neurologic function will improve sufficiently to allow the patient to perceive the benefits of treatment. This definition should not be considered exhaustive; there will be cases in which life-prolonging interventions may reasonably be considered inappropriate even when the patient would survive outside the acute care setting with sufficient cognitive ability to perceive the benefits of treatment. When patients or surrogate decision makers demand interventions that the clinician believes are potentially inappropriate, the seven-step process presented in the multiorganization statement should be followed. Clinicians should recognize the limits of prognostication when evaluating potential neurologic outcome and terminal cases. At times, it may be appropriate to provide time-limited ICU interventions to patients if doing so furthers the patient's reasonable goals of care. If the patient is experiencing pain or suffering, treatment to relieve pain and suffering is always appropriate. The Society of Critical Care Medicine supports the seven-step process presented in the multiorganization statement. This statement provides added guidance to clinicians in the ICU environment.",success
25377017,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Many healthcare workers are concerned about the provision of nonbeneficial treatment in the acute care setting. We sought to explore the perceptions of acute care practitioners to determine whether they perceived nonbeneficial treatment to be a problem, to generate an acceptable definition of nonbeneficial treatment, to learn about their perceptions of the impact and causes of nonbeneficial treatment, and the ways that they feel could reduce or resolve nonbeneficial treatment. National, bilingual, cross-sectional survey of a convenience sample of nursing and medical staff who provide direct patient care in acute medical wards or ICUs in Canada. We received 688 responses (response rate 61%) from 11 sites. Seventy-four percent of respondents were nurses. Eighty-two percent of respondents believe that our current means of resolving nonbeneficial treatment are inadequate. The most acceptable definitions of nonbeneficial treatment were ""advanced curative/life-prolonging treatments that would almost certainly result in a quality of life that the patient has previously stated that he/she would not want"" (88% agreement) and ""advanced curative/life-prolonging treatments that are not consistent with the goals of care (as indicated by the patient)"" (83% agreement). Respondents most commonly believed that nonbeneficial treatment was caused by substitute decision makers who do not understand the limitations of treatment, or who cannot accept a poor prognosis (90% agreement for each cause), and 52% believed that nonbeneficial treatment was ""often"" or ""always"" continued until the patient died or was discharged from hospital. Respondents believed that nonbeneficial treatment was a common problem with a negative impact on all stakeholders (> 80%) and perceived that improved advance care planning and communication training would be the most effective (92% and 88%, respectively) and morally acceptable (95% and 92%, respectively) means to resolve the problem of nonbeneficial treatment. Canadian nurses and physicians perceive that our current means of resolving nonbeneficial treatment are inadequate, and that we need to adopt new techniques of resolving nonbeneficial treatment. The most promising strategies to reduce nonbeneficial treatment are felt to be improved advance care planning and communication training for healthcare professionals.",success
29038186,True,Journal Article;Multicenter Study,,,,,,,,True,"To estimate the incidence, duration and cost of futile treatment for end-of-life hospital admissions. Retrospective multicentre cohort study involving a clinical audit of hospital admissions. Three Australian public-sector tertiary hospitals. Adult patients who died while admitted to one of the study hospitals over a 6-month period in 2012. Incidences of futile treatment among end-of-life admissions; length of stay in both ward and intensive care settings for the duration that patients received futile treatments; health system costs associated with futile treatments; monetary valuation of bed days associated with futile treatment. The incidence rate of futile treatment in end-of-life admissions was 12.1% across the three study hospitals (range 6.0%-19.6%). For admissions involving futile treatment, the mean length of stay following the onset of futile treatment was 15 days, with 5.25 of these days in the intensive care unit. The cost associated with futile bed days was estimated to be $AA12.4 million for the three study hospitals using health system costs, and $A988 000 when using a decision maker's willingness to pay for bed days. This was extrapolated to an annual national health system cost of $A153.1 million and a decision maker's willingness to pay of $A12.3 million. The incidence rate and cost of futile treatment in end-of-life admissions varied between hospitals. The overall impact was substantial in terms of both the bed days and cost incurred. An increased awareness of these economic costs may generate support for interventions designed to reduce futile treatments. We did not include emotional hardship or pain and suffering, which represent additional costs.",success
24810527,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"When used to prolong life without achieving a benefit meaningful to the patient, critical care is often considered ""futile."" Although futile treatment is acknowledged as a misuse of resources by many, no study has evaluated its opportunity cost, that is, how it affects care for others. Our objective was to evaluate delays in care when futile treatment is provided. For 3 months, we surveyed critical care physicians in five ICUs to identify patients that clinicians identified as receiving futile treatment. We identified days when an ICU was full and contained at least one patient who was receiving futile treatment. For those days, we evaluated the number of patients waiting for ICU admission more than 4 hours in the emergency department or more than 1 day at an outside hospital. One health system that included a quaternary care medical center and an affiliated community hospital. Critically ill patients. None. Boarding time in the emergency department and waiting time on the transfer list. Thirty-six critical care specialists made 6,916 assessments on 1,136 patients of whom 123 were assessed to receive futile treatment. A full ICU was less likely to contain a patient receiving futile treatment compared with an ICU with available beds (38% vs 68%, p < 0.001). On 72 (16%) days, an ICU was full and contained at least one patient receiving futile treatment. During these days, 33 patients boarded in the emergency department for more than 4 hours after admitted to the ICU team, nine patients waited more than 1 day to be transferred from an outside hospital, and 15 patients canceled the transfer request after waiting more than 1 day. Two patients died while waiting to be transferred. Futile critical care was associated with delays in care to other patients.",success
20937918,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Heart failure (HF) is a debilitating and chronic condition associated with significant morbidity and mortality. However, much less is known about end-of-life (EOL) costs among patients with HF. To examine trends in resource use and costs during the last 6 months of life among elderly patients with HF, we evaluated data regarding all patients 65 years or older with HF who died between January 1, 2000, to December 31, 2006, in Alberta, Canada, and examined costs associated with all-cause hospitalizations, intensive care, emergency department visits, outpatient visits, physician office visits, and outpatient drugs in the 180 days before death. Overall costs and predictors of costs to the health care system were also examined. The study population included 33,144 patients with HF who died. The mean age at death was 83 years. The clinical profile of patients changed during the study period, with an increasing comorbidity burden over time. Between 2000 and 2006, the percentage of patients hospitalized during the last 6 months of life decreased from 84% to 76% (P<.01); and the percentage dying in hospital decreased from 60% to 54% (P<.01). In 2006, the average EOL cost was $27,983 in Canadian dollars. In multivariate analyses, increasing age was inversely associated with EOL costs and comorbid conditions were associated with higher costs. Resource use in the last 6 months of life among patients with HF in Alberta is changing, with a reduction in hospitalizations, in-hospital deaths, and an increase in the use of outpatient services. However, EOL costs are substantial and continue to increase.",success
30700139,False,Journal Article,,,,,,,,False,,success
24454685,False,Journal Article;Systematic Review,,,,,,,,True,"American Indians and Alaska Native (AI/AN) populations experience significant health disparities compared to non-Hispanic white populations. Cardiovascular disease and related risk factors are increasingly recognized as growing indicators of global health disparities. However, comparative reports on disparities among this constellation of diseases for AI/AN populations have not been systematically reviewed. We performed a literature review on the prevalence of diabetes, metabolic syndrome, dyslipidemia, obesity, hypertension, and cardiovascular disease; and associated morbidity and mortality among AI/AN. A total of 203 articles were reviewed, of which 31 met study criteria for inclusion. Searches were performed on PUBMED, MEDLINE, the CDC MMWR, and the Indian Health Services. Published literature that were published within the last fifteen years and provided direct comparisons between AI/AN to non-AI/AN populations were included. We abstracted data on study design, data source, AI/AN population, comparison group, and. outcome measures. A descriptive synthesis of primary findings is included. Rates of obesity, diabetes, cardiovascular disease, and metabolic syndrome are clearly higher for AI/AN populations. Hypertension and hyperlipidemia differences are more equivocal. Our analysis also revealed that there are likely regional and gender differences in the degree of disparities observed. Studies using BRFSS telephone surveys administered in English may underestimate disparities. Many AI/AN do not have telephones and/or speak English. Regional variability makes national surveys difficult to interpret. Finally, studies using self-reported data may not be accurate. Profound health disparities in cardiovascular diseases and associated risk factors for AI/AN populations persist, perhaps due to low socioeconomic status and access to quality healthcare. Successful programs will address social determinants and increase healthcare access. Community-based outreach to bring health services to the most vulnerable may also be very helpful in this effort. N/A.",success
10318659,False,"Comparative Study;Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Although cardiovascular disease (CVD) used to be rare among American Indians, Indian Health Service data suggest that CVD mortality rates vary greatly among American Indian communities and appear to be increasing. The Strong Heart Study was initiated to investigate CVD and its risk factors in American Indians in 13 communities in Arizona, Oklahoma, and South/North Dakota. A total of 4549 participants (1846 men and 2703 women 45 to 74 years old) who were seen at the baseline (1989 to 1991) examination were subjected to surveillance (average 4.2 years, 1991 to 1995), and 88% of those remaining alive underwent a second examination (1993 to 1995). The medical records of all participants were exhaustively reviewed to ascertain nonfatal cardiovascular events that occurred since the baseline examination or to definitively determine cause of death. CVD morbidity and mortality rates were higher in men than in women and were similar in the 3 geographic areas. Coronary heart disease (CHD) incidence rates among American Indian men and women were almost 2-fold higher than those in the Atherosclerosis Risk in Communities Study. Significant independent predictors of CVD in women were diabetes, age, obesity (inverse), LDL cholesterol, albuminuria, triglycerides, and hypertension. In men, diabetes, age, LDL cholesterol, albuminuria, and hypertension were independent predictors of CVD. At present, CHD rates in American Indians exceed rates in other US populations and may more often be fatal. Unlike other ethnic groups, American Indians appear to have an increasing incidence of CHD, possibly related to the high prevalence of diabetes. In the general US population, the rising prevalence of obesity and diabetes may reverse the decline in CVD death rates. Therefore, aggressive programs to control diabetes and its risk factors are needed.",success
30652897,False,"Journal Article;Research Support, N.I.H., Extramural;Systematic Review",,,,,,,,True,"Beginning in the mid-1990s, the construct of historical trauma was introduced into the clinical and health science literatures to contextualize, describe, and explain disproportionately high rates of psychological distress and health disparities among Indigenous populations. As a conceptual precursor to racial trauma, Indigenous historical trauma (IHT) is distinguished by its emphasis on ancestral adversity that is intergenerationally transmitted in ways that compromise descendent well-being. In this systematic review of the health impacts of IHT, 32 empirical articles were identified that statistically analyzed the relationship between a measure of IHT and a health outcome for Indigenous samples from the United States and Canada. These articles were categorized based on their specific method for operationalizing IHT, yielding 19 articles that were grouped as historical loss studies, 11 articles that were grouped as residential school ancestry studies, and three articles that were grouped as ""other"" studies. Articles in all three categories included diverse respondents, disparate designs, varied statistical techniques, and a range of health outcomes. Most reported statistically significant associations between higher indicators of IHT and adverse health outcomes. Analyses were so complex, and findings were so specific, that this groundbreaking literature has yet to cohere into a body of knowledge with clear implications for health policy or professional practice. At the conceptual level, it remains unclear whether IHT is best appreciated for its metaphorical or literal functions. Nevertheless, the enthusiasm surrounding IHT as an explanation for contemporary Indigenous health problems renders it imperative to refine the construct to enable more valid research. (PsycINFO Database Record (c) 2019 APA, all rights reserved).",success
17077399,False,"Historical Article;Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Disparities in health status between American Indians and other groups in the United States have persisted throughout the 500 years since Europeans arrived in the Americas. Colonists, traders, missionaries, soldiers, physicians, and government officials have struggled to explain these disparities, invoking a wide range of possible causes. American Indians joined these debates, often suggesting different explanations. Europeans and Americans also struggled to respond to the disparities, sometimes working to relieve them, sometimes taking advantage of the ill health of American Indians. Economic and political interests have always affected both explanations of health disparities and responses to them, influencing which explanations were emphasized and which interventions were pursued. Tensions also appear in ongoing debates about the contributions of genetic and socioeconomic forces to the pervasive health disparities. Understanding how these economic and political forces have operated historically can explain both the persistence of the health disparities and the controversies that surround them.",success
24669226,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"Misclassification of race in medical and mortality records has long been documented as an issue in American Indian/Alaska Native data. Yet, little has been shared in a cohesive narrative which outlines why misclassification of American Indian/Alaska Native identity occurs. The purpose of this paper is to provide a summary of the current state of the science in racial misclassification among American Indians and Alaska Natives. We also provide a historical context on the importance of this problem and describe the ongoing political processes that both affect racial misclassification and contribute to the context of American Indian and Alaska Native identity.",success
16048880,False,Historical Article;Journal Article,,,,,,,,True,"This article explains selected historical acts and events that continue to impact comtemporary Native American ethnic identity, social policy, and social services delivery. Although cultural competence is increasingly encouraged in social work education, the events of history usually do not appear as partial explanations for current phenomena. For those who work with Native American populations, understanding this history is a critical piece in the process of acquiring cultural competence. These selected historical events provide at least partial understanding of some contemporary issues which are sometimes presented to social workers and other social services professionals who work with Native populations.",success
16769914,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"The present article presents equations for the prediction of coronary heart disease (CHD) in a population with high rates of diabetes and albuminuria, derived from data collected in the Strong Heart Study, a longitudinal study of cardiovascular disease in 13 American Indian tribes and communities in Arizona, North and South Dakota, and Oklahoma. Participants of the Strong Heart Study were examined initially in 1989-1991 and were monitored with additional examinations and mortality and morbidity surveillance. CHD outcome data through December 2001 showed that age, gender, total cholesterol, low-density lipoprotein (LDL) cholesterol, high-density lipoprotein cholesterol, smoking, diabetes, hypertension, and albuminuria were significant CHD risk factors. Hazard ratios for ages 65 to 75 years, hypertension, LDL cholesterol > or = 160 mg/dL, diabetes, and macroalbuminuria were 2.58, 2.01, 2.44, 1.66, and 2.11 in men and 2.03, 1.69, 2.17, 2.26, and 2.69 in women, compared with ages 45 to 54 years, normal blood pressure, LDL cholesterol <100 mg/dL, no diabetes, and no albuminuria. Prediction equations for CHD and a risk calculator were derived by gender with the use of Cox proportional hazards model and the significant risk factors. The equations provided good discrimination ability, as indicated by a c statistic of 0.70 for men and 0.73 for women. Results from bootstrapping methods indicated good internal validation and calibration. A ""risk calculator"" has been developed and placed on the Strong Heart Study Web site, which provides predicted risk of CHD in 10 years with input of these risk factors. This may be valuable for diverse populations with high rates of diabetes and albuminuria.",success
7631630,False,"Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Although coronary heart disease (CHD) is currently the leading cause of death among American Indians, information on the prevalence of CHD and its association with known cardiovascular risk factors is limited. The Strong Heart Study was initiated in 1988 to quantify cardiovascular disease and its risk factors among three geographically diverse groups of American Indians. Members of 13 Indian communities in Arizona, Oklahoma, and South and North Dakota between 45 and 74 years of age underwent a physical examination that included medical history; an electrocardiogram; anthropometric and blood pressure measurements; an oral glucose tolerance test; and measurements of fasting plasma lipoproteins, fibrinogen, insulin, hemoglobin A1c, and urinary albumin. Prevalence rates of definite myocardial infarction and definite CHD were higher in men than in women at all three centers (p < 0.0001) and higher in those with diabetes mellitus (p = 0.002 in men and p = 0.0003 in women). Diabetes was associated with relatively higher prevalence rates of myocardial infarction (diabetic:nondiabetic prevalence ratio = 3.8 vs. 1.9) and CHD (prevalence ratio = 4.6 vs. 1.8) in women than in men. Prevalence rates of heart disease were lowest in the communities in Arizona; prevalence rates were similar in Oklahoma and South Dakota/North Dakota and were two- to threefold higher than those in Arizona. By logistic regression, prevalent CHD among American Indians was significantly and independently related to age, diabetes, hypertension, albuminuria, percentage of body fat, smoking, high concentrations of plasma insulin, and low concentrations of high density lipoprotein cholesterol. In contrast to reports from other non-Indian populations, diabetes was the strongest risk factor. The lower prevalence of CHD among Indians in Arizona is distinctive in view of their higher rates of diabetes, obesity, hypertension, and albuminuria, but it may be partly related to their low frequency of smoking and their low concentrations of total and low density lipoprotein cholesterol. These findings from the initial Strong Heart Study examination emphasize the importance of diabetes and its associated variables as risk factors for CHD in Native American populations.",success
8585996,True,"Comparative Study;Journal Article;Multicenter Study;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"To estimate prevalence rates of diabetes and impaired glucose tolerance (IGT) in three American Indian populations, using standardized diagnostic criteria, and to assess the association of diabetes with the following selected possible risk factors: age, obesity, family history of diabetes, and amount of Indian ancestry. This cross-sectional study involved enrolled members, men and women aged 45-74 years, of 13 American Indian tribes or communities in Arizona, Oklahoma, and South and North Dakota. Eligible participants were invited to the clinic for a personal interview and a physical examination. Diabetes and IGT status were defined by the World Health Organization criteria and were based on fasting plasma glucose and oral glucose tolerance test results. Data on age, family history of diabetes, and amount of Indian ancestry were obtained from the personal interview, and measures of obesity included body mass index, percentage body fat, and waist-to-hip ratio. A total of 4,549 eligible participants were examined, and diabetes status was determined for 4,304 (1,446 in Arizona, 1,449 in Oklahoma, and 1,409 in the Dakotas). In all three centers, diabetes was more prevalent in women than in men. Arizona had the highest age-adjusted rates of diabetes: 65% in men and 72% in women. Diabetes rates in Oklahoma (38% in men and 42% in women) and South and North Dakota (33% in men and 40% in women), although considerably lower than in Arizona, were several times higher than those reported for the U.S. population. Rates of IGT among the three populations (14-17%) were similar to those in the U.S. population. Diabetes rates were positively associated with age, level of obesity, amount of Indian ancestry, and parental diabetes status. Diabetes is found in epidemic proportions in Native American populations. Prevention programs and periodic screening should be implemented among American Indians. Standards of care and intervention have been developed by the Indian Health Service for individuals in whom diabetes is diagnosed. These programs should be expanded to include those with IGT to improve glycemic control or to reduce the risk of development of diabetes as well as to reduce the risk of diabetic complications.",success
10811594,False,"Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Whether diabetes mellitus (DM) adversely affects left ventricular (LV) structure and function independently of increases in body mass index (BMI) and blood pressure is controversial. Echocardiography was used in the Strong Heart Study, a study of cardiovascular disease in American Indians, to compare LV measurements between 1810 participants with DM and 944 with normal glucose tolerance. Participants with DM were older (mean age, 60 versus 59 years), had higher BMI (32.4 versus 28.9 kg/m(2)) and systolic blood pressure (133 versus 124 mm Hg), and were more likely to be female, to be on antihypertensive treatment, and to live in Arizona (all P<0.001). In analyses adjusted for covariates, women and men with DM had higher LV mass and wall thicknesses and lower LV fractional shortening, midwall shortening, and stress-corrected midwall shortening (all P<0.002). Pulse pressure/stroke volume, a measure of arterial stiffness, was higher in participants with DM (P<0.001 independent of confounders). Non-insulin-dependent DM has independent adverse cardiac effects, including increased LV mass and wall thicknesses, reduced LV systolic chamber and myocardial function, and increased arterial stiffness. These findings identify adverse cardiovascular effects of DM, independent of associated increases in BMI and arterial pressure, that may contribute to cardiovascular events in diabetic individuals.",success
12610050,False,"Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Insulin resistance (IR) and the metabolic syndrome (MS) are associated with type 2 diabetes and adverse cardiovascular disease (CVD) risk factor profiles. Whether IR and MS predict CVD independently of diabetes and other CVD risk factors is not known. This study examines whether IR and/or presence of MS are independently associated with CVD in nondiabetic American Indians (AI). We examined 2283 nondiabetic AI who were free of CVD at the baseline examination of the Strong Heart Study (SHS). CVD risk factors were measured, IR was quantified using the homeostasis model assessment (HOMA), and MS as defined by the National Cholesterol Education Program Adult Treatment Panel (ATP III) was assessed for each participant. Incident CVD and diabetes were ascertained during follow-up. MS was present in 798 individuals (35%), and 181 participants (7.9%) developed CVD over 7.6 +/- 1.8 years of follow-up. Age, BMI, waist circumference, and triglyceride levels increased and HDL cholesterol decreased across tertiles of HOMA-IR. Risk of diabetes increased as a function of baseline HOMA-IR (6.3, 14.6, and 30.1%; P < 0.001) and MS (12.8 vs. 24.5%). In Cox models adjusted for CVD risk factors, risk of CVD did not increase either as a function of baseline HOMA-IR or MS, but individual CVD risk factors predicted subsequent CVD. Among nondiabetic AI in the SHS, HOMA-IR and MS both predict diabetes, but neither predicts CVD independently of other established CVD risk factors.",success
12502653,False,"Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"To determine whether non-HDL cholesterol, a measure of total cholesterol minus HDL cholesterol, is a predictor of CVD in patients with diabetes. The Strong Heart Study, a population-based study of CVD and its risk factors in 13 American Indian communities in three geographic areas in the U.S. The baseline examination, conducted between July 1989 and January 1992, consisted of a personal interview, a physical examination, and laboratory tests. Of the 4,549 women and men aged 45-74 years participating in the study, 2,108 had diabetes but no CVD at baseline. Data on fatal and nonfatal CVD were collected during the follow-up period through 31 December 1998 (average 9 years). Multivariable analyses indicated that non-HDL cholesterol is a strong predictor of CVD in men and women with diabetes and is particularly indicative of coronary events. Hazard ratios for the highest tertile of non-HDL cholesterol in men and women with diabetes (2.23 and 1.80, respectively) were higher than those for either LDL cholesterol or triglycerides alone in both men and women and were higher than the ratio of total/HDL cholesterol in women. The utility of non-HDL cholesterol in predicting CVD extended over a wide range of triglyceride concentrations. This study suggests that non-HDL cholesterol index may be particularly useful in predicting CVD risk in patients with diabetes.",success
11880218,False,Evaluation Study;Journal Article,,,,,,,,True,"To evaluate the distribution of lipoprotein(a) (Lp(a)) and assess its association to cardiovascular disease (CVD) in American Indians. Lp(a) was measured in 3991 American Indians (aged 45-74 years with no prior history of CVD at baseline) from 13 communities in Arizona, Oklahoma, and South/North Dakota. They were followed prospectively from 1989 to 1997 for CVD. The distribution of Lp(a) was examined by center, sex, and diabetic status. Spearman correlation coefficients and Cox regression models were used to evaluate the association of Lp(a) to CVD. A total of 388 participants subsequently developed CVD. Median Lp(a) concentration in American Indians was 3.0 mg/dl. This was almost half of that in whites and one sixth in blacks from the CARDIA study measured by the same method. Nondiabetic participants had significantly higher Lp(a) levels than diabetic participants for both genders. Lp(a) levels were higher in women than in men for nondiabetic participants, but there was no gender difference for diabetic participants. Correlation analysis showed Lp(a) was significantly negatively correlated with the degree of Indian heritage, insulin, triglycerides (TG), fasting plasma glucose (FPG), and 2-hour plasma glucose (2hPG), and positively with low-density lipoproteins (LDL), apoprotein B (apoB), and fibrinogen (FIB). In Cox regression models, adjusting for other risk factors, Lp(a) was no longer a significant predictor of CVD in either diabetic or nondiabetic participants. The lower concentration of Lp(a) in American Indians and the high correlation with Indian heritage confirm the concept that Lp(a) concentration is in large part genetically determined. Lp(a) concentration is not an independent predictor of CVD among American Indians; it is higher in those who develop CVD because of its positive correlation with LDL, apoB, and FIB.",success
8696954,False,"Comparative Study;Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Apo E is an important genetic factor in the development of cardiovascular disease, which is the leading cause of death among American Indians. We investigated the occurrence of the apo E alleles and the relation between apo E polymorphism and blood lipoproteins and apoproteins in members of 13 American Indian communities in three geographic areas. The frequencies of the epsilon 2 alleles in American Indians are significantly lower than those in white Americans, with the lowest frequencies of epsilon 2 in American Indians who reside in Arizona. Levels of LDL cholesterol and apo B were highest in those with epsilon 4 and lowest in those with epsilon 2. Concentrations of HDL cholesterol and apo A-I, however, tended to be lowest in epsilon 4 and highest in epsilon 2. Concentrations of total and VLDL triglycerides were lowest in the epsilon 3 group and higher in groups epsilon 2 and epsilon 4. Differences in concentrations of LDL cholesterol, HDL cholesterol, apo B, and apo A-I with apo E polymorphism were greater in women than in men, and differences in total and VLDL triglyceride concentrations by apo E phenotype were greater in men. Relations of total and VLDL triglycerides with apo E phenotype were stronger in women after menopause. In addition, differences in nearly all lipid and apoprotein concentrations between postmenopausal women and premenopausal women were greater if they had epsilon 2. Relations between apo E phenotype and lipoproteins were seen in individuals with diabetes mellitus as well as in nondiabetics. Apo E was significantly related to glucose control in diabetic women; those with epsilon 3 had higher glucose and hemoglobin A1C concentrations. Our findings show that (1) American Indians have low frequencies of apo epsilon 2; (2) apo E phenotype can influence levels of VLDL, LDL, HDL, apo B, and apo A-I; (3) the associations of apo E polymorphisms with lipid parameters differ between men and women; and (4) the associations in women of apo E polymorphisms with lipid parameters are modified by menopausal status.",success
8707391,True,"Journal Article;Multicenter Study;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Hypertension is a primary risk factor for cardiovascular disease in the United States. Although cardiovascular disease is the leading cause of death among American Indians, the prevalence of hypertension, its awareness and control, and its association with other cardiovascular disease risk factors and physiological variables have not been well studied in this population. The Strong Heart Study is a longitudinal study of cardiovascular disease and its risk factors in American Indians. Participants (2703 women and 1846 men) were members of 13 tribes in central Arizona, southwestern Oklahoma, and regions of South and North Dakota. At least 1500 individuals between 45 and 74 years of age participated from each center in a baseline clinical examination conducted between July 1989 and January 1992. The examination consisted of a personal interview and physical examination that included an oral glucose tolerance test and three consecutive blood pressure measurements. This study reports data from the baseline examination on the prevalence of hypertension and correlates of blood pressure. Results indicated that despite the high frequency of diabetes and obesity, prevalence rates of hypertension in Arizona and Oklahoma were similar to those in the US population in the Third National Health and Nutrition Examination Survey (NHANES III), and rates among South/North Dakota participants were significantly lower (P < .0001). Blood pressure was higher in individuals with diabetes (P < .0001) and was significantly correlated with age (P < .0001) and albuminuria (P < .0001) but only weakly related to obesity. There was no independent relation between blood pressure and insulin. Blood pressure seems to be less affected by obesity and hyperinsulinemia in American Indians compared with other populations. Nevertheless, hypertension should be aggressively treated and controlled in American Indians because it is a known precursor to morbidity and mortality associated with diabetes and cardiovascular disease.",success
16446387,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"There are few data about the impact of the recently-defined category of prehypertension (systolic blood pressure 120 to 139 mm Hg or diastolic blood pressure 80 to 89 mm Hg) on cardiovascular disease incidence. It is also unknown whether this association differs between individuals with or without diabetes. A total of 2629 Strong Heart Study participants free from hypertension and cardiovascular disease at baseline examination were followed for 12 years to observe incident cardiovascular disease. Approximately 42% of the 2629 participants had diabetes. We assessed the prevalence of prehypertension and the hazard ratios of incident cardiovascular disease associated with prehypertension. Prehypertension was more prevalent in diabetic than nondiabetic participants (59.4% versus 48.2%, P<0.001 adjusted for age). Compared with nondiabetic participants with normal blood pressure, the hazard ratios of cardiovascular disease were 3.70 (95% confidence interval: 2.66, 5.15) for those with both prehypertension and diabetes, 1.80 (1.28, 2.54) for those with prehypertension alone and 2.90 (2.03, 4.16) for those with diabetes alone. Impaired glucose tolerance or impaired fasting glucose also greatly increased the cardiovascular disease risk in prehypertensive people. Clinical investigation of more aggressive interventions, such as drug treatment for blood pressure control for prehypertensive individuals with impaired fasting glucose, impaired glucose tolerance, or diabetes is warranted.",success
11377351,False,"Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Although the association of systemic hypertension (SH) with diabetes mellitus (DM) is well established, the cardiac features and hemodynamic profile of patients with SH and DM diagnosed by American Diabetes Association criteria have not been elucidated. To address this issue, echocardiograms were analyzed in 1,025 American Indian participants of the Strong Heart Study with neither DM nor SH, 642 with DM alone, 614 with SH alone, and 874 with SH and DM. In analyses that adjusted for age, gender, body mass index, and heart rate, DM and SH were associated with increased left ventricular (LV) wall thicknesses, with the greatest impact of DM on LV relative wall thickness and of the combination of DM and SH on LV mass (both p <0.001). LV fractional shortening was reduced with SH and SH + DM, midwall shortening was reduced with DM, SH, and their combination, and was reduced in both diabetic groups compared with their nondiabetic counterparts (p <0.001). DM alone was associated with lower measures of LV pump performance (stroke volume, cardiac output, and their indexes) than SH alone. Pulse pressure/stroke index, an indirect measure of arterial stiffness, was elevated in participants with DM or SH alone and most in those with both conditions. There were progressive increases from the reference group to DM alone, SH alone, and DM + SH with regard to prevalences of LV hypertrophy (12% to 19%, 29% and 38%) and subnormal LV myocardial function (7% to 10%, 11% and 18%, both p <0.001). In conclusion, DM and SH each have adverse effects on LV geometry and function, and the combination of SH and DM results in the greatest degree of LV hypertrophy, myocardial dysfunction, and arterial stiffness.",success
18398080,True,"Comparative Study;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, N.I.H., Extramural",NCT00047424,databank,NCT00047424,NCT00047424,NCT00047424,NCT00047424|databank,NCT00047424|databank,True,"Individuals with diabetes are at increased risk for cardiovascular disease (CVD), but more aggressive targets for risk factor control have not been tested. To compare progression of subclinical atherosclerosis in adults with type 2 diabetes treated to reach aggressive targets of low-density lipoprotein cholesterol (LDL-C) of 70 mg/dL or lower and systolic blood pressure (SBP) of 115 mm Hg or lower vs standard targets of LDL-C of 100 mg/dL or lower and SBP of 130 mm Hg or lower. A randomized, open-label, blinded-to-end point, 3-year trial from April 2003-July 2007 at 4 clinical centers in Oklahoma, Arizona, and South Dakota. Participants were 499 American Indian men and women aged 40 years or older with type 2 diabetes and no prior CVD events. Participants were randomized to aggressive (n=252) vs standard (n=247) treatment groups with stepped treatment algorithms defined for both. Primary end point was progression of atherosclerosis measured by common carotid artery intimal medial thickness (IMT). Secondary end points were other carotid and cardiac ultrasonographic measures and clinical events. Mean target LDL-C and SBP levels for both groups were reached and maintained. Mean (95% confidence interval) levels for LDL-C in the last 12 months were 72 (69-75) and 104 (101-106) mg/dL and SBP levels were 117 (115-118) and 129 (128-130) mm Hg in the aggressive vs standard groups, respectively. Compared with baseline, IMT regressed in the aggressive group and progressed in the standard group (-0.012 mm vs 0.038 mm; P < .001); carotid arterial cross-sectional area also regressed (-0.02 mm(2) vs 1.05 mm(2); P < .001); and there was greater decrease in left ventricular mass index (-2.4 g/m(2.7) vs -1.2 g/m(2.7); P = .03) in the aggressive group. Rates of adverse events (38.5% and 26.7%; P = .005) and serious adverse events (n = 4 vs 1; P = .18) related to blood pressure medications were higher in the aggressive group. Clinical CVD events (1.6/100 and 1.5/100 person-years; P = .87) did not differ significantly between groups. Reducing LDL-C and SBP to lower targets resulted in regression of carotid IMT and greater decrease in left ventricular mass in individuals with type 2 diabetes. Clinical events were lower than expected and did not differ significantly between groups. Further follow-up is needed to determine whether these improvements will result in lower long-term CVD event rates and costs and favorable risk-benefit outcomes. clinicaltrials.gov Identifier: NCT00047424.",success
20563294,True,"Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, N.I.H., Extramural",,,,,,,,True,"The Stop Atherosclerosis in Native Diabetics Study (SANDS) reported cardiovascular benefit of aggressive versus standard treatment targets for both low-density lipoprotein cholesterol (LDL-C) and blood pressure (BP) in diabetic individuals. In this analysis, we examined within trial cost-effectiveness of aggressive targets of LDL-C ≤70 mg/dL and systolic BP ≤115 mmHg versus standard targets of LDL-C ≤100 mg/dL and systolic BP ≤130 mmHg. Randomized, open label blinded-to-endpoint 3-year trial. SANDS clinical trial database, Quality of Wellbeing survey, Centers for Medicare and Medicaid Services, Wholesale Drug Prices. American Indians ≥ age 40 years with type 2 diabetes and no previous cardiovascular events. April 2003 to July 2007. Health payer. Participants were randomized to aggressive versus standard groups with treatment algorithms defined for both. Incremental cost-effectiveness. Compared with the standard group, the aggressive group had slightly lower costs of medical services (-$116) but a 54% greater cost for BP medication ($1,242) and a 116% greater cost for lipid-lowering medication ($2,863), resulting in an increased cost of $3,988 over 3 years. Those in the aggressively treated group gained 0.0480 quality-adjusted life-years (QALY) over the standard group. When a 3% discount rate for costs and outcomes was used, the resulting cost per QALY was $82,589. The use of a 25%, 50%, and 75% reduction in drug costs resulted in a cost per QALY of $61,329, $40,070, and $18,810, respectively. This study was limited by use of a single ethnic group and by its 3-year duration. Within this 3-year study, treatment to lower BP and LDL-C below standard targets was not cost-effective because of the cost of the additional medications required to meet the lower targets. With the anticipated availability of generic versions of the BP and lipid-lowering drugs used in SANDS, the cost-effectiveness of this intervention should improve. Published by Elsevier Inc on behalf of the National Lipid Association.",success
8821844,False,"Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Albuminuria is a risk factor for renal and cardiovascular disease. We conducted a cross sectional survey of 4549 older American Indians in Arizona, Oklahoma and North and South Dakota of (micro)albuminuria. A range of 20.1 to 48.3% of all participants had either micro- (> or = 30 to < 300 mg albumin/g creatinine) or macroalbuminuria (> or = 300 mg albumin/g creatinine). A total of 53% of the participants were diabetic, and the prevalence in Arizona (65 to 70%) was significantly greater than the other two sites. Prevalence of micro- and macroalbuminuria were significantly higher among those who were older, diabetic or hypertensive, and participants from Arizona. Even normotensive, nondiabetic Arizona Indians had higher prevalence rates than similar participants elsewhere. Higher prevalence rates of micro- and macroalbuminuria were also found among Arizona participants than participants with similar degrees of glucose intolerance from the other two sites. Indians reporting the greatest degree of Indian blood were more likely to have abnormal albuminuria (P < 0.0001). The duration of diabetes, fasting plasma glucose, systolic blood pressure, fibrinogen and Indian heritage were independently associated with micro- or macroalbuminuria. The association of albuminuria with subsequent ESRD, cardiovascular morbidity and overall mortality suggests that these American Indians will face a large disease burden. The correlation with reported Indian blood implies a strong component of genetic susceptibility, possibly independent of diabetes.",success
28775914,False,Journal Article,,,,,,,,True,"American Indians have a high prevalence of diabetes and higher incidence of stroke than that of whites and blacks in the U.S. Stroke risk prediction models based on data from American Indians would be of clinical and public health value. A total of 3483 (2043 women) Strong Heart Study participants free of stroke at baseline were followed from 1989 to 2010 for incident stroke. Overall, 297 stroke cases (179 women) were identified. Cox models with stroke-free time and risk factors recorded at baseline were used to develop stroke risk prediction models. Assessment of the developed stroke risk prediction models regarding discrimination and calibration was performed by an analogous C-statistic (C) and a version of the Hosmer-Lemeshow statistic (HL), respectively, and validated internally through use of Bootstrapping methods. Age, smoking status, alcohol consumption, waist circumference, hypertension status, an-tihypertensive therapy, fasting plasma glucose, diabetes medications, high/low density lipoproteins, urinary albumin/creatinine ratio, history of coronary heart disease/heart failure, atrial fibrillation, or Left ventricular hypertrophy, and parental history of stroke were identified as the significant optimal risk factors for incident stroke. The models produced a C = 0.761 and HL = 4.668 (p = 0.792) for women, and a C = 0.765 and HL = 9.171 (p = 0.328) for men, showing good discrimination and calibration. Our stroke risk prediction models provide a mechanism for stroke risk assessment designed for American Indians. The models may be also useful to other populations with high prevalence of obesity and/or diabetes for screening individuals for risk of incident stroke and designing prevention programs.",success
22207511,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"American Indians have high rates of stroke. Improved risk stratification could enhance prevention, but the ability of biochemical and echocardiographic markers of preclinical disease to improve stroke prediction is not well-defined. We evaluated such markers as predictors of ischemic stroke in a community-based cohort of American Indians without prevalent cardiovascular or renal disease. Laboratory markers included C-reactive protein, fibrinogen, urine albumin-to-creatinine ratio, and glycohemoglobin (HbA1c), whereas echocardiographic parameters comprised left atrial diameter, left ventricular mass, mitral annular calcification, and the ratio of early to late mitral diastolic velocities. Predictive performance was judged by indices of discrimination, reclassification, and calibration. After adjustment for standard risk factors, only HbA1c, albuminuria, and left atrial diameter were significantly associated with first ischemic stroke. Addition of HbA1c, although not urine albumin-to-creatinine ratio, to a basic clinical model significantly improved the C-statistic (0.714 versus 0.695; P=0.044), whereas left atrial diameter modestly enhanced integrated discrimination improvement (0.90%; P=0.004), but not the C-statistic (0.701; P=0.528). When combined with HbA1c, left atrial diameter further increased integrated discrimination improvement (1.81%; P<0.001) but not the C-statistic (0.716). No marker achieved significant net reclassification improvement. In this cohort at high cardiometabolic risk, HbA1c emerged as the foremost predictor of ischemic stroke when added to traditional risk factors, affording substantially improved discrimination, with a more modest contribution for left atrial diameter. These findings bolster the role of HbA1c in cardiovascular risk assessment among persons with glycometabolic disorders and provide impetus for further study of the incremental value of echocardiography in high-risk populations.",success
27603047,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"The Cerebrovascular Disease and its Consequences in American Indians (CDCAI) Study recruited surviving members of a 20-year, longitudinal, population-based cohort of American Indians focused on cardiovascular disease, its risk factors, and its consequences. The goal of the CDCAI Study is to characterize the burden, risk factors, and manifestations of vascular brain injury identified on cranial MRI. The CDCAI Study investigators enrolled 1,033 participants aged 60 and older from 11 American Indian communities and tribes in the Northern Plains, Southern Plains, and Southwestern United States. In addition to cranial MRI performed according to standardized protocols, participants underwent extensive medical interview, clinical examination, neurocognitive testing, physical function evaluation, electrocardiogram, and provided blood and urine specimens. Participants also self-administered questionnaires covering demographics, quality of life, and medical history. This report describes the design, implementation, and some of the unique challenges of this study and data collection.",success
24754662,False,Journal Article,,,,,,,,True,"We provided contextual risk factor information for a special supplement on causes of death among American Indians and Alaska Natives (AI/ANs). We analyzed 11 years of Behavioral Risk Factor Surveillance System (BRFSS) data for AI/AN respondents in the United States. We combined BRFSS data from 2000 to 2010 to determine the prevalence of selected risk factors for AI/AN and White respondents residing in Indian Health Service Contract Health Service Delivery Area counties. Regional prevalence estimates for AI/AN respondents were compared with the estimates for White respondents for all regions combined; respondents of Hispanic origin were excluded. With some regional exceptions, AI/AN people had high prevalence estimates of tobacco use, obesity, and physical inactivity, and low prevalence estimates of fruit and vegetable consumption, cancer screening, and seatbelt use. These behavioral risk factors were consistent with observed patterns of mortality and chronic disease among AI/AN persons. All are amenable to public health intervention.",success
19302038,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"Atherosclerosis is an inflammatory disease of the wall of large- and medium-sized arteries that is precipitated by elevated levels of low-density lipoprotein (LDL) cholesterol in the blood. Although dendritic cells (DCs) and lymphocytes are found in the adventitia of normal arteries, their number is greatly expanded and their distribution changed in human and mouse atherosclerotic arteries. Macrophages, DCs, foam cells, lymphocytes, and other inflammatory cells are found in the intimal atherosclerotic lesions. Beneath these lesions, adventitial leukocytes organize in clusters that resemble tertiary lymphoid tissues. Experimental interventions can reduce the number of available blood monocytes, from which macrophages and most DCs and foam cells are derived, and reduce atherosclerotic lesion burden without altering blood lipids. Under proatherogenic conditions, nitric oxide production from endothelial cells is reduced and the burden of reactive oxygen species (ROS) and advanced glycation end products (AGE) is increased. Incapacitating ROS-generating NADPH oxidase or the receptor for AGE (RAGE) has beneficial effects. Targeting inflammatory adhesion molecules also reduces atherosclerosis. Conversely, removing or blocking IL-10 or TGF-beta accelerates atherosclerosis. Regulatory T cells and B1 cells secreting natural antibodies are atheroprotective. This review summarizes our current understanding of inflammatory and immune mechanisms in atherosclerosis.",success
16116058,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"High-sensitivity C-reactive protein (CRP) has been investigated extensively as a marker for predicting the risk of cardiovascular disease (CVD). CVD accounts for a large proportion of mortality and morbidity in American Indians; we sought to test the association of CRP and CVD in a population-based American Indian cohort 45 to 74 years old. Of 3277 participants who were CVD-free at baseline, 542 had CRP >10 mg/L and were excluded from analysis; 50.1% of those included had diabetes. There were 343 CVD events among this cohort during a median follow-up of 6.2 years. Multiple CVD risk factors were used as covariates in Cox proportional-hazard models. After exclusions, the median CRP (3.2 mg/L) was higher than reported in many other populations. CRP predicted CVD in models adjusted for traditional risk factors, but not when albuminuria and fibrinogen were included. In subgroup analysis, CRP was strongly related to incident CVD among nondiabetic women participants, even after adjustment for traditional CVD risk factors and other indicators of inflammation. Conversely, CRP was elevated beyond the useful range of the American Heart Association/Centers for Disease Control and Prevention clinical guidelines in 16% of this population, and CRP was not predictive of CVD in important subgroups, such as those with diabetes. CRP was a predictor of CVD in this American Indian population with a high prevalence of diabetes and other risk factors. The predictive ability of CRP varies considerably among subgroups with different risk factor profiles.",success
22235819,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"Inflammation may play a role in increased risk of heart failure (HF) that is associated with obesity, metabolic syndrome (MS), and diabetes. This study investigated associations between inflammatory markers, MS, and incident HF in a population with a high prevalence of diabetes, obesity, and MS. The cohort consisted of 3098 American Indians without prevalent cardiovascular disease who had C-reactive protein (CRP) and fibrinogen measured at the Strong Heart Study phase II examination. Independent associations between inflammatory markers, MS, and HF were analyzed by Cox hazard models. During a mean follow-up of 11 years, 218 participants developed HF. After the adjustment for cardiovascular risk factors, fibrinogen, (hazard ratio [HR], 1.36; 95% confidence interval [CI], 1.15-1.59) but not CRP (HR, 1.25; 95% CI, 0.97-1.32) remained a significant HF predictor. In individuals without diabetes, concomitant presence of MS and elevated CRP or fibrinogen increased HF risk (for MS and CRP: HR, 2.02; 95% CI, 0.95-4.31; for CRP and fibrinogen: HR, 1.75; 95% CI, 0.83-3.72). In a population with a high prevalence of obesity, MS, and diabetes, elevated CRP and fibrinogen increased HF risk. These associations are attenuated by the adjustments for conventional risk factors suggesting that inflammation acts in concert with metabolic and clinical risk factors in increasing HF risk.",success
26104152,False,Journal Article;Systematic Review,,,,,,,,True,"Increased dependence on Western diets and low physical activity have largely contributed to weight gain and associated chronic diseases in the Canadian Inuit population. The purpose of this study was to systematically review factors influencing dietary and physical activity behaviors to guide health promotion interventions and provide recommendations for future studies. We conducted a systematic literature review to identify relevant articles. Searches were conducted between May 2014 and July 2014, and inclusive of articles published up until July 2014. Articles were searched using four databases: PubMed, PsycINFO, SocINDEX, and Psychology and Behavioral Sciences Collection. Eligible studies focused on diet and/or physical activity or determinants of diet and/or physical activity in Canadian Inuit population, and were published in English. A total of 45 articles were included in the analysis. A detailed appraisal of the articles suggested that many Inuit have disconnected from the traditional ways of life, including harvesting and processing of traditional food species and the associated physical activity. In the last two decades there has been a significant shift from consumption of healthy traditional foods to energy-dense store-bought foods particularly among younger Inuit (<50 years of age). Additionally, low socioeconomic status (SES) and high transportation cost affect food accessibility and contribute to poor dietary choices in the population. However, a few articles that described the mediating role of psychosocial factors reported that higher SES, increased healthful food knowledge, and self-efficacy towards healthy dietary behavior, were associated with greater intentions to make healthier food choices and participate in physical activity. It is evident that the rapid social, cultural, and environmental changes in the Arctic have altered dietary and physical activity behaviors of Canadian Inuit. However, our understanding is limited on how these behaviours might be influenced in the face of these changes. Prospective studies are needed to advance our knowledge of cognitive and environmental determinants of Inuit energy balance-related behaviours. These studies can inform the development of health promotion interventions in the population.",success
24222018,False,Journal Article;Practice Guideline,,,,,,,,False,,success
19800772,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"Although Eskimos were thought to be protected from cardiovascular disease (CVD), state health data show a large proportion of deaths from CVD, despite traditional lifestyles and high omega-3 fatty acid intake. This article explores CVD prevalence and its relation to risk factors in Alaska Eskimos. A population-based cohort of 499 Alaska Eskimos > age 45 from the Norton Sound region was examined in 2000-2004 for CVD and associated risk factors as part of the Genetics of Coronary Artery Disease in Alaska Natives study. CVD and atherosclerosis were evaluated and adjudicated using standardized methods. Average age was 58 years; diabetes prevalence was low and high-density lipoprotein cholesterol (HDL-C) concentrations were high, but a large proportion smoked and had high pathogen burden. CVD was higher in men (12.6%) than in women (5.3%) (prevalence ratio 2.4, CI 1.3-4.4). Rates of stroke (6.1% in men, 1.8% in women) were similar to those for coronary heart disease (CHD) (6.1% men, 2.5% women). MI prevalence was low in both genders (1.9% and 0.7%). CVD was higher in men and in those >60 years. Hypertension, diabetes, high LDL-C, high apoB, and low HDL-C were all strong correlates (<.002) and albuminuria and CRP were also correlated with CVD (p<.05) after adjustment for age and gender. Carotid atherosclerosis was correlated with CVD (p=.0079) independent of other risk factors. These data show high CHD and stroke prevalence in Alaska Eskimos, despite low average LDL-C and high HDL-C. Hypertension and high LDL-C were independent correlates; identifying these risk factors early and treating to target is recommended.",success
20220114,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"We assessed changes in cardiovascular disease-related health outcomes and risk factors among American Indians and Alaska Natives by age and gender. We used cross-sectional data from the 1995 to 1996 and the 2005 to 2006 Behavioral Risk Factor Surveillance System. The respondents were 2548 American Indian and Alaska Native women and men aged 18 years or older in 1995-1996 and 11 104 women and men in 2005-2006. We analyzed the prevalence of type 2 diabetes, obesity, hypertension, cigarette smoking, sedentary behavior, and low vegetable or fruit intake. From 1995-1996 to 2005-2006, the adjusted prevalence of diabetes among American Indians and Alaska Natives increased by 26.9%, from 6.7% to 8.5%, and obesity increased by 25.3%, from 24.9% to 31.2%. Hypertension increased by 5%, from 28.1% to 29.5%. Multiple logistic models showed no meaningful changes in smoking, sedentary behavior, or intake of fruits or vegetables. In 2005-2006, 79% of the population had 1 or more of the 6 risk factors, and 46% had 2 or more. Diabetes, obesity, and hypertension and their associated risk factors should be studied further among urban, rural, and reservation American Indian and Alaska Native populations, and effective primary and secondary prevention efforts are critical.",success
21592347,True,"Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, N.I.H., Extramural",NCT01106456,databank,NCT01106456,NCT01106456,NCT01106456,NCT01106456|databank,NCT01106456|databank,True,"Cigarette smoking is the number one cause of preventable death among American Indian and Alaska Natives, AI/ANs. Two out of every five AI/AN will die from tobacco-related diseases if the current smoking rates of AI/ANs (40.8%) persist. Currently, there is no proven, effective culturally-tailored smoking cessation program designed specifically for a heterogeneous population of AI.The primary aim of this group randomized clinical trial is to test the efficacy of ""All Nations Breath of Life"" (ANBL) program compared to a non-tailored ""Current Best Practices"" smoking cessation program among AI smokers. We will randomize 56 groups (8 smokers per group) to the tailored program or non-tailored program for a total sample size of 448 American Indian smokers. All participants in the proposed study will be offered pharmacotherapy, regardless of group assignment. This study is the first controlled trial to examine the efficacy of a culturally-tailored smoking cessation program for American Indians. If the intervention is successful, the potential health impact is significant because the prevalence of smoking is the highest in this population. ClinicalTrials.gov: NCT01106456.",success
25968176,False,"Evaluation Study;Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"Cigarette smoking is the leading preventable cause of death worldwide. American Indians have the highest proportion of smoking in the United States. However, few studies have examined the impact of cigarette smoking on disease mortality in this ethnically important but traditionally understudied minority population. Here we estimated the association of cigarette smoking with cardiovascular disease (CVD), cancer and all-cause mortality in American Indians participating in the Strong Heart Study, a large community-based prospective cohort study comprising of 4549 American Indians (aged 45-74 years) followed for about 20 years (1989-2008). Hazard ratio and population attributable risk (PAR) associated with cigarette smoking were estimated by Cox proportional hazard model, adjusting for sex, study site, age, educational level, alcohol consumption, physical activity, BMI, lipids, renal function, hypertension or diabetes status at baseline, and interaction between current smoker and study site. We found that current smoking was significantly associated with cancer mortality (HR 5.0, [1.9-13.4]) in men, (HR 3.9 [1.6-9.7] in women) and all-cause mortality (HR 1.8, [1.2-2.6] in men, HR 1.6, [1.1-2.4] in women). PAR for cancer and all-cause mortality in men were 41.0 and 18.4 %, respectively, whereas the corresponding numbers in women were 24.9 and 10.9 %, respectively. Current smoking also significantly increases the risk of CVD deaths in women (HR 2.2 [1.1, 4.4]), but not men (HR 1.2 [0.6-2.4]). PAR for CVD mortality in women was 14.9 %. In summary, current smoking significantly increases the risk of CVD (in women), cancer and all-cause mortality in American Indians, independent of known risk factors. Culturally specific smoking cessation programs are urgently needed to reduce smoking-related premature deaths.",success
22918939,False,"Journal Article;Meta-Analysis;Research Support, Non-U.S. Gov't;Systematic Review",,,,,,,,True,"To summarise published empirical research on culturally targeted anti-tobacco media messages for Indigenous or First Nations people and examine the evidence for the effectiveness of targeted and non-targeted campaigns. Studies were sought describing mass media and new media interventions for tobacco control or smoking cessation in Indigenous or First Nations populations. Studies of any design were included reporting outcomes of media-based interventions including: cognitions, awareness, recall, intention to quit and quit rates. Then, 2 reviewers independently applied inclusion criteria, which were met by 21 (5.8%) of the studies found. One author extracted data with crosschecking by a second. Both independently assessed papers using Scottish Intercollegiate Guidelines Network (SIGN; quantitative studies) and Daly et al (qualitative studies). A total of 21 studies were found (4 level 1 randomised controlled trials (RCTs), 11 level 2 studies and 6 qualitative studies) and combined with narrative synthesis. Eight evaluated anti-tobacco TV or radio campaigns; two assessed US websites; three New Zealand studies examined mobile phone interventions; five evaluated print media; three evaluated a CD-ROM, a video and an edutainment intervention. Although Indigenous people had good recall of generic anti-tobacco messages, culturally targeted messages were preferred. New Zealand Maori may be less responsive to holistic targeted campaigns, despite their additional benefits, compared to generic fear campaigns. Culturally targeted internet or mobile phone messages appear to be as effective in American Indians and Maori as generic messages in the general population. There is little research comparing the effect of culturally targeted versus generic messages with similar message content in Indigenous people.",success
9113215,True,"Clinical Trial;Comparative Study;Controlled Clinical Trial;Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"This study was designed to assess the capability of the Doctors Helping Smokers (DHS) model to produce an increase in smoking cessation over controls within four urban Indian Health clinics. A total of 601 Native American smokers were enrolled, surveyed, and measured for cardiovascular risk factors. Of those present in treatment clinics at 1-year follow-up, 7.1% reported being abstinent vs. 4.9% in the control group. Of those who made at least one visit to the clinic during the treatment year, 9.4% self-reported being abstinent in the treatment sites vs. 3.9% in the control group (p = .04). Cotinine validated quits for all enrollees, regardless of whether they attended the clinic during the intervention, are 6.7% (intervention) and 6.8% (control). Number of quit attempts and future quit intentions were greater in the intervention group. Recommendations for future intervention efforts include earlier contact with clinicians, clinic involvement in preplanning, developing the program around the principles and realities of each site, building in more extensive components, and utilizing additional community resources.",success
14534221,False,"Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,False,,success
20402198,False,"Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"We assessed health status and behavioral risks in American Indians (AIs) from rural, northern plains reservation communities. AI interviewers from the communities administered the core and optional modules of the Behavioral Risk Factor Surveillance System (BRFSS) to 404 AI adults randomly selected from housing lists from four AI tribal communities located on the northern plains of the U.S. The BRFSS interview assessed several health functioning areas including medical conditions, preventive screenings, and behavioral risks. We measured health disparities by comparing the AI sample data with a northern plains statewide (North Dakota) sample and a U.S. national sample. We compared outcomes with BRFSS statewide (North Dakota) and U.S. national data from telephone-based interviews. AI participants showed a significantly greater prevalence of diabetes, coronary heart disease, myocardial infarction, smoking, obesity, and heavy alcohol use than either the regional or national samples. They also reported being less likely to engage in leisure-time physical activity and to have had age-appropriate preventive screenings for several diseases including colorectal cancer, prostate cancer, breast cancer, and cardiovascular disease. Face-to-face interviews conducted by AI community members are an effective means of gathering health information about AIs living in rural, reservation communities. AIs living in these communities on the northern plains have a much higher prevalence of many health-risk behaviors and some medical conditions than are found in the general population. Improved health-care access, better preventive screenings, and culturally appropriate community-based health promotion programs and policies should be examined as possible ways to reduce health disparities.",success
27514405,False,Journal Article;Systematic Review,,,,,,,,True,"The aim of this study was to systematically review the evidence-base for the effectiveness of culturally unadapted, culturally adapted and culture-based interventions for Indigenous adults with mental or substance use disorders. We conducted a systematic search of scientific databases, government websites and web-based Indigenous research repositories. We sought studies using designs comparing an intervention group to a control/comparator group or pre- and post-test designs, published between 2000 and 2015 examining interventions to improve individual-level outcomes (e.g. remission, symptoms, quality of life, functioning) or service-level outcomes (e.g. number of interventions delivered) for Indigenous adults with mental or substance use disorders in Australia, Canada, New Zealand or the United States. A total of 16 studies met inclusion criteria. Virtually all North American studies (6 US and 1 Canadian) evaluated culturally unadapted interventions, all of which were interventions for substance use. Two-thirds of Australian and New Zealand studies evaluated culturally adapted interventions and included samples with mental disorders. Of eight culturally unadapted psychological/psychosocial, pharmacological and educational intervention studies, seven reported significant improvements on at least one measure of psychological well-being, mental health problem severity, or significantly reduced alcohol or illicit drug use. Of seven culturally adapted psychological/psychosocial intervention studies, all reported significant improvement on at least one measure of symptoms of mental illness, functioning, and alcohol use. One culture-based psychological/psychosocial intervention study significantly reduced problem severity in medical and psychiatric domains. There remains inconclusive evidence regarding interventions due to a small and methodologically weak evidence-base. The literature would be enhanced by intervention replication and outcome standardisation, validating the outcome instruments used in Indigenous populations, including sample size calculations and using stronger research designs (e.g. interrupted time-series designs). Robust implementation and outcomes research is needed to further progress evidence-based practice in Indigenous mental health.",success
28628397,False,Journal Article;Systematic Review,,,,,,,,True,"Given the disproportionately high levels of alcohol and other drug abuse among Indigenous youth in the United States, the purpose of this systematic review was to explicate the current state of empirically-based and culturally-informed substance abuse prevention and intervention programs for Indigenous youth (ages 9-18). The 14 articles that met inclusion criteria for this review were analyzed both in terms of the cultural intervention itself (primary population, intervention, core tenants, focus of intervention, intervention goals, location, intervention location, and program length) and their evaluation approach. Results indicate variable integration of cultural components with the majority of interventions taking place in schools and treatment facilities, targeting primarily individuals. There is a current gap in research on culturally-informed substance abuse interventions for Indigenous youth, which this review begins to address. Promising areas of future research and interventions include bringing communities and families into treatment and prevention.",success
27924618,True,Journal Article;Randomized Controlled Trial,,,,,,,,True,"Limited available data document higher prevalences of cardiovascular disease (CVD) risk factors and health outcomes among American Indians (AIs) compared to other racial/ethnic groups. As part of a randomized control trial to improve tribal food and physical activity environments, our tribal-academic partnership surveyed a cross-sectional sample of American Indian adults (n = 513) to assess the prevalence of type 2 diabetes, obesity, hypertension, tobacco use, physical activity, and vegetable and fruit intake. Surveys were collected from April through May 2015. We used logistic regression to examine the association between CVD-related risk factors and health outcomes. The prevalence of CVD-related outcomes was high, ranging from 25% for diabetes to 75% for low vegetable intake. The prevalence of diabetes, obesity, and hypertension tended to be higher among participants with any tobacco use compared to no tobacco use, but findings were not statistically significant. The prevalence of diabetes (prevalence ratio 2.1, 95% CI 1.4-3.2) and obesity (prevalence ratio 1.5, 95% CI 1.2-1.8) was higher among participants with low physical activity levels compared to recommended physical activity levels. CVD risk factors and health outcomes persist among American Indians even as some risks (e.g., smoking) appear to be stabilizing or even declining in the general US population. Efforts to include American Indians in national health surveys, implement broad reaching environmental and policy interventions, and address the social determinants of health are critical to the elimination of these disparities.",success
23577646,False,"Journal Article;Research Support, Non-U.S. Gov't;Systematic Review",,,,,,,,True,"Physical activity is beneficial for many chronic conditions. However, activity levels of Native Americans are not well known. This systematic review investigated if Native American populations achieve the recommended physical activity levels, compared current and past activity levels, and assessed the ability of exercise training programmes to improve health outcomes among this population. Electronic databases (e.g. MEDLINE, EMBASE) were searched and citations were cross-referenced. Included articles reported physical activity levels or investigations among Native Americans. This search identified 89 articles: self-report (n = 61), accelerometry and pedometry (n = 10), metabolic monitoring (n = 10) and physical activity interventions (n = 17). Few adults were found to meet the physical activity recommendations (27.2% [95% confidence interval = 26.9-27.5%] self-report, 9% [4-14%] accelerometry). Among children/youth, 26.5% (24.6-28.4%) (self-report) to 45.7% (42.3-49.1%) (pedometry/accelerometry) met the recommendations. Adults and children/youth were generally identified as physically inactive (via doubly labelled water). Overall, Native American adults reported lower activity levels since 2000, compared to 1990s, although similar to 1980s. Few physical activity interventions employed strong methodologies, large sample sizes and objective outcome measures. There is a clear need to increase Native American populations' physical activity. Additional research is required to evaluate exercise training programmes among this population.",success
9620042,False,"Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Community mortality surveillance for 1984-1988 was conducted by researchers of the Strong Heart Study, which examined the incidence, prevalence, and risk factors of cardiovascular disease in three American Indian populations, aged 45-74 years, in Arizona, Oklahoma, and South/North Dakota. All-cause and cardiovascular disease mortality rates were determined through the use of death certificate data. Cardiovascular disease deaths were confirmed by independent systematic review of medical records. In all three populations, men had higher all-cause and cardiovascular disease mortality rates than did women. Oklahoma exhibited slightly lower 5-year, age-adjusted, all-cause mortality (96/1,000) than did Arizona (107/1,000) and South/North Dakota (114/1,000). The leading cause of death among both sexes in Oklahoma and in South/North Dakota was cardiovascular disease. Diabetes mellitus led among Arizona women. The other major causes of death were cancer, liver disease including cirrhosis, and injury. When compared with the rates in each state, average annual all-cause mortality rates were higher for the American Indian populations in almost every age group. The all-cause annual mortality rates in the three Indian populations were close to rates in the US black population and higher than the rates of the entire US population and of US whites. This trend was amplified in the 45- to 64-year age group. Only in the 65- to 74-year age group did mortality rates in the Indian population approach those of the US population. Cardiovascular disease mortality rates were close to the US averages in Arizona and Oklahoma, but they were more than two times higher in South/North Dakota among those between 45 and 64 years of age. Thus, American Indians in Arizona, Oklahoma, and South/North Dakota exhibit high all-cause mortality rates. In particular, the South/North Dakota population cardiovascular disease death rate appears to present a potential target for community-based programs to intervene on known risk factors to promote healthy lifestyles.",success
14964763,False,Journal Article;Review,,,,,,,,True,"We reviewed the literature of population-based studies regarding heart disease and stroke occurrence among Alaska Natives. The existing literature suggests that differences in cardiovascular mortality rates and risk factors exist in Alaska Natives by ethnicity and residence. However, data sources are largely limited to mortality data and small community-based studies. Because cardiovascular disease occurrence has not been well studied among Alaska Natives, it is important to avoid sweeping generalizations about the increasing or decreasing prevalences of cardiovascular disease and risk factors. Recent mortality rates from heart disease (of all types) among Alaska Natives are similar to rates for U.S. whites, and mortality rates from stroke among Alaska Natives are higher than rates for U.S. whites. Mortality rates from ischemic heart disease have been relatively constant among Alaska Natives over the past 20 years, while over the same time period, rates declined dramatically among U.S. Whites. The ischemic heart disease mortality rates among Alaska Native males are now comparable to rates among U.S. White males. Although available data indicate no increase in mortality from ischemic heart disease in Alaska Natives, the relatively constant death rates over the recent 20 years, compared with declining rates elsewhere in the U.S, and the high prevalence of risk factors for ischemic heart disease calls for increased descriptive epidemiologic studies of the incidence and prevalence of cardiovascular disease outcomes. In addition, analytic epidemiologic studies are needed to examine the relationship between lifestyle, especially subsistence and traditional lifestyles, and cardiovascular disease outcomes.",success
12578801,False,"Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"The aims of the Strong Heart Family Study are to clarify the genetic determinants of cardiovascular disease (CVD) risk in American Indians and to map and identify genes for CVD susceptibility. The authors describe the design of the Strong Heart Family Study (conducted between 1998 and 1999) and evaluate the heritabilities of CVD risk factors in American Indians from this study. In the first phase of the study, approximately 950 individuals, aged 18 years or more, in 32 extended families, were examined. The examination consisted of a personal interview, physical examination, laboratory tests, and an ultrasound examination of the carotid arteries. The phenotypes measured during the physical examination included anthropometry, lipoproteins, blood pressure, glycemic status, and clotting factors. Heritabilities for CVD risk factor phenotypes were estimated using a variance component approach and the program SOLAR. After accounting for the effects of covariates, the authors detected significant heritabilities for many CVD risk factor phenotypes (e.g., high density lipoprotein cholesterol (heritability = 0.50) and diastolic blood pressure (heritability = 0.34)). These results suggest that heredity explains a substantial proportion of the variability of CVD risk factors and that these heritabilities are large enough to warrant a search for major risk factor genes.",success
16788905,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"Increasing incidence of cardiovascular disease in traditionally low-risk Alaskan Eskimos is a cause for concern. The purpose of this study was to examine the genetic and environmental correlations of low-density lipoprotein (LDL) subfractions with obesity-related factors in Alaskan Eskimos, using data from the first 954 participants of the Genetics of Coronary Artery Disease in Alaska Natives Study. Estimates of genetic and environmental influence were calculated using a maximum likelihood variance component method implemented in SOLAR. Mean values of weight, body mass index (BMI), and waist were 73.4 +/- 0.5 kg, 27.6 +/- 0.2 kg/m2, and 88.0 +/- 0.4 cm, respectively. LDL, and its small (LDL1), medium (LDL2), and large (LDL3) subfractions, had mean values of 115.8 +/- 1.2 mg/dl, 8.3 +/- 0.4 mg/dl, 19.6 +/- 0.8 mg/dl, and 71.5 +/- 1.5 mg/dl, respectively. Bivariate analysis displayed significant genetic correlations between LDL subfractions and obesity-related factors: LDL1 with BMI (rhoG = 0.67, P < 0.05), waist (rhoG = 0.80, P < 0.001), and subscapular and tricep skinfolds (rhoG = 0.93, P < 0.005, and rhoG = 0.78, P < 0.05, respectively); LDL2 with BMI (rhoG = 0.52, P < 0.05), waist (rhoG = 0.46, P < 0.05), and tricep skinfold (rhoG = 0.60, P < 0.05); and mean LDL size with BMI (rhoG = -0.36), waist (rhoG = -0.42,), and subscapular and tricep skinfolds (rhoG = -0.44 and -0.43, respectively) (P < 0.005). These results show that a common set of genes is influencing LDL size and obesity-related factors in Alaskan Eskimos.",success
21737303,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Little research has focused on the social patterning of diabetes among African Americans. We examined the relationship between socioeconomic status (SES) and the prevalence, awareness, treatment, and control of diabetes among African Americans. Education, income and occupation were examined among 4,303 participants (2,726 women and 1,577 men). Poisson regression estimated relative probabilities (RP) of diabetes outcomes by SES. The prevalence of diabetes was 19.6% in women and 15.9% in men. Diabetes awareness, treatment, and control were 90.0%, 86.8%, and 39.2% in women, respectively, and 88.2%, 84.4%, and 35.9% in men, respectively. In adjusted models, low-income men and women had greater probabilities of diabetes than high-income men and women (RP, 1.94; 95% confidence interval [CI], 1.28-2.92; and RP, 1.35; 95% CI, 1.04-1.74, respectively). Lack of awareness was associated with low education and low occupation in women (RP, 2.28; 95%CI 1.01-5.18; and RP, 2.62; 95% CI, 1.08-6.33, respectively) but not in men. Lack of treatment was associated with low education in women. Diabetes control was not patterned by SES. Diabetes prevalence is patterned by SES, and awareness and treatment are patterned by SES in women but not men. Efforts to prevent diabetes in African Americans need to address the factors that place those of low SES at higher risk.",success
24356528,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, U.S. Gov't, Non-P.H.S.",,,,,,,,True,"Perceived stress may increase risk for coronary heart disease (CHD) and death, but few studies have examined these relationships longitudinally. We sought to determine the association of perceived stress with incident CHD and all-cause mortality. Data were from a prospective study of 24 443 participants without CHD at baseline from the national Reasons for Geographic And Racial Differences in Stroke (REGARDS) study cohort. Outcomes were expert-adjudicated acute CHD and all-cause mortality. Over a mean follow-up of 4.2 (maximum 6.9) years, there were 659 incident CHD events and 1320 deaths. Analyses were stratified by income level because of significant interactions with stress. For individuals with low income, 3529 (35.4%) reported high stress, and for those with high income, 2524 (22.1%) did so. Compared with reporting no stress, those reporting the highest stress had higher risk for incident CHD if they reported low income (sociodemographic-adjusted HR 1.36, 95% CI: 1.04, 1.78) but not high income (sociodemographic-adjusted HR 0.82, 95% CI: 0.57, 1.16); the finding in low income individuals attenuated with adjustment for clinical and behavioral factors (HR 1.29, 95% CI: 0.99, 1.69, P=0.06). After full adjustment, the highest stress category was associated with higher risk for death among those with low income (HR 1.55, 95% CI: 1.31, 1.82) but not high income (HR 1.13, 95% CI: 0.88, 1.46). High stress was associated with greater risks of CHD and death for individuals with low but not high income.",success
24061511,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"Long-term exposure to high levels of arsenic is associated with increased risk for cardiovascular disease, whereas risk from long-term exposure to low to moderate arsenic levels (< 100μg/L in drinking water) is unclear. To evaluate the association between long-term exposure to low to moderate arsenic levels and incident cardiovascular disease. Prospective cohort study. The Strong Heart Study baseline visit between 1989 and 1991, with follow-up through 2008. 3575 American Indian men and women aged 45 to 74 years living in Arizona, Oklahoma, and North and South Dakota. The sum of inorganic and methylated arsenic species in urine at baseline was used as a biomarker of long-term arsenic exposure. Outcomes were incident fatal and nonfatal cardiovascular disease. A total of 1184 participants developed fatal and nonfatal cardiovascular disease. When the highest and lowest quartiles of arsenic concentrations (> 15.7 vs. < 5.8 μg/g creatinine) were compared,the hazard ratios for cardiovascular disease, coronary heart disease, and stroke mortality after adjustment for sociodemographic factors, smoking, body mass index, and lipid levels were 1.65 (95%CI, 1.20 to 2.27; P for trend < 0.001), 1.71 (CI, 1.19 to 2.44; P for trend < 0.001), and 3.03 (CI, 1.08 to 8.50; P for trend = 0.061),respectively. The corresponding hazard ratios for incident cardiovascular disease, coronary heart disease, and stroke were 1.32 (CI,1.09 to 1.59; P for trend = 0.002), 1.30 (CI, 1.04 to 1.62; P for trend = 0.006), and 1.47 (CI, 0.97 to 2.21; P for trend = 0.032).These associations varied by study region and were attenuated after further adjustment for diabetes, hypertension, and kidney disease measures. Direct measurement of individual arsenic levels in drinking water was unavailable. Long-term exposure to low to moderate arsenic levels was associated with cardiovascular disease incidence and mortality.",success
24255048,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Cadmium has been associated with peripheral arterial disease (PAD) in cross-sectional studies, but prospective evidence is lacking. Our goal was to evaluate the association of urine cadmium concentrations with incident PAD in a large population-based cohort. A prospective cohort study was performed with 2864 adult American Indians 45 to 74 years of age from Arizona, Oklahoma, and North and South Dakota who participated in the Strong Heart Study from 1989 to 1991 and were followed through 2 follow-up examination visits in 1993 to 1995 and 1997 to 1999. Participants were free of PAD, defined as an ankle brachial index <0.9 or >1.4 at baseline, and had complete baseline information on urine cadmium, potential confounders, and ankle brachial index determinations in the follow-up examinations. Urine cadmium was measured using inductively coupled plasma mass spectrometry and corrected for urinary dilution by normalization to urine creatinine. Multivariable-adjusted hazard ratios were computed using Cox-proportional hazards models for interval-censored data. A total of 470 cases of incident PAD, defined as an ankle brachial index <0.9 or >1.4, were identified. After adjustment for cardiovascular disease risk factors including smoking status and pack-years, the hazard ratio comparing the 80th to the 20th percentile of urine cadmium concentrations was 1.41 (1.05-1.81). The hazard ratio comparing the highest to the lowest tertile was 1.96 (1.32-2.81). The association persisted after excluding participants with ankle brachial index >1.4 only as well as in subgroups defined by sex and smoking status. Urine cadmium, a biomarker of long-term cadmium exposure, was independently associated with incident PAD, providing further support for cadmium as a cardiovascular disease risk factor.",success
27810857,False,Journal Article,,,,,,,,True,"At high levels, inorganic arsenic exposure is linked to peripheral arterial disease (PAD) and cardiovascular disease. To our knowledge, no prior study has evaluated the association between low-to-moderate arsenic exposure and incident PAD by ankle brachial index (ABI). We evaluated this relationship in the Strong Heart Study, a large population-based cohort study of American Indian communities. A total of 2,977 and 2,966 PAD-free participants who were aged 45-74 years in 1989-1991 were reexamined in 1993-1995 and 1997-1999, respectively, for incident PAD defined as either ABI <0.9 or ABI >1.4. A total of 286 and 206 incident PAD cases were identified for ABI <0.9 and ABI >1.4, respectively. The sum of inorganic and methylated urinary arsenic species (∑As) at baseline was used as a biomarker of long-term exposure. Comparing the highest tertile of ∑As with the lowest, the adjusted hazard ratios were 0.57 (95% confidence interval (CI): 0.32, 1.01) for ABI <0.9 and 2.24 (95% CI: 1.01, 4.32) for ABI >1.4. Increased arsenic methylation (as percent dimethylarsinate) was associated with a 2-fold increased risk of ABI >1.4 (hazard ratio = 2.04, 95% CI: 1.02, 3.41). Long-term low-to-moderate ∑As and increased arsenic methylation were associated with ABI >1.4 but not with ABI <0.9. Further studies are needed to clarify whether diabetes and enhanced arsenic metabolism increase susceptibility to the vasculotoxic effects of arsenic exposure.",success
31060373,True,"Journal Article;Multicenter Study;Research Support, N.I.H., Extramural",,,,,,,,True,"Arsenic exposure has been related to numerous adverse cardiovascular outcomes. The aim of this study was to investigate the cross-sectional and prospective association between arsenic exposure with echocardiographic measures of left ventricular (LV) geometry and functioning. A total of 1337 young adult participants free of diabetes mellitus and cardiovascular disease were recruited from the SHFS (Strong Heart Family Study). The sum of inorganic and methylated arsenic concentrations in urine (ΣAs) at baseline was used as a biomarker of arsenic exposure. LV geometry and functioning were assessed using transthoracic echocardiography at baseline and follow-up. Mean follow-up was 5.6 years, and median (interquartile range) of ΣAs was 4.2 (2.8-6.9) µg/g creatinine. Increased arsenic exposure was associated with prevalent LV hypertrophy, with an odds ratio (95% CI) per a 2-fold increase in ΣAs of 1.47 (1.05-2.08) in all participants and of 1.58 (1.04-2.41) among prehypertensive or hypertensive individuals. Measures of LV geometry, including LV mass index, left atrial systolic diameter, interventricular septum, and LV posterior wall thickness, were positively and significantly related to arsenic exposure. Among measures of LV functioning, stroke volume, and ejection fraction were associated with arsenic exposure. Arsenic exposure was related to an increase in LV wall thickness and LV hypertrophy in young American Indians with a low burden of cardiovascular risk factors. The relationship was stronger in participants with prehypertension or hypertension, suggesting that potential cardiotoxic effects of arsenic might be more pronounced in individuals already undergoing cardiovascular adaptive mechanisms following elevated systemic blood pressure.",success
30373089,False,Journal Article,,,,,,,,True,"Elevated arsenic exposure from drinking water is associated with an increased risk of cardiovascular disease, diabetes, kidney disease, and skin, lung, and bladder cancer. Arsenic contamination in groundwater supplies disproportionately affects rural populations using private wells. Arsenic mitigation programs for American Indian communities are limited. There is an urgent need for targeted approaches to reduce arsenic exposure for at-risk communities using private wells. Formative research was conducted to inform and design a community-based arsenic mitigation intervention for Lakota and Dakota Nations in the Great Plains Area of the United States, where, in some communities, one-quarter of private wells are estimated to have elevated arsenic. Formative research included semi-structured interviews, a community workshop, intervention-planning workshops, and a pilot study of the developed intervention. Community members prioritize aesthetic qualities of water (e.g. taste, color), safety, and other situational factors (e.g. cost) when considering their drinking and cooking water. Although water safety is a concern, awareness and concern for arsenic vary substantially within communities. To reduce arsenic exposure, community members recommended communication of water test results, home visits for intervention delivery, and reminders to use arsenic-safe water. Findings informed the development of an intervention to prevent arsenic exposure through drinking water and cooking, including health promotion messages and household items to facilitate use of an arsenic removal device (e.g. tankards to store filtered water). The pilot study indicated promising acceptability and operability of the developed intervention. This research provides a model for the development of environmental health interventions in partnership with American Indian and other private well-using communities.",success
27199065,False,Journal Article;Review,,,,,,,,True,"This review summarizes evidence from 2 lines of research previously thought to be unrelated: the unexpectedly positive results of TACT (Trial to Assess Chelation Therapy), and a body of epidemiological data showing that accumulation of biologically active metals, such as lead and cadmium, is an important risk factor for cardiovascular disease. Considering these 2 areas of work together may lead to the identification of new, modifiable risk factors for atherosclerotic cardiovascular disease. We examine the history of chelation up through the report of TACT. We then describe work connecting higher metal levels in the body with the future risk of cardiovascular disease. We conclude by presenting a brief overview of a newly planned National Institutes of Health trial, TACT2, in which we will attempt to replicate the findings of TACT and to establish that removal of toxic metal stores from the body is a plausible mechanistic explanation for the benefits of edetate disodium treatment.",success
23215898,False,"Journal Article;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"The development of Bronfenbrenner's bio-social-ecological systems model of human development parallels advances made to the theory of resilience that progressively moved from a more individual (micro) focus on traits to a multisystemic understanding of person-environment reciprocal processes.   This review uses Bronfenbrenner's model and Ungar's social-ecological interpretation of four decades of research on resilience to discuss the results of a purposeful selection of studies of resilience that have been done in different contexts and cultures.   An ecological model of resilience can, and indeed has been shown to help researchers of resilience to conceptualize the child's social and physical ecologies, from caregivers to neighbourhoods, that account for both proximal and distal factors that predict successful development under adversity. Three principles emerged from this review that inform a bio-social-ecological interpretation of resilience: equifinality (there are many proximal processes that can lead to many different, but equally viable, expressions of human development associated with well-being); differential impact (the nature of the risks children face, their perceptions of the resources available to mitigate those risks and the quality of the resources that are accessible make proximal processes more or less influential to children's development); and contextual and cultural moderation (different contexts and cultures provide access to different processes associated with resilience as it is defined locally).   As this review shows, using this multisystemic social-ecological theory of resilience can inform a deeper understanding of the processes that contribute to positive development under stress. It can also offer practitioners and policy makers a broader perspective on principles for the design and implementation of effective interventions.",success
30545559,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"To examine the association of psychosocial resources with prevalent type 2 diabetes (T2D) in 5104 African American men and women. Using data from the Jackson Heart Study (JHS), we evaluated the cross-sectional associations of four psychosocial resources (social support, optimism, religiosity, and social networks) with T2D [fasting glucose ≥126 mg/dL, or HbA1c ≥ 6.5%, or use of diabetic medication]. Multivariable Poisson regression estimated prevalence ratios (PR, 95% confidence interval-CI) of T2D by each psychosocial measure, adjusting for demographics, SES, waist circumference, health behaviors, and depressive symptoms. Women reported greater religiosity and had more social networks than men (p < 0.001). High (vs. low) social support was associated with a lower prevalence of T2D among men after full adjustment (PR 0.74, 95% CI 0.59-0.91). Women with high (vs. low) social networks had a 16% lower prevalence of T2D (PR 0.84, 95% CI 0.73-0.96) after full adjustment. High (vs. low) optimism was associated with a 20% lower prevalence of T2D after adjustment for age (PR 0.80, 95% CI 0.65-0.98). Religiosity was not associated with T2D. Social support and networks should be considered in efforts to prevent T2D among a high-risk group such as African Americans.",success
29567845,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"Mounting evidence links positive psychological functioning to restorative health processes and favourable medical outcomes. However, very little is known about the relationship between optimism, an indicator of psychological functioning and the American Heart Association (AHA)-defined concept of cardiovascular health (CVH), particularly in Hispanics/Latinos of diverse backgrounds. To address limitations of existing literature, this study investigated the association between dispositional optimism and CVH in a heterogeneous sample of Hispanics/Latinos residing in the USA. Cross-sectional study. Data were analysed from 4919 adults ages 18-75 of the Hispanic Community Health Study/Study of Latinos parent study and the Sociocultural Ancillary Study. Optimism was assessed using the 6-item Life Orientation Test-Revised (range from 6 to 30). AHA classification standards were used to derive an additive CVH score with operationalisation of indicators as Ideal, Intermediate and Poor. The overall CVH score included indicators of diet, body mass index, physical activity, cholesterol, blood pressure, fasting glucose and smoking status. Multivariate linear and logistic regressions were used to examine associations of optimism with CVH (Life's Simple 7), after adjusting for sociodemographic factors and depressive symptoms. Each increase in the optimism total score was associated with a greater CVH score (β=0.03 per unit increase, 95% CI 0.01 to 0.05). When modelling tertiles of optimism, participants with moderate (β=0.24 to 95% CI 0.06 to 0.42) and high (β=0.12, 95% CI 0.01 to 0.24) levels of optimism displayed greater CVH scores when compared with their least optimistic peers. This study offers preliminary evidence for an association between optimism and CVH in a large heterogeneous group of Hispanic/Latino adults. Our study adds scientific knowledge of psychological assets that may promote CVH and suggests a novel therapeutic target for consideration. Future studies are needed to explore causality and potential mechanism underlying the relationship between positive emotion and heart health.",success
27254805,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Racial discrimination is a social determinant of health for First Nations people. Cultural resilience has been regarded as a potentially positive resource for social outcomes. Using a compensatory model of resilience, this study sought to determine if cultural resilience (compensatory factor) neutralized or offset the detrimental effect of racial discrimination (social risk factor) on stress (outcome). Data were collected from October 2012 to February 2013 (N = 340) from adult members of the Kettle and Stony Point First Nation community in Ontario, Canada. The outcome was perceived stress; risk factor, racial discrimination; and compensatory factor, cultural resilience. Control variables included individual (education, sociability) and family (marital status, socioeconomic status) resilience resources and demographics (age and gender). The model was tested using sequential regression. The risk factor, racial discrimination, increased stress across steps of the sequential model, while cultural resilience had an opposite modest effect on stress levels. In the final model with all variables, age and gender were significant, with the former having a negative effect on stress and women reporting higher levels of stress than males. Education, marital status, and socioeconomic status (household income) were not significant in the model. The model had R(2) = 0.21 and adjusted R(2) = 0.18 and semipartial correlation (squared) of 0.04 and 0.01 for racial discrimination and cultural resilience, respectively. In this study, cultural resilience compensated for the detrimental effect of racial discrimination on stress in a modest manner. These findings may support the development of programs and services fostering First Nations culture, pending further study.",success
27383090,False,Journal Article;Systematic Review,,,,,,,,True,"Examining American Indian and Alaska Native (AI/AN) resilience using the life course framework could inform public health strategies that support favorable health outcomes, despite adversity (e.g., discrimination, historical loss, comorbidity). A systematic review of peer-reviewed literature published from 1970 to 2015 yielded eight articles on AI/AN life course and resilience. A content analysis identified three themes. AI/AN resilience is 1) an ongoing, dynamic process, 2) evident within linked lives and life transitions, and 3) accessed through cultural knowledge and practice. Resilience research could change the paradigm of AI/AN health research to guide asset-based approaches across the life course.",success
30197551,False,Journal Article,,,,,,,,True,"Spirituality measures often show positive associations with preferred mental health outcomes in the general population; however, research among American Indians (AIs) is limited. We examined the relationships of mental health status and two measures of spirituality - the Midlife Development Inventory (MIDI) and a tribal cultural spirituality measure - in Northern Plains AIs, aged 15-54 (<i>n</i> = 1636). While the MIDI was unassociated with mental health status, the tribal cultural spirituality measure showed a significant relationship with better mental health status. Mental health conditions disproportionately affect AIs. Understanding protective factors such as cultural spirituality that can mitigate mental health disorders is critical to reducing these health disparities.",success
29981069,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Cardiovascular diseases (CVD) are a leading cause of illness and death for Indigenous people in Canada and globally. Appropriate medication can significantly improve health outcomes for persons diagnosed with CVD or for those at high risk of CVD. Poor health literacy has been identified as a major barrier that interferes with client understanding and taking of CVD medication. Strengthening health literacy within health services is particularly relevant in Indigenous contexts, where there are systemic barriers to accessing literacy skills. The aim of this study is to test the effect of a customized, structured health literacy educational program addressing CVD medications. Pre-post-design involves health providers and Indigenous clients at the De dwa da dehs nye>s Aboriginal Health Centre (DAHC) in Ontario, Canada. Forty-seven Indigenous clients with or at high risk of CVD received three educational sessions delivered by a trained Indigenous nurse over a 4- to 7-week period. A tablet application, pill card and booklet supported the sessions. Primary outcomes were knowledge of CVD medications and health literacy practices, which were assessed before and after the programe. Following the program compared to before, mean medication knowledge scores were 3.3 to 6.1 times higher for the four included CVD medications. Participants were also more likely to refer to the customized pill card and booklet for information and answer questions from others regarding CVD. This customized education program was highly effective in increasing medication knowledge and health literacy practice among Indigenous people with CVD or at risk of CVD attending the program at an urban Indigenous health centre.",success
30302343,False,Journal Article;Review,,,,,,,,True,"Diabetes mellitus (DM) is the seventh leading cause of death in the United States and the leading cause of death in the U.S. American Indian/Alaskan Natives (AI/ANs), who comprise only 2% of the total population. The AI/AN population has a high prevalence of DM in adults aged 20 years or older and is developing DM at a younger age than the general U.S. DM is a major risk factor for cardiovascular disease (CVD), and mortality from CVD is higher in AI/ANs than the general population, as is the prevalence of stroke and 1-year poststroke mortality for both genders when compared to non-Hispanic whites. A genome-wide scan found a number of chromosome linkages in the AI/AN population that suggest that genetic factors may contribute to their high risk of DM and CVD. Importantly, studies also suggest that in addition to race/ethnicity, cultural norms and historic conditions play important roles in the prevalence of DM and CVD in this population. Therefore, multiple factors should be taken into consideration when establishing prevention programs to decrease the prevalence of obesity, diabetes, and CVD incidence among adults and children in the AI/AN population. Prevention programs should focus on behavioral risk factors and lifestyle changes like encouraging smoking cessation, healthy diet, and increased physical activity while taking into consideration cultural, economic, and geographic factors.",success
22533661,False,Journal Article;Review,,,,,,,,True,"Community hypertension (HTN) outreach seeks to improve public health by identifying HTN and cardiovascular disease (CVD) risks. In the 1980s, the National Heart, Lung, and Blood Institute (NHLBI) funded multiple positive community studies. Additionally, the Centers for Disease Control and Prevention's (CDC's) Racial and Ethnic Approaches to Community Health (REACH) program addresses CVD risks. In 1978, in Baltimore, MD, the Association of Black Cardiologists (ABC), organized barbershops and churches as HTN control centers, as in New Orleans, LA, since 1993, the Healthy Heart Community Prevention Project (HHCPP). Also, the NHLBI Community Health Workers and Promotores de Salud are beneficial. The American Society of Hypertension (ASH) Hypertension Community Outreach program provides free HTN and CVD screenings, digital BP monitors, multilingual and literacy-appropriate information, and videos. Contemporary major federal programs, such as the Million Hearts Initiative, are ongoing. Overall, the evidence-based Logic Model should enhance planning, implementation, and dissemination.",success
25211728,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"We evaluated cardiovascular disease (CVD) risk factors in American Indians/Alaska Natives (AI/ANs) with diabetes in the Special Diabetes Program for Indians Healthy Heart (SDPI-HH) Demonstration Project. Multidisciplinary teams implemented an intensive case management intervention among 30 health care programs serving 138 tribes. The project recruited 3373 participants, with and without current CVD, between 2006 and 2009. We examined data collected at baseline and 1 year later to determine whether improvements occurred in CVD risk factors and in Framingham coronary heart disease (CHD) risk scores, aspirin use, and smoking status. A1c levels decreased an average of 0.2% (P < .001). Systolic and diastolic blood pressure, low-density lipoprotein (LDL) cholesterol, and triglyceride levels decreased, with the largest significant reduction in LDL cholesterol (∆ = -5.29 mg/dL; P < .001). Average Framingham CHD risk scores also decreased significantly. Aspirin therapy increased significantly, and smoking decreased. Participants with more case management visits had significantly greater reductions in LDL cholesterol and A1c values. SDPI-HH successfully translated an intensive case management intervention. Creative retention strategies and an improved understanding of organizational challenges are needed for future Indian health translational efforts.",success
29508374,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Clinical decision-making may have a role in racial and ethnic disparities in healthcare but has not been evaluated systematically. The purpose of this study was to synthesize qualitative studies that explore various aspects of how a patient's African-American race or Hispanic ethnicity may factor into physician clinical decision-making. Using Ovid MEDLINE, Embase, and Cochrane Library, we identified 13 manuscripts that met inclusion criteria of usage of qualitative methods; addressed US physician clinical decision-making factors when caring for African-American, Hispanic, or Caucasian patients; and published between 2000 and 2017. We derived six fundamental themes that detail the role of patient race and ethnicity on physician decision-making, including importance of race, patient-level issues, system-level issues, bias and racism, patient values, and communication. In conclusion, a non-hierarchical system of intertwining themes influenced clinical decision-making among racial and ethnic minority patients. Future study should systematically intervene upon each theme in order to promote equitable clinical decision-making among diverse racial/ethnic patients.",success
31707940,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Background Race influences medical decision making, but its impact on advanced heart failure therapy allocation is unknown. We sought to determine whether patient race influences allocation of advanced heart failure therapies. Methods and Results Members of a national heart failure organization were randomized to clinical vignettes that varied by patient race (black or white man) and were blinded to study objectives. Participants (N=422) completed Likert scale surveys rating factors for advanced therapy allocation and think-aloud interviews (n=44). Survey results were analyzed by least absolute shrinkage and selection operator and multivariable regression to identify factors influencing advanced therapy allocation, including interactions with vignette race and participant demographics. Interviews were analyzed using grounded theory. Surveys revealed no differences in overall racial ratings for advanced therapies. Least absolute shrinkage and selection operator regression selected no interactions between vignette race and clinical factors as important in allocation. However, interactions between participants aged ≥40 years and black vignette negatively influenced heart transplant allocation modestly (-0.58; 95% CI, -1.15 to -0.0002), with adherence and social history the most influential factors. Interviews revealed sequential decision making: forming overall impression, identifying urgency, evaluating prior care appropriateness, anticipating challenges, and evaluating trust while making recommendations. Race influenced each step: avoiding discussing race, believing photographs may contribute to racial bias, believing the black man was sicker compared with the white man, developing greater concern for trust and adherence with the black man, and ultimately offering the white man transplantation and the black man ventricular assist device implantation. Conclusions Black race modestly influenced decision making for heart transplant, particularly during conversations. Because advanced therapy selection meetings are conversations rather than surveys, allocation may be vulnerable to racial bias.",success
25748764,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"This article reports on the prevalence and correlates of microaggressive experiences in health care settings reported by American Indian (AI) adults with type 2 diabetes mellitus (T2DM). This community-based participatory research project includes two AI reservation communities. Data were collected via in-person article-and-pencil survey interviews with 218 AI adults diagnosed with T2DM. Greater than one third of the sample reported experiencing a microaggression in interactions with their health providers. Reports of microaggressions were correlated with self-reported history of heart attack, worse depressive symptoms, and prior-year hospitalization. Depressive symptom ratings seemed to account for some of the association between microaggressions and hospitalization (but not history of heart attack) in multivariate models. Microaggressive experiences undermine the ideals of patient-centered care and in this study were correlated with worse mental and physical health reports for AIs living with a chronic disease. Providers should be cognizant of these subtle, often unconscious forms of discrimination.",success
22822416,False,Journal Article,,,,,,,,True,"The National Science Foundation and others conclude that institutional transformation is required to ensure equal opportunities for the participation and advancement of men and women in academic science, technology, engineering, mathematics, and medicine (STEMM). Such transformation requires changing the habitual attitudes and behaviors of faculty. Approaching implicit bias as a remediable habit, we present the theoretical basis and conceptual model underpinning an educational intervention to promote bias literacy among university faculty as a step toward institutional transformation regarding gender equity. We describe the development and implementation of a Bias Literacy Workshop in detail so others can replicate or adapt it to their setting. Of the 220 (167 faculty and 53 nonfaculty) attendees from the initial 17 departments/divisions offered this workshop, all 180 who completed a written evaluation found the workshop at least ""somewhat useful"" and 74% found it ""very useful."" Over 68% indicated increased knowledge of the workshop material. Of the 186 participants who wrote a commitment to engage in new activities to promote gender equity, 87% incorporated specific workshop content. Twenty-four participants were interviewed 4-6 months after attending the workshop; 75% of these not only demonstrated increased bias awareness, but described plans to change-or had actually changed-behaviors because of the workshop. Based on our sample of faculty from a Midwestern university, we conclude that at least one third of STEMM faculty who are invited will attend a 2.5-hr Bias Literacy Workshop, that nearly all will find it useful, and that most will complete a written commitment to promoting gender equity. These findings suggest that this educational intervention may effectively promote institutional change regarding gender equity.",success
27680316,False,Journal Article,,,,,,,,True,"Implicit white race preference has been associated with discrimination in the education, criminal justice, and health care systems and could impede the entry of African Americans into the medical profession, where they and other minorities remain underrepresented. Little is known about implicit racial bias in medical school admissions committees. To measure implicit racial bias, all 140 members of the Ohio State University College of Medicine (OSUCOM) admissions committee took the black-white implicit association test (IAT) prior to the 2012-2013 cycle. Results were collated by gender and student versus faculty status. To record their impressions of the impact of the IAT on the admissions process, members took a survey at the end of the cycle, which 100 (71%) completed. All groups (men, women, students, faculty) displayed significant levels of implicit white preference; men (d = 0.697) and faculty (d = 0.820) had the largest bias measures (P < .001). Most survey respondents (67%) thought the IAT might be helpful in reducing bias, 48% were conscious of their individual results when interviewing candidates in the next cycle, and 21% reported knowledge of their IAT results impacted their admissions decisions in the subsequent cycle. The class that matriculated following the IAT exercise was the most diverse in OSUCOM's history at that time. Future directions include preceding and following the IAT with more robust reflection and education on unconscious bias. The authors join others in calling for an examination of bias at all levels of academic medicine.",success
31097028,False,Journal Article;Systematic Review,,,,,,,,True,"Implicit biases are present in the general population and among professionals in various domains, where they can lead to discrimination. Many interventions are used to reduce implicit bias. However, uncertainties remain as to their effectiveness. We conducted a systematic review by searching ERIC, PUBMED and PSYCHINFO for peer-reviewed studies conducted on adults between May 2005 and April 2015, testing interventions designed to reduce implicit bias, with results measured using the Implicit Association Test (IAT) or sufficiently similar methods. 30 articles were identified as eligible. Some techniques, such as engaging with others' perspective, appear unfruitful, at least in short term implicit bias reduction, while other techniques, such as exposure to counterstereotypical exemplars, are more promising. Robust data is lacking for many of these interventions. Caution is thus advised when it comes to programs aiming at reducing biases. This does not weaken the case for implementing widespread structural and institutional changes that are multiply justified.",success
21752073,False,Journal Article,,,,,,,,True,"Non-conscious stereotyping and prejudice contribute to racial and ethnic disparities in health care. Contemporary training in cultural competence is insufficient to reduce these problems because even educated, culturally sensitive, egalitarian individuals can activate and use their biases without being aware they are doing so. However, these problems can be reduced by workshops and learning modules that focus on the psychology of non-conscious bias. THE PSYCHOLOGY OF NON-CONSCIOUS BIAS: Research in social psychology shows that over time stereotypes and prejudices become invisible to those who rely on them. Automatic categorisation of an individual as a member of a social group can unconsciously trigger the thoughts (stereotypes) and feelings (prejudices) associated with that group, even if these reactions are explicitly denied and rejected. This implies that, when activated, implicit negative attitudes and stereotypes shape how medical professionals evaluate and interact with minority group patients. This creates differential diagnosis and treatment, makes minority group patients uncomfortable and discourages them from seeking or complying with treatment. Cultural competence training involves teaching students to use race and ethnicity to diagnose and treat minority group patients, but to avoid stereotyping them by over-generalising cultural knowledge to individuals. However, the Culturally and Linguistically Appropriate Services (CLAS) standards do not specify how these goals should be accomplished and psychological research shows that common approaches like stereotype suppression are ineffective for reducing non-conscious bias. To effectively address bias in health care, training in cultural competence should incorporate research on the psychology of non-conscious stereotyping and prejudice. Workshops or other learning modules that help medical professionals learn about non-conscious processes can provide them with skills that reduce bias when they interact with minority group patients. Examples of such skills in action include automatically activating egalitarian goals, looking for common identities and counter-stereotypical information, and taking the perspective of the minority group patient.",success
30676559,False,Journal Article;Review,,,,,,,,True,"In November 2017, the American Heart Association published updates to its adult and pediatric Basic Life Support and Cardiopulmonary Resuscitation guidelines; one year later, it published updates to its Advanced Cardiovascular Life Support and Pediatric Advanced Life Support guidelines. This article reviews these updated guidelines and highlights the key changes and how to integrate them into practice.",success
31722559,False,Journal Article;Review,,,,,,,,True,"This 2019 focused update to the American Heart Association and American Red Cross first aid guidelines follows the completion of a systematic review of treatments for presyncope of vasovagal or orthostatic origin. This review was commissioned by the International Liaison Committee on Resuscitation and resulted in the development of an international summary statement of the International Liaison Committee on Resuscitation First Aid Task Force Consensus on Science With Treatment Recommendations. This focused update highlights the evidence supporting specific interventions for presyncope of orthostatic or vasovagal origin and recommends the use of physical counterpressure maneuvers. These maneuvers include the contraction of muscles of the body such as the legs, arms, abdomen, or neck, with the goal of elevating blood pressure and alleviating symptoms. Although lower-body counterpressure maneuvers are favored over upper-body counterpressure maneuvers, multiple methods can be beneficial, depending on the situation.",success
31724451,False,Journal Article;Review,,,,,,,,True,"This 2019 focused update to the American Heart Association neonatal resuscitation guidelines is based on 2 evidence reviews recently completed under the direction of the International Liaison Committee on Resuscitation Neonatal Life Support Task Force. The International Liaison Committee on Resuscitation Expert Systematic Reviewer and content experts performed comprehensive reviews of the scientific literature on the appropriate initial oxygen concentration for use during neonatal resuscitation in 2 groups: term and late-preterm newborns (≥35 weeks of gestation) and preterm newborns (<35 weeks of gestation). This article summarizes those evidence reviews and presents recommendations. The recommendations for neonatal resuscitation are as follows: In term and late-preterm newborns (≥35 weeks of gestation) receiving respiratory support at birth, the initial use of 21% oxygen is reasonable. One hundred percent oxygen should not be used to initiate resuscitation because it is associated with excess mortality. In preterm newborns (<35 weeks of gestation) receiving respiratory support at birth, it may be reasonable to begin with 21% to 30% oxygen and to base subsequent oxygen titration on oxygen saturation targets. These guidelines require no change in the Neonatal Resuscitation Algorithm-2015 Update.",success
31722543,False,"Journal Article;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"The International Liaison Committee on Resuscitation has initiated a continuous review of new, peer-reviewed, published cardiopulmonary resuscitation science. This is the third annual summary of the International Liaison Committee on Resuscitation International Consensus on Cardiopulmonary Resuscitation and Emergency Cardiovascular Care Science With Treatment Recommendations. It addresses the most recent published resuscitation evidence reviewed by International Liaison Committee on Resuscitation Task Force science experts. This summary addresses the role of cardiac arrest centers and dispatcher-assisted cardiopulmonary resuscitation, the role of extracorporeal cardiopulmonary resuscitation in adults and children, vasopressors in adults, advanced airway interventions in adults and children, targeted temperature management in children after cardiac arrest, initial oxygen concentration during resuscitation of newborns, and interventions for presyncope by first aid providers. Members from 6 International Liaison Committee on Resuscitation task forces have assessed, discussed, and debated the certainty of the evidence on the basis of the Grading of Recommendations, Assessment, Development, and Evaluation criteria, and their statements include consensus treatment recommendations. Insights into the deliberations of the task forces are provided in the Justification and Evidence to Decision Framework Highlights sections. The task forces also listed priority knowledge gaps for further research.",success
20598363,False,"Journal Article;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"Pre-eclampsia remains a leading cause of maternal and perinatal mortality and morbidity. It is a pregnancy-specific disease characterised by de-novo development of concurrent hypertension and proteinuria, sometimes progressing into a multiorgan cluster of varying clinical features. Poor early placentation is especially associated with early onset disease. Predisposing cardiovascular or metabolic risks for endothelial dysfunction, as part of an exaggerated systemic inflammatory response, might dominate in the origins of late onset pre-eclampsia. Because the multifactorial pathogenesis of different pre-eclampsia phenotypes has not been fully elucidated, prevention and prediction are still not possible, and symptomatic clinical management should be mainly directed to prevent maternal morbidity (eg, eclampsia) and mortality. Expectant management of women with early onset disease to improve perinatal outcome should not preclude timely delivery-the only definitive cure. Pre-eclampsia foretells raised rates of cardiovascular and metabolic disease in later life, which could be reason for subsequent lifestyle education and intervention.",success
16581405,False,"Journal Article;Research Support, Non-U.S. Gov't;Systematic Review",,,,,,,,True,"The reduction of maternal deaths is a key international development goal. Evidence-based health policies and programmes aiming to reduce maternal deaths need reliable and valid information. We undertook a systematic review to determine the distribution of causes of maternal deaths. We selected datasets using prespecified criteria, and recorded dataset characteristics, methodological features, and causes of maternal deaths. All analyses were restricted to datasets representative of populations. We analysed joint causes of maternal deaths from datasets reporting at least four major causes (haemorrhage, hypertensive disorders, sepsis, abortion, obstructed labour, ectopic pregnancy, embolism). We examined datasets reporting individual causes of death to investigate the heterogeneity due to methodological features and geographical region and the contribution of haemorrhage, hypertensive disorders, abortion, and sepsis as causes of maternal death at the country level. 34 datasets (35,197 maternal deaths) were included in the primary analysis. We recorded wide regional variation in the causes of maternal deaths. Haemorrhage was the leading cause of death in Africa (point estimate 33.9%, range 13.3-43.6; eight datasets, 4508 deaths) and in Asia (30.8%, 5.9-48.5; 11,16 089). In Latin America and the Caribbean, hypertensive disorders were responsible for the most deaths (25.7%, 7.9-52.4; ten, 11,777). Abortion deaths were the highest in Latin America and the Caribbean (12%), which can be as high as 30% of all deaths in some countries in this region. Deaths due to sepsis were higher in Africa (odds ratio 2.71), Asia (1.91), and Latin America and the Caribbean (2.06) than in developed countries. Haemorrhage and hypertensive disorders are major contributors to maternal deaths in developing countries. These data should inform evidence-based reproductive health-care policies and programmes at regional and national levels. Capacity-strengthening efforts to improve the quality of burden-of-disease studies will further validate future estimates.",success
18437143,False,Journal Article,,,,,,,,True,"Few studies have reported on population-level incidence of or trends in the hypertensive disorders of pregnancy, and none report on data through 2004. We describe population trends in the incidence rates of preeclampsia, eclampsia, and gestational hypertension in the United States for 1987-2004. We analyzed public-use data from the National Hospital Discharge Survey (NHDS), which has been conducted by the Centers for Disease Control and Prevention, National Center for Health Statistics since 1965. We calculated crude and age-adjusted incidence rates and estimated the risk associated with available demographic variables using Cox regression modeling. Rates of preeclampsia and gestational hypertension increased significantly (by 25 and 184%, respectively) over the study period; in contrast, the rate of eclampsia decreased by 22% (nonsignificant). Women under the age of 20 were at significantly greater risk for all three outcomes. Women in the south of the country were at significantly greater risk for preeclampsia and gestational hypertension when compared to those in the Northeast. The increase in gestational hypertension may be exaggerated because of the revised clinical guidelines published in the 1990s; these same revisions would likely have reduced diagnoses of preeclampsia. Therefore, our observation of a small but consistent increase in preeclampsia is a conservative indication of a true population-level change.",success
24201165,False,Journal Article,,,,,,,,True,"To estimate the contributions of biological aging, historical trends, and birth cohort effects on trends in pre-eclampsia in the United States. Population based retrospective study. National hospital discharge survey datasets, 1980-2010, United States. 120 million women admitted to hospital for delivery. Temporal changes in rates of mild and severe pre-eclampsia in relation to maternal age, year of delivery, and birth cohorts. Poisson regression as well as multilevel age-period-cohort models with adjustment for obesity and smoking were incorporated. The rate of pre-eclampsia was 3.4%. The age-period-cohort analysis showed a strong age effect, with women at the extremes of maternal age having the greatest risk of pre-eclampsia. In comparison with women delivering in 1980, those delivering in 2003 were at 6.7-fold (95% confidence interval 5.6-fold to 8.0-fold) increased risk of severe pre-eclampsia. Period effects declined after 2003. Trends for severe pre-eclampsia also showed a modest birth cohort effect, with women born in the 1970s at increased risk. Compared with women born in 1955, the risk ratio for women born in 1970 was 1.2 (95% confidence interval 1.1 to 1.3). Similar patterns were also evident for mild pre-eclampsia, although attenuated. Changes in the population prevalence of obesity and smoking were associated with period and cohort trends in pre-eclampsia but did not explain the trends. Rates of severe pre-eclampsia have been increasing in the United States and age-period-cohort effects all contribute to these trends. Although smoking and obesity have driven these trends, changes in the diagnostic criteria may have also contributed to the age-period-cohort effects. Health consequences of rising obesity rates in the United States underscore that efforts to reduce obesity may be beneficial to maternal and perinatal health.",success
28708975,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Preeclampsia is a leading cause of maternal morbidity and mortality and adverse neonatal outcomes. Little is known about the extent of the health and cost burden of preeclampsia in the United States. This study sought to quantify the annual epidemiological and health care cost burden of preeclampsia to both mothers and infants in the United States in 2012. We used epidemiological and econometric methods to assess the annual cost of preeclampsia in the United States using a combination of population-based and administrative data sets: the National Center for Health Statistics Vital Statistics on Births, the California Perinatal Quality Care Collaborative Databases, the US Health Care Cost and Utilization Project database, and a commercial claims data set. Preeclampsia increased the probability of an adverse event from 4.6% to 10.1% for mothers and from 7.8% to 15.4% for infants while lowering gestational age by 1.7 weeks (P < .001). Overall, the total cost burden of preeclampsia during the first 12 months after birth was $1.03 billion for mothers and $1.15 billion for infants. The cost burden per infant is dependent on gestational age, ranging from $150,000 at 26 weeks gestational age to $1311 at 36 weeks gestational age. In 2012, the cost of preeclampsia within the first 12 months of delivery was $2.18 billion in the United States ($1.03 billion for mothers and $1.15 billion for infants), and was disproportionately borne by births of low gestational age.",success
10645865,False,Journal Article,,,,,,,,True,"To study risk factors for pre-eclampsia in a large cohort of Latin American and Caribbean women. Retrospective cross-sectional study from the Perinatal Information System, the database of the Latin American Center for Perinatology and Human Development, Montevideo, Uruguay. Latin America and the Caribbean, 1985-1997. Population 878,680 pregnancies at 700 hospitals; of these 42,530 were complicated by pre-eclampsia and 1,872 by eclampsia. Crude and adjusted relative risks (RR) of risk factors for pre-eclampsia. Adjusted relative risks were obtained after adjustment for potential confounding factors through multiple logistic regression models based on the method of generalised estimating equations. The following risk factors were significantly associated with increased risk of pre-eclampsia: nulliparity (RR 2 x 38; 95% CI 2 x 28-2 x 49); multiple pregnancy (RR 2 x 10; 95% CI 1 x 90-2 x 32); history of chronic hypertension (RR 1 x 99; 95% CI 1 x 78-2 x 22); gestational diabetes mellitus (RR 1 x 93; 95% CI 1 x 66-2 x 25); maternal age > or = 35 years (RR 1 x 67; 95% CI 1 x 58-1 x 77); fetal malformation (RR 1 x 26; 95% CI 1 x 16-1 x 37); and mother not living with infant's father (RR 1 x 21; 95% CI 1 x 15-1 x 26). Pre-eclampsia risk increased according to pre-pregnancy body mass index (BMI). In comparison with women with a normal pre-pregnancy BMI (19 x 8 to 26 x 0), the RR estimates were 1 x 57 (95% CI 1 x 49-1 x 64) and 2 x 81 95% CI 2 x 69-2 x 94), respectively, for overweight women (pre-pregnancy BMI = 26 x 1 to 29 x 0) and obese women (pre-pregnancy BMI > 29 x 0). Cigarette smoking during pregnancy and a pre-pregnancy BMI < 19 x 8 were significant protective factors against the development of pre-eclampsia. The pattern of risk factors among nulliparous and multiparous women was quite similar. Risk factors for pre-eclampsia observed among Latin American and Caribbean women are similar to those found among North American and European women.",success
27094586,False,"Journal Article;Meta-Analysis;Research Support, Non-U.S. Gov't;Systematic Review",,,,,,,,True,"To develop a practical evidence based list of clinical risk factors that can be assessed by a clinician at ≤ 16 weeks' gestation to estimate a woman's risk of pre-eclampsia. Systematic review and meta-analysis of cohort studies. PubMed and Embase databases, 2000-15. Cohort studies with ≥ 1000 participants that evaluated the risk of pre-eclampsia in relation to a common and generally accepted clinical risk factor assessed at ≤ 16 weeks' gestation. Two independent reviewers extracted data from included studies. A pooled event rate and pooled relative risk for pre-eclampsia were calculated for each of 14 risk factors. There were 25,356,688 pregnancies among 92 studies. The pooled relative risk for each risk factor significantly exceeded 1.0, except for prior intrauterine growth restriction. Women with antiphospholipid antibody syndrome had the highest pooled rate of pre-eclampsia (17.3%, 95% confidence interval 6.8% to 31.4%). Those with prior pre-eclampsia had the greatest pooled relative risk (8.4, 7.1 to 9.9). Chronic hypertension ranked second, both in terms of its pooled rate (16.0%, 12.6% to 19.7%) and pooled relative risk (5.1, 4.0 to 6.5) of pre-eclampsia. Pregestational diabetes (pooled rate 11.0%, 8.4% to 13.8%; pooled relative risk 3.7, 3.1 to 4.3), prepregnancy body mass index (BMI) >30 (7.1%, 6.1% to 8.2%; 2.8, 2.6 to 3.1), and use of assisted reproductive technology (6.2%, 4.7% to 7.9%; 1.8, 1.6 to 2.1) were other prominent risk factors. There are several practical clinical risk factors that, either alone or in combination, might identify women in early pregnancy who are at ""high risk"" of pre-eclampsia. These data can inform the generation of a clinical prediction model for pre-eclampsia and the use of aspirin prophylaxis in pregnancy.",success
15036703,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"To determine whether gestational diabetes mellitus (GDM) increases the risk for preeclampsia independent of other risk factors. The association between GDM and preeclampsia was analyzed in a population of women who had given birth to singletons registered in Swedish Medical Birth Register from 1992 through 1996 (n=430,852). GDM occurred in 0.8% and preeclampsia in 2.9% of all pregnancies. The rate of preeclampsia was higher in the GDM than in the non-GDM group (6.1% versus 2.8%). High age, nullipara, chronic hypertension, kidney disease, and high body mass index (BMI) were all independently associated with increased risk for preeclampsia. Smoking was associated with decreased risk. Adjusted odds ratio for GDM as a risk factor for preeclampsia was 1.61 (95% confidence interval (CI) 1.39-1.86) when prepregnancy BMI, which was a true confounder, was included in the last step of the multiple logistic regression analysis. There is an independent and significant association between GDM and preeclampsia. Obesity is a major confounding factor but could not explain the total excess risk.",success
20688887,False,"Journal Article;Meta-Analysis;Research Support, N.I.H., Extramural;Systematic Review",,,,,,,,True,"Studies of the impact of systemic lupus erythematosus (SLE) and its pregnancy complications have yielded conflicting results. Major limitations of these studies relate to their small numbers of patients and retrospective designs. The aim of this study was to perform a systematic literature review of pregnancy outcomes in women with SLE and a meta-analysis of the association of lupus nephritis with adverse pregnancy outcomes. We searched electronic databases from 1980 to 2009 and reviewed papers with validity criteria. Random-effects analytical methods were used to evaluate pregnancy complications rates. Thirty-seven studies with 1842 patients and 2751 pregnancies were included. Maternal complications included lupus flare (25.6%), hypertension (16.3%), nephritis (16.1%), pre-eclampsia (7.6%), and eclampsia (0.8%). The induced abortion rate was 5.9%, and when excluded, fetal complications included spontaneous abortion (16.0%), stillbirth (3.6%), neonatal deaths (2.5%), and intrauterine growth retardation (12.7%). The unsuccessful pregnancy rate was 23.4%, and the premature birth rate was 39.4%. Meta-regression analysis showed statistically significant positive associations between premature birth rate and active nephritis and increased hypertension rates in subjects with active nephritis or a history of nephritis. History of nephritis was also associated with pre-eclampsia. Anti-phospholipid antibodies were associated with hypertension, premature birth, and an increased rate of induced abortion. In patients with SLE, both lupus nephritis and anti-phospholipid antibodies increase the risks for maternal hypertension and premature births. The presented evidence further supports timing of pregnancy relative to SLE activity and multispecialty care of these patients.",success
26487769,False,"Journal Article;Meta-Analysis;Research Support, Non-U.S. Gov't;Systematic Review",,,,,,,,True,"We undertook a systematic review and meta-analysis of published cohort studies and case-control studies to estimate (1) the risk of pregnancy complications among patients with CKD versus those without CKD and (2) the risk of CKD progression among pregnant patients versus nonpregnant controls with CKD. We searched electronic databases for studies published between 1946 and 2014, and we reviewed articles using validity criteria. Random-effects analytical methods were used. Twenty-three studies (14 with data for adverse pregnancy outcomes and 9 for renal outcomes) with 506,340 pregnancies were included. Pregnancy with CKD had greater odds of preeclampsia (odds ratio [OR], 10.36; 95% confidence interval [95% CI], 6.28 to 17.09), premature delivery (OR, 5.72; 95% CI, 3.26 to 10.03), small for gestational age/low birth weight (OR, 4.85; 95% CI, 3.03 to 7.76), cesarean section (OR, 2.67; 95% CI, 2.01 to 3.54), and failure of pregnancy (OR, 1.80; 95% CI, 1.03 to 3.13). Subgroup analysis showed that odds of preeclampsia (P<0.01) and premature delivery (P<0.01) were higher in women with nondiabetic nephropathy compared with diabetic nephropathy, and the odds of preeclampsia (P=0.01) and premature delivery (P<0.01) were higher in women with macroproteinuria compared with microproteinuria. The median for follow-up time for renal events was 5 years (interquartile range, 5-14.7 years). There were no significant differences in the occurrence of renal events between CKD pregnant women and those without pregnancy (OR, 0.96; 95% CI, 0.69 to 1.35). Subgroup analysis showed that publication year, sample size, follow-up years, type of primary disease, CKD classification, level of serum creatinine at baseline, proteinuria, and level of systolic BP did not modify the renal outcomes. The risks of adverse maternal and fetal outcomes in pregnancy are higher for women with CKD versus pregnant women without CKD. However, pregnancy was not a risk factor for progression of renal disease in women with CKD before pregnancy.",success
3768285,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Our report concerns the incidences of pre-eclampsia and eclampsia in 147 sisters, 248 daughters, 74 granddaughters, and 131 daughters-in-law of women who have had eclampsia. The disorder is highly heritable. We have analysed the data in two ways, firstly, as a single gene condition and, secondly, as a multifactorial condition. The observed incidences fit closely with the single gene model with frequency of the putative gene being 0.25. When Falconer's method of estimating heritabilities of discrete characters is used, estimates of 120% (sisters), 88% (daughters), and 105% (granddaughters)--none significantly different from 100%-are obtained. Insofar as possible, our definition of pre-eclampsia corresponds with EPH in the descriptive classification of the Organisation Gestosis and to 'severe pre-eclampsia' in Nelson's classification. The women were delivered in many different hospitals, however, and many records fail to provide all of the essential information.",success
8513325,False,"Comparative Study;Journal Article;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Pregnancy-induced hypertension (PIH) is a heterogeneous disorder which complicates 5-7% of all pregnancies and remains a leading cause of maternal, fetal and neonatal morbidity and mortality. Severe preeclampsia is the most distinctive and life-threatening form; a multi-system disorder more common in first pregnancies, it is characterized by high blood pressure and proteinuria. In a series of Caucasian women with pregnancy-induced hypertension, we have observed a significant association of preeclampsia with a molecular variant of angiotensinogen, T235, found previously to be associated with essential hypertension. This finding is corroborated in a sample ascertained in Japan. Together, these observations support a new pathophysiological interpretation of preeclampsia and of its relation to some forms of essential hypertension.",success
21429808,False,Journal Article;Review,,,,,,,,True,"Hypertension is the most frequent medical complication occurring during pregnancy. In this chapter, we aim to address the genetic contribution to these disorders, with specific focus on pre-eclampsia. The pathogenic mechanisms underlying pre-eclampsia remain to be elucidated; however, immune maladaptation, inadequate placental development and trophoblast invasion, placental ischaemia, oxidative stress and thrombosis are all thought to represent key factors in the development of disease. Furthermore, all of these components have genetic factors that may be involved in the pathogenic changes occurring. The familial nature of pre-eclampsia has been known for many years and, as such, extensive genetic research has been carried out in this area using strategies that include candidate gene studies and linkage analysis. Interactions between fetal and maternal genotypes, the effect of environmental factors, and epistasis will also be considered.",success
18192844,True,Journal Article;Multicenter Study,,,,,,,,True,"To determine whether outcomes differed for women with pre-eclampsia according to the presence of proteinuria and whether non-proteinuric pre-eclampsia is similar to gestational hypertension. From 1987 to 2005, at three hospitals in Sydney, Australia, women referred to the obstetric medicine team were recruited. Outcomes for three groups were compared: proteinuric pre-eclampsia, non-proteinuric pre-eclampsia and gestational hypertension. Women with proteinuric pre-eclampsia were more likely to have severe hypertension (39 versus 30%, P = 0.003), deliver preterm infants (39 versus 30%, P = 0.007) and had a higher perinatal mortality rate (25.2 versus 5.7 per 1000, P = 0.02) than those with non-proteinuric pre-eclampsia, who were more likely to have thrombocytopenia and liver disease. Women with non-proteinuric pre-eclampsia were more likely to have multiple pregnancies (3.9 versus 9.9%, P < 0.001), experience severe hypertension (8.9 versus 29.7%, P < 0.001), and deliver preterm infants (11.3 versus 30.2%, P < 0.001) who were small for gestational age (12.7 versus 20.9%, P < 0.001) than those with gestational hypertension. This study highlights differences between non-proteinuric pre-eclampsia and gestational hypertension. The subclassification of 'non-proteinuric pre-eclampsia' should be added to existing classification systems to alert clinicians to potential risks.",success
26241418,False,Journal Article,,,,,,,,True,"Hypertensive disorders of pregnancy remain among the leading causes of maternal morbidity and mortality. The onset of headaches in patients with hypertensive disorders of pregnancy has been considered as a premonitory symptom for eclampsia and other adverse maternal outcomes. Headaches are very common symptoms during pregnancy and the postpartum period with a reported incidence of 39%; however, headache is absent in 30-50% of women before the onset of eclampsia and is a poor predictor of eclampsia and adverse maternal outcomes. If included in the definition of cerebral or visual disturbances, headache may be considered a symptom of preeclampsia, a diagnostic feature of preeclampsia with severe features, a premonitory symptom of eclampsia, and an indication for delivery. Inclusion of this nonspecific symptom in the diagnosis and management of hypertensive disorders of pregnancy in the absence of an evidence basis may lead to unintended consequences including excessive testing, visits to outpatient offices or emergency departments, additional hospitalization, and iatrogenic preterm delivery without proven benefit. If a cerebral disturbance such as severe or persistent headache presents for the first time during pregnancy or postpartum, an evaluation should be performed that considers a broad differential diagnosis, including but not limited to hypertensive disorders of pregnancy, and the diagnostic evaluation is similar to that in nonpregnant adults. This commentary draws attention to the implications of considering the cerebral disturbance of headache as a symptom that portends adverse pregnancy outcome in the current recommendations for diagnosing and managing hypertensive disorders of pregnancy.",success
21355860,False,Journal Article;Meta-Analysis;Systematic Review,,,,,,,,True,"Maternal symptoms such as severe headache, nausea and vomiting, visual disturbances and epigastric pain have been associated with complications in women with preeclampsia. To determine the accuracy of maternal symptoms in predicting complications in women with preeclampsia by systematic review. We searched MEDLINE (1951-2010), EMBASE (1980-2010), the Cochrane Library (2009) and the MEDION database. Studies which evaluated the accuracy of symptoms in women with preeclampsia for predicting complications were selected in a two-stage process. Information was extracted by two independent reviewers. We summarized accuracy with a bivariate model estimating sensitivity, specificity and area under the curve. Six primary articles with 2573 women were included. The area under the curve for predicting complications for headache, epigastric pain and visual disturbances was 0.58 (95%CI 0.24-0.86), 0.70 (95%CI 0.30-0.93) and 0.74 (95%CI 0.33-0.94). The sensitivity and specificity of the symptoms in predicting adverse maternal outcomes were respectively as follows: headache 0.54 (95%CI 0.27-0.79) and 0.59 (95%CI 0.38-0.76); epigastric pain 0.34 (95%CI 0.22-0.5) and 0.83 (95%CI 0.76-0.89); visual disturbances 0.27 (95%CI 0.07-0.65) and 0.81 (95%CI 0.71, 0.88); nausea and vomiting 0.24 (95%CI 0.21, 0.27) and 0.87 (95%CI 0.85, 0.89). The presence of symptoms is more useful in predicting complications in preeclampsia compared to their absence in excluding adverse events.",success
21185591,True,"Clinical Trial;Journal Article;Multicenter Study;Research Support, Non-U.S. Gov't;Validation Study",,,,,,,,True,"Pre-eclampsia is a leading cause of maternal deaths. These deaths mainly result from eclampsia, uncontrolled hypertension, or systemic inflammation. We developed and validated the fullPIERS model with the aim of identifying the risk of fatal or life-threatening complications in women with pre-eclampsia within 48 h of hospital admission for the disorder. We developed and internally validated the fullPIERS model in a prospective, multicentre study in women who were admitted to tertiary obstetric centres with pre-eclampsia or who developed pre-eclampsia after admission. The outcome of interest was maternal mortality or other serious complications of pre-eclampsia. Routinely reported and informative variables were included in a stepwise backward elimination regression model to predict the adverse maternal outcome. We assessed performance using the area under the curve (AUC) of the receiver operating characteristic (ROC). Standard bootstrapping techniques were used to assess potential overfitting. 261 of 2023 women with pre-eclampsia had adverse outcomes at any time after hospital admission (106 [5%] within 48 h of admission). Predictors of adverse maternal outcome included gestational age, chest pain or dyspnoea, oxygen saturation, platelet count, and creatinine and aspartate transaminase concentrations. The fullPIERS model predicted adverse maternal outcomes within 48 h of study eligibility (AUC ROC 0·88, 95% CI 0·84-0·92). There was no significant overfitting. fullPIERS performed well (AUC ROC >0·7) up to 7 days after eligibility. The fullPIERS model identifies women at increased risk of adverse outcomes up to 7 days before complications arise and can thereby modify direct patient care (eg, timing of delivery, place of care), improve the design of clinical trials, and inform biomedical investigations related to pre-eclampsia. Canadian Institutes of Health Research; UNDP/UNFPA/WHO/World Bank Special Programme of Research, Development, and Research Training in Human Reproduction; Preeclampsia Foundation; International Federation of Obstetricians and Gynecologists; Michael Smith Foundation for Health Research; and Child and Family Research Institute.",success
22777026,False,"Journal Article;Meta-Analysis;Research Support, Non-U.S. Gov't;Systematic Review",,,,,,,,True,"To determine the diagnostic accuracy of two ""spot urine"" tests for significant proteinuria or adverse pregnancy outcome in pregnant women with suspected pre-eclampsia. Systematic review and meta-analysis. Searches of electronic databases 1980 to January 2011, reference list checking, hand searching of journals, and contact with experts. Diagnostic studies, in pregnant women with hypertension, that compared the urinary spot protein to creatinine ratio or albumin to creatinine ratio with urinary protein excretion over 24 hours or adverse pregnancy outcome. Study characteristics, design, and methodological and reporting quality were objectively assessed. Study results relating to diagnostic accuracy were extracted and synthesised using multivariate random effects meta-analysis methods. Twenty studies, testing 2978 women (pregnancies), were included. Thirteen studies examining protein to creatinine ratio for the detection of significant proteinuria were included in the multivariate analysis. Threshold values for protein to creatinine ratio ranged between 0.13 and 0.5, with estimates of sensitivity ranging from 0.65 to 0.89 and estimates of specificity from 0.63 to 0.87; the area under the summary receiver operating characteristics curve was 0.69. On average, across all studies, the optimum threshold (that optimises sensitivity and specificity combined) seems to be between 0.30 and 0.35 inclusive. However, no threshold gave a summary estimate above 80% for both sensitivity and specificity, and considerable heterogeneity existed in diagnostic accuracy across studies at most thresholds. No studies looked at protein to creatinine ratio and adverse pregnancy outcome. For albumin to creatinine ratio, meta-analysis was not possible. Results from a single study suggested that the most predictive result, for significant proteinuria, was with the DCA 2000 quantitative analyser (>2 mg/mmol) with a summary sensitivity of 0.94 (95% confidence interval 0.86 to 0.98) and a specificity of 0.94 (0.87 to 0.98). In a single study of adverse pregnancy outcome, results for perinatal death were a sensitivity of 0.82 (0.48 to 0.98) and a specificity of 0.59 (0.51 to 0.67). The maternal ""spot urine"" estimate of protein to creatinine ratio shows promising diagnostic value for significant proteinuria in suspected pre-eclampsia. The existing evidence is not, however, sufficient to determine how protein to creatinine ratio should be used in clinical practice, owing to the heterogeneity in test accuracy and prevalence across studies. Insufficient evidence is available on the use of albumin to creatinine ratio in this area. Insufficient evidence exists for either test to predict adverse pregnancy outcome.",success
15369647,False,Comparative Study;Journal Article,,,,,,,,True,"To determine prospectively in hypertensive pregnant women 1) the accuracy of dipstick testing for proteinuria using automated urinalysis, 2) factors that might affect such accuracy, and 3) the potential impact of automated dipstick testing on the accuracy of diagnosis of preeclampsia according to acceptance of proteinuria at either 1 + or 2 + level. Prospective study. Antenatal day assessment unit and antenatal ward of St George Hospital, a teaching hospital in Sydney, Australia. 170 hypertensive pregnant women attending as outpatients or inpatients. 503 midstream urine samples were collected prospectively on separate occasions from 170 women. Full urinalysis was recorded using the Bayer Clinitek 50 automated urinalysis device and Multistix 10SG urinalysis strips (Bayer Diagnostics, Victoria, Australia). Each MSU was analysed for spot protein/creatinine ratio and also for culture and sensitivity if symptoms of a urinary tract infection were present or dipstick included positive nitrites. Urinalysis protein results were compared with spot urinary protein/creatinine ratio (previously shown to correlate with 24-hr urine protein excretion) to determine the accuracy of urinalysis. True proteinuria was defined as a ratio >/= 30 mg protein/mmol creatinine. False positive dipstick tests ranged from 7% at 3 + level to 71% at 1 + proteinuria level while false negative rates were 7% for ""nil"" and 14% for ""trace"" proteinuria, 9% overall. Accepting the dipstick proteinuria result at face value led to an incorrect diagnosis of preeclampsia or gestational hypertension in 85 (50%) women. Dipstick proteinuria was significantly more likely to be correct (true positive/true negative) if diastolic blood pressure was elevated > 90 mmHg (p = 0.032) and in the absence of ketonuria (p = 0.001). Accepting a diagnosis of preeclampsia on the basis of de novo hypertension and dipstick testing alone was accurate less often (70%) when > 1 + was used as a discriminant value than at the 82% of presentations when > 2 + was used (p = 0.001). Accepting ""nil"" or ""trace"" proteinuria as a true negative dipstick results fails to identify approximately 1 in 11 hypertensive pregnant women with true proteinuria, a false negative rate that may be acceptable provided these women are subject to ongoing vigilant clinical review. Even with automated urinalysis the false positive rate for dipstick levels >/= 1 + is very high, particularly in the presence of ketonuria and relying on this alone to diagnose preeclampsia leads to significant errors in diagnosis. Accepting >/= 2 + dipstick proteinuria improves overall diagnostic accuracy for preeclampsia at the expense of a higher false negative rate. This study emphasizes the need to confirm dipstick proteinuria with a further test such as a spot urine protein/creatinine ratio in all hypertensive pregnant women, particularly in research studies.",success
10453825,False,Journal Article,,,,,,,,True,"To determine: 1. whether an alternative definition of gestational hypertension and pre-eclampsia stratifies women according to their risk of maternal and fetal complications; 2. whether pregnancy outcome in women with gestational hypertension differs in the presence or absence of '+' proteinuria; and 3. whether a blood pressure rise of > or = 30/15 mmHg during pregnancy is associated with adverse outcome in women who remain normotensive. Prospective, nested case-control study. Community based. Healthy, nulliparous women (n = 1496). Women recruited into a study investigating serum markers predictive of pre-eclampsia were classified as having gestational hypertension (systolic blood pressure > or = 140 mmHg with a rise of > or = 30 mmHg and/or diastolic blood pressure > or = 90 mmHg with a rise of > or = 15 mmHg) or pre-eclampsia (gestational hypertension plus proteinuria > or = 2+on dipstick or > 0.3 g/24 h). Maternal and fetal complications in gestational hypertension or pre-eclampsia were compared with a control group of 223 randomly selected normotensive women. The main outcome measures were severe maternal disease, preterm birth and small for gestational age infant. A stepwise increase in adverse maternal and fetal outcomes occurred in gestational hypertension (n = 117, 7.8%) and pre-eclampsia (n = 71, 4.8%). Severe maternal disease developed in 26.5% (21.4% severe hypertension alone, 5.1% multisystem disease) of women with gestational hypertension and 63.4% (21.1% severe hypertension alone, 42.3% multisystem disease) of women with pre-eclampsia (OR 4.8; 95% CI 2.4-9.5). Preterm birth and small for gestational age infants were more frequent in gestational hypertension (OR 1.7; 95% CI 0.5-5.4, and OR 2.0; 95% CI 1.0-3.7, respectively) and pre-eclampsia (OR 14.6; 95% CI 5.8-37.8, and OR 2.6; 95% CI 1.2-5.3) than in the normotensive group. Among women with gestational hypertension severe maternal disease was more common in women with '+' proteinuria (41.7%) than in those with no proteinuria (15.9%): OR 3.8; 95% CI 1.5-9.8. Pregnancies were uncomplicated in the 27% of normotensive women who had a rise of > or = 30 mmHg systolic blood pressure and/or > or = 15 mmHg rise in diastolic blood pressure. In the nulliparous population studied our definition of gestational hypertension and pre-eclampsia identified women at increasing risk of maternal and fetal complications. In gestational hypertension, the presence of proteinuria '+' was associated with a 3.8-fold increase in severe maternal disease. Normotensive women who have a rise in blood pressure > or = 30/15 mmHg had uncomplicated pregnancies.",success
28697093,False,Journal Article,,,,,,,,True,"Complications arising from hypertensive disorders of pregnancy are among the leading causes of preventable severe maternal morbidity and mortality. Timely and appropriate treatment has the potential to significantly reduce hypertension-related complications. To assist health care providers in achieving this goal, this patient safety bundle provides guidance to coordinate and standardize the care provided to women with severe hypertension during pregnancy and the postpartum period. This is one of several patient safety bundles developed by multidisciplinary work groups of the National Partnership for Maternal Safety under the guidance of the Council on Patient Safety in Women's Health Care. These safety bundles outline critical clinical practices that should be implemented in every maternity care setting. Similar to other bundles that have been developed and promoted by the Partnership, the hypertension safety bundle is organized into four domains: Readiness, Recognition and Prevention, Response, and Reporting and Systems Learning. Although the bundle components may be adapted to meet the resources available in individual facilities, standardization within an institution is strongly encouraged. This commentary provides information to assist with bundle implementation.",success
22036739,False,Journal Article;Review,,,,,,,,True,"The focus of this article is to review and challenge some current concepts surrounding the diagnosis and management of pre-eclampsia as well as considering where our management might head in the future. Pre-eclampsia is a syndrome defined by the new onset of hypertension in the 2nd half of pregnancy that is generally, but not always, accompanied by proteinuria. Whilst in recent times our understanding and management of this condition have improved there are some areas where evidence and opinions differ. In this review we will discuss the diagnosis of pre-eclampsia and the concept of the 'atypical' presentation. We will outline how to identify those women with pre-eclampsia who will have a poorer pregnancy outcome. We will address the question of when to deliver and how to treat if we decide to prolong the pregnancy. Finally we acknowledge that pre-eclampsia is more than a disorder of pregnancy and has lifelong implications for the mother and infant.",success
19019323,False,Journal Article;Review,,,,,,,,True,"Preeclampsia, eclampsia, and hemolysis, elevated liver enzymes, and low platelets syndrome are major obstetric disorders that are associated with substantial maternal and perinatal morbidities. As a result, it is important that clinicians make timely and accurate diagnoses to prevent adverse maternal and perinatal outcomes associated with these syndromes. In general, most women will have a classic presentation of preeclampsia (hypertension and proteinuria) at > 20 weeks of gestation and/or < 48 hours after delivery. However, recent studies have suggested that some women will experience preeclampsia without > or = 1 of these classic findings and/or outside of these time periods. Atypical cases are those that develop at < 20 weeks of gestation and > 48 hours after delivery and that have some of the signs and symptoms of preeclampsia without the usual hypertension or proteinuria. The purpose of this review was to increase awareness of the nonclassic and atypical features of preeclampsia-eclampsia. In addition, a stepwise approach toward diagnosis and treatment of patients with these atypical features is described.",success
19930427,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"1. The presence of proteinuria is not essential to the diagnosis of pre-eclampsia under many diagnostic consensus statements. The aim of the present study was to assess maternal and perinatal outcomes after proteinuric pre-eclampsia compared with other non-proteinuric disease presentations. 2. An individual patient data review (n = 670) was undertaken for 2003-2006 at a tertiary referral centre in Sydney (NSW, Australia). Women were diagnosed in accordance with the Australasian Society for the Study of Hypertension in Pregnancy Consensus Statement. Data were analysed with the Chi-squared test, t-tests and non-parametric tests. Statistical significance was set at P < 0.05. 3. The proteinuric cohort had higher systolic and diastolic blood pressure recordings than the non-proteinuric cohort (160/102 and 149/94 mmHg, respectively; P < 0.001), and were also administered magnesium sulphate more frequently (44 vs 22%, respectively; P < 0.001), delivered at earlier gestation (37 vs 38 weeks, respectively; P < 0.001), required operative delivery more frequently (63 vs 48%, respectively; P < 0.001) and received more antihypertensive medications during the antenatal period (72 vs 57%, respectively; P < 0.001). Acute renal failure and acute pulmonary oedema were rare. Four cases of eclampsia all occurred in non-proteinuric women. The perinatal mortality rate was lower for the offspring of women with proteinuric pre-eclampsia compared with offspring of non-proteinuric women (13/1000 and 31/1000, respectively; P = 0.006). 4. The results of the present study indicate that the presence of proteinuria denotes a group of women who have higher antenatal blood pressure, who deliver at earlier gestation and require operative delivery more commonly, although it is not an indicator of other markers of maternal morbidity or perinatal mortality.",success
21266269,False,"Journal Article;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"Preeclampsia is a multi-organ syndrome of pregnancy, defined by the new onset of hypertension and proteinuria after 20 weeks' gestation. This working definition ignores the variable multi-organ involvement of a syndrome that can include seizures in the absence of hypertension, or fulminating hepatic necrosis in the absence of proteinuria. These disparate clinical features are akin to an accelerated metabolic syndrome with widespread maternal endothelial dysfunction in the presence of a relatively underperfused placenta. Delivery of the placenta remains the only cure, but years after a pregnancy complicated by preeclampsia, women are at increased risk of chronic hypertension, diabetes mellitus, ischemic heart disease, cerebrovascular disease, kidney disease, thromboembolism, hypothyroidism, and even impaired memory. This article describes how pregnancy propels vulnerable women toward preeclampsia and how a brief, usually single, episode of this acute pregnancy syndrome defines those vulnerable to chronic disease in later life.",success
15519429,False,Journal Article;Review,,,,,,,,True,"Pregnancies complicated by hemolysis, elevated liver enzymes, and low platelets (HELLP) syndrome require a well-formulated management plan. The development of this syndrome after 34 weeks' gestation or with documentation of maternal or fetal compromise is an indication for delivery. Acute fatty liver of pregnancy, hemolytic uremic syndrome, and thrombotic thrombocytopenic purpura may present with signs, symptoms, and laboratory abnormalities that may be confused with HELLP syndrome. Thorough investigation is warranted because of the differences in proper management among these various complications of pregnancy. Expectant management in patients with HELLP syndrome remote from term and the use of corticosteroids to improve postpartum maternal outcome remain experimental.",success
7778647,False,Case Reports;Journal Article,,,,,,,,True,"The syndrome of hemolysis, elevated liver enzymes, and low platelet count (HELLP) was first described by Weinstein in 1982 and is generally thought to represent a variant of the preeclampsia-eclampsia syndrome. As with other severe manifestations of preeclampsia-eclampsia, epigastric pain and liver tenderness are commonly recognized presenting symptoms of this syndrome, but an underappreciated presenting symptom is generalized malaise or symptoms similar to a flulike syndrome. Two case examples, a review of one private hospital's recent cases, and data contained in the literature are presented to stress the importance of malaise as a presenting complaint during late pregnancy, with recommendations for screening these patients.",success
19464507,False,Journal Article;Review,,,,,,,,True,"Pre-eclampsia is mainly responsible for the world's large maternal mortality rates, mostly due to acute cerebral complications. This review provides insight into the pathogenesis of the neurologic complications of hypertensive disease in pregnancy. In addition, practical relevance for clinical care is highlighted. Pertaining to pregnancy, the blood pressure level at which cerebral autoregulation operates and possible deregulation occurs is unknown, but is likely to be variable. From clinical observation, eclampsia may occur despite a mild clinical picture and before the development of hypertension or proteinuria. Furthermore, failure of cerebrovascular autoregulatory mechanisms in response to either an acute and/or relatively large blood pressure increase may be more important than the absolute blood pressure value. It may be the acuity of the blood pressure rise in the setting of endothelial dysfunction that interrupts the delicate balance between capillary and cellular perfusion pressures that leads to the neurological complications of pre-eclampsia.",success
15684172,False,Comparative Study;Journal Article;Review,,,,,,,,True,"The pathogenesis of eclamptic convulsions remains unknown. Cerebral imaging suggests that cerebral abnormalities in eclampsia (mostly vasogenic edema) are similar to those found in hypertensive encephalopathy. However, cerebral imaging is not necessary for the diagnosis or management of most women with eclampsia. The onset of eclamptic convulsions can be antepartum (38-53%), intrapartum (18-36%), or postpartum (11-44%). Recent data reveal an increase in the proportion of women who develop eclampsia beyond 48 hours after delivery. Other than early detection of preeclampsia, there are no reliable tests or symptoms for predicting the development of eclampsia. In developed countries, the majority of cases reported in recent series are considered unpreventable. Magnesium sulfate is the drug of choice for reducing the rate of eclampsia developing intrapartum and immediately postpartum. There are 4 large randomized trials comparing magnesium sulfate with no treatment or placebo in patients with severe preeclampsia. The rate of eclampsia was significantly lower in those assigned to magnesium sulfate (0.6% versus 2.0%, relative risk 0.39, 95% confidence interval 0.28-0.55). Thus, the number of women needed to treat to prevent one case of eclampsia is 71. Magnesium sulfate is the drug of choice to prevent recurrent convulsions in eclampsia. The development of eclampsia is associated with increased risk of adverse outcome for both mother and fetus, particularly in the developing nations. Pregnancies complicated by eclampsia require a well-formulated management plan. Women with a history of eclampsia are at increased risk of eclampsia (1-2%) and preeclampsia (22-35%) in subsequent pregnancies. Recommendations for diagnosis, prevention, management, and counseling of these women are provided based on results of recent studies and my own clinical experience.",success
22015866,False,Journal Article,,,,,,,,True,"To characterize the symptoms that immediately precede eclamptic seizures. We did a prospective observational study of all women admitted to a single center in Tanzania between May 1, 2007 and April 30, 2008 who had an eclamptic seizure. During their admission they were asked a uniform set of questions related to symptoms preceding the seizure. There were 3,267 deliveries and 46 cases of eclampsia (1.4%). Neurologic symptoms (headache [80%] with or without visual disturbance [45%]) were the most common prodrome symptoms, regardless of degree of hypertension or whether the seizure occurred antepartum or postpartum. Twenty percent of women with eclampsia reported no neurologic symptoms before seizure. Neurologic symptoms commonly precede eclampsia. A minority of patients with eclampsia (17%) had no prodromal symptoms before their eclamptic seizure. Premonitory symptoms may provide an early warning of imminent eclampsia.",success
16018776,False,Journal Article,,,,,,,,True,"To ascertain the characteristics, clinical features, and maternal fetal outcome in eclampsia in a tertiary referral center with 24 000 deliveries per year. This is a cross-sectional study, in which 50 case notes were retrieved retrospectively and data was analyzed descriptively. Eclampsia was significant in the Malay primipara patients (n = 14, P = 0.034) and the 20-24-year-old primipara patients (n = 11, P = 0.01). Most were significantly antepartum (64%) and preterm seizures (68%), and 16% were early onset (<31 weeks). Two-thirds were booked and one-third were inpatients. Twenty per cent did not have hypertension or pre-eclampsia antenatally. Most presented with headache (66%) and hyper-reflexia (48%). Only 16% presented with all three prodromal symptoms and 14% were asymptomatic. Half had diastolic blood pressure (DBP) of <110 mmHg and the level of DBP was not significantly associated with the presence of prodromal symptoms and signs. There was increased morbidity, operative intervention, admission to intensive care and more low birth weight babies. Most babies that weighed <2.5 kg had poor Apgar score at 1 min, but most babies had good Apgar score at 5 min (16 babies >2.5 kg, 22 babies < or =2.5 kg, P = 0.006). The corrected perinatal mortality was 40/1000. There was increased maternal and perinatal morbidity but no maternal mortality. Contributing factors are the atypical presentation, early onset of disease and the absence of risk factors. There is a need to develop new methods to identify this group of patients in an effort to further reduce the prevalence of this dangerous condition.",success
10453832,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"To study estimated cerebral perfusion pressure and its relation to headache and scotomata in women with pre-eclampsia. Prospective, observational study. University teaching hospitals. Seventy-nine pre-eclamptic women with (n = 42) and without (n = 37) headache. Patients with scotomata were also studied separately. Transcranial Doppler ultrasound was used to estimate the resistance index, pulsatility index, and estimated cerebral perfusion pressure in the middle cerebral artery. eCPP data were plotted on the same axes as the mean (and 5th and 95th% prediction limits) eCPP data from 63 normal pregnant women followed longitudinally through pregnancy. Data outside of the 95% prediction limits were regarded as abnormal. Data from the pre-eclamptic women were also expressed in terms of the number of standard deviations from the mean value established for normal pregnancy (multiples of the standard deviation: MOS). All studies were prior to labour, under similar conditions, and before volume expansion or treatment. Analysis of data was performed using Student's t test, Mann-Whitney U test, ANOVA, and Fisher's exact test with two-tailed P < 0.05, and receiver operating characteristic curve analysis with a one-tailed P < 0.05. Resistance index, pulsatility index, and eCPP. Pre-eclamptic women with headache were much more likely to have abnormal eCPP (34/42; 88%) than those without headache (18/37; 49%), P = 0.004, OR 4.5 (95% CI 1.5 to 13.9). There were no differences in terms of MOS in the resistance index or pulsatility index between the two groups, but estimated perfusion pressure, expressed as multiples of the standard deviation in the group with headache, was significantly higher than in the women without. Headache was noted in both over-perfusion and under-perfusion states. Only women with headache had scotomata, and their presence was not related to the severity of the headache or any difference in resistance indices or eCPP. Headache in women with pre-eclampsia is strongly associated with the presence of abnormal cerebral perfusion pressure. This information may be of use in clinical management.",success
9532990,True,Clinical Trial;Journal Article;Randomized Controlled Trial,,,,,,,,True,"To determine whether the administration of prophylactic intravenous magnesium sulphate reduces the occurrence of eclampsia in women with severe pre-eclampsia. Randomised controlled trial. A tertiary referral obstetric unit. Eight hundred and twenty-two women with severe pre-eclampsia requiring termination of pregnancy by induction of labour or caesarean section. The women were randomised to receive either placebo (saline) or magnesium sulphate intravenously. The investigators were blinded to the contents of the pre-mixed solutions. The occurrence of eclampsia in the two groups. The data of 699 women were evaluated. Fourteen were withdrawn after randomisation. The overall incidence of eclampsia was 1.8%. Of 345 women who received magnesium sulphate, one developed eclampsia (0.3%); in the placebo group, 11/340 women (3.2%) developed eclampsia (relative risk 0.09; 95% confidence interval 0.01-0.69; P = 0.003). The use of intravenous magnesium sulphate in the management of women with severe pre-eclampsia significantly reduced the development of eclampsia.",success
7819845,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"To measure the incidence of eclampsia, establish how often it is preceded by signs of pre-eclampsia, document the morbidity associated with eclampsia, and determine the maternal case fatality rates. A prospective, descriptive study of every case of eclampsia in the United Kingdom in 1992. Information was collected from reviews of hospital case notes and questionnaires to general practitioners. All 279 hospitals in the United Kingdom with a consultant obstetric unit. Obstetricians and midwives notified 582 possible cases, and 383 were confirmed as eclampsia. The national incidence of eclampsia was 4.9/10,000 maternities (95% confidence interval 4.5 to 5.4). Most convulsions occurred despite antenatal care (70%) and within one week of the woman's last visit to a doctor or midwife (85%). Three quarters of first seizures occurred in hospital, of which 38% developed before both proteinuria and hypertension had been documented. Forty four per cent of cases occurred postpartum, more than a third (38%) antepartum, and the remainder (18%) intrapartum. Nearly one in 50 women (1.8%) died, and 35% of all women had at least one major complication. The rate of stillbirths and neonatal deaths was 22.2/1000 and 34.1/1000, respectively. Preterm eclampsia occurred more commonly antepartum and was associated with more maternal complications and fetuses that were small for gestational age, as well as with higher rates of stillbirth and neonatal mortality. Antepartum eclampsia, which was more likely to occur preterm, was associated with a higher rate of maternal complications and a higher neonatal mortality. Both factors (gestational prematurity and antepartum occurrence) contributed independently to the severity of the outcome. Eclampsia occurs in nearly one in 2000 maternities in the United Kingdom and is associated with high maternal morbidity and fatality in cases. It may present unheralded by warning signs. Preterm and antenatal eclampsia seem to be particularly severe.",success
7726272,False,Journal Article;Review,,,,,,,,True,"Over a 14-year period at Parkland Hospital, the clinical courses of 15 women with severe preeclampsia or eclampsia were further complicated by blindness. Our purpose is to describe their management and outcome, as well as to offer insight to the pathophysiologic characteristics of blindness complicating pregnancy-induced hypertension. Prospective ascertainment of women with blindness and pregnancy-induced hypertension was done. These cases were managed according to the standardized preeclampsia-eclampsia regimen used at our hospital since 1955. Briefly, this regimen includes magnesium sulfate given intramuscularly to prevent or control seizures, hydralazine to lower dangerously elevated blood pressure, intravenous fluid restriction, and delivery. There were 15 women with blindness that persisted from 4 hours to 8 days; it subsequently resolved completely in all. Of the 13 women who underwent computed tomography, 8 had low-density areas localized predominantly in the occipital lobes. Five of these 13 subsequently underwent magnetic resonance imaging and 2 showed corresponding hyperintense lesions in the occipital areas. On the basis of previously published experiences with computed tomography in women with eclampsia, as well as the experiences described here, we conclude that cortical blindness associated with preeclampsia-eclampsia results from petechial hemorrhages and focal edema in the occipital cortex. These lesions are likely stimulated by disparity in cerebral regional blood flow that is characterized by vasospasm and diminished flow primarily affecting the posterior circulation.",success
8559202,False,Journal Article,,,,,,,,True,"In some patients who are hospitalized for acute illness, we have noted a reversible syndrome of headache, altered mental functioning, seizures, and loss of vision associated with findings indicating predominantly posterior leukoencephalopathy on imaging studies. To elucidate this syndrome, we searched the log books listing computed tomographic (CT) and magnetic resonance imaging (MRI) studies performed at the New England Medical Center in Boston and Hôpital Sainte Anne in Paris; we found 15 such patients who were evaluated from 1988 through 1994. Of the 15 patients, 7 were receiving immunosuppressive therapy after transplantation or as treatment for aplastic anemia, 1 was receiving interferon for melanoma, 3 had eclampsia, and 4 had acute hypertensive encephalopathy associated with renal disease (2 with lupus nephritis, 1 with acute glomerulonephritis, and 1 with acetaminophen-induced hepatorenal failure). Altogether, 12 patients had abrupt increases in blood pressure, and 8 had some impairment of renal function. The clinical findings included headaches, vomiting, confusion, seizures, cortical blindness and other visual abnormalities, and motor signs. CT and MRI studies showed extensive bilateral white-matter abnormalities suggestive of edema in the posterior regions of the cerebral hemispheres, but the changes often involved other cerebral areas, the brain stem, or the cerebellum. The patients were treated with antihypertensive medications, and immunosuppressive therapy was withdrawn or the dose was reduced. In all 15 patients, the neurologic deficits resolved within two weeks. Reversible, predominantly posterior leukoencephalopathy may develop in patients who have renal insufficiency or hypertension or who are immunosuppressed. The findings on neuroimaging are characteristic of subcortical edema without infarction.",success
21878596,False,Journal Article,,,,,,,,True,"To assess the prevalence, clinical presentations, and neuroimaging abnormalities in a series of patients treated for eclampsia at Mayo Clinic in Rochester, MN. We reviewed the records of all pregnant patients diagnosed as having eclampsia at Mayo Clinic in Rochester, MN, between January 1, 2001, and December 31, 2008. All patients who underwent neuroimaging were identified, and all studies were reviewed by an independent neuroradiologist. Comparisons were made between groups who did and did not undergo imaging to identify differentiating clinical or laboratory variables. Thirteen cases of eclampsia were found, with neuroimaging studies available for 7: magnetic resonance imaging (n=6) and computed tomography (n=1). All 7 patients developed eclamptic seizures, and 2 of 7 patients had severe hypertension, with recorded systolic blood pressures exceeding 180 mm Hg. Neuroimaging showed characteristic changes of posterior reversible encephalopathy syndrome (PRES) in all patients. Follow-up imaging showed resolution in 2 of 3 patients; 1 patient had residual neuroimaging abnormalities. Our results suggest that the clinical syndrome of eclampsia is associated with an anatomical substrate that is recognizable by neuroimaging as PRES. The levels of blood pressure elevation are lower than those reported in cases of PRES because of hypertensive encephalopathy. Further studies are needed to determine whether more aggressive blood pressure control and early neuroimaging may have a role in the management of these patients.",success
16159105,False,Journal Article,,,,,,,,True,"The phenomenon of reversible cerebral arterial segmental vasoconstriction has been associated with several conditions including pregnancy and puerperium (""postpartum angiopathy""), thunderclap headache, and use of vasoconstrictive medications. Patients with cerebral vasoconstriction typically present with sudden, severe, and recurrent (""thunderclap"") headaches and can develop strokes. Cerebral vasoconstriction syndromes are under- recognized, are poorly characterized, and are frequently misdiagnosed as primary cerebral vasculitis. This article presents an illustrative case report and reviews the historical aspects, clinical and imaging characteristics, etiology, differential diagnosis, management, and prognosis of cerebral vasoconstriction syndromes.",success
15947178,False,Journal Article;Review,,,,,,,,True,"Preeclampsia is a relatively common pregnancy disorder that originates in the placenta and causes variable maternal and fetal problems. In the worst cases, it may threaten the survival of both mother and baby. We summarize recent work on the causes of preeclampsia, which reveals a new mode of maternal immune recognition of the fetus, relevant to the condition. The circulating factors derived from the placenta, which contributes to the clinical syndrome, are now better understood. This brief review on preeclampsia does not cover all aspects of this intriguing condition but focuses on some new and interesting findings.",success
12908998,False,"Journal Article;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"Preeclampsia is a heterogeneous disorder, and as with other diseases (e.g., type I and type II diabetes), progress in the understanding of this disorder would be assisted greatly if subtypes could be characterized. We suggest that a first step would be to subdivide preeclampsia into early-onset disease (< 34 + 0 weeks') and late onset disease (> 34 + 0 weeks').",success
12547721,False,Comparative Study;Journal Article,,,,,,,,True,"Placental apoptosis is increased in vivo in preeclampsia (PE) and intrauterine growth restriction (IUGR). The cause and pathological implications of this phenomenon are unknown. This study considers the apoptotic susceptibility of villous trophoblasts from normal, PE, and IUGR pregnancies. Cultured cytotrophoblasts (CTs) and an in vitro model of syncytialization were used. CTs were isolated from term placentas of 12 normal, 12 PE, and 12 IUGR pregnancies. Apoptosis was determined by terminal dUTP nick-end labeling (TUNEL), Annexin V binding, and ADP:ATP ratios. Cells were stimulated with tumor necrosis factor-alpha/interferon-gamma or reduced oxygen (<5 KPa). For CTs, ADP:ATP <1 correlates with Annexin V binding. For normal pregnancy, tumor necrosis factor-alpha and depleted oxygen significantly increased TUNEL, Annexin V binding and ADP:ATP in CTs and syncytiotrophoblasts (STs). Spontaneous apoptosis was similar between groups for both cell types. After stimulation, TUNEL and Annexin V binding of CTs were significantly raised in PE and IUGR as compared with normal pregnancy. After oxygen reduction, ADP:ATP in CTs and STs were significantly elevated in IUGR. TUNEL was also increased in STs in PE after oxygen depletion and was significantly raised in STs from IUGR pregnancies after stimulation with both agonists. This is the first description of enhanced apoptosis in isolated villous trophoblasts in PE and IUGR. These intrinsic differences may represent an important factor in the pathophysiology of these conditions.",success
11349196,False,Journal Article,,,,,,,,True,Placentas were obtained at delivery from 34 pregnancies complicated by preeclampsia and from 34 uncomplicated pregnancies. The incidence of apoptotic nuclei was significantly greater (P <.01) in the placentas from the pregnancies complicated by preeclampsia.,success
1751443,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"To examine the deportation of trophoblast cells into the maternal blood in pre-eclamptic (gestational proteinuric hypertension) and normal pregnancy. The monoclonal anti-cytokeratin antibody JMB2 was used in the APAAP technique to label trophoblast cells in cell smears of uterine vein blood obtained at caesarean section. 10 women with proteinuric pre-eclampsia requiring caesarean section, 10 pregnant women requiring elective caesarean section for reasons other than pre-eclampsia and five control women who had never been pregnant. Three populations of trophoblast cells were identified; two mononuclear cytotrophoblast types with diameters varying from 11-14 microns and 19-25 microns respectively, and multinucleated syncytiotrophoblast cells varying in size from 23-88 microns. Women with pre-eclampsia had more trophoblast cells in uterine vein blood than were found in pregnant women without pre-eclampsia. There was no correlation between the numbers of trophoblast cells and the stage of gestation or severity of the pre-eclampsia, although an acute maternal or fetal event necessitating delivery was associated with increased deportation of trophoblast. Mononuclear cytotrophoblast cells were detected in the peripheral blood of only 1 of 5 pre-eclamptic patients, despite their presence in the uterine vein blood of all 5 women. Trophoblast deportation is increased in pre-eclamptic pregnancy, with both cytotrophoblast and syncytiotrophoblast present in the uterine vein blood, but there is no correlation with the severity of the disease. In some cases cytotrophoblast may also enter the peripheral circulation.",success
16957146,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, N.I.H., Intramural",,,,,,,,True,"Alterations in circulating soluble fms-like tyrosine kinase 1 (sFlt1), an antiangiogenic protein, and placental growth factor (PlGF), a proangiogenic protein, appear to be involved in the pathogenesis of preeclampsia. Since soluble endoglin, another antiangiogenic protein, acts together with sFlt1 to induce a severe preeclampsia-like syndrome in pregnant rats, we examined whether it is associated with preeclampsia in women. We performed a nested case-control study of healthy nulliparous women within the Calcium for Preeclampsia Prevention trial. The study included all 72 women who had preterm preeclampsia (<37 weeks), as well as 480 randomly selected women--120 women with preeclampsia at term (at > or =37 weeks), 120 women with gestational hypertension, 120 normotensive women who delivered infants who were small for gestational age, and 120 normotensive controls who delivered infants who were not small for gestational age. Circulating soluble endoglin levels increased markedly beginning 2 to 3 months before the onset of preeclampsia. After the onset of clinical disease, the mean serum level in women with preterm preeclampsia was 46.4 ng per milliliter, as compared with 9.8 ng per milliliter in controls (P<0.001). The mean serum level in women with preeclampsia at term was 31.0 ng per milliliter, as compared with 13.3 ng per milliliter in controls (P<0.001). Beginning at 17 weeks through 20 weeks of gestation, soluble endoglin levels were significantly higher in women in whom preterm preeclampsia later developed than in controls (10.2 ng per milliliter vs. 5.8 ng per milliliter, P<0.001), and at 25 through 28 weeks of gestation, the levels were significantly higher in women in whom term preeclampsia developed than in controls (8.5 ng per milliliter vs. 5.9 ng per milliliter, P<0.001). An increased level of soluble endoglin was usually accompanied by an increased ratio of sFlt1:PlGF. The risk of preeclampsia was greatest among women in the highest quartile of the control distributions for both biomarkers but not for either biomarker alone. Rising circulating levels of soluble endoglin and ratios of sFlt1:PlGF herald the onset of preeclampsia.",success
18175242,False,Journal Article,,,,,,,,True,"The soluble form of vascular endothelial growth factor receptor-1 (sVEGFR-1), an antagonist to vascular endothelial growth factor and placental growth factor, has been implicated in the pathophysiology of preeclampsia. Preeclampsia and pregnancy complicated with small for gestational age (SGA) fetuses share some pathophysiologic derangements, such as failure of physiologic transformation of the spiral arteries, endothelial cell dysfunction, and leukocyte activation. The objectives of this study were to: (1) determine whether plasma concentrations of sVEGFR-1 in mothers with SGA fetuses without preeclampsia at the time of diagnosis are different from those in patients with preeclampsia or normal pregnant women, and (2) examine the relationship between plasma concentrations of sVEGFR-1 and Doppler velocimetry in uterine and umbilical arteries in patients with preeclampsia and those with SGA. A cross-sectional study was conducted to determine the concentrations of the soluble form of VEGFR-1 in plasma obtained from normal pregnant women (n = 135), women with SGA fetuses (n = 53), and patients with preeclampsia (n = 112). Patients with SGA fetuses and those with preeclampsia were sub-classified according to the results of uterine and umbilical artery Doppler velocimetry examinations. Plasma concentrations of sVEGFR-1 were determined by an ELISA. Since these concentrations change with gestational age, differences among various subgroups were statistically estimated with the delta value, defined as the difference between the observed and expected plasma sVEGFR-1 concentration. The expected values were derived from regression analysis of plasma sVEGFR-1 concentrations in normal pregnancy. Regression analysis and univariate and multivariate analysis were employed. (1) Mothers with SGA fetuses had a mean plasma concentration of sVEGFR-1 higher than normal pregnant women (p < 0.001), but lower than patients with preeclampsia (p < 0.001). (2) Among patients with SGA fetuses, only those with abnormal uterine artery Doppler velocimetry had a mean plasma sVEGFR-1 concentration significantly higher than normal pregnant women (p < 0.001). (3) Among mothers with SGA fetuses in whom Doppler velocimetry was performed (n = 41), those with abnormalities in both the uterine and umbilical artery velocimetry had the highest mean delta of sVEGFR-1 plasma concentration (mean +/- standard deviation (SD): 0.69 +/- 0.29). Conversely, patients who had normal Doppler velocimetry in both uterine and umbilical arteries had the lowest mean delta (mean +/- SD: 0.09 +/- 0.29) of sVEGFR-1 plasma concentrations (ANOVA; p < 0.001). (4) Among patients with preeclampsia in whom Doppler velocimetry was performed (n = 69), those with abnormalities in both the uterine and umbilical artery velocimetry had the highest mean delta sVEGFR-1 plasma concentration (mean +/- SD: 1.01 +/- 0.22) among all groups classified (ANOVA; p < 0.001). (5) Among patients with SGA and those with preeclampsia, there was a relationship (Chi-square for trend p < 0.001 for both) between the severity of Doppler velocimetry abnormalities and the proportion of patients who had high delta sVEGFR-1 plasma concentrations (defined as a concentration two standard deviations (2SD) above the mean delta of normal pregnant women). (6) Multiple regression analysis suggested that the diagnostic category (e.g., SGA or preeclampsia), Doppler abnormalities, and gestational age at blood sampling were associated with an increase in plasma sVEGFR-1 concentrations (p < 0.001). These observations provide support for the participation of the soluble receptor of vascular endothelial growth factor in the pathophysiology of SGA with abnormal uterine artery Doppler velocimetry and preeclampsia. An excess of sVEGFR-1 is released into the maternal circulation of patients with preeclampsia and those with SGA fetuses, as abnormalities of impedance to blood flow involve uterine and umbilical circulation.",success
16545329,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"The purpose of this study was to evaluate possible relationships between placental markers and endothelial dysfunction in preeclampsia and intrauterine growth restriction. A prospective study was conducted in 76 patients with preeclampsia and 37 patients with intrauterine growth restriction that were classified as early onset (<34 weeks of gestational age) or late onset, and 40 control subjects. Plasma levels of placental growth factor, soluble fms-like tyrosine kinase-1, vascular cell adhesion molecule-1, and uterine artery Doppler indices were measured. In early-onset preeclampsia and intrauterine growth restriction, placental growth factor was lower and soluble fms-like tyrosine kinase-1 and vascular cell adhesion molecule-1 higher than in control subjects, although all changes were more pronounced in preeclampsia. In late-onset preeclampsia, those patients with abnormal uterine artery Doppler indices had higher soluble fms-like tyrosine kinase-1 and vascular cell adhesion molecule-1 levels. Biochemical changes in early-onset preeclampsia and intrauterine growth restriction point to a common placental disorder and a state of endothelial dysfunction, which may require interaction with other factors to explain the maternal disease in preeclampsia. Data in late-onset preeclampsia suggest that a proportion of them may occur with minimal placental involvement.",success
15284201,False,Journal Article,,,,,,,,True,"Sufficient cytotrophoblast (CT) invasion into the uterine wall and subsequent remodeling of maternal uterine vasculature is critical to establish uteroplacental circulation. The production of vascular endothelial growth factor (VEGF) family molecules is confirmed in placental cells including CTs, but it is not elucidated how the VEGF system in CTs is controlled by oxygen tension and how it is involved in the development of placental circulation. To address this, we explored the effect of oxygen tension on the expression of VEGF, placenta growth factor (PlGF), and their antagonist, soluble fms-like tyrosine kinase-1 (sFlt-1) using ELISA and real-time PCR in a primary CT cell culture. For comparison, the same was conducted in parallel using other cells comprising placenta, such as human umbilical vein endothelial cells (HUVECs) and villous fibroblasts (VFs). Reduced oxygen resulted in a pronounced increase in sFlt-1 mRNA amount and sFlt-1 release into the culture media in CTs, whereas this was not the case with HUVECs and VFs. Free (not bound to sFlt-1) VEGF was not detected in CT culture media regardless of oxygen concentration, even though VEGF expression was stimulated by reduced oxygen in CTs, which was similar to the stimulation in HUVECs and VFs. Free PlGF was also diminished in CT culture media by reduced oxygen. These results implicate that CTs possess a unique property to enhance sFlt-1 production under reduced oxygen, which could consequently antagonize angiogenic activity of VEGF and PlGF. The presented findings might provide a framework with which to understand the mechanism of uterine vascular remodeling and its perturbations as exemplified in preeclampsia.",success
16627691,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Elevated expression of soluble vascular endothelial growth factor receptor-1 (sFlt-1) in preeclampsia plays a major role in the pathogenesis of this serious disorder of human pregnancy. Although reduced placental oxygenation is thought to be involved in the pathogenesis of preeclampsia, it is unclear how oxygen regulates placental sFlt-1 expression. The aims herein were to investigate sFlt-1 expression in in vivo and in vitro physiological and pathological models of human placental hypoxia and to understand the role of hypoxia inducible factor-1 (HIF-1) in regulating the expression of this molecule. sFlt-1 expression in placental villi was significantly increased under physiological low oxygen conditions in early first-trimester and in high-altitude placentae, as well as in pathological low oxygen conditions, such as preeclampsia. In high-altitude and in preeclamptic tissue, sFlt-1 localized within villi to perivascular regions, the syncytiotrophoblast layer, and syncytial knots. In first-trimester villous explants, low oxygen, but not hypoxia-reoxygenation (HR), increased sFlt-1 expression. Moreover, exposure of villous explants to dimethyloxalyl-glycin, a pharmacological inhibitor of prolyl-hydroxylases, which mimics hypoxia by increasing HIF-1alpha stability, increased sFlt-1 expression. Conversely, HIF-1alpha knockdown using antisense oligonucleotides, decreased sFlt-1 expression. In conclusion, placental sFlt-1 expression is increased by both physiologically and pathologically low levels of oxygen. This oxygen-induced effect is mediated via the transcription factor HIF-1. Low oxygen levels, as opposed to intermittent oxygen tension (HR) changes, play an important role in regulating sFlt-1 expression in the developing human placenta and hence may contribute to the development of preeclampsia.",success
23161443,False,Journal Article,,,,,,,,False,,success
6711634,False,Journal Article,,,,,,,,True,"Since 1955, a standardized treatment regimen has been used to manage 245 cases of eclampsia at Parkland Memorial Hospital. Magnesium sulfate alone effectively controlled controlled convulsions in the great majority of cases. The only maternal death among the 245 cases reemphasizes the risk of respiratory arrest that is inherent in the administration of magnesium sulfate when given in large doses intravenously. Hydralazine to lower the diastolic blood pressure somewhat, when it was 110 mm Hg or higher, prevented intracranial hemorrhage. Avoidance of diuretics and hyperosmotic agents and limitation of fluid intake were not associated with severe renal failure. Pulmonary edema was rare. Vaginal delivery was achieved in the majority of cases. Oxytocin often proved effective for initiating and maintaining labor even remote from term. The results obtained with this regimen justify its continued clinical application.",success
7295601,False,Journal Article,,,,,,,,True,"The platelet count in 550 patients with gestational hypertension was significantly lower and the mean platelet volume significantly higher than in normal pregnant women. Both the platelet count and volume became increasingly abnormal when hypertension was accompanied by oedema, proteinuria or both, and women with severe pre-eclampsia or eclampsia had the lowest platelet counts and the highest mean platelet volume. The proportion of patients with thrombocytopenia and/or macrothrombocytosis also varied with the severity of the clinical presentation. Fibrinogen degradation products were found mainly in fully developed pre-eclampsia. These findings confirm the concept of a rapid platelet turnover caused by low-grade disseminated intravascular coagulation in gestational hypertension. The platelet pattern in essential hypertension is similar to that seen in normal pregnancy.",success
21272124,False,Journal Article;Review,,,,,,,,True,"With the recent discovery of potential serum 'toxins' in human preeclampsia, it is timely to consider how these might relate to preeclamptic nephropathy. This review will discuss the clinical presentation of preeclampsia with an emphasis on renal involvement. It will explore the nature of the renal histological changes including endothelial and the more recently discovered podocyte changes, the implications of elevated anti-angiogenic molecules, anti-angiotensin-1 receptor agonistic antibodies and other proposed mechanisms in causing or exacerbating renal lesions. It will also explore the role of pre-existing renal disease in causing preeclampsia and the potential for new biomarkers, both serum and urinary, to inform clinical practice with regard to differentiating preeclampsia from pre-existing renal disease. Recommendations about the future of women who have had preeclampsia are unclear but the general consensus is that there are future cardiovascular risks, and to a lesser extent, future renal risks in these women. Regular review of proteinuria and glomerular filtration rate as well as overall cardiovascular risk status seems a logical step.",success
23216619,False,"Journal Article;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"In diseases with proteinuria, for example nephrotic syndrome and pre-eclampsia, there often are suppression of plasma renin-angiotensin-aldosterone system components, expansion of extracellular volume and avid renal sodium retention. Mechanisms of sodium retention in proteinuria are reviewed. In animal models of nephrotic syndrome, the amiloride-sensitive epithelial sodium channel ENaC is activated while more proximal renal Na(+) transporters are down-regulated. With suppressed plasma aldosterone concentration and little change in ENaC abundance in nephrotic syndrome, the alternative modality of proteolytic activation of ENaC has been explored. Proteolysis leads to putative release of an inhibitory peptide from the extracellular domain of the γ ENaC subunit. This leads to full activation of the channel. Plasminogen has been demonstrated in urine from patients with nephrotic syndrome and pre-eclampsia. Urine plasminogen correlates with urine albumin and is activated to plasmin within the urinary space by urokinase-type plasminogen activator. This agrees with aberrant filtration across an injured glomerular barrier independent of the primary disease. Pure plasmin and urine samples containing plasmin activate inward current in single murine collecting duct cells. In this study, it is shown that human lymphocytes may be used to uncover the effect of urine plasmin on amiloride- and aprotinin-sensitive inward currents. Data from hypertensive rat models show that protease inhibitors may attenuate blood pressure. Aberrant filtration of plasminogen and conversion within the urinary space to plasmin may activate γ ENaC proteolytically and contribute to inappropriate NaCl retention and oedema in acute proteinuric conditions and to hypertension in diseases with chronic microalbuminuria/proteinuria.",success
6720261,False,Journal Article,,,,,,,,True,"Maternal serum urate levels were studied in 50 normal pregnancies and 72 cases of severe pre-eclampsia. Markedly elevated levels of serum urate were found in severe pre-eclampsia, compared with normal pregnancy. In severe pre-eclampsia significantly higher levels were found prior to parturition in cases of growth retardation and perinatal distress, compared with patients whose newborns were of normal size and condition. Particularly high serum urate levels were found early in the third trimester in cases of perinatal death. A slight but significant correlation was found between the weight centile of the newborn and the last maternal urate level before parturition. A rapidly rising urate level reliably predicted perinatal distress. The last maternal serum urate before parturition was correlated with the hemoglobin and erythrocyte volume fraction values in the same blood sample.",success
17140293,False,"Journal Article;Research Support, N.I.H., Intramural;Review",,,,,,,,True,"This article reviews the anatomy and physiology of the uterine circulation, with emphasis on the remodeling of spiral arteries during normal pregnancy, and the timing and anatomical pathways of trophoblast invasion of the spiral arteries. We review the definitions of the placental bed and basal plate of the placenta, their relevance to the study of the physiologic transformation of the spiral arteries, as well as the methods to obtain and examine placental bed biopsy specimens. We also examine the role of the extravillous trophoblast in normal and abnormal pregnancies, and the criteria used to diagnose failure of physiologic transformation of the spiral arteries. Finally, we comment on the use of uterine artery Doppler velocimetry as a surrogate marker of chronic uteroplacental ischemia.",success
16490251,False,Journal Article;Review,,,,,,,,True,"Uterine spiral arteries play a vital role in supplying nutrients to the placenta and fetus, and for this purpose they are remodelled into highly dilated vessels by the action of invading trophoblast (physiological change). Knowledge of the mechanisms of these changes is relevant for a better understanding of pre-eclampsia and other pregnancy complications which show incomplete spiral artery remodelling. Controversies still abound concerning different steps in these physiological changes, and several of these disagreements are highlighted in this review, thereby suggesting directions for further research. First, a better definition of the degree of decidua- versus trophoblast-associated remodelling may help to devise a more adequate terminology. Other contestable issues are the vascular plugging and its relation with oxygen, trophoblast invasion from the outside or the inside of the vessels (intravasation versus extravasation), the impact of haemodynamics on endovascular migration, the replacement of arterial components by trophoblast, maternal tissue repair mechanisms and the role of uterine natural killer (NK) cells. Several of these features may be disturbed in complicated pregnancies, including the early decidua-associated vascular remodelling, vascular plugging and haemodynamics. The hyperinflammatory condition of pre-eclampsia may be responsible for vasculopathies such as acute atherosis, although the overall impact of such lesions on placental function is far from clear. Several features of the human placental bed are mirrored by processes in other species with haemochorial placentation, and studying such models may help to illuminate poorly understood aspects of human placentation.",success
21848483,False,"Journal Article;Research Support, N.I.H., Intramural",,,,,,,,True,"Preeclampsia (PE) has been classified into early- and late-onset disease. These two phenotypic variants of PE have been proposed to have a different pathophysiology. However, the gestational age cut-off to define ""early"" vs. ""late"" PE has varied among studies. The objective of this investigation was to determine the prevalence of lesions consistent with maternal underperfusion of the placenta in patients with PE as a function of gestational age. A nested case-control study of 8307 singleton pregnant women who deliver after 20 weeks of gestation was constructed based on a cohort. Cases were defined as those with PE (n=910); controls were pregnant women who did not have a hypertensive disorder in pregnancy (n=7397). The frequency of maternal underperfusion of the placenta (according to the criteria of the Society for Pediatric Pathology) was compared between the two groups. Logistic regression was used for analysis. Estimated relative risks (RRs) were calculated from odds ratios. 1) The prevalence of lesions consistent with maternal underperfusion was higher in patients with PE than in the control group [43.3% vs. 15.9%, unadjusted odds ratio 4.0 (95% CI 3.5-4.7); P<0.001]; 2) the estimated RR of maternal underperfusion lesions in PE was higher than in the control group [RR=2.8 (95% CI 2.5-3.0)]; 3) the lower the gestational age at delivery, the higher the RR for these lesions; 4) early-onset PE, regardless of the gestational age used to define it (<32, 33, 34, 35 or 37 weeks) had a significantly higher frequency of placental lesions consistent with maternal underperfusion than late-onset PE (P<0.001 for all). 1) The earlier the gestational age of preeclampsia at delivery, the higher the frequency of placental lesions consistent with maternal underperfusion; 2) our data suggest that demonstrable placental involvement as determined by pathologic examination differs in early- and late-onset preeclampsia; and 3) this phenomenon appears to be a continuum, and we could not identify a clear and unambiguous gestational age at which lesions consistent with underperfusion would not be present.",success
23480655,False,Journal Article,,,,,,,,True,"The prediction and early diagnosis of preeclampsia remains limited due to its heterogeneous clinical presentation and unclear pathophysiology. However, accumulating evidence indicates that angiogenic imbalances during pregnancy may play a central role in the mechanisms of injury of preeclampsia. Moreover, a growing body of evidence suggests that a combination of biochemical and biophysical parameters in the first and second trimester may contribute to the identification of patients at high risk of early-onset and/or severe preeclampsia. This article reviews proposed mechanisms of injury in preeclampsia as well as recent attempts in the prediction of this pregnancy complication. The article also highlights the limitations of these studies, in particular their low positive predictive value, indicating that any prophylactic intervention would expose a large number of patients who would not develop the disease. The prediction of early-onset preeclampsia using biochemical and biophysical parameters or the combination of both is in general better than the prediction of late-onset preeclampsia. We propose a conceptual framework whereby the timing of presentation of preeclampsia may be a function of the timing of the insults to the fetal supply line as well as a function of the fetal response to these insults.",success
19478794,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"A number of different biophysical and biochemical markers have been proposed as predictors of preeclampsia. Factors involved in the angiogenic balance are suggested as candidate markers. The purpose of this prospective, longitudinal cohort study was to determine whether a ratio between Angiopoietin-1 (Ang-1) and Angiopoietin-2 (Ang-2) can be used to predict preeclampsia in a low-risk population. A cohort of healthy pregnant women (n = 469) were enrolled at gestational weeks 8-12. Plasma samples were collected at gestational weeks 10, 25, 28, 33, and 37. By using commercially available enzyme-linked immunosorbent assay kits Ang-1 and Ang-2 were analyzed. The median Ang-1/Ang-2 ratio increased during pregnancy in all women, but the ratios were significantly lower at gestational weeks 25 and 28 in women who later developed preeclampsia than in normal pregnant women (1.49 compared to 2.19 and 2.12 compared to 3.54, P < 0.05 and P < 0.05). Our data indicate that in a low-risk population of women the Ang-1/Ang-2 ratio in plasma constitutes a possible biomarker for prediction of later onset of preeclampsia.",success
19900040,False,"Journal Article;Research Support, N.I.H., Intramural",,,,,,,,True,"Changes in the maternal plasma concentrations of angiogenic (placental growth factor (PlGF) and vascular endothelial growth factor (VEGF)) and anti-angiogenic factors (sEng and vascular endothelial growth factor receptor-1 (sVEGFR-1)) precede the clinical presentation of preeclampsia. This study was conducted to examine the role of maternal plasma PlGF, sEng, and sVEGFR-1 concentrations in early pregnancy and midtrimester in the identification of patients destined to develop preeclampsia. This longitudinal cohort study included 1622 consecutive singleton pregnant women. Plasma samples were obtained in early pregnancy (6-15 weeks) and midtrimester (20-25 weeks). Maternal plasma PlGF, sEng, and sVEGFR-1 concentrations were determined using sensitive and specific immunoassays. The primary outcome was the development of preeclampsia. Secondary outcomes included term, preterm, and early-onset preeclampsia. Receiving operating characteristic curves, sensitivity, specificity, positive and negative likelihood ratios, and multivariable logistic regression were applied. A p-value of <0.05 was considered significant. (1) The prevalence of preeclampsia, term, preterm, (<37 weeks) and early-onset preeclampsia (<34 weeks) was 3.8 (62/1622), 2.5 (40/1622), 1.4 (22/1622) and 0.6% (9/1622), respectively; (2) Higher likelihood ratios were provided by ratios of midtrimester plasma concentrations of PlGF, sEng, and sVEGFR-1 than single analytes; (3) Individual angiogenic and anti-angiogenic factors did not perform well in the identification of preeclampsia as a whole; in particular, they perform poorly in the prediction of term preeclampsia; (4) In contrast, a combination of these analytes such as the PlGF/sEng ratio, its delta and slope had the best predictive performance with a sensitivity of 100%, a specificity of 98-99%, and likelihood ratios for a positive test of 57.6, 55.6 and 89.6, respectively, for predicting early-onset preeclampsia. (1) The PlGF/sEng ratio and its delta and slope had an excellent predictive performance for the prediction of early-onset preeclampsia, with very high likelihood ratios for a positive test result and very low likelihood ratios for a negative test result; and (2) Although the positive likelihood ratios are high and the positive predictive values low, the number of patients needed to be closely followed is 4:1 for the PlGF/sEng ratio and 3:1 for the slope of PlGF/sEng.",success
19273739,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"This study aimed to establish a method of screening for pregnancy hypertension by a combination of maternal variables, including mean arterial pressure, uterine artery pulsatility index, pregnancy-associated plasma protein-A, and placental growth factor in early pregnancy. The base-cohort population constituted of 7797 singleton pregnancies, including 34 case subjects who developed preeclampsia (PE) requiring delivery before 34 weeks (early PE) and 123 with late PE, 136 with gestational hypertension, and 7504 cases subjects (96.3%) who were unaffected by PE or gestational hypertension. Maternal history, uterine artery pulsatility index, mean arterial pressure, and pregnancy-associated plasma protein-A were recorded in all of the cases in the base cohort, but placental growth factor was measured only in the case-control population of 209 cases who developed hypertensive disorders and 418 controls. In each case the measured mean arterial pressure, uterine artery pulsatility index, pregnancy-associated plasma protein-A, and placental growth factor were converted to a multiple of the expected median (MoM) after correction for maternal characteristics found to affect the measurements in the unaffected group. Early PE and late PE were associated with increased mean arterial pressure (1.15 MoM and 1.08 MoM) and uterine artery pulsatility index (1.53 MoM and 1.23 MoM) and decreased pregnancy-associated plasma protein-A (0.53 MoM and 0.93 MoM) and placental growth factor (0.61 MoM and 0.83 MoM). Logistic regression analysis was used to derive algorithms for the prediction of hypertensive disorders. It was estimated that, with the algorithm for early PE, 93.1%, 35.7%, and 18.3% of early PE, late PE, and gestational hypertension, respectively, could be detected with a 5% false-positive rate and that 1 in 5 pregnancies classified as being screen positive would develop pregnancy hypertension. This method of screening is far superior to the traditional approach, which relies entirely on maternal history.",success
8705410,False,Journal Article,,,,,,,,True,"The use of Doppler studies of the uterine arteries in the prediction of pre-eclampsia and intrauterine growth retardation has had mixed success. The introduction of color Doppler imaging and the use of the ""notch' to define an abnormal waveform have helped to improve the predictive value of uterine artery Doppler screening. The aim of this study was to evaluate the use of uterine artery Doppler in a group of women of mixed race and parity. This study was a prospective, cross-sectional analysis of 1326 unselected women who were screened with continuous wave uterine Doppler at 19-21 weeks, as part of a fetal anomaly/dating scan. A total of 214 women with abnormal uterine artery waveforms (notching) were referred for assessment at 24 weeks; 191 attended and had color Doppler imaging/pulsed Doppler studies of both uterine arteries. Data from 185 pregnancies were suitable for analysis. There were abnormal uterine Doppler findings (uni- or bilateral notching) in 110 patients at 24 weeks; 48 had bilateral notching. The sensitivity of notching for the prediction of proteinuric pregnancy-induced hypertension (PPIH) was similar in primiparas (76.9%), multiparas (77.7%), African-Caribbean women (82.6%) and Caucasian women (71.4%). The sensitivity of bilateral notching for the prediction of PPIH requiring delivery before 34 weeks was 81.2%, and 57.6% for babies small for gestational age (SGA), with positive predictive values of 27% (PPIH), 31.2% (SGA) and 37.5% (any complication). Patients with persistent bilateral notching are particularly at risk of developing PPIH or delivering an SGA baby before 34 weeks' gestation; they warrant increased surveillance, and may be a group that could benefit from prophylactic therapies.",success
12420836,False,"Journal Article;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"Doppler ultrasound provides a non-invasive method for the study of the uteroplacental circulation. In normal pregnancy, impedance to flow in the uterine arteries decreases with gestation, which may be the consequence of trophoblastic invasion of the spiral arteries and their conversion into low-resistance vessels. Pre-eclampsia and fetal growth restriction are associated with failure of trophoblastic invasion of spiral arteries, and Doppler studies, in these conditions, have shown that impedance to flow in the uterine arteries is increased. A series of screening studies involving assessment of impedance to flow in the uterine arteries have examined the potential value of Doppler in identifying pregnancies at risk of the complications of impaired placentation. This review examines the findings of Doppler studies in unselected populations. Searches of a computerized medical database were performed to identify relevant studies. Only those studies that provided sufficient data to allow calculation of the performance of the test were included in the analysis. Likelihood ratios were calculated for each study and are reported for pre-eclampsia, fetal growth restriction and perinatal death as well as for more severe forms of pre-eclampsia and fetal growth restriction. The literature search identified 19 relevant studies, four of which were excluded from the further analysis. The main characteristics and results of the 15 remaining studies provided discrepant results, which may be the consequence of differences in Doppler technique for sampling, the definition of abnormal flow velocity waveform, differences in the populations examined, the gestational age at which women were studied and different criteria for the diagnosis of pre-eclampsia and fetal growth restriction. Nevertheless, the studies provided evidence that increased impedance to flow in the uterine arteries is associated with increased risk for subsequent development of pre-eclampsia, fetal growth restriction and perinatal death. In addition, women with normal impedance to flow in the uterine arteries constituted a group that have a low risk of developing obstetric complications related to uteroplacental insufficiency. The review suggests that increased impedance to flow in the uterine arteries in pregnancies attending for routine antenatal care identifies about 40% of those who subsequently develop pre-eclampsia and about 20% of those who develop fetal growth restriction. Following a positive test, the likelihood of these complications is increased by about 6 and 3.5 times, respectively.",success
11844162,True,"Journal Article;Multicenter Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"To determine the value of transvaginal color Doppler assessment of the uterine arteries at 23 weeks of gestation in predicting the subsequent development of pre-eclampsia and fetal growth restriction. Women with singleton pregnancies attending for routine ultrasound examination at 23 weeks in any one of seven hospitals underwent Doppler assessment of the uterine arteries. The presence of an early diastolic notch in the waveform was noted, and the mean pulsatility index of the two arteries was calculated. Screening characteristics in the prediction of pre-eclampsia and the delivery of a low birth-weight infant were calculated. Doppler examination of the uterine arteries was attempted in 8335 consecutive singleton pregnancies, satisfactory waveforms were obtained from both vessels in 8202 (98.4%) cases and complete outcome data were available in 7851 (95.7%) of these. The mean gestational age was 23 (range, 22-24) weeks. The mean uterine artery pulsatility index did not change significantly with gestation (r = -0.0078; P = 0.483); the median value was 1.04 and the 95th centile was 1.63. In 9.3% of cases early diastolic notches in the waveform from both uterine arteries were present and in an additional 11.1% of cases there were notches unilaterally. Pre-eclampsia with fetal growth restriction occurred in 42 (0.5%) cases, pre-eclampsia without fetal growth restriction in 71 (0.9%) and fetal growth restriction without pre-eclampsia in 698 (8.9%). The sensitivity of increased pulsatility index above the 95th centile (1.63) for pre-eclampsia with fetal growth restriction was 69%, for pre-eclampsia without fetal growth restriction was 24%, for fetal growth restriction without pre-eclampsia was 13%, for pre-eclampsia irrespective of fetal growth restriction was 41% and for fetal growth restriction irrespective of pre-eclampsia was 16%. The sensitivity of fetal growth restriction defined by the 5th rather than the 10th centile was higher (19% vs. 16%). The sensitivity for both pre-eclampsia and fetal growth restriction was inversely related to the gestational age at delivery; when delivery occurred before 32 weeks, the sensitivity for all cases of pre-eclampsia with fetal growth restriction, pre-eclampsia without fetal growth restriction and fetal growth restriction without pre-eclampsia increased to 93%, 80% and 56%, respectively. The sensitivity of bilateral notches in predicting pre-eclampsia and/or fetal growth restriction was similar to that of increased pulsatility index but the screen-positive rate with notches (9.3%) was much higher than that with increased pulsatility index (5.1%). A one-stage color Doppler screening program at 23 weeks identifies most women who subsequently develop severe pre-eclampsia and/or fetal growth restriction.",success
18332385,False,"Journal Article;Meta-Analysis;Research Support, Non-U.S. Gov't;Systematic Review",,,,,,,,True,"Alterations in waveforms in the uterine artery are associated with the development of pre-eclampsia and intrauterine growth restriction. We investigated the predictive accuracy of all uterine artery Doppler indices for both conditions in the first and second trimesters. We identified relevant studies through searches of MEDLINE, EMBASE, the Cochrane Library and Medion databases (all records to April 2006) and by checking bibliographies of identified studies and consulting with experts. Four of us independently selected studies, extracted data and assessed study validity. We performed a bivariable meta-analysis of sensitivity and specificity and calculated likelihood ratios. We identified 74 studies of pre-eclampsia (total 79,547 patients) and 61 studies of intrauterine growth restriction (total 41 131 patients). Uterine artery Doppler ultrasonography provided a more accurate prediction when performed in the second trimester than in the first-trimester. Most Doppler indices had poor predictive characteristics, but this varied with patient risk and outcome severity. An increased pulsatility index with notching was the best predictor of pre-eclampsia (positive likelihood ratio 21.0 among high-risk patients and 7.5 among low-risk patients). It was also the best predictor of overall (positive likelihood ratio 9.1) and severe (positive likelihood ratio 14.6) intrauterine growth restriction among low-risk patients. Abnormal uterine artery waveforms are a better predictor of pre-eclampsia than of intrauterine growth restriction. A pulsatility index, alone or combined with notching, is the most predictive Doppler index. These indices should be used in clinical practice. Future research should also concentrate on combining uterine artery Doppler ultrasonography with other tests.",success
28657417,True,"Comparative Study;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",,,ISRCTN13633058,,,,,True,"Preterm preeclampsia is an important cause of maternal and perinatal death and complications. It is uncertain whether the intake of low-dose aspirin during pregnancy reduces the risk of preterm preeclampsia. In this multicenter, double-blind, placebo-controlled trial, we randomly assigned 1776 women with singleton pregnancies who were at high risk for preterm preeclampsia to receive aspirin, at a dose of 150 mg per day, or placebo from 11 to 14 weeks of gestation until 36 weeks of gestation. The primary outcome was delivery with preeclampsia before 37 weeks of gestation. The analysis was performed according to the intention-to-treat principle. A total of 152 women withdrew consent during the trial, and 4 were lost to follow up, which left 798 participants in the aspirin group and 822 in the placebo group. Preterm preeclampsia occurred in 13 participants (1.6%) in the aspirin group, as compared with 35 (4.3%) in the placebo group (odds ratio in the aspirin group, 0.38; 95% confidence interval, 0.20 to 0.74; P=0.004). Results were materially unchanged in a sensitivity analysis that took into account participants who had withdrawn or were lost to follow-up. Adherence was good, with a reported intake of 85% or more of the required number of tablets in 79.9% of the participants. There were no significant between-group differences in the incidence of neonatal adverse outcomes or other adverse events. Treatment with low-dose aspirin in women at high risk for preterm preeclampsia resulted in a lower incidence of this diagnosis than placebo. (Funded by the European Union Seventh Framework Program and the Fetal Medicine Foundation; EudraCT number, 2013-003778-29 ; Current Controlled Trials number, ISRCTN13633058 .).",success
22552037,True,"Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",,,,,,,,True,"There is uncertainty regarding the efficacy of increasing n-3 long-chain PUFA (LCPUFA) intake during pregnancy in reducing the risk of gestational diabetes mellitus (GDM) and preeclampsia. The objective was to determine whether n-3 LCPUFA supplementation in pregnancy reduces the incidence of GDM or preeclampsia. A secondary objective was to assess the effect of n-3 LCPUFA supplementation on perinatal complications. This was a double-blind, multicenter randomized control trial-the DHA to Optimize Mother Infant Outcome (DOMInO) trial. Pregnant women (n = 2399) of <21 wk gestation were randomly assigned to receive DHA-enriched fish oil (800 mg/d) or vegetable oil capsules without DHA from trial entry to birth. The presence of GDM or preeclampsia was assessed through a blinded audit of medical records. Birth outcomes and prenatal complications were also assessed. The overall incidences of GDM and preeclampsia were 8% and 5%, respectively, based on clinical diagnosis. The RR of GDM was 0.97 (95% CI: 0.74, 1.27) and of preeclampsia was 0.87 (95% CI: 0.60, 1.25), and they did not differ significantly between the groups. Birth weight, length, and head circumference z scores also did not differ between the groups. There were 12 perinatal deaths and 5 neonatal convulsions in the control group compared with 3 perinatal deaths and no neonatal convulsions in the DHA group (P = 0.03 in both cases). DHA supplementation of 800 mg/d in the second half of pregnancy does not reduce the risk of GDM or preeclampsia. Whether supplementation reduces the risk of perinatal death and neonatal convulsions requires further investigation. The DOMInO trial was registered with the Australian New Zealand Clinical Trials Registry as TRN12605000569606.",success
17535985,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"Vitamin D has direct influence on molecular pathways proposed to be important in the pathogenesis of preeclampsia, yet the vitamin D-preeclampsia relation has not been studied. We aimed to assess the effect of maternal 25-hydroxyvitamin D [25(OH)D] concentration on the risk of preeclampsia and to assess the vitamin D status of newborns of preeclamptic mothers. We conducted a nested case-control study of pregnant women followed from less than 16 wk gestation to delivery (1997-2001) at prenatal clinics and private practices. Patients included nulliparous pregnant women with singleton pregnancies who developed preeclampsia (n = 55) or did not develop preeclampsia (n = 219). Women's banked sera were newly measured for 25(OH)D. The main outcome measure was preeclampsia (new-onset gestational hypertension and proteinuria for the first time after 20 wk gestation). Our hypotheses were formulated before data collection. Adjusted serum 25(OH)D concentrations in early pregnancy were lower in women who subsequently developed preeclampsia compared with controls [geometric mean, 45.4 nmol/liter, and 95% confidence interval (CI), 38.6-53.4 nmol/liter, vs. 53.1 and 47.1-59.9 nmol/liter; P < 0.01]. There was a monotonic dose-response relation between serum 25(OH)D concentrations at less than 22 wk and risk of preeclampsia. After confounder adjustment, a 50-nmol/liter decline in 25(OH)D concentration doubled the risk of preeclampsia (adjusted odds ratio, 2.4; 95% CI, 1.1-5.4). Newborns of preeclamptic mothers were twice as likely as control newborns to have 25(OH)D less than 37.5 nmol/liter (adjusted odds ratio, 2.2; 95% CI, 1.2-4.1). Maternal vitamin D deficiency may be an independent risk factor for preeclampsia. Vitamin D supplementation in early pregnancy should be explored for preventing preeclampsia and promoting neonatal well-being.",success
30209050,True,"Clinical Trial, Phase III;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",NCT01355159,databank,NCT01355159;ISRCTN23781770,NCT01355159,NCT01355159,NCT01355159|databank,NCT01355159|databank,True,"To determine the efficacy of high dose folic acid supplementation for prevention of pre-eclampsia in women with at least one risk factor: pre-existing hypertension, prepregnancy diabetes (type 1 or 2), twin pregnancy, pre-eclampsia in a previous pregnancy, or body mass index ≥35. Randomised, phase III, double blinded international, multicentre clinical trial. 70 obstetrical centres in five countries (Argentina, Australia, Canada, Jamaica, and UK). 2464 pregnant women with at least one high risk factor for pre-eclampsia were randomised between 2011 and 2015 (1144 to the folic acid group and 1157 to the placebo group); 2301 were included in the intention to treat analyses. Eligible women were randomised to receive either daily high dose folic acid (four 1.0 mg oral tablets) or placebo from eight weeks of gestation to the end of week 16 of gestation until delivery. Clinicians, participants, adjudicators, and study staff were masked to study treatment allocation. The primary outcome was pre-eclampsia, defined as hypertension presenting after 20 weeks' gestation with major proteinuria or HELLP syndrome (haemolysis, elevated liver enzymes, low platelets). Pre-eclampsia occurred in 169/1144 (14.8%) women in the folic acid group and 156/1157 (13.5%) in the placebo group (relative risk 1.10, 95% confidence interval 0.90 to 1.34; P=0.37). There was no evidence of differences between the groups for any other adverse maternal or neonatal outcomes. Supplementation with 4.0 mg/day folic acid beyond the first trimester does not prevent pre-eclampsia in women at high risk for this condition. Current Controlled Trials ISRCTN23781770 and ClinicalTrials.gov NCT01355159.",success
2664523,True,Clinical Trial;Journal Article;Randomized Controlled Trial,,,,,,,,True,"There is evidence that aspirin in low doses favorably influences the course of pregnancy-induced hypertension, but the mechanism, although assumed to involve suppression of the production of thromboxane by platelets, has not been established. We performed a randomized study of the effect of the long-term daily administration of 60 mg of aspirin (n = 17) or placebo (n = 16) on platelet thromboxane A2 and vascular prostacyclin in women at risk for pregnancy-induced hypertension. Low doses of aspirin were associated with a longer pregnancy and increased weight of newborns. Serum levels of thromboxane B2, a stable product of thromboxane A2, were almost completely (greater than 90 percent) inhibited by low doses of aspirin. The urinary excretion of immunoreactive thromboxane B2 was significantly reduced without changes in the level of 6-keto-prostaglandin F1 alpha, a product of prostacyclin. Mass spectrometric analysis showed that aspirin reduced the excretion of the 2,3-dinor-thromboxane B2 metabolite--mainly of platelet origin--by 81 percent and of thromboxane B2, probably chiefly of renal origin, by 59 percent. The urinary excretion of 6-keto-prostaglandin F1 alpha and of its metabolite 2,3-dinor-6-keto-prostaglandin F1 alpha was not affected. Low doses of aspirin only partially (63 percent) reduced neonatal serum thromboxane B2. No hemorrhagic complications were observed in the newborns. Thus, in women at risk for pregnancy-induced hypertension, low doses of aspirin selectively suppressed maternal platelet thromboxane B2 while sparing vascular prostacyclin, but only partially suppressed neonatal platelet thromboxane B2, allowing hemostatic competence in the fetus and newborn.",success
2664522,True,Clinical Trial;Journal Article;Randomized Controlled Trial,,,,,,,,True,"We carried out a prospective, randomized, double-blind, placebo-controlled study to investigate the capacity of aspirin to prevent pregnancy-induced hypertension and to alter prostaglandin metabolism. A total of 791 pregnant women with various risk factors for pre-eclamptic toxemia were screened with use of the rollover test (a comparison of blood pressure before and after the woman rolls from her left side to her back) during week 28 or 29 of gestation. Of 69 women with abnormal results (an increase in blood pressure during the rollover test), 65 entered the study and were treated with a daily dose of either aspirin (100 mg; 34 women) or placebo (31 women) during the third trimester of pregnancy. The number of women in whom pregnancy-induced hypertension developed was significantly lower among the aspirin-treated than among the placebo-treated women (4 [11.8 percent] vs. 11 [35.5 percent]; P = 0.024); the same was true for the incidence of preeclamptic toxemia (1 [2.9 percent] vs 7 [22.6 percent]; P = 0.019). The mean ratio of serum levels of thromboxane A2 to serum levels of prostacyclin metabolites after three weeks of treatment decreased by 34.7 percent in the aspirin-treated group but increased by 51.2 percent in the placebo-treated group. No serious maternal or neonatal side effects of treatment occurred in either group. We conclude that low daily doses of aspirin taken during the third trimester of pregnancy significantly reduce the incidence of pregnancy-induced hypertension and pre-eclamptic toxemia in women at high risk for these disorders, possibly through the correction of an imbalance between levels of thromboxane and prostacyclin.",success
27640943,False,Journal Article;Meta-Analysis;Systematic Review,,,,,,,,True,"Preeclampsia and fetal growth restriction are major causes of perinatal death and handicap in survivors. Randomized clinical trials have reported that the risk of preeclampsia, severe preeclampsia, and fetal growth restriction can be reduced by the prophylactic use of aspirin in high-risk women, but the appropriate dose of the drug to achieve this objective is not certain. We sought to estimate the impact of aspirin dosage on the prevention of preeclampsia, severe preeclampsia, and fetal growth restriction. We performed a systematic review and meta-analysis of randomized controlled trials comparing the effect of daily aspirin or placebo (or no treatment) during pregnancy. We searched MEDLINE, Embase, Web of Science, and Cochrane Central Register of Controlled Trials up to December 2015, and study bibliographies were reviewed. Authors were contacted to obtain additional data when needed. Relative risks for preeclampsia, severe preeclampsia, and fetal growth restriction were calculated with 95% confidence intervals using random-effect models. Dose-response effect was evaluated using meta-regression and reported as adjusted R<sup>2</sup>. Analyses were stratified according to gestational age at initiation of aspirin (≤16 and >16 weeks) and repeated after exclusion of studies at high risk of biases. In all, 45 randomized controlled trials included a total of 20,909 pregnant women randomized to between 50-150 mg of aspirin daily. When aspirin was initiated at ≤16 weeks, there was a significant reduction and a dose-response effect for the prevention of preeclampsia (relative risk, 0.57; 95% confidence interval, 0.43-0.75; P < .001; R<sup>2</sup>, 44%; P = .036), severe preeclampsia (relative risk, 0.47; 95% confidence interval, 0.26-0.83; P = .009; R<sup>2</sup>, 100%; P = .008), and fetal growth restriction (relative risk, 0.56; 95% confidence interval, 0.44-0.70; P < .001; R<sup>2</sup>, 100%; P = .044) with higher dosages of aspirin being associated with greater reduction of the 3 outcomes. Similar results were observed after the exclusion of studies at high risk of biases. When aspirin was initiated at >16 weeks, there was a smaller reduction of preeclampsia (relative risk, 0.81; 95% confidence interval, 0.66-0.99; P = .04) without relationship with aspirin dosage (R<sup>2</sup>, 0%; P = .941). Aspirin initiated at >16 weeks was not associated with a risk reduction or a dose-response effect for severe preeclampsia (relative risk, 0.85; 95% confidence interval, 0.64-1.14; P = .28; R<sup>2</sup>, 0%; P = .838) and fetal growth restriction (relative risk, 0.95; 95% confidence interval, 0.86-1.05; P = .34; R<sup>2</sup>, not available; P = .563). Prevention of preeclampsia and fetal growth restriction using aspirin in early pregnancy is associated with a dose-response effect. Low-dose aspirin initiated at >16 weeks' gestation has a modest or no impact on the risk of preeclampsia, severe preeclampsia, and fetal growth restriction. Women at high risk for those outcomes should be identified in early pregnancy.",success
27810551,False,Journal Article;Meta-Analysis;Review,,,,,,,,True,"The optimum time for commencing antiplatelet therapy for the prevention of preeclampsia and its complications is unclear. Aggregate data meta-analyses suggest that aspirin is more effective if given prior to 16 weeks' gestation, but data are limited because of an inability to place women in the correct gestational age subgroup from relevant trials. The objective of the study was to use the large existing individual participant data set from the Perinatal Antiplatelet Review of International Studies Collaboration to assess whether the treatment effects of antiplatelet agents on preeclampsia and its complications vary based on whether treatment is started before or after 16 weeks' gestation. A meta-analysis of individual participant data including 32,217 women and 32,819 babies recruited to 31 randomized trials comparing low-dose aspirin or other antiplatelet agents with placebo or no treatment for the prevention of preeclampsia has been published previously. Using this existing data set, we performed a prespecified subgroup analysis based on gestation at randomization to antiplatelet agents before 16 weeks, compared with at or after 16 weeks, for 4 of the main outcomes prespecified in the Perinatal Antiplatelet Review of International Studies protocol: preeclampsia, death of baby, preterm birth before 34 weeks, and small-for-gestational-age baby. Individual participant data for the subgroups were combined in a meta-analysis using RevMan software. Heterogeneity was assessed with the I<sup>2</sup> statistic. The χ<sup>2</sup> test for interaction was used to assess statistically significant (P < .05) differences in treatment effect between subgroups. There was no significant difference in the effects of antiplatelet therapy for women randomized before 16 weeks' gestation compared with those randomized at or after 16 weeks for any of the 4 prespecified outcomes: preeclampsia, relative risk, 0.90, (95% confidence interval, 0.79-1.03; 17 trials, 9241 women) for <16 weeks and relative risk, 0.90 (95% confidence interval, 0.83-0.98; 22 trials, 21,429 women) for ≥16 weeks (interaction test, P = .98); death of baby, relative risk, 0.89 (95% confidence interval, 0.73-1.09; 15 trials, 8626 women) for <16 weeks and relative risk, 0.92 (95% confidence interval, 0.79-1.07; 21 trials, 22,336 women) for ≥16 weeks (interaction test, P = .80); preterm birth prior to 34 weeks, relative risk, 0.90 (95% confidence interval, 0.77-1.04; 19 trials, 9155 women) for <16 weeks and relative risk, 0.91 (95% confidence interval, 0.82-1.00; 25 trials, 22,117 women) for ≥16 weeks (interaction test, P = .91); and small-for-gestational-age baby, relative risk, 0.76 (95% confidence interval, 0.61-0.94; 13 trials, 6393 women) for <16 weeks and relative risk, 0.95 (95% confidence interval, 0.84-1.08; 18 trials, 14,996 women) for ≥16 weeks (interaction test, P = .08). The effect of low-dose aspirin and other antiplatelet agents on preeclampsia and its complications is consistent, regardless of whether treatment is started before or after 16 weeks' gestation. Women at an increased risk of preeclampsia should be offered antiplatelet therapy, regardless of whether they are first seen before or after 16 weeks' gestation.",success
29044702,False,"Journal Article;Meta-Analysis;Research Support, Non-U.S. Gov't;Systematic Review",,,,,,,,True,"To perform meta-analyses of studies evaluating the risk of pre-eclampsia in high-risk insulin-resistant women taking metformin prior to, or during pregnancy. A search was conducted of the Medline, EMBASE, Web of Science and Scopus databases. Both randomized controlled trials and prospective observational cohort studies of metformin treatment vs. placebo/control or insulin either prior to or during pregnancy were selected. The main outcome measure was the incidence of pre-eclampsia in each treatment group. Overall, in five randomized controlled trials comparing metformin treatment (n = 611) with placebo/control (n = 609), no difference in the risk of pre-eclampsia was found [combined/pooled risk ratio (RR), 0.86 (95% CI 0.33-2.26); P = 0.76; I<sup>2</sup>  = 66%]. Meta-analysis of four cohort studies again showed no significant effect [RR, 1.21 (95% CI 0.56-2.61); P = 0.62; I<sup>2</sup>  = 30%]. A meta-analysis of eight randomized controlled trials comparing metformin (n = 838) with insulin (n = 836), however, showed a reduced risk of pre-eclampsia with metformin [RR, 0.68 (95% CI 0.48-0.95); P = 0.02; I<sup>2</sup>  = 0%]. No heterogeneity was present in the metformin vs. insulin analysis of randomized controlled trials, whereas high levels of heterogeneity were present in studies comparing metformin with placebo/control. Pre-eclampsia was a secondary outcome in most of the studies. The mean weight gain from time of enrolment to delivery was lower in the metformin group (P = 0.05, metformin vs. placebo; P = 0.004, metformin vs. insulin). In studies randomizing pregnant women to glucose-lowering therapy, metformin was associated with lower gestational weight gain and a lower risk of pre-eclampsia compared with insulin.",success
21465139,False,Journal Article;Review,,,,,,,,True,"Preeclampsia is a pregnancy-induced hypertensive disorder found most commonly in nulliparous women. Recent research performed in animal models of the disease has revealed some of the underlying mechanisms of preeclampsia. Specifically, placental insufficiency and the resulting hypoxia/ischemia have been shown to be crucial to disease progression. In response to placental hypoxia/ischemia, several pathways are activated, which contribute to the clinical manifestations of the disease: increased circulating levels of the anti-angiogenic protein sFlt-1, activation of the maternal inflammatory response, suppressed nitric oxide production, enhanced endothelin-1 production, and induction of reactive oxygen formation. Despite advances in the understanding of the disorder, therapeutic approaches to the treatment of preeclampsia are severely limited. New lines of research, however, indicate some possible new therapeutic approaches for the management of preeclampsia and offer hope for an effective pharmacologic intervention.",success
19843000,True,"Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",NCT00141310,databank,NCT00141310,NCT00141310,NCT00141310,NCT00141310|databank,NCT00141310|databank,True,"To determine if the phosphodiesterase type 5 inhibitor sildenafil prolongs pregnancy in women with preeclampsia. Women with preeclampsia at gestational ages 24-34 weeks were recruited from nine hospitals in the UK, and randomly assigned to sildenafil citrate or placebo. Medication was increased every 3 days from 20 mg three times daily (tid), to 40 mg, and 80 mg tid. The primary endpoint was prolongation of pregnancy from randomisation to delivery (days). Secondary endpoints were markers of maternal disease and cord pH at delivery and infant weight. Details of all adverse events were also collected. Plasma samples were taken to establish pharmacokinetic information. Data analysed on a modified intention to treat analysis. The study had a power of >95% to detect a difference of 5 days. Of 35 women, 17 were allocated to sildenafil and 18 to placebo. There was no difference in time from randomisation to delivery in the two treatment groups, with a median time of 4 days (range 1-15) in the sildenafil group and 4.5 days (range 1-30) in the placebo group. Sildenafil achieved maximum drug concentrations of 48 ng/ml, 88 ng/ml, and 271 ng/ml after 3 days of 20 mg, 40 mg and 80 mg tid, respectively. We have safely conducted a clinical trial of a drug not routinely used during pregnancy. Sildenafil in the escalating dose regimen 20-80 mg tid was well tolerated, with no increase in maternal or fetal morbidity or mortality but did not prolong pregnancy duration in women with preeclampsia. (ClinicalTrials.gov number, NCT 00141310).",success
27400005,True,"Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",,,,,,,,True,"To evaluate whether therapy with sildenafil citrate prolongs gestation in women with preeclampsia. In a randomized double-blind, placebo-controlled trial, 100 singleton pregnancies with preeclampsia between 24 and 33 weeks of gestation were randomized to 50 mg oral sildenafil citrate every 8 hours or placebo. The primary outcome was prolongation of pregnancy from randomization to delivery. Secondary outcomes were changes in resistance indices of uterine, umbilical, and middle cerebral arteries by Doppler, fetal and maternal complications, and adverse neonatal outcomes. Power analysis estimated that to detect a difference of 5 days in pregnancy duration, 43 patients would have to be randomized to each group. From June 2013 to October 2015, 50 patients were randomized to each group. Pregnancy duration was on average 4 days longer (14.4 days, 95% confidence interval [CI] 12.5-16.6 days compared with 10.4 days, 95% CI 8.4-12.3 days, P=.008) and percent reduction in pulsatility indices of uterine and umbilical arteries higher (22.5% and 18.5%, compared with placebo 2.1% and 2.5%, P<.001) for patients treated with sildenafil compared with placebo. Maternal blood pressure before and 24 hours after randomization was lower with sildenafil (sildenafil: 100.3±5.6 mm Hg compared with 116.4±5.1 mm Hg, P<.05; placebo: 110.6±6.2 mm Hg compared with 114.7±6.5 mm Hg, P=.21). There was no difference in perinatal morbidity, mortality, or adverse effects between groups. Therapy with sildenafil citrate was associated with pregnancy prolongation of approximately 4 days compared with placebo in women with preeclampsia. Brazilian Registry of Clinical Trials, www.ensaiosclinicos.gov.br, RBR-8qj4p5.",success
21962629,False,Journal Article;Review,,,,,,,,True,"Gestational hypertension/pre-eclampsia is the most frequent obstetrical complication, complicating 26%-29% of all gestations in nulliparous women. In general, the diagnosis of mild gestational hypertension/pre-eclampsia is made at 38 weeks or more in approximately 80% of cases. For many years, the optimal timing of delivery for patients with mild gestational hypertension/pre-eclampsia at 37-0/7 to 39-6/7 weeks was unclear. Recently, investigators of the HYPITAT (Pregnancy-induced hypertension and pre-eclampsia after 36 weeks: induction of labor versus expectant monitoring: A comparison of maternal and neonatal outcome, maternal quality of life and costs) randomized trial evaluated maternal and neonatal complications in patients at 36-40 weeks' gestation who were randomized to either induction of labor or expectant monitoring. The results of this trial revealed that induction of labor at or after 37-0 weeks was associated with lower rate of maternal complications without increased rates of either cesarean delivery or neonatal complications. In contrast, the optimum management for those with mild hypertension/pre-eclampsia with stable maternal and fetal conditions at 34-0/7 to 36-6/7 weeks remains uncertain. Therefore, there is urgent need for research to evaluate the reasons for late preterm birth in such women as well as for a randomized trial to evaluate the optimal timing for delivery in such patients.",success
19656558,True,"Comparative Study;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",,,ISRCTN08132825,,,,,True,"Robust evidence to direct management of pregnant women with mild hypertensive disease at term is scarce. We investigated whether induction of labour in women with a singleton pregnancy complicated by gestational hypertension or mild pre-eclampsia reduces severe maternal morbidity. We undertook a multicentre, parallel, open-label randomised controlled trial in six academic and 32 non-academic hospitals in the Netherlands between October, 2005, and March, 2008. We enrolled patients with a singleton pregnancy at 36-41 weeks' gestation, and who had gestational hypertension or mild pre-eclampsia. Participants were randomly allocated in a 1:1 ratio by block randomisation with a web-based application system to receive either induction of labour or expectant monitoring. Masking of intervention allocation was not possible. The primary outcome was a composite measure of poor maternal outcome--maternal mortality, maternal morbidity (eclampsia, HELLP syndrome, pulmonary oedema, thromboembolic disease, and placental abruption), progression to severe hypertension or proteinuria, and major post-partum haemorrhage (>1000 mL blood loss). Analysis was by intention to treat and treatment effect is presented as relative risk. This study is registered, number ISRCTN08132825. 756 patients were allocated to receive induction of labour (n=377 patients) or expectant monitoring (n=379). 397 patients refused randomisation but authorised use of their medical records. Of women who were randomised, 117 (31%) allocated to induction of labour developed poor maternal outcome compared with 166 (44%) allocated to expectant monitoring (relative risk 0.71, 95% CI 0.59-0.86, p<0.0001). No cases of maternal or neonatal death or eclampsia were recorded. Induction of labour is associated with improved maternal outcome and should be advised for women with mild hypertensive disease beyond 37 weeks' gestation. ZonMw.",success
12548227,True,Journal Article;Multicenter Study,,,,,,,,True,"Current treatment of preeclampsia no longer mandates delivery for proteinuria of >5 g per 24 hours. We sought to determine whether delayed delivery of preeclampsia with massive proteinuria (>10 g/24 h) increased maternal or neonatal morbidity. Records of all women with preeclampsia who were delivered at <37 weeks of gestation between January 1, 1997, and June 30, 2001, were reviewed. Patients with underlying renal disease or multiple gestation were excluded. Patients were characterized as having mild (<5 g/24 h), severe (5-9.9 g/24 h), or massive (>10 g/24 h) proteinuria. Outcomes were compared using the chi(2) test, one-way analysis of variance, or Fisher exact test. Two hundred nine patients met the inclusion criteria: 125 patients had mild proteinuria, 43 patients had severe proteinuria, and 41 patients had massive proteinuria. No significant differences in maternal morbidity were seen. Massive proteinuria was associated with earlier onset of preeclampsia, earlier gestational age at delivery, and higher rates of prematurity complications. After correction for prematurity, massive proteinuria has no significant effect on neonatal outcomes. Women with preeclampsia and massive proteinuria did not have increased maternal morbidity compared with women with severe or mild proteinuria. Massive proteinuria appears to be a marker for early-onset disease and progression to severe preeclampsia. Neonatal morbidity appears to be a function of prematurity rather than of massive proteinuria itself.",success
19277923,False,Journal Article;Meta-Analysis;Systematic Review,,,,,,,,True,"To compare outcomes associated with expectant vs. interventionist care of severe preeclampsia in observational studies. Medline (01/1980-07/2007), bibliographies of retrieved papers, personal files, Cochrane Database of Systematic Reviews. Expectant or interventionist care of preeclampsia at <34 wk. TABULATION, INTEGRATION, RESULTS: Data abstraction independently by two reviewers. Median [IQR] of clinical maternal/perinatal outcomes presented. 72 publications, primarily from tertiary care centres in Dutch and developed world sites. Expectant care of severe preeclampsia <34 wk (39 cohorts, 4,650 women), for which 40% of women are eligible, is associated with pregnancy prolongation of 7-14 d, and few serious maternal complications (median <5%), similar to interventionist care (2 studies, 42 women). Complication rates are higher with HELLP <34wk (12 cohorts, 438 women) and severe preeclampsia <28wk (6 cohorts, 305 women), similar to interventionist care (6 cohorts, 467 women and 2 cohorts, 70 women, respectively). Expectant care of HELLP <34 wk (12 cohorts, 438 women) is associated with fewer days gained (median 5), but more serious maternal morbidity (e.g., eclampsia, median 15%). More than half of women have at least temporary improvement of HELLP. In the developed world, expectant (vs. interventionist) care of severe preeclampsia or HELLP <34 wk is associated with reduced neonatal death and complications. Stillbirth is higher in Dutch and developing world sites where viability thresholds are higher. For preeclampsia <24wk (4 cohorts), perinatal mortality is >80%. No predictors of adverse maternal/perinatal outcomes were identified (13 studies). Future research should establish the best maternal/fetal monito regimen and indications for delivery with expectant care. A definitive RCT is needed.",success
23954534,True,"Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",,,,,,,,True,"The objective of the study was to determine whether expectant management of severe preeclampsia prior to 34 weeks of gestation results in improved neonatal outcome in countries with limited resources. This was a randomized clinical trial performed in 8 tertiary hospitals in Latin America. Criteria of randomization included gestational age between 28 and 33 weeks' gestation and the presence of severe hypertensive disorders. Patients were randomized to steroids with prompt delivery (PD group) after 48 hours vs steroids and expectant management (EXM group). The primary outcome was perinatal mortality. A total of 267 patients were randomized, 133 to the PD group and 134 to the EXM group. Pregnancy prolongation was 2.2 days for the PD group vs 10.3 days for the EXM group (P = .0001). The rate of perinatal mortality (9.4% vs 8.7%; P = .81; relative risk [RR], 0.91; 95% confidence interval [CI], 0.34-1.93) was not improved with expectant management, and neither was the composite of neonatal morbidities (56.4% vs 55.6%; P = .89; RR, 01.01; 95% CI, 0.81-1.26). There was no significant difference in maternal morbidity in the EXM group compared with the PD group (25.2% vs 20.3%; P = .34; RR, 1.24; 95% CI, 0.79-1.94). However, small gestational age (21.7% vs 9.4%; P = .005; RR, 2.27; 95% CI, 1.21-4.14) and abruption were more common with expectant management (RR, 5.07; 95% CI, 1.13-22.7; P = .01). There were no maternal deaths. This study does not demonstrate neonatal benefit with expectant management of severe preeclampsia from 28 to 34 weeks. Additionally, a conservative approach may increase the risk of abruption and small for gestational age.",success
28059842,False,Journal Article;Review,,,,,,,,True,"Preeclampsia with severe features (SPE) remote from term remains a major cause of maternal morbidity and mortality worldwide. With increasing diagnosis of SPE remote from term and improved methods for monitoring maternal and fetal well-being, several challenges have been made regarding management of preeclampsia. We reviewed the scientific literature of the diagnosis and outcome of SPE before 28 weeks. On the basis of this review, we will present our recommendations on management of SPE before 28 weeks' gestation. In summary, expectant management of SPE at <28 weeks is appropriate in selected cases. Careful in-hospital maternal and fetal surveillance are recommended.",success
31348224,False,Consensus Development Conference;Journal Article,,,,,,,,True,"Maternal mortality and severe maternal morbidity, particularly among women of color, have increased in the United States. The leading medical causes of maternal mortality include cardiovascular disease, infection, and common obstetric complications such as hemorrhage, and vary by timing relative to the end of pregnancy. Although specific modifications in the clinical management of some of these conditions have been instituted, more can be done to improve the system of care for high-risk women at facility and population levels. The goal of levels of maternal care is to reduce maternal morbidity and mortality, including existing disparities, by encouraging the growth and maturation of systems for the provision of risk-appropriate care specific to maternal health needs. To standardize a complete and integrated system of perinatal regionalization and risk-appropriate maternal care, this classification system establishes levels of maternal care that pertain to basic care (level I), specialty care (level II), subspecialty care (level III), and regional perinatal health care centers (level IV). The determination of the appropriate level of care to be provided by a given facility should be guided by regional and state health care entities, national accreditation and professional organization guidelines, identified regional perinatal health care service needs, and regional resources. State and regional authorities should work together with the multiple institutions within a region, and with the input from their obstetric care providers, to determine the appropriate coordinated system of care and to implement policies that promote and support a regionalized system of care. These relationships enhance the ability of women to give birth safely in their communities while providing support for circumstances when higher level resources are needed. This document is a revision of the original 2015 Levels of Maternal Care Obstetric Care Consensus, which has been revised primarily to clarify terminology and to include more recent data based on published literature and feedback from levels of maternal care implementation.",success
11040855,False,Journal Article;Review,,,,,,,,True,"Hypertension affects 10% of pregnancies in the United States and remains a leading cause of both maternal and fetal morbidity and mortality. Hypertension in pregnancy includes a spectrum of conditions, most notably preeclampsia, a form of hypertension unique to pregnancy that occurs de novo or superimposed on chronic hypertension. Risks to the fetus include premature delivery, growth retardation, and death. The only definitive treatment of preeclampsia is delivery. Treatment of severe hypertension is necessary to prevent cerebrovascular, cardiac, and renal complications in the mother. The 2 other forms of hypertension, chronic and transient hypertension, usually have more benign courses. Optimal treatment of high blood pressure in pregnancy requires consideration of several aspects unique to gestational cardiovascular physiology. The major goal is to prevent maternal complications without compromising uteroplacental perfusion and fetal circulation. Before an antihypertensive agent is prescribed, the potential risk to the fetus from intrauterine drug exposure should be carefully reviewed.",success
15699287,False,Comparative Study;Guideline;Journal Article;Practice Guideline,,,,,,,,True,"Accurate measurement of blood pressure is essential to classify individuals, to ascertain blood pressure-related risk, and to guide management. The auscultatory technique with a trained observer and mercury sphygmomanometer continues to be the method of choice for measurement in the office, using the first and fifth phases of the Korotkoff sounds, including in pregnant women. The use of mercury is declining, and alternatives are needed. Aneroid devices are suitable, but they require frequent calibration. Hybrid devices that use electronic transducers instead of mercury have promise. The oscillometric method can be used for office measurement, but only devices independently validated according to standard protocols should be used, and individual calibration is recommended. They have the advantage of being able to take multiple measurements. Proper training of observers, positioning of the patient, and selection of cuff size are all essential. It is increasingly recognized that office measurements correlate poorly with blood pressure measured in other settings, and that they can be supplemented by self-measured readings taken with validated devices at home. There is increasing evidence that home readings predict cardiovascular events and are particularly useful for monitoring the effects of treatment. Twenty-four-hour ambulatory monitoring gives a better prediction of risk than office measurements and is useful for diagnosing white-coat hypertension. There is increasing evidence that a failure of blood pressure to fall during the night may be associated with increased risk. In obese patients and children, the use of an appropriate cuff size is of paramount importance.",success
17766606,False,Journal Article,,,,,,,,True,"To estimate whether magnesium therapy is the optimal management for women with mild preeclampsia. A decision analytic model was designed for women with mild preeclampsia to estimate whether empiric magnesium therapy or no magnesium therapy is the optimal management strategy. The model considered relevant clinical events: seizure, placental abruption, and magnesium toxicity. Modeled outcomes were maternal mortality, neonatal mortality, and neurologic neonatal compromise. The two strategies were compared based on the probability of clinical events and outcomes and the utilities or values assigned to the outcomes by prior research. Probabilities and utilities were derived from the literature. The base-case analysis showed that although the no-magnesium strategy results in a 15% reduction in neonatal mortality and avoids most maternal drug toxicity, it produces a twofold increase in maternal death and more neurologically compromised neonates compared with empiric magnesium. The two strategies are essentially equivalent with regard to aggregate maternal and neonatal outcomes (0.9792 compared with 0.9781 utilities). Multivariable sensitivity analysis using Monte Carlo simulation confirmed the decision to be a ""toss-up,"" yielding a similar mean utility for no-magnesium and magnesium strategies (0.9789+/-0.1374 compared with 0.9784+/-0.1390, respectively). Our decision model indicates that either strategy, using or not using empiric magnesium sulfate therapy, is acceptable. The clinical decision of whether to use magnesium in patients with mild preeclampsia for seizure prophylaxis should be determined by the physician or institution, considering patient values or preferences and the unique risk-benefit trade-off of each strategy.",success
15284724,False,Comparative Study;Journal Article;Review,,,,,,,,True,"In the US, the routine use of magnesium sulfate for seizure prophylaxis in women with preeclampsia is an ingrained obstetric practice. During the past decade, several observational studies and randomized trials have described the use of various regimens of magnesium sulfate to prevent or reduce the rate of seizures and complications in women with preeclampsia. There are only 2 double-blind, placebo-controlled trials evaluating the use of magnesium sulfate in mild preeclampsia. There were no instances of eclampsia among 181 women assigned to placebo, and there were no differences in the percentage of women who progressed to severe preeclampsia (12.5% in magnesium group vs 13.8% in the placebo group, relative risk [RR] 0.90; 95% CI 0.52-1.54). However, the number of women enrolled in these trials is too limited to draw any valid conclusions. There are 4 randomized controlled trials that compare the use of no magnesium sulfate, or a placebo vs magnesium sulfate, to prevent convulsions in patients with severe preeclampsia. The rate of eclampsia was 0.6% among 6343 patients assigned to magnesium sulfate vs 2.0 % among 6330 patients assigned to a placebo or control (RR 0.39; 95% CI 0.28-0.55). However, the reduction in the rate of eclampsia was not associated with a significant benefit in either maternal or perinatal outcome. In addition, there was a higher rate of maternal respiratory depression among those assigned magnesium sulfate (RR 2.06; 95% CI 1.33-3.18). The evidence to date confirms the efficacy of magnesium sulfate in reduction of seizures in women with eclampsia and severe preeclampsia; however, this benefit does not affect overall maternal and perinatal mortality and morbidities. The evidence regarding the benefit-to-risk ratio of magnesium sulfate prophylaxis in mild preeclampsia remains uncertain, and does not justify its routine use for that purpose.",success
2193561,False,Journal Article;Review,,,,,,,,True,"In studies in experimental animals and in edematous patients, the nonosmotic release of vasopressin has been found to be consistently associated with activation of the sympathetic nervous and renin-angiotensin-aldosterone systems. Moreover, the sympathetic nervous system is known to modulate the nonosmotic release of vasopressin and activation of the renin-angiotensin-aldosterone system. These findings led to our proposal that body fluid volume regulation involves dynamic interaction between cardiac output and peripheral arterial resistance. In this context, neither total extracellular fluid volume nor total blood volume are determinants of renal sodium and water excretion. With a decrease in effective arterial blood volume (EABV) initiated by either decreased cardiac output or peripheral arterial vasodilation, the acute response involves vasoconstriction mediated by angiotensin, sympathetic mediators, and vasopressin. The renal vasoconstriction, which accompanies either decreased cardiac output or peripheral arterial vasodilation, causes a decreased distal tubular delivery of sodium and water, thus maximizing the water-retaining effect of vasopressin and impairing normal escape from the sodium-retaining effect of aldosterone. The elevated glomerular filtration rate and filtered sodium load seen in pregnant women allow increased distal sodium and water delivery despite a decrease in EABV, thus limiting edema formation during gestation.",success
8916993,False,Journal Article;Meta-Analysis,,,,,,,,True,"To evaluate the effectiveness of magnesium sulphate in the treatment of eclampsia and pre-eclampsia by a systematic quantitative overview of controlled clinical trials. Online searching of the MEDLINE database between 1966 and 1995, and scanning of the bibliography of known primary studies and review articles on the use of magnesium sulphate in eclampsia and pre-eclampsia. Study-selection, study quality assessment and data extraction were performed independently by two reviewers under masked conditions. Where possible outcome data from trials were pooled and summarised using the Mantel-Haenszel method. One thousand seven hundred and forty-three women with eclampsia and 2390 with pre-eclampsia included in nine randomised trials that evaluated the effects of magnesium sulphate. Seizure activity and maternal death. In eclampsia, recurrence of seizures was less common with magnesium sulphate therapy compared with phenytoin (odds ratio [OR] 0.27, 95% CI 0.17-0.45, P = 0.00) and diazepam (OR 0.41, 95% CI 0.30-0.57, P = 0.00). As indicated by the point estimate, there was a trend towards a reduction in maternal mortality with magnesium sulphate in eclampsia (OR 0.51, 95% CI 0.24-1.07, P = 0.10 versus phenytoin; OR 0.78, 95% CI 0.41-1.45, P = 0.52 versus diazepam). When used for seizure prophylaxis in pre-eclampsia, magnesium sulphate was found to be more effective than phenytoin (OR 0.15, 95% CI 0.03-0.72, P = 0.01). Magnesium sulphate is a superior drug in preventing the recurrence of seizures in eclampsia and in seizure prophylaxis in pre-eclampsia.",success
12540643,True,"Clinical Trial;Comparative Study;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Magnesium sulfate may prevent eclampsia by reducing cerebral vasoconstriction and ischemia. Nimodipine is a calcium-channel blocker with specific cerebral vasodilator activity. Our objective was to determine whether nimodipine is more effective than magnesium sulfate for seizure prophylaxis in women with severe preeclampsia. We conducted an unblinded, multicenter trial in which 1650 women with severe preeclampsia were randomly assigned to receive either nimodipine (60 mg orally every 4 hours) or intravenous magnesium sulfate (given according to the institutional protocol) from enrollment until 24 hours post partum. High blood pressure was controlled with intravenous hydralazine as needed. The primary outcome measure was the development of eclampsia, as defined by a witnessed tonic-clonic seizure. Demographic and clinical characteristics were similar in the two groups. The women who received nimodipine were more likely to have a seizure than those who received magnesium sulfate (21 of 819 [2.6 percent] vs. 7 of 831 [0.8 percent], P=0.01). The adjusted risk ratio for eclampsia associated with nimodipine, as compared with magnesium sulfate, was 3.2 (95 percent confidence interval, 1.1 to 9.1). The antepartum seizure rates did not differ significantly between groups, but the nimodipine group had a higher rate of postpartum seizures (9 of 819 [1.1 percent] vs. 0 of 831, P=0.01). There were no significant differences in neonatal outcome between the two groups. More women in the magnesium sulfate group than in the nimodipine group needed hydralazine to control blood pressure (54.3 percent vs. 45.7 percent, P<0.001). Magnesium sulfate is more effective than nimodipine for prophylaxis against seizures in women with severe preeclampsia.",success
10803454,False,Journal Article;Review,,,,,,,,True,"Magnesium sulfate (MgSO4) is the agent most commonly used for treatment of eclampsia and prophylaxis of eclampsia in patients with severe pre-eclampsia. It is usually given by either the intramuscular or intravenous routes. The intramuscular regimen is most commonly a 4 g intravenous loading dose, immediately followed by 10 g intramuscularly and then by 5 g intramuscularly every 4 hours in alternating buttocks. The intravenous regimen is given as a 4 g dose, followed by a maintenance infusion of 1 to 2 g/h by controlled infusion pump. After administration, about 40% of plasma magnesium is protein bound. The unbound magnesium ion diffuses into the extravascular-extracellular space, into bone, and across the placenta and fetal membranes and into the fetus and amniotic fluid. In pregnant women, apparent volumes of distribution usually reach constant values between the third and fourth hours after administration, and range from 0.250 to 0.442 L/kg. Magnesium is almost exclusively excreted in the urine, with 90% of the dose excreted during the first 24 hours after an intravenous infusion of MgSO4. The pharmacokinetic profile of MgSO4 after intravenous administration can be described by a 2-compartment model with a rapid distribution (a) phase, followed by a relative slow beta phase of elimination. The clinical effect and toxicity of MgSO4 can be linked to its concentration in plasma. A concentration of 1.8 to 3.0 mmol/L has been suggested for treatment of eclamptic convulsions. The actual magnesium dose and concentration needed for prophylaxis has never been estimated. Maternal toxicity is rare when MgSO4 is carefully administered and monitored. The first warning of impending toxicity in the mother is loss of the patellar reflex at plasma concentrations between 3.5 and 5 mmol/L. Respiratory paralysis occurs at 5 to 6.5 mmol/L. Cardiac conduction is altered at greater than 7.5 mmol/L, and cardiac arrest can be expected when concentrations of magnesium exceed 12.5 mmol/L. Careful attention to the monitoring guidelines can prevent toxicity. Deep tendon reflexes, respiratory rate, urine output and serum concentrations are the most commonly followed variables. In this review, we will outline the currently available knowledge of the pharmacokinetics of MgSO4 and its clinical usage for women with pre-eclampsia and eclampsia.",success
26599617,False,"Journal Article;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"The pharmacokinetic basis of magnesium sulphate (MgSO4 ) dosing regimens for eclampsia prophylaxis and treatment is not clearly established. To review available data on clinical pharmacokinetic properties of MgSO4 when used for women with pre-eclampsia and/or eclampsia. MEDLINE, EMBASE, CINAHL, POPLINE, Global Health Library and reference lists of eligible studies. All study types investigating pharmacokinetic properties of MgSO4 in women with pre-eclampsia and/or eclampsia. Two authors extracted data on basic pharmacokinetic parameters reflecting the different aspects of absorption, bioavailability, distribution and excretion of MgSO4 according to identified dosing regimens. Twenty-eight studies investigating pharmacokinetic properties of 17 MgSO4 regimens met our inclusion criteria. Most women (91.5%) in the studies had pre-eclampsia. Baseline serum magnesium concentrations were consistently <1 mmol/l across studies. Intravenous loading dose between 4 and 6 g was associated with a doubling of this baseline concentration half an hour after injection. Maintenance infusion of 1 g/hour consistently produced concentrations well below 2 mmol/l, whereas maintenance infusion at 2 g/hour and the Pritchard intramuscular regimen had higher but inconsistent probability of producing concentrations between 2 and 3 mmol/l. Volume of distribution of magnesium varied (13.65-49.00 l) but the plasma clearance was fairly similar (4.28-5.00 l/hour) across populations. The profiles of Zuspan and Pritchard regimens indicate that the minimum effective serum magnesium concentration for eclampsia prophylaxis is lower than the generally accepted level. Exposure-response studies to identify effective alternative dosing regimens should target concentrations achievable by these standard regimens. Minimum effective serum magnesium concentration for eclampsia prophylaxis is lower than the generally accepted therapeutic level.",success
14572362,False,Comparative Study;Journal Article,,,,,,,,True,"We anticipated that the universal use of a standard magnesium sulfate infusion to prevent eclamptic convulsions in preeclamptic patients would result in alterations in circulating magnesium levels that were negatively correlated with the patient's body mass index. We postulated that the highest failure rate with seizure prophylaxis would occur in patients with the highest body mass index. After discarding 6 patients, this study was performed in 194 of 200 preeclamptic patients admitted to our high risk pregnancy unit between February 2000 and August 2000, who were divided into four groups determined by body mass indices. A standard magnesium sulfate infusion protocol (loading dose 4.5 g/15 minutes followed by 1.8 g/hour) was administered to 194 preeclamptic patients. One hundred and thirty-eight severe preeclamptic patients received magnesium sulfate during both antepartum and postpartum periods. The remaining 56 patients only received the therapy during the postpartum period. Serial serum magnesium levels of each groups were recorded and compared. The 1.8 g infusion rate produced acceptable magnesium levels in the majority of patients but most were in the lower 50% of the therapeutic range. Levels were lowest in patients with high body mass indices (this group recorded most of the subtherapeutic levels, particularly when patient were infused antepartum). Apart from 13 referred patients who had convulsed prior to admission no eclampsia occurred during the antepartum period while seizures occurred in nine women during the postpartum period. Two hours after the initiation of the therapy, magnesium levels were inversely related to the body mass index (BMI) both during the ante- and postpartum periods (Prepartum; group I: 5.97 mg/dl, group II: 4.90 mg/dl, group III: 4.35 mg/dl, group IV: 3.88 mg/dl; Postpartum; group I: 5.89 mg/dl, group II: 5.71 mg/dl, group III: 4.82 mg/dl and group IV: 4.61 mg/dl, Table 4). Although the lowest levels were detected in patients with high body mass indices, in contrast to our hypothesis, eclamptic seizures occurred in four patients with low body mass indices. Furthermore therapeutic serum magnesium levels were detected in three of these patients. There was no association between treatment failures and body mass or with magnesium levels. The infusion regimen described herein resulted in therapeutic levels in the majority of patients that correlated inversely with body mass index. However most levels fell within the lower range of what many studies consider ""therapeutic"" suggesting that maintenance infusion rates of at least 2-2.5 g/hour would be more appropriate. This would be particularly true in patients with body mass indices exceeding 30, where subtherapeutic levels occurred most frequently. The study's limited power prevents conclusions on outcomes but what is of interest is that eclamptic convulsions did not correlate with either body mass index or circulating plasma magnesium levels.",success
17012442,False,Journal Article,,,,,,,,True,"To describe the incidence of eclampsia in women with mild gestational hypertension when only women with severe gestational hypertension are given magnesium sulfate prophylaxis. This is a prospective 4(1/2)-year observational study. Those women who met our criteria for severe gestational hypertension received intravenous magnesium sulfate prophylaxis, and women with nonsevere hypertension did not. Data were collected at delivery to ascertain the incidence of eclampsia and maternal and neonatal morbidity. A total of 72,004 women were delivered during the study period, 6,431 had gestational hypertension, 3,935 met the criteria for severe disease and were given magnesium sulfate prophylaxis, 2,496 women with nonsevere hypertension were not treated. Eighty-seven women developed eclampsia, for an overall incidence of 1 in 828 deliveries, a 50% increase when compared with 5 preceding years where all women with gestational hypertension were given magnesium sulfate prophylaxis. Of the 2,496 women with nonsevere hypertension who were not treated, 27 had eclampsia (1 in 92). Women with eclampsia were more likely to require general anesthesia for cesarean delivery compared with hypertensive women without eclampsia (23% versus 4%, P < .001), but they had no additional morbidity. Infants of eclamptic mothers had more adverse outcomes than those without convulsions (12% versus 1%, P < .04). Selective magnesium sulfate prophylaxis results in an increased overall incidence of eclampsia because of more seizures in women with nonsevere gestational hypertension who are not given magnesium sulfate prophylaxis. II-3.",success
8616123,True,Clinical Trial;Journal Article;Randomized Controlled Trial,,,,,,,,False,,success
18771976,False,Comparative Study;Journal Article,,,,,,,,True,"The purpose of this study was to describe the success rate of and analyze differences in neonatal outcomes with labor induction, compared with elective cesarean delivery in women with early-onset severe preeclampsia. We conducted a cross-sectional study of women with severe preeclampsia who required delivery between 24 and 34 weeks of gestation. Bivariate and multivariable regression analyses were used to determine factors that were associated with assignment to, success of, and odds of neonatal outcomes after induction of labor. Fifty-seven and four-tenths percent of 491 women underwent induction of labor. Vaginal delivery occurred in 6.7%, 47.5%, and 68.8% of women who underwent labor induction between 24 and 28, 28 and 32, and 32 and 34 weeks of gestation, respectively. Induction of labor was not associated with an increase in neonatal morbidity or mortality rate after we controlled for gestational age and other confounders. Neonatal outcomes are not worsened by induction of labor in women with early-onset severe preeclampsia, although it is rarely successful at <28 weeks of gestation.",success
22071049,False,Journal Article;Review,,,,,,,,True,"We sought to review the risks and benefits of expectant management of severe preeclampsia remote from term, and to provide recommendations for expectant management, maternal and fetal evaluation, treatment, and indications for delivery. Studies were identified through a search of the MEDLINE database for relevant peer-reviewed articles published in the English language from January 1980 through December 2010. Additionally, the Cochrane Library, guidelines by organizations, and studies identified through review of the above documents and review articles were utilized to identify relevant articles. Where reliable data were not available, opinions of respected authorities were used. Published randomized trials and observational studies regarding management of severe preeclampsia occurring <34 weeks of gestation suggest that expectant management of selected patients can improve neonatal outcomes but that delivery is often required for worsening maternal or fetal condition. Patients who are not candidates for expectant management include women with eclampsia, pulmonary edema, disseminated intravascular coagulation, renal insufficiency, abruptio placentae, abnormal fetal testing, HELLP syndrome, or persistent symptoms of severe preeclampsia. For women with severe preeclampsia before the limit of viability, expectant management has been associated with frequent maternal morbidity with minimal or no benefits to the newborn. Expectant management of a select group of women with severe preeclampsia occurring <34 weeks' gestation may improve newborn outcomes but requires careful in-hospital maternal and fetal surveillance.",success
16116006,True,Clinical Trial;Comparative Study;Journal Article,,,,,,,,True,"We previously showed that, in comparison with term healthy parturients, patients with severe preeclampsia had a less frequent incidence of spinal hypotension, which was less severe and required less ephedrine. In the present study, we hypothesized that these findings were attributable to preeclampsia-associated factors rather than to a smaller uterine mass. The incidence and severity of hypotension were compared between severe preeclamptics (n = 65) and parturients with preterm pregnancies (n = 71), undergoing spinal anesthesia for cesarean delivery (0.5% bupivacaine, sufentanil, morphine). Hypotension was defined as the need for ephedrine (systolic blood pressure <100 mm Hg in parturients with preterm fetuses or 30% decrease in mean blood pressure in both groups). Apgar scores and umbilical arterial blood pH were also studied. Neonatal and placental weights were similar between the groups. Hypotension was less frequent in preeclamptic patients than in women with preterm pregnancies (24.6% versus 40.8%, respectively, P = 0.044). Although the magnitude of the decrease in systolic, diastolic, and mean arterial blood pressure was similar between groups, preeclamptic patients required less ephedrine than women in the preterm group to restore blood pressure to baseline levels (9.8 +/- 4.6 mg versus 15.8 +/- 6.2 mg, respectively, P = 0.031). The risk of hypotension in the preeclamptic group was almost 2 times less than that in the preterm group (relative risk = 0.603; 95% confidence interval, 0.362-1.003; P = 0.044). The impact of Apgar scores was minor, and umbilical arterial blood pH was not affected. We conclude that preeclampsia-associated factors, rather than a smaller uterine mass, account for the infrequent incidence of spinal hypotension in preeclamptic patients.",success
16116005,True,"Clinical Trial;Comparative Study;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",,,,,,,,True,"In this randomized, multicenter study we compared the hemodynamic effects of spinal and epidural anesthesia for cesarean delivery in severely preeclamptic patients. The epidural group (n = 47) received 2% lidocaine with epinephrine 1:400,000, 18-23 mL, followed by 3 mg of morphine after delivery. The spinal group (n = 53) received 2.2 mL of 0.5% hyperbaric bupivacaine plus 0.2 mg morphine. We hypothesized that the lowest MAP (mean arterial blood pressure, the primary outcome) during the delivery period would have to be at least 10 mm Hg less in the spinal group to be of clinical importance. We found that there was a statistically significant difference in MAP, with more patients in the spinal group exhibiting hypotension (P < 0.001). Although the incidence of hypotension (systolic arterial blood pressure, SAP < or =100 mm Hg) was more frequent in the spinal group than in the epidural group (51% versus 23%), the duration of significant hypotension (SAP < or =100 mm Hg) was short (< or =1 min) in both groups. There was more use of ephedrine in the spinal group than in the epidural group (median, 6 versus 0 mg) but hypotension was easily treated in all patients. Neonatal outcomes assessed by Apgar scores and the umbilical arterial blood gas analysis were similar in both groups. Adverse neonatal outcomes (5-min Apgar score < 7 and umbilical arterial blood pH < 7.20) were found in only 2 premature newborns (weight < 1500 g) who were born without maternal hypotension after regional anesthesia. We conclude that the results of this large prospective study support the use of spinal anesthesia for cesarean delivery in severely preeclamptic patients.",success
9054245,False,Journal Article,,,,,,,,True,"Anesthesia-related complications are the sixth leading cause of pregnancy-related death in the United States. This study reports characteristics of anesthesia-related deaths during obstetric delivery in the United States from 1979-1990. Each state reports deaths that occur within 1 yr of delivery to the Centers for Disease Control and Prevention as part of the ongoing Pregnancy Mortality Surveillance. Maternal death certificates (with identifiers removed) matched with live birth or fetal death certificates when available from 1979-1990 were reviewed to identify deaths due to anesthesia, the cause of death, the procedure for delivery, and the type of anesthesia provided. Maternal mortality rates per million live births were calculated. Case fatality rates and risk ratios were computed to compare general to regional anesthesia for cesarean section deliveries. The anesthesia-related maternal mortality rate decreased from 4.3 per million live births in the first triennium (1979-1981) to 1.7 per million in the last (1988-1990). The number of deaths involving general anesthesia have remained stable, but the number of regional anesthesia-related deaths have decreased since 1984. The case-fatality risk ratio for general anesthesia was 2.3 (95% confidence interval [CI], 1.9-2.9) times that for regional anesthesia before 1985, increasing to 16.7 (95% CI, 12.9-21.8) times that after 1985. Most maternal deaths due to complications of anesthesia occurred during general anesthesia for cesarean section. Regional anesthesia is not without risk, primarily because of the toxicity of local anesthetics and excessively high regional blocks. The incidence of these deaths is decreasing, however, and deaths due to general anesthesia remain stable in number and hence account for an increased proportion of total deaths. Heightened awareness of the toxicity of local anesthetics and related improvements in technique may have contributed to a reduction in complications of regional anesthesia.",success
20926478,True,"Journal Article;Multicenter Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"This study compared the stroke-free survival rates and hazard ratios (HRs) for stroke between preeclamptic women who received general anaesthesia and those who received neuraxial anaesthesia for Caesarean section (CS). This study used 2002-7 data from the Taiwan National Health Insurance Research Database. The stroke-free survival rate was estimated by the Kaplan-Meier method. The log-rank test was used to examine the difference in the stroke-free survival rates between general, spinal, and epidural anaesthesia. The Cox proportional hazard regression was used to estimate the HR for general anaesthesia. A total of 303 862 women underwent CS of which 8567 had preeclampsia (75 stroke cases) and 295 295 did not (303 stroke cases). The stroke-free survival rate was significantly lower in the preeclamptic women who received general anaesthesia when compared with those who received epidural (P=0.008) or spinal anaesthesia (P<0.001) within the 6 yr period after the index delivery. There was no statistically significant difference between spinal and epidural anaesthesia in terms of stroke rate (P=0.143). The unadjusted HR of stroke for general anaesthesia was 2.81 [95% confidence interval (CI), 1.69-4.64; P<0.001]. After adjusting for potential confounders, the adjusted HR for general anaesthesia was 2.38 (95% CI, 1.33-4.28; P=0.004) compared with neuraxial anaesthesia over a 1-6 yr follow-up period. In this study, general anaesthesia for CS delivery was associated with increased risk of stroke when compared with neuraxial anaesthesia in preeclamptic women.",success
7978443,False,Journal Article;Review,,,,,,,,False,,success
28383323,True,Journal Article;Multicenter Study;Observational Study,,,,,,,,True,"Thrombocytopenia has been considered a relative or even absolute contraindication to neuraxial techniques due to the risk of epidural hematoma. There is limited literature to estimate the risk of epidural hematoma in thrombocytopenic parturients. The authors reviewed a large perioperative database and performed a systematic review to further define the risk of epidural hematoma requiring surgical decompression in this population. The authors performed a retrospective cohort study using the Multicenter Perioperative Outcomes Group database to identify thrombocytopenic parturients who received a neuraxial technique and to estimate the risk of epidural hematoma. Patients were stratified by platelet count, and those requiring surgical decompression were identified. A systematic review was performed, and risk estimates were combined with those from the existing literature. A total of 573 parturients with a platelet count less than 100,000 mm who received a neuraxial technique across 14 institutions were identified in the Multicenter Perioperative Outcomes Group database, and a total of 1,524 parturients were identified after combining the data from the systematic review. No cases of epidural hematoma requiring surgical decompression were observed. The upper bound of the 95% CI for the risk of epidural hematoma for a platelet count of 0 to 49,000 mm is 11%, for 50,000 to 69,000 mm is 3%, and for 70,000 to 100,000 mm is 0.2%. The number of thrombocytopenic parturients in the literature who received neuraxial techniques without complication has been significantly increased. The risk of epidural hematoma associated with neuraxial techniques in parturients at a platelet count less than 70,000 mm remains poorly defined due to limited observations.",success
19775301,False,Journal Article;Review,,,,,,,,True,"Neuraxial anaesthesia is increasingly performed in thrombocytopenic patients at the time of delivery of pregnancy. There is a lack of data regarding the optimum platelet count at which spinal procedures can be safely performed. Reports are often confounded by the presence of other risk factors for spinal haematomata, such as anticoagulants, antiplatelet agents and other acquired or congenital coagulopathies/platelet function defects or rapidly falling platelet counts. In the absence of these additional risk factors, a platelet count of 80 x 10(9)/l is a 'safe' count for placing an epidural or spinal anaesthetic and 40 x 10(9)/l is a 'safe' count for lumbar puncture. It is likely that lower platelet counts may also be safe but there is insufficient published evidence to make recommendations for lower levels at this stage. For patients with platelet counts of 50-80 x 10(9)/l requiring epidural or spinal anaesthesia and patients with a platelet count 20-40 x 10(9)/l requiring a lumbar puncture, an individual decision based on assessment of risks and benefits should be made.",success
12015530,False,"Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Intravenous magnesium sulfate is widely used in obstetrics for the treatment of both preterm labor and preeclampsia. Although therapeutic levels of total magnesium have been proposed, the levels remain controversial. Because the active form of magnesium is the free or ionized form, it is essential to determine whether ionized magnesium and total magnesium levels are highly correlated in vivo. We sought to examine the correlation between ionized magnesium and total magnesium under basal and therapeutic conditions and to define the initiation and elimination pharmacokinetics of both forms during intravenous magnesium sulfate infusion. Twenty-four singleton pregnant patients who were candidates for magnesium sulfate were studied (preterm labor, 15; preeclampsia, 9). Serial blood samples were taken before the magnesium sulfate infusion, during the first 4 hours after the initiation of magnesium sulfate infusion and for 4 hours after the discontinuation of the infusion. Baseline levels of total magnesium and ionized magnesium were not different between patients with preterm labor and with preeclampsia. Among patients with preeclampsia, although not patients with preterm labor, the initial apparent volume of distribution was significantly smaller for total magnesium than for ionized magnesium (16,397 +/- 1441 vs 23,856 +/- 2745 mL, respectively; P =.03), and the elimination half-life was greater for total magnesium as compared to ionized magnesium (707 +/- 160 vs 313 +/- 29 minutes;P <.05). Linear regression analysis demonstrated a lack of correlation between ionized magnesium and total magnesium during the pretreatment period and during the steady state infusion for both preterm labor and preeclampsia. The measurement of total magnesium may not be adequate for the titration of therapeutic magnesium infusions in patients with preeclampsia or preterm labor because of the lack of correlation between total magnesium and the physiologically active ionized magnesium. Further studies may determine whether the measurement of ionized magnesium is a superior method for following the adequacy and safety of the treatment of preeclampsia and preterm labor.",success
21979459,False,Journal Article,,,,,,,,True,"To estimate and evaluate the demographics, clinical course, and complications of delayed postpartum preeclampsia in patients with and without eclampsia. We conducted a retrospective cohort study of patients who were discharged and later readmitted with the diagnosis of delayed postpartum preeclampsia more than 2 days to 6 weeks or less after delivery between January 2003 and August 2009. One hundred fifty-two patients met criteria for the diagnosis of delayed postpartum preeclampsia. Of these, 96 (63.2%) patients had no antecedent diagnosis of hypertensive disease in the current pregnancy, whereas seven (4.6%), 14 (9.2%), 28 (18.4%), and seven (4.6%) patients had gestational hypertension, chronic hypertension, preeclampsia, and preeclampsia superimposed on chronic hypertension, respectively, during the peripartum period. Twenty-two patients (14.5%) developed postpartum eclampsia, and more than 90% of these patients presented within 7 days after discharge from the hospital. The most common presenting symptom was headache in 105 (69.1%) patients. Patients who developed eclampsia were significantly younger than those who did not (mean ± standard deviation, 23.2 ± 6.2 compared with 28.3 ± 6.7 years; adjusted odds ratio [OR] 1.13, 95% confidence interval [CI] 1.02-1.26, P=.03), and other demographic variables were no different. A lower readmission hemoglobin was associated with a lower odds of progression to eclampsia (10.7 ± 1.7 compared with 11.6 ± 2.2 g/dL, adjusted OR 0.75, 95% CI 0.57-0.98, P=.04). One week after discharge appears to be a critical period for the development of postpartum eclampsia. Education about the possibility of delayed postpartum preeclampsia and eclampsia should occur after delivery, whether or not patients develop hypertensive disease before discharge from the hospital.",success
12066093,True,Journal Article;Multicenter Study,,,,,,,,True,"The purpose of this study was to determine whether there is a shift in the timing of eclampsia in relation to delivery and whether traditional symptoms precede impending postpartum eclampsia. A multicenter analysis of data from patients with eclampsia from March 1996 through February 2001 at the University of Cincinnati, the University of Tennessee, Memphis, and Central Baptist Hospital, Lexington. Data were collected regarding the relationship of the patient's first seizure to delivery, prodromal symptoms, neuroimaging studies, use of magnesium sulfate, antihypertensive therapy, and follow-up medical care. The analysis focused on women who had late postpartum eclampsia. During the study period, 89 patients were diagnosed with eclampsia. Twenty-nine women (33%) had postpartum eclampsia, of whom 23 women (79%) had late onset (>48 hours). Interestingly, only 5 of these 23 women (22%) had been previously diagnosed with preeclampsia. Twenty-one patients (91%) with late postpartum eclampsia had at least 1 prodromal symptom, and 12 patients (52%) had >1 symptom that heralded the seizure: 20 women (87%) had headache; 10 women (44%) had visual changes; 5 women (22%) had nausea or vomiting; and 2 women (9%) experienced epigastric pain. Only 7 of these 21 women (33%) sought care for their symptoms, of whom 6 women (86%) had clinical evidence of preeclampsia that was not considered by the treating physician. Among all patients with eclampsia, there were 7 cases of aspiration pneumonia, 3 cases of pulmonary edema, 3 cases of pleural effusion, 2 cases of disseminated intravascular coagulation, and no cases of maternal death. Current obstetric treatment in the United States has resulted in a shift of eclampsia toward the postpartum period, with most cases being seen as late post partum. To reduce the rate of late postpartum eclampsia, efforts should be directed to the education of the health care providers and patients regarding the importance of prompt reporting and evaluation of symptoms of preeclampsia during the postpartum period.",success
21740315,False,Comparative Study;Journal Article,,,,,,,,True,"Delayed postpartum preeclampsia is a poorly studied disorder. We compared new onset delayed postpartum preeclampsia (NOPP) to recurrent/persistent, delayed onset postpartum preeclampsia (RPP) to see whether these were different disorders. Delayed onset preeclampsia was defined as readmission >2 days to ≤ 6 weeks postpartum for preeclampsia. The NOPP group had no antecedent diagnosis of hypertensive disorders in the current pregnancy, and was compared to the RPP defined as a prior hypertensive disorder in the current pregnancy in terms of maternal demographics, obstetric and medical history, intrapartum and early postpartum course and clinical signs and symptoms and outcomes on postpartum readmission. There were a total of 56 (36.8%) patients in the RPP and 96 (63.2%) patients in the NOPP groups. NOPP cases delivered significantly later 39.0 ± 2 weeks vs. 37 ± 3.0 weeks p < 0.001, and had significantly lower blood pressure during the antepartum, early postpartum and readmission periods. In addition the NOPP group had significantly higher average number of symptoms 2 vs. 1.5 p = 0.013 on postpartum readmission. There were no statistically significant differences in the rates of major complications. In this comprehensive study of delayed postpartum preeclampsia, there were few significant differences in the clinical course and no differences in complications in the NOPP subgroup compared to cases with preeclampsia recurring in the late postpartum period.",success
15167870,True,Comparative Study;Journal Article;Multicenter Study,,,,,,,,True,"Preeclampsia affects 6% to 8% of pregnancies. There are few data regarding hypertensive disorders that are diagnosed in the postpartum period. Our purpose was to determine the demographics, outcomes, and treatment of this complication. This was a multicenter retrospective study of women who had received a diagnosis of hypertension/preeclampsia in the postpartum period. Inclusion criteria were readmission of a patient with this diagnosis (<or=6 weeks after the delivery). Data from 151 women were studied. Complications included 24 cases (15.9%) of eclampsia, 9 cases (5.9%) of pulmonary edema, 6 cases (3.9%) of endomyometritis, 2 cases (1.3%) of thromboembolism, and 1 case of maternal death. Seventy-eight patients required antihypertensive medications on discharge. Subanalysis performed between the eclamptic and non-eclamptic women showed no difference among groups. Delivery does not eliminate the risk for preeclampsia and its complications. Efforts should be directed at the continued monitoring, reporting, and evaluating of the symptoms of preeclampsia during the postpartum period.",success
29505772,True,"Comparative Study;Journal Article;Randomized Controlled Trial;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Nonsteroidal antiinflammatory drug use has been shown to increase blood pressure in nonpregnant adults. Because of this, the American College of Obstetricians and Gynecologists suggests avoiding their use in women with postpartum hypertension; however, evidence to support this recommendation is lacking. Our goal was to test the hypothesis that nonsteroidal antiinflammatory drugs, such as ibuprofen, adversely affect postpartum blood pressure control in women with preeclampsia with severe features. At delivery, we randomized women with preeclampsia with severe features to receive around-the-clock oral dosing with either 600 mg of ibuprofen or 650 mg of acetaminophen every 6 hours. Dosing began within 6 hours after delivery and continued until discharge, with opioid analgesics available as needed for breakthrough pain. Study drugs were encapsulated in identical capsules such that patients, nurses, and physicians were masked to study allocation. Exclusion criteria were serum aspartate aminotransferase or alanine aminotransferase >200 mg/dL, serum creatinine >1.0 mg/dL, infectious hepatitis, gastroesophageal reflux disease, age <18 years, or current incarceration. Our primary outcome was the duration of severe-range hypertension, defined as the time (in hours) from delivery to the last blood pressure ≥160/110 mm Hg. Secondary outcomes were time from delivery to last blood pressure ≥150/100 mm Hg, mean arterial pressure, need for antihypertensive medication at discharge, prolongation of hospital stay for blood pressure control, postpartum use of short-acting antihypertensives for acute blood pressure control, and opioid use for breakthrough pain. We analyzed all outcome data according to intention-to-treat principles. We assessed 154 women for eligibility, of whom 100 met entry criteria, agreed to participate, and were randomized to receive postpartum ibuprofen or acetaminophen for first-line pain control. Seven patients crossed over or did not receive their allocated study drug, and 93 completed the study protocol in their assigned groups. We found no differences in baseline characteristics between groups, including mode of delivery, body mass index, parity, race, chronic hypertension, and maximum blood pressure prior to delivery. We did not find a difference in the duration of severe-range hypertension in the ibuprofen vs acetaminophen groups (35.3 vs 38.0 hours, P = .30). There were no differences between groups in the secondary outcome measures of time from delivery to last blood pressure ≥150/100 mm Hg, postpartum mean arterial pressure, maximum postpartum systolic or diastolic blood pressures, any postpartum blood pressure ≥160/110 mm Hg, short-acting antihypertensive use for acute blood pressure control, length of postpartum stay, need to extend postpartum stay for blood pressure control, antihypertensive use at discharge, or opioid use for inadequate pain control. In a subgroup analysis of patients who experienced severe-range hypertension, the mean time to blood pressure control in the acetaminophen group was 68.4 hours and ibuprofen group was 56.7 hours (P = .26). At 6 weeks postpartum, there were no differences between groups in the rates of obstetric triage visits, hospital readmissions, continued opioid use, or continued antihypertensive use. The first-line use of ibuprofen rather than acetaminophen for postpartum pain did not lengthen the duration of severe-range hypertension in women with preeclampsia with severe features.",success
28885417,False,Journal Article,,,,,,,,True,"To estimate whether nonsteroidal antiinflammatory drugs (NSAIDs) are associated with persistent postpartum hypertension in a cohort of women with preeclampsia and severe features. We conducted a retrospective cohort study at a single, tertiary center from January 2013 to December 2015. All women diagnosed with severe preeclampsia who remained hypertensive for greater than 24 hours after delivery were included. The primary outcome was the rate of persistent postpartum hypertension, defined as systolic blood pressure 150 mm Hg or greater or diastolic 100 mm Hg or greater (or both), on two occasions, at least 4 hours apart. Secondary outcomes included severe maternal morbidity: pulmonary edema, renal dysfunction, stroke, eclampsia, and intensive care unit admission. Additional outcomes included length of postpartum hospital stay, receipt of narcotics, and hospital readmission. Multivariable logistic regression was performed to adjust for confounders. Adjusted odds ratios (ORs) are reported for applicable study outcomes. Of the 399 women with severe preeclampsia, 324 (81%) remained hypertensive 24 hours after delivery. Two hundred forty-three (75%) received NSAIDs (either ibuprofen or ketorolac) and 81 (25%) did not. After multivariable logistic regression, the likelihood of reaching a blood pressure of 150 mm Hg systolic or 100 mm Hg diastolic (or both), on two occasions, at least 4 hours apart, was similar between those who received NSAIDs compared with those who did not (70% compared with 73%; adjusted OR 1.1, 95% CI 0.6-2.0). Similarly, puerperal occurrence of pulmonary edema (3% compared with 10%; OR 4.4, 95% CI 1.5-13.1), renal dysfunction (5% compared with 8%; OR 1.7, 95% CI 0.6-4.8), eclampsia (1% compared with 0%; P=.34), or intensive care unit admission (3% compared with 8%; OR 2.4, 95% CI 0.8-7.1) was similar between the groups. There were no differences in the rate of narcotic use (89% compared with 75%; adjusted OR 0.6 95% CI 0.18-1.70). In this cohort of women with preeclampsia and severe features before delivery, NSAIDs were not associated with increased rates of persistent postpartum hypertension.",success
26104814,False,Journal Article,,,,,,,,True,"Non-steroidal anti-inflammatory drug (NSAID) use has the potential to adversely affect blood pressure in women with hypertensive disorders of pregnancy. We sought to evaluate this association. Women affected with severe hypertensive disorders of pregnancy were identified by retrospective chart review. The medication administration record was then used to identify controls (no NSAID exposure) until a sufficient number of patients were obtained, after which the cases (NSAID exposed) were identified in a chronological manner during the same study period until a 2:1 ratio was achieved. The primary outcome was the change in mean of all postpartum mean arterial pressures (MAP) throughout the hospital stay. Power analysis showed that 146 exposed and 73 unexposed subjects were necessary to obtain 90% power to detect a MAP difference of 10mmHg between the groups. Secondary outcomes included: initiation of anti-hypertensive medication, need for increased doses of anti-hypertension medication, and adverse events related to hypertension. 223 women had severe hypertensive disorders of pregnancy, of whom 75 (34%) were not exposed to NSAIDs and 148 (66%) were exposed. NSAID exposure was not associated with a difference in the average MAP postpartum (p=0.70), nor any of the secondary outcomes evaluated. Exposure to NSAIDs was less likely as serum creatinine increased (p=0.012). In women with severe hypertensive disorders of pregnancy, NSAIDs did not appear to increase the average postpartum MAP, increase the requirement for anti-hypertensive medications, or increase the rate of adverse postpartum events.",success
30399109,False,Journal Article,,,,,,,,True,"To evaluate whether postpartum nonsteroidal antiinflammatory drug (NSAID) administration is associated with increased blood pressure in women with hypertensive disorders of pregnancy and to estimate the association between NSAID administration and use of opioid medication. We conducted a retrospective cohort study of women with hypertensive disorders of pregnancy. Patients were analyzed in two groups according to whether they received NSAIDs postpartum. Study participants were women delivered at a tertiary care center from 2008 to 2015. The primary outcome was change in mean arterial pressure during the postpartum period. Secondary outcomes were postpartum pain scores, cumulative postpartum opioid requirement, initiation or dose escalation of antihypertensive agents, and adverse postpartum outcomes including acute renal failure, change in hematocrit, and maternal readmission for hypertensive disorder. Two hundred seventy-six women with hypertensive disorders of pregnancy were included (129 NSAID-unexposed and 147 NSAID-exposed). Postpartum NSAID administration was not associated with a statistically significant change in mean arterial pressure compared with no NSAID administration (-0.7 vs -1.8; mean difference 1.10, 95% CI -1.44 to 3.64). Similarly, no difference was observed between the cohorts in terms of need for initiation or escalation in dose of antihypertensive agents or maternal readmission for hypertensive disorder. The study was underpowered to determine whether NSAID administration was associated with any difference in less frequent secondary outcomes (eg, incidence of acute renal insufficiency, need for postpartum transfusion) or cumulative opioid use. Nonsteroidal antiinflammatory drug administration to postpartum patients with hypertensive disorders of pregnancy is not associated with a change in blood pressure or requirement for antihypertensive medication.",success
3740137,False,Journal Article,,,,,,,,True,"Over a 1-year period, seven eclamptic patients with repetitive seizures while receiving therapeutic levels of intravenous magnesium sulfate were evaluated by computerized axial tomography. In five patients brain abnormalities were identified, which included diffuse cerebral edema (one), cerebral venous thrombosis (two), and low density white matter (two). Clinical management of eclamptic women on the basis of structural central nervous system abnormalities documented by computerized tomography appears to warrant further investigation.",success
15121574,False,Journal Article;Review,,,,,,,,True,"Hemolysis, elevated liver enzymes, and low platelets (HELLP) syndrome has been recognized as a complication of preeclampsia-eclampsia for decades. Recognition of this syndrome in women with preeclampsia is increasing because of the frequency of blood test results that reveal unexpected thrombocytopenia or elevated liver enzymes. The diagnosis of HELLP syndrome requires the presence of hemolysis based on examination of the peripheral smear, elevated indirect bilirubin levels, or low serum haptoglobin levels in association with significant elevation in liver enzymes and a platelet count below 100,000/mm(3) after ruling out other causes of hemolysis and thrombocytopenia. The presence of this syndrome is associated with increased risk of adverse outcome for both mother and fetus. During the past 15 years, several retrospective and observational studies and a few randomized trials have been published in an attempt to refine the diagnostic criteria, to identify risk factors for adverse pregnancy outcome, and to treat women with this syndrome. Despite the voluminous literature, the diagnosis and management of this syndrome remain controversial. Recent studies suggest that some women with partial HELLP syndrome may be treated with expectant management or corticosteroid therapy. This review will emphasize the controversies surrounding the diagnosis and management of this syndrome. Recommendation for diagnosis, management, and counseling of these women is also provided based on results of recent studies and my own clinical experience.",success
28701333,False,Journal Article,,,,,,,,True,"<b>Objectives</b> To determine how soon after delivery the risk of post-pregnancy hypertension increases in women with hypertensive disorders of pregnancy and how the risk evolves over time.<b>Design</b> Nationwide register based cohort study.<b>Setting</b> Denmark.<b>Populations</b> 482 972 primiparous women with a first live birth or stillbirth between 1995 and 2012 (cumulative incidence analyses), and 1 025 118 women with at least one live birth or stillbirth between 1978 and 2012 (Cox regression analyses).<b>Main outcome measures</b> 10 year cumulative incidences of post-pregnancy hypertension requiring treatment with prescription drugs, and hazard ratios estimated using Cox regression.<b>Results</b> Of women with a hypertensive disorder of pregnancy in a first pregnancy in their 20s, 14% developed hypertension in the first decade post partum, compared with 4% of women with normotensive first pregnancies in their 20s. The corresponding percentages for women with a first pregnancy in their 40s were 32% and 11%, respectively. In the year after delivery, women with a hypertensive disorder of pregnancy had 12-fold to 25-fold higher rates of hypertension than did women with a normotensive pregnancy. Rates in women with a hypertensive disorder of pregnancy were threefold to 10-fold higher 1-10 years post partum and remained twice as high even 20 or more years later.<b>Conclusions</b> The risk of hypertension associated with hypertensive disorders of pregnancy is high immediately after an affected pregnancy and persists for more than 20 years. Up to one third of women with a hypertensive disorder of pregnancy may develop hypertension within a decade of an affected pregnancy, indicating that cardiovascular disease prevention in these women should include blood pressure monitoring initiated soon after pregnancy.",success
29971437,False,"Journal Article;Observational Study;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Women with a history of hypertensive disorders of pregnancy (HDP) are nearly twice as likely to develop cardiovascular disease (CVD) as those who are normotensive during pregnancy. However, the emergence of CVD risk factors after HDP is less well-understood. To identify associations between HDP and maternal CVD risk factors and chart the trajectory of risk factor development after pregnancy. Observational cohort study. United States. 58 671 parous NHS II (Nurses' Health Study II) participants who did not have CVD or risk factors of interest at baseline. Women were followed for self-reported physician diagnosis of chronic hypertension and hypercholesterolemia and confirmed type 2 diabetes mellitus (T2DM) from their first birth through 2013; mean follow-up ranged from 25 to 32 years across these end points. Multivariable Cox proportional hazards models estimated hazard ratios (HRs) and 95% CIs, with adjustment for prepregnancy confounders. Compared with women who were normotensive during pregnancy, those with gestational hypertension (2.9%) or preeclampsia (6.3%) in their first pregnancy had increased rates of chronic hypertension (HRs, 2.8 [95% CI, 2.6 to 3.0] and 2.2 [CI, 2.1 to 2.3], respectively), T2DM (HRs, 1.7 [CI, 1.4 to 1.9] and 1.8 [CI, 1.6 to 1.9], respectively), and hypercholesterolemia (HRs, 1.4 [CI, 1.3 to 1.5] and 1.3 [CI, 1.3 to 1.4], respectively). Although these women were more likely to develop CVD risk factors throughout follow-up, the relative risk for chronic hypertension was strongest within 5 years after their first birth. Recurrence of HDP further elevated risks for all end points. Participants self-reported HDP. Women with HDP in their first pregnancy had increased rates of chronic hypertension, T2DM, and hypercholesterolemia that persisted for several decades. These women may benefit from lifestyle intervention and early screening to reduce lifetime risk for CVD. National Institutes of Health.",success
23397514,False,"Journal Article;Meta-Analysis;Research Support, Non-U.S. Gov't;Systematic Review",,,,,,,,True,"There is increasing evidence that pre-eclampsia, a principal cause of maternal morbidity, may also be a risk factor for future cardiovascular and cerebrovascular events. This review aimed to assess the current evidence and quantify the risks of cardiovascular disease (CVD), cerebrovascular events and hypertension associated with prior diagnosis of pre-eclampsia. Medline and Embase were searched with no language restrictions, as were core journals and reference lists from reviews up until January 2012. Case-control and cohort studies which reported cardiovascular and cerebrovascular diseases or hypertension diagnosed more than 6 weeks postpartum, in women who had a history of pre-eclampsia relative to women who had unaffected pregnancies, were included. Fifty articles were included in the systematic review and 43 in the meta-analysis. Women with a history of pre-eclampsia or eclampsia were at significantly increased odds of fatal or diagnosed CVD [odds ratio (OR) = 2.28, 95% confidence interval (CI): 1.87, 2.78], cerebrovascular disease (OR = 1.76, 95% CI 1.43, 2.21) and hypertension [relative risk (RR) = 3.13, 95% CI 2.51, 3.89]. Among pre-eclamptic women, pre-term delivery was not associated with an increased risk of a future cardiovascular event (RR = 1.32, 95% CI 0.79, 2.22). Women diagnosed with pre-eclampsia are at increased risk of future cardiovascular or cerebrovascular events, with an estimated doubling of odds compared to unaffected women. This has implications for the follow-up of all women who experience pre-eclampsia, not just those who deliver pre-term. This association may reflect shared common risk factors for both pre-eclampsia and cardiovascular and cerebrovascular disease.",success
19061708,False,"Journal Article;Meta-Analysis;Research Support, Non-U.S. Gov't;Systematic Review",,,,,,,,True,"Preeclampsia affects 3% to 5% of gestations and eclampsia 0.05% to 0.93%, but their subsequent cardiovascular sequelae are unclear. The aim of this study was to determine if women with a history of preeclampsia/eclampsia are at increased risk of long-term cardiovascular sequelae. From Medline and Embase searches, we included case-control and cohort studies that examined cardiac, cerebrovascular or peripheral arterial disease, or cardiovascular mortality>6 weeks postpartum, in women with and without a history of preeclampsia/eclampsia and that controlled for or matched for confounders. Two independent reviewers determined study eligibility and extracted data. Five case-control and 10 cohort studies met eligibility criteria, with a total of 116,175 women with and 2,259,576 women without preeclampsia/eclampsia. Most studies focused on women<56 years of age. Relative to women with uncomplicated pregnancies, women with a history of preeclampsia/eclampsia had an increased risk of subsequent cardiac disease in both the case-control studies (odds ratio 2.47, 95% CI 1.22-5.01) and the cohort studies (relative risk [RR] 2.33, 1.95-2.78), as well as an increased risk of cerebrovascular disease (RR 2.03, 1.54-2.67), peripheral arterial disease (RR 1.87, 0.94-3.73), and cardiovascular mortality (RR 2.29, 1.73-3.04). Meta-regression revealed a graded relationship between the severity of preeclampsia/eclampsia and the risk of cardiac disease (mild: RR 2.00, 1.83-2.19, moderate: RR 2.99, 2.51-3.58, severe: RR 5.36, 3.96-7.27, P<.0001). Women with a history of preeclampsia/eclampsia have approximately double the risk of early cardiac, cerebrovascular, and peripheral arterial disease, and cardiovascular mortality. Further research is needed to determine the mechanisms underlying these associations and to identify effective prevention strategies.",success
15670111,False,"Journal Article;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Pre-eclampsia has been described as a 'disease of first pregnancies' and many believe that its occurrence in a later pregnancy signals a fundamentally different entity. We sought to compare risk factors in first and subsequent pregnancies. We studied 1319 cases of pre-eclampsia recorded in a historical cohort of 82,436 deliveries in Jerusalem in 1964-76. Logistic regression was used to control for covariates. The adjusted odds ratio (OR) for pre-eclampsia in first births was 2.58 (95% confidence interval[CI] 2.23, 2.97), compared with all later birth order groups, between which there were no detectable differences in risk. Other risk factors included increasing maternal age, diabetes (OR 5.64, 95% CI 4.33, 7.35), multiple gestations (OR 3.38, 95% CI 2.54, 4.49), fetal haemolytic disease (OR 2.24, 95% CI 1.43, 3.50) and lower maternal education. The risk of pre-eclampsia was not associated with the mother's employment outside the home and did not differ between immigrants vs. Israeli-born mothers or between groups of women whose fathers had been born in Western Asia, North Africa or Europe. Effects of each risk factor were similar within first and subsequent births. These results lend no support to the hypothesis that there is a fundamental difference between pre-eclampsia in a first pregnancy compared with that occurring in a later pregnancy; conclusions may be moderated, however, by the knowledge that the incidence of pre-eclampsia was low in this historical cohort.",success
16298217,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Maternal placental syndromes, including the hypertensive disorders of pregnancy and abruption or infarction of the placenta, probably originate from diseased placental vessels. The syndromes arise most often in women who have metabolic risk factors for cardiovascular disease, including obesity, pre-pregnancy hypertension, diabetes mellitus, and dyslipidaemia. Our aim was to assess the risk of premature vascular disease in women who had had a pregnancy affected by maternal placental syndromes. We did a population-based retrospective cohort study in Ontario, Canada, of 1.03 million women who were free from cardiovascular disease before their first documented delivery. We defined the following as maternal placental syndromes: pre-eclampsia, gestational hypertension, placental abruption, and placental infarction. Our primary endpoint was a composite of cardiovascular disease, defined as hospital admission or revascularisation for coronary artery, cerebrovascular, or peripheral artery disease at least 90 days after the delivery discharge date. The mean (SD) age of participants was 28.2 (5.5) years at the index delivery, and 75 380 (7%) women were diagnosed with a maternal placental syndrome. The incidence of cardiovascular disease was 500 per million person-years in women who had had a maternal placental syndrome compared with 200 per million in women who had not (adjusted hazard ratio [HR] 2.0, 95 CI 1.7-2.2). This risk was higher in the combined presence of a maternal placental syndrome and poor fetal growth (3.1, 2.2-4.5) or a maternal placental syndrome and intrauterine fetal death (4.4, 2.4-7.9), relative to neither. The risk of premature cardiovascular disease is higher after a maternal placental syndrome, especially in the presence of fetal compromise. Affected women should have their blood pressure and weight assessed about 6 months postpartum, and a healthy lifestyle should be emphasised.",success
28816365,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Hypertensive disorders in pregnancy (HDP) have been shown to predict later risk of cardiovascular disease (CVD). However, previous studies have not accounted for subsequent pregnancies and their complications, which are potential confounders and intermediates of this association. A cohort of 146 748 women with a first pregnancy was constructed using the Clinical Practice Research Datalink. HDP was defined using diagnostic codes, elevated blood pressure readings, or new use of an anti-hypertensive drug between 18 weeks' gestation and 6 weeks post-partum. The study outcomes were incident CVD and hypertension. Marginal structural Cox models (MSM) were used to account for time-varying confounders and intermediates. Time-fixed exposure defined at the first pregnancy was used in secondary analyses. A total of 997 women were diagnosed with incident CVD, and 6812 women were diagnosed with hypertension or received a new anti-hypertensive medication during the follow-up period. Compared with women without HDP, those with HDP had a substantially higher rate of CVD (hazard ratio (HR) 2.2, 95% confidence interval (CI) 1.7, 2.7). In women with HDP, the rate of hypertension was five times that of women without a HDP (HR 5.6, 95% CI 5.1, 6.3). With overlapping 95% CIs, the time-fixed analysis and the MSM produced consistent results for both outcomes. Women with HDP are at increased risk of developing subsequent CVD and hypertension. Similar estimates obtained with the MSM and the time-fixed analysis suggests that subsequent pregnancies do not confound a first episode of HDP and later CVD.",success
21690502,False,"Journal Article;Research Support, N.I.H., Intramural;Research Support, Non-U.S. Gov't;Review",,,,,,,,False,,success
20660802,False,"Comparative Study;Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Preeclampsia and gestational hypertension are associated with increased risk for cardiovascular disease later in life. We have assessed whether the effect can be attributed to factors that operate in pregnancy or to prepregnancy risk factors that are shared by both disorders. Longitudinal data from 2 consecutive waves of a Norwegian population-based study (the Nord-Trøndelag Health Study [HUNT]) were combined with data from the Medical Birth Registry of Norway. Among 24 865 women who had participated in both HUNT 1 and 2, we indentified 3225 women with a singleton birth between the 2 studies who had standardized measurements of blood pressure, serum lipids, and body mass index. The crude results showed that women who experienced preeclampsia or gestational hypertension in pregnancy had substantially higher levels of body mass index and systolic and diastolic blood pressures and unfavorable lipids compared with other women. However, after adjustment for prepregnancy measurements, the difference in body mass index was attenuated by >65%, and the difference in blood pressure was attenuated by approximately 50%. In relation to high-density lipoprotein cholesterol and triglycerides, differences between the groups were attenuated by 40% and 72%, respectively. These results suggest that the positive association of preeclampsia and gestational hypertension with postpregnancy cardiovascular risk factors may be due largely to shared prepregnancy risk factors rather than reflecting a direct influence of the hypertensive disorder in pregnancy.",success
24613324,False,Journal Article;Review,,,,,,,,True,"Cardiovascular disease continues to be the leading cause of death in the western world. Due to advancements in diagnosis, prevention, and treatment, cardiovascular mortality has fallen in recent years. Previous studies have evaluated the impact of traditional risk factors such as hypercholesterolemia and smoking. However, limited studies have been conducted to evaluate sex discrepancies among patients with cardiovascular disease. Pre-eclampsia is a multisystem placentally mediated disease, which usually arises after 32 weeks of gestation and classically presents with hypertension and proteinuria. Pre-eclampsia affects 2% to 8% of all pregnancies worldwide and is often complicated by fetal growth restriction. Women with a history of pre-eclampsia are at increased risk of future cardiovascular complications. Therefore, this topic is of significance to the cardiovascular health of over 300 million women worldwide. The goal of this review is to determine the association of pre-eclampsia and future cardiovascular risk and to explore the potential management options for these high-risk women.",success
24682347,False,Journal Article;Practice Guideline,,,,,,,,False,,success
24682348,False,Journal Article;Practice Guideline,,,,,,,,False,,success
24345399,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"The global burden of atrial fibrillation (AF) is unknown. We systematically reviewed population-based studies of AF published from 1980 to 2010 from the 21 Global Burden of Disease regions to estimate global/regional prevalence, incidence, and morbidity and mortality related to AF (DisModMR software). Of 377 potential studies identified, 184 met prespecified eligibility criteria. The estimated number of individuals with AF globally in 2010 was 33.5 million (20.9 million men [95% uncertainty interval (UI), 19.5-22.2 million] and 12.6 million women [95% UI, 12.0-13.7 million]). Burden associated with AF, measured as disability-adjusted life-years, increased by 18.8% (95% UI, 15.8-19.3) in men and 18.9% (95% UI, 15.8-23.5) in women from 1990 to 2010. In 1990, the estimated age-adjusted prevalence rates of AF (per 100 000 population) were 569.5 in men (95% UI, 532.8-612.7) and 359.9 in women (95% UI, 334.7-392.6); the estimated age-adjusted incidence rates were 60.7 per 100 000 person-years in men (95% UI, 49.2-78.5) and 43.8 in women (95% UI, 35.9-55.0). In 2010, the prevalence rates increased to 596.2 (95% UI, 558.4-636.7) in men and 373.1 (95% UI, 347.9-402.2) in women; the incidence rates increased to 77.5 (95% UI, 65.2-95.4) in men and 59.5 (95% UI, 49.9-74.9) in women. Mortality associated with AF was higher in women and increased by 2-fold (95% UI, 2.0-2.2) and 1.9-fold (95% UI, 1.8-2.0) in men and women, respectively, from 1990 to 2010. There was evidence of significant regional heterogeneity in AF estimations and availability of population-based data. These findings provide evidence of progressive increases in overall burden, incidence, prevalence, and AF-associated mortality between 1990 and 2010, with significant public health implications. Systematic, regional surveillance of AF is required to better direct prevention and treatment strategies.",success
21540439,False,Journal Article,,,,,,,,True,"Detailed information on the cost burden of atrial fibrillation (AF) is limited. To provide an up-to-date estimate of the national cost of AF, we conducted a retrospective, observational cohort study using administrative claims from the MarketScan Commercial and Medicare Supplemental research data bases, 2004 to 2006. Patients aged ≥20 years with ≥1 inpatient or ≥2 outpatient AF diagnoses in 2005 (first diagnosis=index) and ≥12 months' enrollment before and after index were selected. AF patients were propensity score-matched (1:1) with non-AF control subjects. Medical costs (2008 US$), including AF costs, other cardiovascular, and noncardiovascular costs, were examined over 1 year after index. National incremental costs of AF were based on age-/sex-specific AF prevalence projections for 2010. In total, 89 066 AF patients were matched to non-AF control subjects. Over 1 year, 37.5% of AF versus 17.5% of control subjects were hospitalized and 2.1% versus 0.1% died during hospitalization. For AF versus control subjects, mean annual inpatient costs per patient were $7841 versus $2622 (incremental cost, $5218), outpatient medical costs were $9225 versus $5629 ($3596), and outpatient pharmacy costs were $3605 versus $3714 (-$109) (all P<0.001). The total incremental cost of AF was $8705 per patient. The national incremental cost of AF was $26.0 billion (AF, $6.0 billion; other cardiovascular, $9.9 billion; noncardiovascular, $10.1 billion). Cardiovascular costs were based on claims with a primary disease diagnosis and may be underestimates. On the basis of current US age- and sex-specific prevalence data, the national incremental AF cost is estimated to range from $6.0 to $26.0 billion.",success
27974350,False,Journal Article;Meta-Analysis,,,,,,,,True,"Observational studies have identified an association between body mass index (BMI) and incident atrial fibrillation (AF). Inferring causality from observational studies, however, is subject to residual confounding, reverse causation, and bias. The primary objective of this study was to evaluate the causal association between BMI and AF by using genetic predictors of BMI. We identified 51 646 individuals of European ancestry without AF at baseline from 7 prospective population-based cohorts initiated between 1987 and 2002 in the United States, Iceland, and the Netherlands with incident AF ascertained between 1987 and 2012. Cohort-specific mean follow-up ranged from 7.4 to 19.2 years, over which period there was a total of 4178 cases of incident AF. We performed a Mendelian randomization with instrumental variable analysis to estimate a cohort-specific causal hazard ratio for the association between BMI and AF. Two genetic instruments for BMI were used: <i>FTO</i> genotype (rs1558902) and a BMI gene score comprising 39 single-nucleotide polymorphisms identified by genome-wide association studies to be associated with BMI. Cohort-specific estimates were combined by random-effects, inverse variance-weighted meta-analysis. In age- and sex-adjusted meta-analysis, both genetic instruments were significantly associated with BMI (<i>FTO</i>: 0.43 [95% confidence interval, 0.32-0.54] kg/m<sup>2</sup> per A-allele, <i>P</i><0.001; BMI gene score: 1.05 [95% confidence interval, 0.90-1.20] kg/m<sup>2</sup> per 1-U increase, <i>P</i><0.001) and incident AF (<i>FTO</i>, hazard ratio, 1.07 [1.02-1.11] per A-allele, <i>P</i>=0.004; BMI gene score, hazard ratio, 1.11 [1.05-1.18] per 1-U increase, <i>P</i><0.001). Age- and sex-adjusted instrumental variable estimates for the causal association between BMI and incident AF were hazard ratio, 1.15 (1.04-1.26) per kg/m<sup>2</sup>, <i>P</i>=0.005 (<i>FTO</i>) and 1.11 (1.05-1.17) per kg/m<sup>2</sup>, <i>P</i><0.001 (BMI gene score). Both of these estimates were consistent with the meta-analyzed estimate between observed BMI and AF (age- and sex-adjusted hazard ratio 1.05 [1.04-1.06] per kg/m<sup>2</sup>, <i>P</i><0.001). Multivariable adjustment did not significantly change findings. Our data are consistent with a causal relationship between BMI and incident AF. These data support the possibility that public health initiatives targeting primordial prevention of obesity may reduce the incidence of AF.",success
11343485,False,"Journal Article;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Atrial fibrillation is the most common arrhythmia in elderly persons and a potent risk factor for stroke. However, recent prevalence and projected future numbers of persons with atrial fibrillation are not well described. To estimate prevalence of atrial fibrillation and US national projections of the numbers of persons with atrial fibrillation through the year 2050. Cross-sectional study of adults aged 20 years or older who were enrolled in a large health maintenance organization in California and who had atrial fibrillation diagnosed between July 1, 1996, and December 31, 1997. Prevalence of atrial fibrillation in the study population of 1.89 million; projected number of persons in the United States with atrial fibrillation between 1995-2050. A total of 17 974 adults with diagnosed atrial fibrillation were identified during the study period; 45% were aged 75 years or older. The prevalence of atrial fibrillation was 0.95% (95% confidence interval, 0.94%-0.96%). Atrial fibrillation was more common in men than in women (1.1% vs 0.8%; P<.001). Prevalence increased from 0.1% among adults younger than 55 years to 9.0% in persons aged 80 years or older. Among persons aged 50 years or older, prevalence of atrial fibrillation was higher in whites than in blacks (2.2% vs 1.5%; P<.001). We estimate approximately 2.3 million US adults currently have atrial fibrillation. We project that this will increase to more than 5.6 million (lower bound, 5.0; upper bound, 6.3) by the year 2050, with more than 50% of affected individuals aged 80 years or older. Our study confirms that atrial fibrillation is common among older adults and provides a contemporary basis for estimates of prevalence in the United States. The number of patients with atrial fibrillation is likely to increase 2.5-fold during the next 50 years, reflecting the growing proportion of elderly individuals. Coordinated efforts are needed to face the increasing challenge of optimal stroke prevention and rhythm management in patients with atrial fibrillation.",success
29699974,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, Non-P.H.S.",,,,,,,,True,"To examine the association between risk factor burdens-categorized as optimal, borderline, or elevated-and the lifetime risk of atrial fibrillation. Community based cohort study. Longitudinal data from the Framingham Heart Study. Individuals free of atrial fibrillation at index ages 55, 65, and 75 years were assessed. Smoking, alcohol consumption, body mass index, blood pressure, diabetes, and history of heart failure or myocardial infarction were assessed as being optimal (that is, all risk factors were optimal), borderline (presence of borderline risk factors and absence of any elevated risk factor), or elevated (presence of at least one elevated risk factor) at index age. Lifetime risk of atrial fibrillation at index age up to 95 years, accounting for the competing risk of death. At index age 55 years, the study sample comprised 5338 participants (2531 (47.4%) men). In this group, 247 (4.6%) had an optimal risk profile, 1415 (26.5%) had a borderline risk profile, and 3676 (68.9%) an elevated risk profile. The prevalence of elevated risk factors increased gradually when the index ages rose. For index age of 55 years, the lifetime risk of atrial fibrillation was 37.0% (95% confidence interval 34.3% to 39.6%). The lifetime risk of atrial fibrillation was 23.4% (12.8% to 34.5%) with an optimal risk profile, 33.4% (27.9% to 38.9%) with a borderline risk profile, and 38.4% (35.5% to 41.4%) with an elevated risk profile. Overall, participants with at least one elevated risk factor were associated with at least 37.8% lifetime risk of atrial fibrillation. The gradient in lifetime risk across risk factor burden was similar at index ages 65 and 75 years. Regardless of index ages at 55, 65, or 75 years, an optimal risk factor profile was associated with a lifetime risk of atrial fibrillation of about one in five; this risk rose to more than one in three a third in individuals with at least one elevated risk factor.",success
16818816,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Limited data exist on trends in incidence of atrial fibrillation (AF). We assessed the community-based trends in AF incidence for 1980 to 2000 and provided prevalence projections to 2050. The adult residents of Olmsted County, Minnesota, who had ECG-confirmed first AF in the period 1980 to 2000 (n=4618) were identified. Trends in age-adjusted incidence were determined and used to construct model-based prevalence estimates. The age- and sex-adjusted incidence of AF per 1000 person-years was 3.04 (95% CI, 2.78 to 3.31) in 1980 and 3.68 (95% CI, 3.42 to 3.95) in 2000. According to Poisson regression with adjustment for age and sex, incidence of AF increased significantly (P=0.014), with a relative increase of 12.6% (95% CI, 2.1 to 23.1) over 21 years. The increase in age-adjusted AF incidence did not differ between men and women (P=0.84). According to the US population projections by the US Census Bureau, the number of persons with AF is projected to be 12.1 million by 2050, assuming no further increase in age-adjusted incidence of AF, but 15.9 million if the increase in incidence continues. The age-adjusted incidence of AF increased significantly in Olmsted County during 1980 to 2000. Whether or not this rate of increase continues, the projected number of persons with AF for the United States will exceed 10 million by 2050, underscoring the urgent need for primary prevention strategies against AF development.",success
28784826,False,Journal Article;Review,,,,,,,,True,"There has been increasing focus on the rising burden of atrial fibrillation (AF) since the turn of the millennium. The AF epidemic is projected not only to have an impact on morbidity and mortality, but also to result in increasing healthcare use and cost. Intensive research over the previous decades has improved our understanding of this complex arrhythmia while unraveling more knowledge gaps and inadequacies of current therapeutic options. Specifically, the advances in catheter ablation technology and strategies have not translated into significant gains in procedural success rates over recent years. Therefore, strategies aiming at lowering the risk of AF development and progression are urgently needed to curtail the AF epidemic and improve outcomes in affected individuals. Recent research has highlighted the potential beneficial effects of lifestyle and risk factor management for AF as upstream noninvasive therapy. The evidence supporting this treatment paradigm beyond routine clinical AF management argues for change in the delivery of care to patients who have this debilitating arrhythmia. In this review, we highlight the contributory role of risk factors to AF pathogenesis from both bench and bedside studies. Next, we discuss the rationale and potential benefits of risk factor modification for sinus rhythm maintenance. Last, we propose an integrated care model to incorporate risk factor modification as the fourth pillar of AF care in conjunction with established pillars of rate control, rhythm control, and anticoagulation therapy.",success
26113406,False,"Comparative Study;Journal Article;Research Support, Non-U.S. Gov't",,,ACTRN12614001123639,,,,,True,"Obesity begets atrial fibrillation (AF). Although cardiorespiratory fitness is protective against incident AF in obese individuals, its effect on AF recurrence or the benefit of cardiorespiratory fitness gain is unknown. This study sought to evaluate the role of cardiorespiratory fitness and the incremental benefit of cardiorespiratory fitness improvement on rhythm control in obese individuals with AF. Of 1,415 consecutive patients with AF, 825 had a body mass index ≥27 kg/m(2) and were offered risk factor management and participation in a tailored exercise program. After exclusions, 308 patients were included in the analysis. Patients underwent exercise stress testing to determine peak metabolic equivalents (METs). To determine a dose response, cardiorespiratory fitness was categorized as: low (<85%), adequate (86% to 100%), and high (>100%). Impact of cardiorespiratory fitness gain was ascertained by the objective gain in fitness at final follow-up (≥2 METs vs. <2 METs). AF rhythm control was determined using 7-day Holter monitoring and AF severity scale questionnaire. There were no differences in baseline characteristics or follow-up duration between the groups defined by cardiorespiratory fitness. Arrhythmia-free survival with and without rhythm control strategies was greatest in patients with high cardiorespiratory fitness compared to adequate or low cardiorespiratory fitness (p < 0.001 for both). AF burden and symptom severity decreased significantly in the group with cardiorespiratory fitness gain ≥2 METs as compared to <2 METs group (p < 0.001 for all). Arrhythmia-free survival with and without rhythm control strategies was greatest in those with METs gain ≥2 compared to those with METs gain <2 in cardiorespiratory fitness (p < 0.001 for both). Cardiorespiratory fitness predicts arrhythmia recurrence in obese individuals with symptomatic AF. Improvement in cardiorespiratory fitness augments the beneficial effects of weight loss. (Evaluating the Impact of a Weight Loss on the Burden of Atrial Fibrillation [AF] in Obese Patients; ACTRN12614001123639).",success
25456757,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"The long-term outcome of atrial fibrillation (AF) ablation demonstrates attrition. This outcome may be due to failure to attenuate the progressive substrate promoted by cardiovascular risk factors. The goal of this study was to evaluate the impact of risk factor and weight management on AF ablation outcomes. Of 281 consecutive patients undergoing AF ablation, 149 with a body mass index ≥27 kg/m(2) and ≥1 cardiac risk factor were offered risk factor management (RFM) according to American Heart Association/American College of Cardiology guidelines. After AF ablation, all 61 patients who opted for RFM and 88 control subjects were assessed every 3 to 6 months by clinic review and 7-day Holter monitoring. Changes in the Atrial Fibrillation Severity Scale scores were determined. There were no differences in baseline characteristics, number of procedures, or follow-up duration between the groups (p = NS). RFM resulted in greater reductions in weight (p = 0.002) and blood pressure (p = 0.006), and better glycemic control (p = 0.001) and lipid profiles (p = 0.01). At follow-up, AF frequency, duration, symptoms, and symptom severity decreased more in the RFM group compared with the control group (all p < 0.001). Single-procedure drug-unassisted arrhythmia-free survival was greater in RFM patients compared with control subjects (p < 0.001). Multiple-procedure arrhythmia-free survival was markedly better in RFM patients compared with control subjects (p < 0.001), with 16% and 42.4%, respectively, using antiarrhythmic drugs (p = 0.004). On multivariate analysis, type of AF (p < 0.001) and RFM (hazard ratio 4.8 [95% confidence interval: 2.04 to 11.4]; p < 0.001) were independent predictors of arrhythmia-free survival. Aggressive RFM improved the long-term success of AF ablation. This study underscores the importance of therapy directed at the primary promoters of the AF substrate to facilitate rhythm control strategies.",success
25792361,False,"Journal Article;Research Support, Non-U.S. Gov't",,,ACTRN12614001123639,,,,,True,"Obesity and atrial fibrillation (AF) frequently coexist. Weight loss reduces the burden of AF, but whether this is sustained, has a dose effect, or is influenced by weight fluctuation is unknown. This study sought to evaluate the long-term impact of weight loss and weight fluctuation on rhythm control in obese individuals with AF. Of 1,415 consecutive patients with AF, 825 had a body mass index ≥ 27 kg/m(2) and were offered weight management. After screening for exclusion criteria, 355 were included in this analysis. Weight loss was categorized as group 1 (≥ 10%), group 2 (3% to 9%), and group 3 (<3%). Weight trend and/or fluctuation was determined by yearly follow-up. We determined the impact on the AF severity scale and 7-day ambulatory monitoring. There were no differences in baseline characteristics or follow-up among the groups. AF burden and symptom severity decreased more in group 1 compared with groups 2 and 3 (p < 0.001 for all). Arrhythmia-free survival with and without rhythm control strategies was greatest in group 1 compared with groups 2 and 3 (p < 0.001 for both). In multivariate analyses, weight loss and weight fluctuation were independent predictors of outcomes (p < 0.001 for both). Weight loss ≥ 10% resulted in a 6-fold (95% confidence interval: 3.4 to 10.3; p < 0.001) greater probability of arrhythmia-free survival compared with the other 2 groups. Weight fluctuation >5% partially offset this benefit, with a 2-fold (95% confidence interval: 1.0 to 4.3; p = 0.02) increased risk of arrhythmia recurrence. Long-term sustained weight loss is associated with significant reduction of AF burden and maintenance of sinus rhythm. (Long-Term Effect of Goal directed weight management on Atrial Fibrillation Cohort: A 5 Year follow-up study [LEGACY Study]; ACTRN12614001123639).",success
29401239,True,"Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",NCT00877643,databank,NCT00877643,NCT00877643,NCT00877643,NCT00877643|databank,NCT00877643|databank,True,"Atrial fibrillation (AF) is a progressive disease. Targeted therapy of underlying conditions refers to interventions aiming to modify risk factors in order to prevent AF. We hypothesised that targeted therapy of underlying conditions improves sinus rhythm maintenance in patients with persistent AF. We randomized patients with early persistent AF and mild-to-moderate heart failure (HF) to targeted therapy of underlying conditions or conventional therapy. Both groups received causal treatment of AF and HF, and rhythm control therapy. In the intervention group, on top of that, four therapies were started: (i) mineralocorticoid receptor antagonists (MRAs), (ii) statins, (iii) angiotensin converting enzyme inhibitors and/or receptor blockers, and (iv) cardiac rehabilitation including physical activity, dietary restrictions, and counselling. The primary endpoint was sinus rhythm at 1 year during 7 days of Holter monitoring. Of 245 patients, 119 were randomized to targeted and 126 to conventional therapy. The intervention led to a contrast in MRA (101 [85%] vs. 5 [4%] patients, P < 0.001) and statin use (111 [93%] vs. 61 [48%], P < 0.001). Angiotensin converting enzyme inhibitors/angiotensin receptor blockers were not different. Cardiac rehabilitation was completed in 109 (92%) patients. Underlying conditions were more successfully treated in the intervention group. At 1 year, sinus rhythm was present in 89 (75%) patients in the intervention vs. 79 (63%) in the conventional group (odds ratio 1.765, lower limit of 95% confidence interval 1.021, P = 0.042). RACE 3 confirms that targeted therapy of underlying conditions improves sinus rhythm maintenance in patients with persistent AF. Clinicaltrials.gov NCT00877643.",success
29912366,False,Journal Article;Observational Study,,,,,,,,True,"Atrial fibrillation (AF) is a progressive disease. Obesity is associated with progression of AF. This study evaluates the impact of weight and risk factor management (RFM) on progression of the AF. As described in the Long-Term Effect of Goal-Directed Weight Management in an Atrial Fibrillation Cohort: A Long-Term Follow-Up (LEGACY) Study, of 1415 consecutive AF patients, 825 had body mass index ≥ 27 kg/m2 and were offered weight and RFM. After exclusion, 355 were included for analysis. Weight loss was categorized as: Group 1 (<3%), Group 2 (3-9%), and Group 3 (≥10%). Change in AF type was determined by clinical review and 7-day Holter yearly. Atrial fibrillation type was categorized as per the Heart Rhythm Society consensus. There were no differences in baseline characteristic or follow-up duration between groups (P = NS). In Group 1, 41% progressed from paroxysmal to persistent and 26% from persistent to paroxysmal or no AF. In Group 2, 32% progressed from paroxysmal to persistent and 49% reversed from persistent to paroxysmal or no AF. In Group 3, 3% progressed to persistent and 88% reversed from persistent to paroxysmal or no AF (P < 0.001). Increased weight loss was significantly associated with greater AF freedom: 45 (39%) in Group 1, 69 (67%) in Group 2, and 116 (86%) in Group 3 (P ≤ 0.001). Obesity is associated with progression of the AF disease. This study demonstrates the dynamic relationship between weight/risk factors and AF. Weight-loss management and RFM reverses the type and natural progression of AF.",success
24436019,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"It is recognized that higher height and weight are associated with higher risk of atrial fibrillation or flutter (AF) but it is unclear whether risk of AF is related to body fat, body fat location, or lean body mass. This article reports the Danish population-based prospective cohort Diet, Cancer and Health study conducted among 55,273 men and women 50-64 years of age at recruitment. The associations between bioelectrical impedance derived measures of body composition and combinations of anthropometric measures of body fat distribution and risk of an incident record of AF in the Danish Registry of Patients were investigated. During follow-up (median 13.5 years) AF developed in 1,669 men and 912 women. Higher body fat at any measured location was associated with higher risk of AF. The adjusted hazard ratio (HR) per 1 sex-specific standard deviation (SD) increment in body fat mass was 1.29 (95% confidence interval [CI], 1.24-1.33). Higher lean body mass was also associated with a higher risk of AF. The adjusted HR for 1 sex-specific SD increment was 1.40 (95% CI, 1.35-1.45). Higher body fat and higher lean body mass were both associated with higher risk of AF.",success
25460864,False,Congress,,,,,,,,False,,success
15562125,False,"Journal Article;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Obesity is associated with atrial enlargement and ventricular diastolic dysfunction, both known predictors of atrial fibrillation (AF). However, it is unclear whether obesity is a risk factor for AF. To examine the association between body mass index (BMI) and the risk of developing AF. Prospective, community-based observational cohort in Framingham, Mass. We studied 5282 participants (mean age, 57 [SD, 13] years; 2898 women [55%]) without baseline AF (electrocardiographic AF or arterial flutter). Body mass index (calculated as weight in kilograms divided by square of height in meters) was evaluated as both a continuous and a categorical variable (normal defined as <25.0; overweight, 25.0 to <30.0; and obese, > or =30.0). In addition to adjusting for clinical confounders by multivariable techniques, we also examined models including echocardiographic left atrial diameter to examine whether the influence of obesity was mediated by changes in left atrial dimensions. Association between BMI or BMI category and risk of developing new-onset AF. During a mean follow-up of 13.7 years, 526 participants (234 women) developed AF. Age-adjusted incidence rates for AF increased across the 3 BMI categories in men (9.7, 10.7, and 14.3 per 1000 person-years) and women (5.1, 8.6, and 9.9 per 1000 person-years). In multivariable models adjusted for cardiovascular risk factors and interim myocardial infarction or heart failure, a 4% increase in AF risk per 1-unit increase in BMI was observed in men (95% confidence interval [CI], 1%-7%; P = .02) and in women (95% CI, 1%-7%; P = .009). Adjusted hazard ratios for AF associated with obesity were 1.52 (95% CI, 1.09-2.13; P = .02) and 1.46 (95% CI, 1.03-2.07; P = .03) for men and women, respectively, compared with individuals with normal BMI. After adjustment for echocardiographic left atrial diameter in addition to clinical risk factors, BMI was no longer associated with AF risk (adjusted hazard ratios per 1-unit increase in BMI, 1.00 [95% CI, 0.97-1.04], P = .84 in men; 0.99 [95% CI, 0.96-1.02], P = .56 in women). Obesity is an important, potentially modifiable risk factor for AF. The excess risk of AF associated with obesity appears to be mediated by left atrial dilatation. These prospective data raise the possibility that interventions to promote normal weight may reduce the population burden of AF.",success
29759357,False,Journal Article,,,,,,,,True,"The purpose of this study was to quantify the magnitude of association between incremental increases in body mass index (BMI) and the development of incident, post-operative, and post-ablation atrial fibrillation (AF). Obesity has been estimated to account for one-fifth of all AF and approximately 60% of recent increases in population AF incidence. From a public health perspective, obesity, therefore, is a modifiable risk factor that could be profitably targeted. A systematic review and meta-analysis was conducted. Medline and EMBASE databases were searched for observational studies reporting data on the association between obesity and incident, post-operative, and post-ablation AF. Studies were included if they reported or provided data allowing calculation of risk estimates. Data from 51 studies including 626,603 individuals contributed to this analysis. There were 29% (odds ratio [OR]: 1.29, 95% confidence interval [CI]: 1.23 to 1.36) and 19% (OR: 1.19, 95% CI: 1.13 to 1.26) greater excess risks of incident AF for every 5-U BMI increase in cohort and case-control studies, respectively. Similarly, there were 10% (OR: 1.10, 95% CI: 1.04 to 1.17) and 13% (OR: 1.13, 95% CI: 1.06 to 1.22) greater excess risks of post-operative and post-ablation AF for every 5-U increase in BMI, respectively. Incremental increases in BMI are associated with a significant excess risk of AF in different clinical settings. For every 5-U increase in BMI, there were 10% to 29% greater excess risks of incident, post-operative, and post-ablation AF. By providing a comprehensive and reliable quantification of the relationship between incremental increases in obesity and AF across different clinical settings, our findings highlight the potential for even moderate reductions in population body mass indexes to have a significant effect in mitigating the rising burden of AF.",success
27923804,False,Journal Article;Meta-Analysis,,,,,,,,True,"Although adiposity is increasingly recognized as a risk factor for atrial fibrillation (AF), the importance of epicardial fat compared with other adipose tissue depots remains uncertain. We sought to characterize and compare the associations of AF with epicardial fat and measures of abdominal and overall adiposity. We conducted a meta-analysis of 63 observational studies including 352 275 individuals, comparing AF risk for 1-SD increases in epicardial fat, waist circumference, waist/hip ratio, and body mass index. A 1-SD higher epicardial fat volume was associated with a 2.6-fold higher odds of AF (odds ratio, 2.61; 95% confidence interval [CI], 1.89-3.60), 2.1-fold higher odds of paroxysmal AF (odds ratio, 2.14; 95% CI, 1.45-3.16) and, 5.4-fold higher odds of persistent AF (odds ratio, 5.43; 95% CI, 3.24-9.12) compared with sinus rhythm. Likewise, a 1-SD higher epicardial fat volume was associated with 2.2-fold higher odds of persistent compared with paroxysmal AF (odds ratio, 2.19; 95% CI, 1.66-2.88). Similar associations existed for postablation, postoperative, and postcardioversion AF. In contrast, associations of abdominal and overall adiposity with AF were less extreme, with relative risks per 1-SD higher values of 1.32 (95% CI, 1.25-1.41) for waist circumference, 1.11 (95% CI, 1.08-1.14) for waist/hip ratio, and 1.22 (95% CI, 1.17-1.27) for body mass index. Strong and graded associations were observed between increasing epicardial fat and AF. Moreover, the strength of associations of AF with epicardial fat is greater than for measures of abdominal or overall adiposity. Further studies are needed to assess the mechanisms and clinical relevance of epicardial fat.",success
18611964,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Obesity has been shown to be a risk factor for first atrial fibrillation (AF), but whether it is associated with progression from paroxysmal to permanent AF is unknown. In this longitudinal cohort study, Olmsted County, MN residents confirmed to have developed paroxysmal AF during 1980-2000 were identified and followed passively to 2006. The interrelationships of body mass index (BMI), left atrial (LA) size, and progression to permanent AF were analysed. Of a total of 3248 patients (mean age 71 +/- 15 years; 54% men) diagnosed with paroxysmal AF, 557 (17%) progressed to permanent AF (unadjusted incidence, 36/1000 person-years) over a median follow-up period of 5.1 years (interquartile range 1.2-9.4). Adjusting for age and sex, BMI independently predicted the progression to permanent AF (hazard ratio, HR 1.04, CI 1.03-1.06; P < 0.0001). Compared with normal BMI (18.5-24.9 kg/m(2)), obesity (30-34.9 kg/m(2)) and severe obesity (>or=35 kg/m(2)) were associated with increased risk for progression [HR 1.54 (CI 1.2-2.0; P = 0.0004) and 1.87 (CI 1.4-2.5; P < 0.0001, respectively)]. BMI remained highly significant even after multiple adjustments. In the subgroup with echocardiographic assessment (n = 744), LA volume was incremental to BMI for independent prediction of progression after multiple adjustments, and did not weaken the association between BMI and progression to permanent AF (HR 1.04; CI 1.02-1.05; P < 0.0001). There was a graded risk relationship between BMI and progression from paroxysmal to permanent AF. This relationship was not weakened by LA volume, which was independent of and incremental to BMI for the prediction of progression to permanent AF.",success
21195377,False,Journal Article,,,,,,,,True,"Obesity is associated with new-onset atrial fibrillation (AF). However, the effect of obesity on AF recurrence or burden has not been studied. The aim of this study was to investigate the relation between AF recurrence, AF burden, and body mass index (BMI). A limited-access data set from the Atrial Fibrillation Follow-Up Investigation of Rhythm Management (AFFIRM) trial provided by the National Heart, Lung, and Blood Institute was used. Statistical analysis was done with a generalized linear mixed model. In 2,518 patients who had BMIs recorded, higher BMI was associated with a higher number of cardioversions (odds ratio [OR] 1.017, 95% confidence interval [CI] 1.005 to 1.029 for a BMI increase of 1 kg/m(2); OR 1.088, 95% CI 1.024 to 1.155 for a BMI increase of 5 kg/m(2); OR 1.183, 95% CI 1.049 to 1.334 for a BMI increase of 10 kg/m(2); p = 0.006 for each). Increased BMI was also associated with a higher likelihood of being in AF on follow-up (OR 1.020, 95% CI 1.002 to 1.038 per 1 kg/m(2) increased BMI, p = 0.0283; OR 1.104, 95% CI 1.011 to 1.205 per 5 kg/m(2) increased BMI, p = 0.0283; OR 1.218, 95% CI 1.021 to 1.452 per 10 kg/m(2) increased BMI, p = 0.0283). In a multivariate analysis, left atrial size but not BMI was an independent predictor of AF recurrence and AF burden. Because left atrial size was correlated with BMI, the effect of BMI on AF can be likely explained by greater left atrial size in subjects with higher BMIs. In conclusion, obesity is associated with a higher incidence of recurrence of AF and greater AF burden.",success
22972153,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"After an initial episode of atrial fibrillation (AF), AF may recur and become permanent. AF progression is associated with higher morbidity and mortality. Understanding the risk factors for permanent AF could help identify people who would benefit most from interventions. To determine whether body mass index (BMI), diabetes, hypertension, and blood pressure levels are associated with permanent AF among people whose initial AF episode terminated. Population-based inception cohort study. Enrollees in Group Health, an integrated health care system, aged 30-84 with newly diagnosed AF in 2001-2004, whose initial AF terminated within 6 months and who had at least 6 months of subsequent follow-up (N = 1,385). Clinical characteristics were determined from medical records. Permanent AF was determined from medical records and ECG and administrative databases. Permanent AF was defined as AF present on two separate occasions 6-36 months apart, without any documented sinus rhythm between the two occasions. Cox proportional hazards models were used to estimate adjusted hazard ratios (HRs). Five-year cumulative incidence of permanent AF was 24 %. Compared with normal BMI (18.5-24.9 kg/m(2)), BMI levels of 25.0-29.9 (overweight), 30.0-34.9 (obese 1), 35.0-39.9 (obese 2), and ≥ 40.0 kg/m(2) (obese 3) were associated with HRs of permanent AF of 1.26 (95 % CI: 0.92, 1.72); 1.35 (0.96, 1.91); 1.50 (0.97, 2.33); and 1.79 (1.13, 2.84), adjusted for age, sex, diabetes, hypertension, blood pressure, coronary heart disease, valvular heart disease, heart failure, and prior stroke. Diabetes, hypertension, and blood pressure were not associated with permanent AF. For people whose initial AF episode terminates, benefits of having lower BMI may include a lower risk of permanent AF. Risk of permanent AF was similar for people with and without diabetes or hypertension and across blood pressure levels.",success
23063864,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Obesity is associated with atrial fibrillation (AF); however, the mechanisms by which it induces AF are unknown. To examine the effect of progressive weight gain on the substrate for AF. Thirty sheep were studied at baseline, 4 months, and 8 months, following a high-calorie diet. Ten sheep were sampled at each time point for cardiac magnetic resonance imaging and hemodynamic studies. High-density multisite biatrial epicardial mapping was used to quantify effective refractory period, conduction velocity, and conduction heterogeneity index at 4 pacing cycle lengths and AF inducibility. Histology was performed for atrial fibrosis, inflammation, and intramyocardial lipidosis, and molecular analysis was performed for endothelin-A and -B receptors, endothelin-1 peptide, platelet-derived growth factor, transforming growth factor β1, and connective tissue growth factor. Increasing weight was associated with increasing left atrial volume (P = .01), fibrosis (P = .02), inflammatory infiltrates (P = .01), and lipidosis (P = .02). While there was no change in the effective refractory period (P = .2), there was a decrease in conduction velocity (P<.001), increase in conduction heterogeneity index (P<.001), and increase in inducible (P = .001) and spontaneous (P = .001) AF. There was an increase in atrial cardiomyocyte endothelin-A and -B receptors (P = .001) and endothelin-1 (P = .03) with an increase in adiposity. In association, there was a significant increase in atrial interstitial and cytoplasmic transforming growth factor β1 (P = .02) and platelet-derived growth factor (P = .02) levels. Obesity is associated with atrial electrostructural remodeling. With progressive obesity, there were changes in atrial size, conduction, histology, and expression of profibrotic mediators. These changes were associated with spontaneous and more persistent AF.",success
26139051,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Obesity and atrial fibrillation (AF) are public health issues with significant consequences. This study sought to delineate the development of global electrophysiological and structural substrate for AF in sustained obesity. Ten sheep fed ad libitum calorie-dense diet to induce obesity over 36 weeks were maintained in this state for another 36 weeks; 10 lean sheep with carefully controlled weight served as controls. All sheep underwent electrophysiological and electroanatomic mapping; hemodynamic and imaging assessment (echocardiography and dual-energy x-ray absorptiometry); and histology and molecular evaluation. Evaluation included atrial voltage, conduction velocity (CV), and refractoriness (7 sites, 2 cycle lengths), vulnerability for AF, fatty infiltration, atrial fibrosis, and atrial transforming growth factor (TGF)-β1 expression. Compared with age-matched controls, chronically obese sheep demonstrated greater total body fat (p < 0.001); LA volume (p < 0.001); LA pressure (p < 0.001), and PA pressures (p < 0.001); reduced atrial CV (LA p < 0.001) with increased conduction heterogeneity (p < 0.001); increased fractionated electrograms (p < 0.001); decreased posterior LA voltage (p < 0.001) and increased voltage heterogeneity (p < 0.001); no change in the effective refractory period (ERP) (p > 0.8) or ERP heterogeneity (p > 0.3). Obesity was associated with more episodes (p = 0.02), prolongation (p = 0.01), and greater cumulative duration (p = 0.02) of AF. Epicardial fat infiltrated the posterior LA in the obese group (p < 0.001), consistent with reduced endocardial voltage in this region. Atrial fibrosis (p = 0.03) and TGF-β1 protein (p = 0.002) were increased in the obese group. Sustained obesity results in global biatrial endocardial remodeling characterized by LA enlargement, conduction abnormalities, fractionated electrograms, increased profibrotic TGF-β1 expression, interstitial atrial fibrosis, and increased propensity for AF. Obesity was associated with reduced posterior LA endocardial voltage and infiltration of contiguous posterior LA muscle by epicardial fat, representing a unique substrate for AF.",success
26702314,False,Journal Article,,,,,,,,True,"Because obesity is an important risk factor for atrial fibrillation (AF), we conducted an animal study to examine the effect of a high-fat diet (HFD) on atrial properties and AF inducibility. Ten 8-week-old pigs (weight, 18-23 kg) were divided into two groups. For 18 weeks, five pigs were fed a HFD (HFD group) and five were fed a normal diet (control group). Maps of atrial activation and voltages during sinus rhythm were created for all pigs using the EnSite NavX system. Effective refractory period (ERP) and AF inducibility were also determined. When AF was induced, complex fractionated atrial electrogram (CFAE) mapping was performed. At 18 weeks, hearts were removed for comparing the results of histological analysis between the two groups. Body weight, lipid levels, hemodynamics, cardiac structures, and electrophysiological properties were also compared. Total cholesterol levels were significantly higher (347 [191-434] vs. 81 [67-88] mg/dL, P=0.0088), and left atrium pressure was higher (34.5 [25.6-39.5] vs. 24.5 [21.3-27.8] mmHg, P=0.0833) in the HFD group than in the control group, although body weight only increased marginally (89 [78-101] vs. 70 [66-91] kg, P=0.3472). ERPs of the pulmonary vein (PV) were shorter (P<0.05) and AF lasted longer in the HFD group than in the control group (80 [45-1350] vs. 22 [3-30] s, P=0.0212). Neither CFAE site distribution nor histopathological characteristics differed between the two groups. The shorter ERPs for the PV observed in response to the HFD increased vulnerability to AF, and these electrophysiological characteristics may underlie obesity-related AF.",success
26274906,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"Epicardial adiposity and plasma levels of free fatty acids (FFAs) are elevated in atrial fibrillation, heart failure and obesity, with potentially detrimental effects on myocardial function. As major components of epicardial fat, FFAs may be abnormally regulated, with a potential to detrimentally modulate electro-mechanical function. The cellular mechanisms underlying such effects of FFAs are unknown. To determine the mechanisms underlying electrophysiological effects of palmitic (PA), stearic (SA) and oleic (OA) FFAs on sheep atrial myocytes. We used electrophysiological techniques, numerical simulations, biochemistry and optical imaging to examine the effects of acutely (≤ 15 min), short-term (4-6 hour) or 24-hour application of individual FFAs (10 μM) on isolated ovine left atrial myocytes (LAMs). Acute and short-term incubation in FFAs resulted in no differences in passive or active properties of isolated left atrial myocytes (LAMs). 24-hour application had differential effects depending on the FFA. PA did not affect cellular passive properties but shortened (p<0.05) action potential duration at 30% repolarization (APD30). APD50 and APD80 were unchanged. SA had no effect on resting membrane potential but reduced membrane capacitance by 15% (p<0.05), and abbreviated APD at all values measured (p≤0.001). OA did not significantly affect passive or active properties of LAMs. Measurement of the major voltage-gated ion channels in SA treated LAMs showed a ~60% reduction (p<0.01) of the L-type calcium current (ICa-L) and ~30% reduction (p<0.05) in the transient outward potassium current (ITO). A human atrial cell model recapitulated SA effects on APD. Optical imaging showed that SA incubated for 24 hours altered t-tubular structure in isolated cells (p<0.0001). SA disrupts t-tubular architecture and remodels properties of membrane ionic currents in sheep atrial myocytes, with potential implications in arrhythmogenesis.",success
20504944,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Atrial fibrillation (AF) has been linked to inflammatory factors and obesity. Epicardial fat is a source of several inflammatory mediators related to the development of coronary artery disease. We hypothesized that periatrial fat may have a similar role in the development of AF. Left atrium (LA) epicardial fat pad thickness was measured in consecutive cardiac CT angiograms performed for coronary artery disease or AF. Patients were grouped by AF burden: no (n=73), paroxysmal (n=60), or persistent (n=36) AF. In a short-axis view at the mid LA, periatrial epicardial fat thickness was measured at the esophagus (LA-ESO), main pulmonary artery, and thoracic aorta; retrosternal fat was measured in axial view (right coronary ostium level). LA area was determined in the 4-chamber view. LA-ESO fat was thicker in patients with persistent AF versus paroxysmal AF (P=0.011) or no AF (P=0.003). LA area was larger in patients with persistent AF than paroxysmal AF (P=0.004) or without AF (P<0.001). LA-ESO was a significant predictor of AF burden even after adjusting for age, body mass index, and LA area (odds ratio, 5.30; 95% confidence interval, 1.39 to 20.24; P=0.015). A propensity score-adjusted multivariable logistic regression that included age, body mass index, LA area, and comorbidities was also performed and the relationship remained statistically significant (P=0.008). Increased posterior LA fat thickness appears to be associated with AF burden independent of age, body mass index, or LA area. Further studies are necessary to examine cause and effect, and if inflammatory, paracrine mediators explain this association.",success
25466809,False,Journal Article,,,,,,,,True,"Epicardial adipose tissue (EAT), as an endocrine organ, may serve as a source of pro-inflammatory cytokines. Also, given the strong relationship between atrial fibrillation (AF), obesity and inflammation, the purpose of this study was to investigate the association of non-valvular AF with epicardial and periatrial fat. A total of 618 (192 in sinus rhythm, 169 with paroxysmal AF, 133 with persistent AF and 124 with permanent AF) patients who underwent CT angiography for the evaluation of CAD or pulmonary vein anatomy before catheter ablation were enrolled in this study. Thickness of the EAT and periatrial fat were measured by CT angiography. Together with body mass index, these were examined in relation to the presence and severity of AF and left atrial (LA) diameter. Patients with AF had significantly more total EAT and periatrial fat thickness compared with patients in sinus rhythm (p < 0.001). EAT thickness was significantly higher in permanent, persistent and paroxysmal AF compared with sinus rhythm group (p < 0.001). Multivariable multinomial logistic regression analysis comparing patients with sinus rhythm and subtypes of AF revealed a significant association between periatrial fat and total EAT thickness with all AF subtypes. Correlation analysis demonstrated that both total EAT thickness and periatrial fat thickness were significantly correlated with LA diameter (p < 0.05). Epicardial fat thickness is associated with both the presence and severity of AF independent of all other risk factors including LA diameter. Mediators for the association of EAT with AF pathophysiology requires future large scale prospective studies.",success
24786144,False,"Comparative Study;Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Once atrial fibrillation (AF) progresses to sustained forms, adverse outcomes increase and treatment success rates decrease. Therefore, identification of risk factors predisposing to persistence of AF may have a significant impact on AF morbidity. We prospectively examined the differential associations between traditional, lifestyle, and biomarker AF risk factors and development of paroxysmal versus nonparoxysmal AF (persistent/permanent) among 34 720 women enrolled in the Women's Health Study who were free of cardiovascular disease and AF at baseline. AF patterns were defined based on current guidelines and classified according to the most sustained form of AF within 2 years of diagnosis. During a median follow-up of 16.4 years, 690 women developed paroxysmal AF and 349 women developed nonparoxysmal AF. In multivariable time-varying competing risk models, increasing age (hazard ratio [HR] 1.11, 95% CI 1.10 to 1.13, versus HR 1.08, 1.07 to 1.09, per year), body mass index (HR 1.07, 1.05 to 1.09, versus HR 1.03, 1.02 to 1.05, per kg/m(2)), and weight (HR 1.30, 1.22 to 1.39, versus HR 1.14, 1.08 to 1.20, per 10 kg) were more strongly associated with the development of nonparoxysmal AF compared with paroxysmal AF. Hemoglobin A1c levels at baseline were directly related to the development of nonparoxysmal AF but inversely associated with paroxysmal AF in multivariable competing risk models (P for nonequal association=0.01). In women without AF or CVD at baseline, increasing age, adiposity, and higher hemoglobin A1c levels were preferentially associated with the early development of nonparoxysmal AF. These data raise the hypothesis that efforts aimed at weight reduction or glycemic control may affect the proportion of the population with sustained AF.",success
24240932,True,"Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",,,,,,,,True,"Obesity is a risk factor for atrial fibrillation. Whether weight reduction and cardiometabolic risk factor management can reduce the burden of atrial fibrillation is not known. To determine the effect of weight reduction and management of cardiometabolic risk factors on atrial fibrillation burden and cardiac structure. Single-center, partially blinded, randomized controlled study conducted between June 2010 and December 2011 in Adelaide, Australia, among overweight and obese ambulatory patients (N = 150) with symptomatic atrial fibrillation. Patients underwent a median of 15 months of follow-up. Patients were randomized to weight management (intervention) or general lifestyle advice (control). Both groups underwent intensive management of cardiometabolic risk factors. The primary outcomes were Atrial Fibrillation Severity Scale scores: symptom burden and symptom severity. Scores were measured every 3 months from baseline to 15 months. Secondary outcomes performed at baseline and 12 months were total atrial fibrillation episodes and cumulative duration measured by 7-day Holter, echocardiographic left atrial area, and interventricular septal thickness. Of 248 patients screened, 150 were randomized (75 per group) and underwent follow-up. The intervention group showed a significantly greater reduction, compared with the control group, in weight (14.3 and 3.6 kg, respectively; P < .001) and in atrial fibrillation symptom burden scores (11.8 and 2.6 points, P < .001), symptom severity scores (8.4 and 1.7 points, P < .001), number of episodes (2.5 and no change, P = .01), and cumulative duration (692-minute decline and 419-minute increase, P = .002). Additionally, there was a reduction in interventricular septal thickness in the intervention and control groups (1.1 and 0.6 mm, P = .02) and left atrial area (3.5 and 1.9 cm2, P = .02). In this study, weight reduction with intensive risk factor management resulted in a reduction in atrial fibrillation symptom burden and severity and in beneficial cardiac remodeling. These findings support therapy directed at weight and risk factors in the management of atrial fibrillation. anzctr.org.au Identifier: ACTRN12610000497000.",success
26386801,True,"Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, N.I.H., Extramural;Research Support, N.I.H., Intramural;Research Support, U.S. Gov't, Non-P.H.S.",NCT00017953,databank,NCT00017953,NCT00017953,NCT00017953,NCT00017953|databank,NCT00017953|databank,True,"Obesity is associated with higher risk of atrial fibrillation (AF), but the impact of behavioral weight loss interventions on atrial fibrillation (AF) risk in persons with diabetes is unknown. We addressed this question in the Look AHEAD randomized trial. A total of 5,067 overweight or obese individuals 45 to 76 years old with type 2 diabetes without prevalent AF were randomized to either an intensive lifestyle intervention (ILI) designed to achieve and maintain weight loss through caloric reduction and increased physical activity or a diabetes support and education usual care group. Atrial fibrillation was ascertained from electrocardiograms at study examinations and hospitalization discharge summaries. Multivariable Cox models were used to estimate the intention-to-treat effect of the intervention adjusting for baseline covariates. During a mean follow-up of 9.0 years, 294 incident AF cases were identified. Rates of AF were comparable in the ILI and diabetes support and education groups (6.1 and 6.7 cases per 1,000 person-years, respectively, P = .42). The intervention did not affect AF incidence (multivariable hazard ratio [HR] 0.99, 95% CI 0.77-1.28). Similarly, neither weight loss nor improvement in physical fitness during the first year of the intervention was significantly associated with AF incidence: multivariable hazard ratio (95% CI) comparing top versus bottom quartile was 0.70 (0.41-1.18) for weight loss and 0.88 (0.55-1.43) for physical fitness improvement. In a large randomized trial of overweight and obese individuals with type 2 diabetes, an ILI that induced modest weight loss did not reduce the risk of developing AF.",success
30611665,False,Journal Article,,,,,,,,True,"Obesity is associated with an increased risk of atrial fibrillation (AF). Bariatric surgery results insubstantial long-term weight loss and the amelioration of several chronic comorbidities. We hypothesized that weightreduction with bariatric surgery would reduce the long-term incidence of AF. To assess the association between bariatric surgery and AF prevention. University Hospital, United States. All patients who underwent bariatric surgery at a single institution from 1985-2015 (n = 3,572) were propensity score matched 1:1 to a control population of obese patients with outpatient appointments (n = 45,750) in our clinical data repository. Patients with a prior diagnosis of AF were excluded. Demographics, relevant comorbidities, and insurance status were collected and a chart review was performed for all patients with AF. Paired univariate analyses were used to compare the two groups. After propensity score matching, 5,044 total patients were included (2,522 surgical, 2,522 non-surgical). There were no differences in preoperative body mass index (BMI) (47.1 vs 47.7 kg/m<sup>2</sup>, P = 0.76) or medical comorbidities between groups. The incidence of AF was lower among surgical patients (0.8% vs 2.9%, P = 0.0001). In patients ultimately diagnosed with AF, time from enrollment to development of AF did not differ between groups; however, surgical patients with AF experienced a significantly higher reduction in excess BMI compared to non-surgical patients with AF (57.9% vs -3.8%, P<0.001). The incidence of AF was lower among patients who underwent bariatric surgery compared to their medically managed counterparts. Weight reduction with bariatric surgery may reduce the long-term incidence of AF.",success
31304532,False,Journal Article;Observational Study,,,,,,,,True,"Obesity decreases arrhythmia-free survival after atrial fibrillation (AF) ablation by mechanisms that are not fully understood. We investigated the impact of pre-ablation bariatric surgery (BS) on AF recurrence after ablation. In this retrospective observational cohort study, 239 consecutive morbidly obese patients (body mass index ≥40 kg/m2 or ≥35 kg/m2 with obesity-related complications) were followed for a mean of 22 months prior to ablation. Of these patients, 51 had BS prior to ablation, and our primary outcome was whether BS was associated with a lower rate of AF recurrence during follow-up. Adjustment for confounding was performed with multivariable Cox proportional hazard models and propensity-score based analyses. During a mean follow-up of 36 months after ablation, 10/51 patients (20%) in the BS group had recurrent AF compared with 114/188 (61%) in the non-BS group (P < 0.0001). In the BS group, 6 patients (12%) underwent repeat ablation compared with 77 patients (41%) in the non-BS group, (P < 0.0001). On multivariable analysis, the association between BS and lower AF recurrence remained significant. Similarly, after weighting and adjusting for the inverse probability of the propensity score, BS was still associated with a lower hazard of AF recurrence (hazard ratio 0.14, 95% confidence interval 0.05-0.39; P = 0.002). Bariatric surgery is associated with a lower AF recurrence after ablation. Morbidly obese patients should be considered for BS prior to AF ablation, though prospective multicentre studies should be performed to confirm our novel finding.",success
28521886,False,Journal Article,,,,,,,,True,"Obesity is repeatedly emphasized as a risk factor for atrial fibrillation or flutter (AF). However, the underlying evidence may be questioned, as the obvious correlations between various anthropometric measures hamper identification of the characteristics that are biologically driving AF risk, and recent studies suggest that fat carries limited or no independent risk of AF. This study sought to assess mutually adjusted associations among AF risk and height, weight, body mass index, hip and waist circumference, waist-to-hip ratio, and bioelectrical impedance-derived measures of fat mass, lean body mass, and fat percentage. Anthropometric measures and self-reported life-style information were collected from 1993 to 1997 in a population-based cohort including 55,273 persons age 50 to 64 years who were followed in Danish registers until June 2013. During a median of 17 years of follow-up, 3,868 persons developed AF. Adjusted hazard ratios per population SD difference (HRs) showed highly statistically significant, positive associations for all 9 anthropometric measures (HRs ranging from 1.08 [95% confidence interval (CI): 1.05 to 1.12] for waist-to-hip ratio to 1.37 [95% CI: 1.33 to 1.42] for lean body mass). Pairwise mutual adjustment of the 9 measures left the association for lean body mass virtually unchanged (lowest HR: 1.33 [95% CI: 1.28 to 1.39] when adjusting for height), whereas no other association remained substantial when adjusted for lean body mass (highest HR: 1.05 [95% CI: 1.01 to 1.10] for height). Lean body mass was the predominant anthropometric risk factor for AF, whereas no association was observed for either of the obesity-related anthropometric measures after adjustment for lean body mass.",success
21511110,False,"Comparative Study;Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"The aim of this study was to characterize the relationship between pericardial fat and atrial fibrillation (AF). Obesity is an important risk factor for AF. Pericardial fat has been hypothesized to exert local pathogenic effects on nearby cardiac structures above and beyond that of systemic adiposity. One hundred ten patients undergoing first-time AF ablation and 20 reference patients without AF underwent cardiac magnetic resonance imaging for the quantification of periatrial, periventricular, and total pericardial fat volumes using a previously validated technique. Together with body mass index and body surface area, these were examined in relation to the presence of AF, the severity of AF, left atrial volume, and long-term AF recurrence after ablation. Pericardial fat volumes were significantly associated with the presence of AF, AF chronicity, and AF symptom burden (all p values <0.05). Pericardial fat depots were also predictive of long-term AF recurrence after ablation (p = 0.035). Finally, pericardial fat depots were also associated with left atrial volume (total pericardial fat: r = 0.46, p < 0.001). Importantly, these associations persisted after multivariate adjustment and additional adjustment for body weight. In contrast, however, systemic measures of adiposity, such as body mass index and body surface area, were not associated with these outcomes in multivariate-adjusted models. Pericardial fat is associated with the presence of AF, the severity of AF, left atrial volumes, and poorer outcomes after AF ablation. These associations are both independent of and stronger than more systemic measures of adiposity. These findings are consistent with the hypothesis of a local pathogenic effect of pericardial fat on the arrhythmogenic substrate supporting AF.",success
18678768,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"Vigorous exertion and endurance training have been reported to increase atrial fibrillation (AF). Associations of habitual light or moderate activity with AF incidence have not been evaluated. We prospectively investigated associations of leisure-time activity, exercise intensity, and walking habits, assessed at baseline and updated during follow-up visits, with incident AF, diagnosed by annual 12-lead ECGs and hospital discharge records, from 1989 to 2001 among 5446 adults > or =65 years of age in the Cardiovascular Health Study. During 47 280 person-years of follow-up, 1061 new AF cases occurred (incidence 22.4/1000 person-years). In multivariable-adjusted analyses, leisure-time activity was associated with lower AF incidence in a graded manner, with 25% (hazard ratio [HR] 0.75, 95% confidence interval [CI] 0.61 to 0.90), 22% (HR 0.78, 95% CI 0.65 to 0.95), and 36% (HR 0.64, 95% CI 0.52 to 0.79) lower risk in quintiles 3, 4, and 5 versus quintile 1 (P for trend <0.001). Exercise intensity had a U-shaped relationship with AF (quadratic P=0.02): Versus no exercise, AF incidence was lower with moderate-intensity exercise (HR 0.72, 95% CI 0.58 to 0.89) but not with high-intensity exercise (HR 0.87, 95% CI 0.64 to 1.19). Walking distance and pace were each associated with lower AF risk in a graded manner (P for trend <0.001); when we assessed the combined effects of distance and pace, individuals in quartiles 2, 3, and 4 had 25% (HR 0.75, 95% CI 0.56 to 0.99), 32% (HR 0.68, 95% CI 0.50 to 0.92), and 44% (HR 0.56, 95% CI 0.38 to 0.82) lower AF incidence than individuals in quartile 1. Findings appeared unrelated to confounding by comorbidity or indication. After evaluation of cut points of moderate leisure-time activity (approximately 600 kcal/week), walking distance (12 blocks per week), and pace (2 mph), 26% of all new AF cases (95% CI 7% to 43%) appeared attributable to absence of these activities. Light to moderate physical activities, particularly leisure-time activity and walking, are associated with significantly lower AF incidence in older adults.",success
24829373,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"This study examines the influence of physical activity at different ages and of different types, on the risk of developing atrial fibrillation (AF) in a large cohort of Swedish men. Information about physical activity was obtained from 44 410 AF-free men, aged 45-79 years (mean age=60), who had completed a self-administered questionnaire at baseline in 1997. Participants reported retrospectively their time spent on leisure-time exercise and on walking or bicycling throughout their lifetime (at 15, 30 and 50 years of age, and at baseline (mean age=60)). Participants were followed-up in the Swedish National Inpatient Register for ascertainment of AF. Cox proportional hazards regression models were used to estimate relative risks (RR) with 95% CIs, adjusted for potential confounders. During a median follow-up of 12 years, 4568 cases of AF were diagnosed. We observed a RR of 1.19 (95% CI 1.05 to 1.36) of developing AF in men who at the age of 30 years had exercised for >5 h/week compared with <1 h/week. The risk was even higher (RR 1.49, 95% CI 1.14 to 1.95) among the men who exercised >5 h/week at age 30 and quit exercising later in life (<1 h/week at baseline). Walking/bicycling at baseline was inversely associated with risk of AF (RR 0.87, 95% CI 0.77 to 0.97 for >1 h/day vs almost never) and the association was similar after excluding men with previous coronary heart disease or heart failure at baseline (corresponding RR 0.88, 95% CI 0.77 to 0.998). Leisure-time exercise at younger age is associated with an increased risk of AF, whereas walking/bicycling at older age is associated with a decreased risk.",success
26019224,True,"Journal Article;Multicenter Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"Previous studies have found that regular participation in intense physical activity increases the risk of developing atrial fibrillation (AF) in men, but it remains unclear how physical activity influences the risk of AF in women. We aimed to examine whether physical activity of different types and at different ages influences the development of AF in women. In the population-based Swedish Mammography Cohort, information about physical activity was obtained from 36 513 AF-free women (49-83 years old, median age 60 years) who had completed a questionnaire at study entry (1997). Participants reported their time spent on leisure-time exercise and on walking or bicycling throughout their lifetime (at study entry, and at 30 and 50 years of age). We used the Swedish National Inpatient Register (IPR) to determine whether the participants were diagnosed with AF. Cox proportional hazards regression models were used to estimate relative risks (RR) with 95% CI, adjusted for potential confounders. During a median follow-up of 12 years (10th percentile 7.5 years, 90th percentile 12.0 years), 2915 cases of AF were diagnosed. The risk of AF decreased with increasing levels of leisure-time exercise at study entry (RR 0.85, 95% CI 0.75 to 0.95 for ≥4 h/week vs <1 h/week) and walking/bicycling (RR 0.81, 95% CI 0.72 to 0.92, for ≥40 min/day vs almost never). Physical activity is associated with a reduced risk of AF in women. Moderate amount of physical activity was sufficient to significantly reduce AF risk.",success
21487092,False,"Journal Article;Research Support, N.I.H., Extramural",,,,,,,,True,"Physical activity (PA) is well known to reduce the risk of cardiovascular disease. We hypothesized that regular PA, possibly acting through reductions in blood pressure and body mass index (BMI), would reduce the risk of incident atrial fibrillation (AF) in women. We prospectively followed 34 759 women who reported their leisure-time PA levels for the occurrence of AF. We estimated energy expenditure in metabolic equivalent (MET)-h/wk and validated self-reported AF with medical records. The mean (SD) age of the 34 759 participants was 54.6 (7.0) years, the mean BMI was 26.0 (5.0) kg/m(2), 26.5% had hypertension, and the median (IQR) PA was 8.4 (2.8, 20.4) MET-h/wk. After a median of 14.4 years of observation, 968 women had development of AF. In age-, cholesterol-, smoking-, alcohol-, diabetes-, and race-adjusted models, increasing quintiles of PA were associated with reduced risks of AF (hazard ratio for extreme quintiles, 0.82; 0.66 to 1.01; P trend=0.007 over quintiles). Although this association was not substantially different after adjusting for hypertension (0.87; 0.70 to 1.07; P trend 0.02), it was attenuated after adjustment for BMI (0.99; 0.80 to 1.23; P trend=0.22). Women who achieved the federal government's recommendation of 7.5 MET-h/wk of PA were at reduced risk of AF compared with those who did not (0.86; 0.75 to 0.98; P=0.03). This association was also attenuated by BMI (0.96; 0.84 to 1.10; P=0.57). In middle-aged women, physical activity was associated with a modestly reduced risk of AF. However, this relationship was no longer significant after controlling for body mass index.",success
24907285,True,"Journal Article;Multicenter Study;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"Physical activity (PA) has previously been suggested to attenuate the risk of atrial fibrillation (AF) conferred by excess body weight and weight gain. We prospectively examined the relationship between body size, weight change, and level of PA in a biracial cohort of middle-aged men and women. Baseline characteristics on risk factor levels were obtained on 14 219 participants from the Atherosclerosis Risk in Communities Study. AF incidence was ascertained from 1987 to 2009. Adjusted Cox proportional hazards models were used to estimate the associations between body mass index, waist circumference, relative weight change, and PA level with incident AF. During follow-up, there were 1775 cases of incident AF. Body mass index and waist circumference were positively associated with AF as was weight loss/gain of >5% initial body weight. An ideal level of PA had a small protective effect on AF risk and partially attenuated the risk of AF associated with excess weight in men but not women: compared with men with a normal body mass index, the risk of AF in obese men with an ideal, intermediate, and poor level of PA at baseline was increased by 37%, 129%, and 156% (Pinteraction=0.04). During follow-up, PA did not modify the association between weight gain and risk of AF. Obesity and extreme weight change are risk factors for incident AF, whereas being physically active is associated with a small reduction in risk. In men only, being physically active offset some, but not all, of the risk incurred with excess body weight.",success
25142057,False,"Journal Article;Observational Study;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Atrial fibrillation (AF) is the most common cardiac arrhythmia and is associated with increased risk of stroke and death. Obesity is an independent risk factor for AF, but modifiers of this risk are not well known. We studied the roles of obesity, physical activity, and their interaction in conferring risk of incident AF. The Women's Health Initiative (WHI) Observational Study was a prospective observational study of 93 676 postmenopausal women followed for an average of 11.5 years. Incident AF was identified using WHI-ascertained hospitalization records and diagnostic codes from Medicare claims. A multivariate Cox's hazard regression model adjusted for demographic and clinical risk factors was used to evaluate the interaction between obesity and physical activity and its association with incident AF. After exclusion of women with prevalent AF, incomplete data, or underweight body mass index (BMI), 9792 of the remaining 81 317 women developed AF. Women were, on average, 63.4 years old, 7.8% were African American, and 3.6% were Hispanic. Increased BMI (hazard ratio [HR], 1.12 per 5-kg/m(2) increase; 95% confidence interval [CI], 1.10 to 1.14) and reduced physical activity (>9 vs. 0 metabolic equivalent task hours per week; HR, 0.90; 95% CI, 0.85 to 0.96) were independently associated with higher rates of AF after multivariate adjustment. Higher levels of physical activity reduced the AF risk conferred by obesity (interaction P=0.033). Greater physical activity is associated with lower rates of incident AF and modifies the association between obesity and incident AF.",success
29939081,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Background Atrial fibrillation is the most common heart rhythm disorder, and high body mass index is a well-established risk factor for atrial fibrillation. The objective of this study was to examine the associations of physical activity and body mass index and risk of atrial fibrillation, and the modifying role of physical activity on the association between body mass index and atrial fibrillation. Design The design was a prospective cohort study. Methods This study followed 43,602 men and women from the HUNT3 study in 2006-2008 until first atrial fibrillation diagnosis or end of follow-up in 2015. Atrial fibrillation diagnoses were collected from hospital registers and validated by medical doctors. Cox proportional hazard regression analysis was performed to assess the association between physical activity, body mass index and atrial fibrillation. Results During a mean follow-up of 8.1 years (352,770 person-years), 1459 cases of atrial fibrillation were detected (4.1 events per 1000 person-years). Increasing levels of physical activity were associated with gradually lower risk of atrial fibrillation ( p trend 0.069). Overweight and obesity were associated with an 18% (hazard ratio 1.18, 95% confidence interval 1.03-1.35) and 59% (hazard ratio 1.59, 95% confidence interval 1.37-1.84) increased risk of atrial fibrillation, respectively. High levels of physical activity attenuated some of the higher atrial fibrillation risk in obese individuals (hazard ratio 1.53, 95% confidence interval 1.03-2.28 in active and 1.96, 95% confidence interval 1.44-2.67 in inactive) compared to normal weight active individuals. Conclusion Overweight and obesity were associated with increased risk of atrial fibrillation. Physical activity offsets some, but not all, atrial fibrillation risk associated with obesity.",success
27068670,False,Journal Article,,,,,,,,True,"To assess the association between exercise capacity and the risk of developing atrial fibrillation (AF). A symptom-limited exercise tolerance test was conducted to assess exercise capacity in 5962 veterans (mean age, 56.8±11.0 years) from the Veterans Affairs Medical Center, Washington, DC. None had evidence of AF or ischemia at the time of or before undergoing their exercise tolerance test. We established 4 fitness categories based on age-stratified quartiles of peak metabolic equivalent task (MET) achieved: least fit (4.9±1.10 METs; n=1446); moderately fit (6.7±1.0 METs; n=1490); fit (7.9±1.0 METs; n=1585), and highly fit (9.3±1.2 METs; n=1441). Multivariable Cox proportional hazards regression models were used to compare the AF-exercise capacity association between fitness categories. During a median follow-up period of 8.3 years, 722 (12.1%) individuals developed AF (14.5 per 1000 person-years; 95% CI, 13.9-15.9 per 1000 person-years). Exercise capacity was inversely related to AF incidence. The risk was 21% lower (hazard ratio, 0.79; 95% CI, 0.76-0.82) for each 1-MET increase in exercise capacity. Compared with the least fit individuals, hazard ratios were 0.80 (95% CI, 0.67-0.97) for moderately fit individuals, 0.55 (95% CI, 0.45-0.68) for fit individuals, and 0.37 (95% CI, 0.29-0.47) for highly fit individuals. Similar trends were observed in those younger than 65 years and those 65 years or older. Increased fitness is inversely and independently associated with the reduced risk of developing AF. The decrease in risk was graded and precipitous with only modest increases in exercise capacity. These findings counter previous suggestions that even moderate increases in physical activity, as recommended by national and international guidelines, increase the risk of AF, with marked protection against AF noted with increasing levels of fitness.",success
16815571,True,Journal Article;Randomized Controlled Trial,,,,,,,,True,"A randomised study was conducted to determine if short-term exercise training in patients with chronic atrial fibrillation (AF) might improve symptoms and health-related quality of life (HRQoL). AF patients (64+/-7 years) were randomised to exercise training (n=15) or a 2-month control period (n=15) followed by an exercise training program (ETP). The ETP consisted of 24 training sessions with aerobic exercise and muscle strengthening. A cycle ergometer test, with recording of perceived exertion on the Borg scale, was performed. The participants completed HRQoL questionnaires, the Short-Form 36 (SF-36) and Symptom and Severity Checklist (SSCL), before and after training. Because there were no changes after two months in the control group, pooled data for all patients are presented before and after training. Four of the eight SF-36 scales improved significantly (p<0.05) following training: physical functioning (82+/-14 pre-ETP, 86+/-10 post-ETP), bodily pain (82+/-17 pre-ETP, 92+/-14 post-ETP), vitality (61+/-14 pre-ETP, 68+/-13 post-ETP) and role-emotional (85+/-28 pre-ETP, 94+/-20 post-ETP). The SF-36 physical component summary scale also increased from 49+/-6 pre-ETP to 52+/-6 post-ETP (p<0.05). Significant improvements were also observed for summary and specific symptom scores of the SSCL. Exercise capacity improved by 41+/-20% and perceived exertion during testing by 1.4 points after training (p<0.05 for both). The study demonstrates a significant improvement in HRQoL, symptoms during exercise testing and exercise capacity after a short-term exercise training program in patients with chronic AF.",success
22137082,True,Journal Article;Randomized Controlled Trial,,,,,,,,True,"Exercise training is beneficial in ischemic and congestive heart disease. However, the effect on atrial fibrillation (AF) is unknown. Forty-nine patients with permanent AF (age [mean ± SD], 70.2 ± 7.8 years; male-to-female ratio, 0.75; body mass index [mean ± SD], 29.7 ± 4.3 kg/m(2)) were randomized to 12-week aerobic exercise training or a control group. Exercise capacity, 6-minute walk test (6MWT), cardiac output, quality of life, and natriuretic peptides were measured. Cardiac output was measured at rest and during ergometer testing, and atrial natriuretic peptide and N-terminal pro-B-type natriuretic peptide were measured before and after the training period. Quality of life was evaluated using the Short-Form 36 and Minnesota Living With Heart Failure (MLHF-Q) questionnaires. Improved exercise capacity and 6MWT were observed in the active patients (P < .001), and at study end, there was a significant difference between the active patients and the controls (P = .002). Resting pulse decreased in the active patients (94.8 ± 22.4 to 86.3 ± 22.5 beats/min, P = .049) but remained unchanged in the controls. Cardiac output was unchanged from baseline to end-of-study period. The MLHF-Q score improved in the active group (21.1 ± 18.0 vs 15.4 ± 17.5, P = .03). Active patients showed progress in 3 of the 8 Short-Form 36 subscales: physical functioning (P = .02), general health perceptions (P = .001), and vitality (P = .02). Natriuretic peptides were unchanged. Twelve weeks of exercise training increased exercise capacity and 6MWT and decreased resting pulse rate significantly in patients with AF. Overall quality of life increased significantly as measured by the cardiology-related MLHF-Q. Cardiac output and natriuretic peptides were unchanged in both groups.",success
28796004,False,Journal Article;Meta-Analysis;Review,,,,,,,,True,"Exercise training has become part of the standard care for patients with cardiovascular disease. We investigated the effects of exercise training on exercise capacity, cardiac function, BMI, and quality of life in patients with atrial fibrillation (AF). We searched for randomized-controlled trials of supervised exercise training versus care without exercise training (the control) in patients with permanent or nonpermanent AF published up to November 2016. Standard mean differences (SMD) or mean differences (MD), and 95% confidence intervals (CIs) were calculated using random-effect models. We identified 259 trials, and after an assessment of relevance, five trials with a combined total of 379 participants were analyzed. In AF patients, exercise training significantly improved exercise capacity and left ventricular ejection fraction compared with the control (SMD: 0.91, 95% CI: 0.70 to 1.12; MD: 4.8%, 95% CIs: 1.56 to 8.03, respectively). Compared with the control, exercise training also significantly reduced BMI (MD: -0.47 kg/m, 95% CIs: -0.89 to -0.06) and significantly improved scores in the 'general health' and 'vitality' sections of the 36-item Short Form Health Status Survey (SMD: 0.71, 95% CIs: 0.30 to 1.12; SMD: 0.81, 95% CIs: 0.40 to 1.23, respectively). Exercise training improved exercise capacity, left ventricular ejection fraction, and some the 36-item Short Form Health Status Survey scores, and reduced BMI in AF patients.",success
21406280,False,Journal Article,,,,,,,,True,"To date, no study has objectively measured physical activity levels among U.S. adults according to the 2008 Physical Activity Guidelines for Americans (PAGA). The purpose of this study was to assess self-reported and objectively measured physical activity among U.S. adults according to the PAGA. Using data from the NHANES 2005-2006, the PAGA were assessed using three physical activity calculations: moderate plus vigorous physical activity ≥150 minutes/week (MVPA); moderate plus two instances of vigorous physical activity ≥150 minutes/week (M2VPA); and time spent above 3 METs ≥500 MET-minutes/week (METPA). Self-reported physical activity included leisure, transportation, and household activities. Objective activity was measured using Actigraph accelerometers that were worn for 7 consecutive days. Analyses were conducted in 2009-2010. U.S. adults reported 324.5 ± 18.6 minutes/week (M ± SE) of moderate physical activity and 73.6 ± 3.9 minutes/week of vigorous physical activity, although accelerometry estimates were 45.1 ± 4.6 minutes/week of moderate physical activity and 18.6 ± 6.6 minutes/week of vigorous physical activity. The proportion of adults meeting the PAGA according to M2VPA was 62.0% for self-report and 9.6% for accelerometry. According to the NHANES 2005-2006, fewer than 10% of U.S. adults met the PAGA according to accelerometry. However, physical activity estimates vary substantially depending on whether self-reported or measured via accelerometer.",success
19633305,False,Journal Article;Meta-Analysis;Systematic Review,,,,,,,,True,"The aim of this study was to examine by a systematic literature review and meta-analysis whether the risk of atrial fibrillation (AF) is higher in athletes compared with not athletes. A comprehensive systematic search was conducted for case-control studies that examined cases of AF or atrial flutter in athletes vs. controls. Extracted data from the eligible studies were meta-analysed using fixed effects model. Six case-control studies were eligible for meta-analysis. A total of 655 athletes and 895 controls were compared. Mean age was 51+/-9 years and 93% were men. There were 147 (23%) vs. 116 (12.5%) cases of AF among athletes compared with controls. The overall risk of AF was significantly higher in athletes than in controls with odds ratio (95% confidence interval)=5.29 (3.57-7.85), P=0.0001, and Z-score=8.08. For heterogeneity, the calculated chi2=2.92, P=0.633, and I2=0% were not significant. The risk of AF is significantly higher in athletes compared with not athletes. However, this finding should be confirmed further in large-scale prospective longitudinal studies.",success
23756332,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"We aimed to investigate the association of number of completed races and finishing time with risk of arrhythmias among participants of Vasaloppet, a 90 km cross-country skiing event. All the participants without cardiovascular disease who completed Vasaloppet during 1989-98 were followed through national registries until December 2005. Primary outcome was hospitalization for any arrhythmia and secondary outcomes were atrial fibrillation/flutter (AF), bradyarrhythmias, other supraventricular tachycardias (SVT), and ventricular tachycardia/ventricular fibrillation/cardiac arrest (VT/VF/CA). Among 52 755 participants, 919 experienced arrhythmia during follow-up. Adjusting for age, education, and occupational status, those who completed the highest number of races during the period had higher risk of any arrhythmias [hazard ratio (HR)1.30; 95% CI 1.08-1.58; for ≥5 vs. 1 completed race], AF (HR 1.29; 95% CI 1.04-1.61), and bradyarrhythmias (HR 2.10; 95% CI 1.28-3.47). Those who had the fastest relative finishing time also had higher risk of any arrhythmias (HR 1.30; 95% CI 1.04-1.62; for 100-160% vs. >240% of winning time), AF (1.20; 95% CI 0.93-1.55), and bradyarrhythmias (HR 1.85; 95% CI 0.97-3.54). SVT or VT/VF/CA was not associated with finishing time or number of completed races. Among male participants of a 90 km cross-country skiing event, a faster finishing time and a high number of completed races were associated with higher risk of arrhythmias. This was mainly driven by a higher incidence of AF and bradyarrhythmias. No association with SVT or VT/VF/CA was found.",success
18065754,False,Journal Article,,,,,,,,True,"Significant brady- and tachyarrhythmias may occur in active endurance athletes. It is controversial whether these arrhythmias do persist after cessation of competitive endurance training. Among all 134 former Swiss professional cyclists [hereafter, former athletes (FAs)] participating at least once in the professional bicycle race Tour de Suisse in 1955-1975, 62 (46%) were recruited for the study. The control group consisted of 62 male golfers matched for age, weight, hypertension, and cardiac medication. All participants were screened with history, clinical and echocardiographic examination, ECG, and 24 h ECG. The time for the last bicycle race of FAs was 38 +/- 6 years. The mean age at examination was 66 +/- 6 years in controls and 66 +/- 7 years in FAs (P = 0.47). The percentage of study participants with >4 h current cardiovascular training per week was identical. QRS duration (102 +/- 20 vs. 95 +/- 13 ms, P = 0.03) and corrected QTc interval (416 +/- 27 vs. 404 +/- 18, P = 0.004) were longer in FAs. There was no significant difference in the number of isolated atrial or ventricular premature complexes, or supraventricular tachycardias in the 24 h ECG; however, ventricular tachycardias tended to occur more often in FAs than in controls (15 vs. 3%, P = 0.05). The average heart rate was lower in FAs (66 +/- 9 vs. 70 +/- 8 b.p.m.) (P = 0.004). Paroxysmal or persistent atrial fibrillation or flutter was reported more often in FAs (P = 0.028). Sinus node disease (SND), defined as bradycardia of <40 b.p.m. (10 vs. 2%), atrial flutter (6 vs. 0%), pacemaker for bradyarrhythmias (3 vs. 0%), and/or maximal RR interval of >2.5 s (6 vs. 0%), was more common in FA (16%) than in controls (2%, P = 0.006). Observed survival of all FAs was not different from the expected. Among FAs, SND occurred significantly more often compared with age-matched controls, and there is trend towards more frequent ventricular tachycardias. Further studies have to evaluate prevention of arrhythmias with extreme endurance training, the necessity of regular follow-up of heart rhythm, and management of arrhythmias in former competitive endurance athletes.",success
15963583,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"Lone atrial fibrillation (LAF) is characterized by the presence of atrial fibrillation in the absence of structural heart disease or other identifiable cause of arrhythmia. In a recent study, we reported sport practice to be more frequent in LAF patients than in the general population. The aim of the study was to determine the association between sport practice and the prevalence of LAF in men. An age-matched case-control study was designed. Cases were identified from consecutive patients who attended an outpatient clinic; 51 men with LAF were included, 20 of them with vagal characteristics. Controls were selected from the general population (n=109). A questionnaire to assess former and current sport practice and the number of lifetime hours of sport practice was administered. Conditional logistic regression was used for statistical analysis. The proportion of patients with LAF who reported current sport practice (31%) was higher than that observed in controls (14%). In the logistic regression, current practice of sport was associated with a higher prevalence of LAF (OR=3.13; 95% CI: 1.39-7.05). The practice of more than 1500 lifetime hours of sport appears to be the threshold for the observed association. Current practice of sport with a lifetime practice greater than 1500 h was associated with LAF (OR=2.87; 95% CI: 1.20-6.91). In men, the combination of current and prolonged lifetime sport practice is associated with higher risk of LAF.",success
18390875,False,"Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"The aim of this study is to determine the incidence of lone atrial fibrillation (LAF) in males according to sport practice and to identify possible clinical markers related to LAF among marathon runners. A retrospective cohort study was designed. A group of marathon runners (n = 252) and a population-based sample of sedentary men (n = 305) recruited in 1990-92 and 1994-96, respectively, were contacted in 2002-03 and invited to attend an outpatient clinic to identify suggestive symptoms of having experienced an arrhythmia requiring medical attention. In those with suggestive symptoms of atrial fibrillation, medical records were reviewed. Finally, LAF was diagnosed on the basis of the presence of atrial fibrillation in an electrocardiographic recording. In the group of marathon runners, an echocardiogram was performed at inclusion and at the end of the study. The annual incidence rate of LAF among marathon runners and sedentary men was 0.43/100 and 0.11/100, respectively. Endurance sport practice was associated with a higher risk of incident LAF in the multivariate age- and blood pressure-adjusted Cox regression models (hazard ratio = 8.80; 95% confidence interval: 1.26-61.29). In the group of marathon runners, left atrial inferosuperior diameter and left atrial volume were both associated with a higher risk of incident LAF. Long-term endurance sport practice is associated with a higher risk of symptomatic LAF in men. This risk is associated with a larger left atrial inferosuperior diameter and volume in physically active subjects.",success
26243014,False,Journal Article;Meta-Analysis;Systematic Review,,,,,,,,True,"Enhancing cardiovascular fitness can lead to substantial health benefits. High-intensity interval training (HIT) is an efficient way to develop cardiovascular fitness, yet comparisons between this type of training and traditional endurance training are equivocal. Our objective was to meta-analyse the effects of endurance training and HIT on the maximal oxygen consumption (VO2max) of healthy, young to middle-aged adults. Six electronic databases were searched (MEDLINE, PubMed, SPORTDiscus, Web of Science, CINAHL and Google Scholar) for original research articles. A search was conducted and search terms included 'high intensity', 'HIT', 'sprint interval training', 'endurance training', 'peak oxygen uptake', and 'VO2max'. Inclusion criteria were controlled trials, healthy adults aged 18-45 years, training duration ≥2 weeks, VO2max assessed pre- and post-training. Twenty-eight studies met the inclusion criteria and were included in the meta-analysis. This resulted in 723 participants with a mean ± standard deviation (SD) age and initial fitness of 25.1 ± 5 years and 40.8 ± 7.9 mL·kg(-1)·min(-1), respectively. We made probabilistic magnitude-based inferences for meta-analysed effects based on standardised thresholds for small, moderate and large changes (0.2, 0.6 and 1.2, respectively) derived from between-subject SDs for baseline VO2max. The meta-analysed effect of endurance training on VO2max was a possibly large beneficial effect (4.9 mL·kg(-1)·min(-1); 95 % confidence limits ±1.4 mL·kg(-1)·min(-1)), when compared with no-exercise controls. A possibly moderate additional increase was observed for typically younger subjects (2.4 mL·kg(-1)·min(-1); ±2.1 mL·kg(-1)·min(-1)) and interventions of longer duration (2.2 mL·kg(-1)·min(-1); ±3.0 mL·kg(-1)·min(-1)), and a small additional improvement for subjects with lower baseline fitness (1.4 mL·kg(-1)·min(-1); ±2.0 mL·kg(-1)·min(-1)). When compared with no-exercise controls, there was likely a large beneficial effect of HIT (5.5 mL·kg(-1)·min(-1); ±1.2 mL·kg(-1)·min(-1)), with a likely moderate greater additional increase for subjects with lower baseline fitness (3.2 mL·kg(-1)·min(-1); ±1.9 mL·kg(-1)·min(-1)) and interventions of longer duration (3.0 mL·kg(-1)·min(-1); ±1.9 mL·kg(-1)·min(-1)), and a small lesser effect for typically longer HIT repetitions (-1.8 mL·kg(-1)·min(-1); ±2.7 mL·kg(-1)·min(-1)). The modifying effects of age (0.8 mL·kg(-1)·min(-1); ±2.1 mL·kg(-1)·min(-1)) and work/rest ratio (0.5 mL·kg(-1)·min(-1); ±1.6 mL·kg(-1)·min(-1)) were unclear. When compared with endurance training, there was a possibly small beneficial effect for HIT (1.2 mL·kg(-1)·min(-1); ±0.9 mL·kg(-1)·min(-1)) with small additional improvements for typically longer HIT repetitions (2.2 mL·kg(-1)·min(-1); ±2.1 mL·kg(-1)·min(-1)), older subjects (1.8 mL·kg(-1)·min(-1); ±1.7 mL·kg(-1)·min(-1)), interventions of longer duration (1.7 mL·kg(-1)·min(-1); ±1.7 mL·kg(-1)·min(-1)), greater work/rest ratio (1.6 mL·kg(-1)·min(-1); ±1.5 mL·kg(-1)·min(-1)) and lower baseline fitness (0.8 mL·kg(-1)·min(-1); ±1.3 mL·kg(-1)·min(-1)). Endurance training and HIT both elicit large improvements in the VO2max of healthy, young to middle-aged adults, with the gains in VO2max being greater following HIT when compared with endurance training.",success
17548726,True,"Comparative Study;Journal Article;Randomized Controlled Trial;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, Non-P.H.S.",,,,,,,,True,"Exercise training reduces the symptoms of chronic heart failure. Which exercise intensity yields maximal beneficial adaptations is controversial. Furthermore, the incidence of chronic heart failure increases with advanced age; it has been reported that 88% and 49% of patients with a first diagnosis of chronic heart failure are >65 and >80 years old, respectively. Despite this, most previous studies have excluded patients with an age >70 years. Our objective was to compare training programs with moderate versus high exercise intensity with regard to variables associated with cardiovascular function and prognosis in patients with postinfarction heart failure. Twenty-seven patients with stable postinfarction heart failure who were undergoing optimal medical treatment, including beta-blockers and angiotensin-converting enzyme inhibitors (aged 75.5+/-11.1 years; left ventricular [LV] ejection fraction 29%; VO2peak 13 mL x kg(-1) x min(-1)) were randomized to either moderate continuous training (70% of highest measured heart rate, ie, peak heart rate) or aerobic interval training (95% of peak heart rate) 3 times per week for 12 weeks or to a control group that received standard advice regarding physical activity. VO2peak increased more with aerobic interval training than moderate continuous training (46% versus 14%, P<0.001) and was associated with reverse LV remodeling. LV end-diastolic and end-systolic volumes declined with aerobic interval training only, by 18% and 25%, respectively; LV ejection fraction increased 35%, and pro-brain natriuretic peptide decreased 40%. Improvement in brachial artery flow-mediated dilation (endothelial function) was greater with aerobic interval training, and mitochondrial function in lateral vastus muscle increased with aerobic interval training only. The MacNew global score for quality of life in cardiovascular disease increased in both exercise groups. No changes occurred in the control group. Exercise intensity was an important factor for reversing LV remodeling and improving aerobic capacity, endothelial function, and quality of life in patients with postinfarction heart failure. These findings may have important implications for exercise training in rehabilitation programs and future studies.",success
25323267,True,"Letter;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",,,,,,,,False,,success
25771785,False,Journal Article;Meta-Analysis;Systematic Review,,,,,,,,True,"Vascular dysfunction is a precursor to the atherosclerotic cascade, significantly increasing susceptibility to cardiovascular events such as myocardial infarction or stroke. Previous studies have revealed a strong relationship between vascular function and cardiorespiratory fitness (CRF). Thus, since high-intensity interval training (HIIT) is a potent method of improving CRF, several small randomized trials have investigated the impact on vascular function of HIIT relative to moderate-intensity continuous training (MICT). The aim of this study was to systematically review the evidence and quantify the impact on vascular function of HIIT compared with MICT. Three electronic databases (PubMed, Embase, and MEDLINE) were searched (until May 2014) for randomized trials comparing the effect of at least 2 weeks of HIIT and MICT on vascular function. HIIT protocols involved predominantly aerobic exercise at a high intensity, interspersed with active or passive recovery periods. We performed a meta-analysis to compare the mean difference in the change in vascular function assessed via brachial artery flow-mediated dilation (FMD) from baseline to post-intervention between HIIT and MICT. The impact of HIIT versus MICT on CRF, traditional cardiovascular disease (CVD) risk factors, and biomarkers associated with vascular function (oxidative stress, inflammation, and insulin resistance) was also reviewed across included studies. Seven randomized trials, including 182 patients, met the eligibility criteria and were included in the meta-analysis. A commonly used HIIT prescription was four intervals of 4 min (4 × 4 HIIT) at 85-95% of maximum or peak heart rate (HRmax/peak), interspersed with 3 min of active recovery at 60-70% HRmax/peak, three times per week for 12-16 weeks. Brachial artery FMD improved by 4.31 and 2.15% following HIIT and MICT, respectively. This resulted in a significant (p < 0.05) mean difference of 2.26%. HIIT also had a greater tendency than MICT to induce positive effects on secondary outcome measures, including CRF, traditional CVD risk factors, oxidative stress, inflammation, and insulin sensitivity. HIIT is more effective at improving brachial artery vascular function than MICT, perhaps due to its tendency to positively influence CRF, traditional CVD risk factors, oxidative stress, inflammation, and insulin sensitivity. However, the variability in the secondary outcome measures, coupled with the small sample sizes in these studies, limits this finding. Nonetheless, this review suggests that 4 × 4 HIIT, three times per week for at least 12 weeks, is a powerful form of exercise to enhance vascular function.",success
12471307,False,"Journal Article;Research Support, Non-U.S. Gov't;Systematic Review",,,,,,,,True,"To review and update the evidence relating to the personal, social, and environmental factors associated with physical activity (PA) in adults. Systematic review of the peer-reviewed literature to identify papers published between 1998 and 2000 with PA (and including exercise and exercise adherence). Qualitative reports or case studies were not included. Thirty-eight new studies were located. Most confirmed the existence of factors already known to be correlates of PA. Changes in status were noted in relation to the influence of marital status, obesity, smoking, lack of time, past exercise behavior, and eight environmental variables. New studies were located which focused on previously understudied population groups such as minorities, middle and older aged adults, and the disabled. The newly reported studies tend to take a broader ""ecological"" approach to understanding the correlates of PA and are more focused on environmental factors. There remains a need to better understand environmental influences and the factors that influence different types of PA. As most of the work in this field still relies on cross-sectional studies, longitudinal and intervention studies will be required if causal relationships are to be inferred.",success
26733609,True,"Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't",NCT01325675,databank,NCT01325675,NCT01325675,NCT01325675,NCT01325675|databank,NCT01325675|databank,True,"Exercise training is an effective treatment for important atrial fibrillation (AF) comorbidities. However, a high level of endurance exercise is associated with an increased AF prevalence. We assessed the effects of aerobic interval training (AIT) on time in AF, AF symptoms, cardiovascular health, and quality of life in AF patients. Fifty-one patients with nonpermanent AF were randomized to AIT (n=26) consisting of four 4-minute intervals at 85% to 95% of peak heart rate 3 times a week for 12 weeks or to a control group (n=25) continuing their regular exercise habits. An implanted loop recorder measured time in AF continuously from 4 weeks before to 4 weeks after the intervention period. Cardiac function, peak oxygen uptake (o2peak), lipid status, quality of life, and AF symptoms were evaluated before and after the 12-week intervention period. Mean time in AF increased from 10.4% to 14.6% in the control group and was reduced from 8.1% to 4.8% in the exercise group (P=0.001 between groups). AF symptom frequency (P=0.006) and AF symptom severity (P=0.009) were reduced after AIT. AIT improved o2peak, left atrial and ventricular ejection fraction, quality-of-life measures of general health and vitality, and lipid values compared with the control group. There was a trend toward fewer cardioversions and hospital admissions after AIT. AIT for 12 weeks reduces the time in AF in patients with nonpermanent AF. This is followed by a significant improvement in AF symptoms, o2peak, left atrial and ventricular function, lipid levels, and QoL. URL: http://www.clinicaltrials.gov. Unique identifier: NCT01325675.",success
28231325,True,Journal Article;Randomized Controlled Trial,NCT01817998,databank,NCT01817998,NCT01817998,NCT01817998,NCT01817998|databank,NCT01817998|databank,True,"Physical activity at moderate-high intensity is recommended to prevent lifestyle diseases. Patients with atrial fibrillation are at risk of a sedentary lifestyle due to fear of exercise-induced episodes of atrial fibrillation. The burden of arrhythmia can be reduced by physical exercise. The effect of exercise intensity on burden of atrial fibrillation needs to be studied further. In a 12-week randomized controlled trial, 76 patients with paroxysmal/persistent atrial fibrillation were allocated to perform exercise at either low intensity or high intensity (50% and 80% of maximal perceived exertion, respectively). Primary outcome was burden of AF measured by daily electrocardiography-reporting during 12 weeks. Secondarily, change in maximal oxygen uptake (peak VO2) and 1-year hospitalization was compared between low and high intensity exercise. Sixty-three patients completed the follow-up. In the intention-to-treat analysis, we found no statistical difference in burden of atrial fibrillation between low and high intensity exercise (incidence rate ratio 0.742, 95% CI 0.29-1.91, P = 0.538). No serious adverse events were reported and there was no difference in hospitalization between the two exercise groups. Both exercise groups improved significantly in peak VO2 (low intensity: 3.62 mL O2/kg/min, SD 3.77; high intensity: 2.87 mL O2/kg/min, SD 4.98), with no statistical difference between-groups (mean difference: 0.76 mL O2/kg/min, 95% CI -3.22-1.7). High intensity physical exercise was not superior to low intensity physical exercise in reducing burden of atrial fibrillation. HI exercise was well tolerated; no evidence of an increased risk was found for HI compared to LI exercise. Larger studies are required to further prove our findings. ClinicalTrials.gov NCT01817998.",success
28904878,False,Journal Article,,,,,,,,True,"Atrial fibrillation (AF) is highly common, and is most frequently observed in individuals with hypertension and structural cardiac disease. Sympathetic hyperactivity plays a fundamental role in the progression, maintenance and aggravation of arrhythmia. Endurance exercise training clearly lowers sympathetic activity in sympathoexcitatory disease states, and is well-tolerated by patients with chronic kidney disease (CKD). We assessed 50 CKD patients with hypertension. Each patient provided a complete medical history and underwent a physical examination. We used an implantable cardiac monitor over a 3-year follow-up period to evaluate the effects of high-intensity interval training (HIIT) and moderate exercise (ModEx) physical activity protocols on AF occurrence, and determined the effectiveness of these protocols in improving renal function. Subjects were followed up every 6 months after the beginning of the intervention. During the 3-year follow-up, AF onset was higher in CKD patients who engaged in HIIT (72%) than in those who engaged in ModEx (24%) (hazard ratio, 3.847; 95% confidence interval, 1.694-8.740, <i>P</i> = 0.0013 by log-rank test). Both groups exhibited significant intra-group changes in the mean systolic 24-hour ambulatory blood pressure measurements (ABPM) between baseline and 12, 24, and 36 months. There were also significant differences in the mean systolic 24-hour ABPM between the groups at the same time points. In CKD patients with hypertension, improvements in AF onset, renal function and some echocardiographic parameters were more evident in subjects who engaged in ModEx than in those who engaged in HIIT during 3 years of follow-up.",success
29748195,True,"Journal Article;Randomized Controlled Trial;Research Support, N.I.H., Extramural",NCT02039154,databank,NCT02039154,NCT02039154,NCT02039154,NCT02039154|databank,NCT02039154|databank,True,"Exercise mitigates many cardiovascular risk factors associated with atrial fibrillation. Endurance training has been associated with atrial structural changes which can increase the risk for atrial fibrillation. The dose of exercise training required for these changes is uncertain. We sought to evaluate the impact of exercise on left atrial (LA) mechanical and electrical function in healthy, sedentary, middle-aged adults. Sixty-one adults (52±5 years) were randomized to either 10 months of high-intensity exercise training or yoga. At baseline and post-training, all participants underwent maximal exercise stress testing to assess cardiorespiratory fitness, P-wave signal-averaged electrocardiography for filtered P-wave duration and atrial late potentials (root mean square voltage of the last 20 ms), and echocardiography for LA volume, left ventricular end-diastolic volume, and mitral inflow for assessment of LA active emptying. Post-training data were compared with 14 healthy age-matched Masters athletes. LA volume, Vo<sub>2</sub> max, and left ventricular end-diastolic volume increased in the exercise group (15%, 17%, and 16%, respectively) with no change in control (<i>P</i><0.0001). LA active emptying decreased post-exercise versus controls (5%; <i>P</i>=0.03). No significant changes in filtered P-wave duration or root mean square voltage of the last 20 ms occurred after exercise training. LA and left ventricular volumes remained below Masters athletes. The athletes had longer filtered P-wave duration but no difference in the frequency of atrial arrhythmia. Changes in LA structure, LA mechanical function, and left ventricular remodeling occurred after 10 months of exercise but without significant change in atrial electrical activity. A longer duration of training may be required to induce electrical changes thought to cause atrial fibrillation in middle-aged endurance athletes. URL: https://www.clinicaltrials.gov. Unique Identifier: NCT02039154.",success
24763467,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"Autonomic nervous system activation can induce significant and heterogeneous changes of atrial electrophysiology and induce atrial tachyarrhythmias, including atrial tachycardia and atrial fibrillation (AF). The importance of the autonomic nervous system in atrial arrhythmogenesis is also supported by circadian variation in the incidence of symptomatic AF in humans. Methods that reduce autonomic innervation or outflow have been shown to reduce the incidence of spontaneous or induced atrial arrhythmias, suggesting that neuromodulation may be helpful in controlling AF. In this review, we focus on the relationship between the autonomic nervous system and the pathophysiology of AF and the potential benefit and limitations of neuromodulation in the management of this arrhythmia. We conclude that autonomic nerve activity plays an important role in the initiation and maintenance of AF, and modulating autonomic nerve function may contribute to AF control. Potential therapeutic applications include ganglionated plexus ablation, renal sympathetic denervation, cervical vagal nerve stimulation, baroreflex stimulation, cutaneous stimulation, novel drug approaches, and biological therapies. Although the role of the autonomic nervous system has long been recognized, new science and new technologies promise exciting prospects for the future.",success
18227919,False,Journal Article,,,,,,,,True,"Relaxation techniques are established in managing of cardiac patients during rehabilitation aiming to reduce future adverse cardiac events. It has been hypothesized that relaxation-training programs may significantly improve cardiac autonomic nervous tone. However, this has not been proven for all available relaxation techniques. We tested this assumption by investigating cardiac vagal modulation during yoga.We examined 11 healthy yoga practitioners (7 women and 4 men, mean age: 43 +/- 11; range: 26-58 years). Each individual was subjected to training units of 90 min once a week over five successive weeks. During two sessions, they practiced a yoga program developed for cardiac patients by B.K.S. Iyengar. On three sessions, they practiced a placebo program of relaxation. On each training day they underwent ambulatory 24 h Holter monitoring. The group of yoga practitioners was compared to a matched group of healthy individuals not practicing any relaxation techniques. Parameters of heart rate variability (HRV) were determined hourly by a blinded observer. Mean RR interval (interval between two R-waves of the ECG) was significantly higher during the time of yoga intervention compared to placebo and to control (P < 0.001 for both). The increase in HRV parameters was significantly higher during yoga exercise than during placebo and control especially for the parameters associated with vagal tone, i.e. mean standard deviation of NN (Normal Beat to Normal Beat of the ECG) intervals for all 5-min intervals (SDNNi, P < 0.001 for both) and root mean square successive difference (rMSSD, P < 0.01 for both). In conclusion, relaxation by yoga training is associated with a significant increase of cardiac vagal modulation. Since this method is easy to apply with no side effects, it could be a suitable intervention in cardiac rehabilitation programs.",success
14652490,True,"Clinical Trial;Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"This study evaluated the effect of Tai Chi Chuan (TCC) on the autonomic nervous modulation in older persons. Twenty TCC practitioners and 20 normal controls were included in this study. The stationary state spectral heart rate variability (HRV) measures between TCC practitioners and normal controls, and the sequential changes in HRV measures after classical Yang's TCC were compared. The total power, very low-frequency power, low-frequency power, normalized low-frequency power, and low-/high-frequency power ratios in TCC practitioners were all significantly higher than those of normal controls, whereas the heart rate and systolic and diastolic blood pressures were not different between these two groups of subjects. After TCC, the normalized high-frequency power increased significantly from 22.8 +/- 14.6 normalized units (nu) before TCC to 28.2 +/- 16.1 nu 30 min after TCC and to 30.6 +/- 18.4 nu 60 min after TCC. In contrast, the low-/high-frequency power ratio decreased significantly from 2.5 +/- 2.4 before TCC to 1.8 +/- 1.4 30 min after TCC and to 2.2 +/- 2.9 60 min after TCC. The heart rate, systolic blood pressure, diastolic blood pressure, mean arterial blood pressure, and pulse pressure also decreased sequentially after TCC. The short-term effect of TCC was to enhance the vagal modulation and tilt the sympathovagal balance toward deceased sympathetic modulation in older persons. TCC might be good health-promoting calisthenics for older persons.",success
30050592,False,Journal Article,,,,,,,,True,"Tai Chi synergy T1 exercise is an aerobic exercise derived mainly from Tai Chi exercise. It is also derived from the Eight Trigrams Palms, form and will boxing, mantis boxing, Qigong, and Yoga, with a total of 16 sessions in 63 minutes. In this study, we investigated its effects on autonomic modulation, metabolism, immunity, and physical function in healthy practitioners. We recruited a total of 26 volunteers and 23 control participants. Heart rate variability (HRV), blood pressure, and body mass index (BMI) were recorded before and after practicing Tai Chi synergy T1 exercise and regular walking for 10 weeks, respectively. Serum glucose, cholesterol, and peripheral blood including B and T cell counts were also measured. They underwent one-minute bent-knee sit-ups, sit and reach test, and three-minute gradual step test. Tai Chi synergy T1 exercise enhanced parasympathetic modulation and attenuated sympathetic nerve control with increased very low frequency (VLF) and high frequency (HF) but decreased low frequency (LF) compared to the control group. Metabolic profiles including serum glucose, cholesterol, and BMI significantly improved after exercise. The exercise enhanced innate and adaptive immunity by increasing the counts of CD3+ T cells, CD19+ B cells, and CD16+CD56+ NK cells but decreasing the CD3+ cytotoxic T cell count. All monitored parameters including physical fitness and physical strength improved after the exercise. Tai Chi synergy T1 exercise improves autonomic modulation, body metabolism, physical fitness, and physical strength after 10 weeks of practice.",success
24509942,True,"Clinical Trial;Journal Article;Research Support, Non-U.S. Gov't",,,,,,,,True,"This study investigates the breathing frequency (BF)-independent effect of Tai Chi Chuan (TCC) on autonomic nervous modulation in TCC practitioners. Twenty-five TCC practitioners and 25 sedentary normal controls were recruited. The stationary heart rate variability (HRV) measures of TCC practitioners and controls were compared. The same HRV measures in TCC practitioners and among the controls, TCC practitioners before TCC and TCC practitioners 30 min after TCC were compared. In TCC practitioners, the BF, normalized high-frequency power (nHFP), and normalized very low-frequency power were significantly increased, while the normalized low-frequency power (nLFP) was significantly decreased 30 min after TCC. The BF correlated significantly and negatively with heart rate (HR), nHFP and nLFP, and correlated significantly and positively with mean RR interval (MnRR) before TCC in TCC practitioners. A slower BF is associated with a higher HR, a greater vagal modulation, and a greater combined sympatho-vagal modulation before TCC. To remove the effect of BF on HRV measures, new indices such as HR*BF, nHFP*BF, nLFP*BF, and MnRR/BF were introduced for comparison among the controls, TCC practitioners before TCC, and TCC practitioners 30 min after TCC. Thirty minutes after TCC, the MnRR/BF of TCC practitioner was smaller whereas HR*BF and nHFP*BF were greater than those before TCC. The BF-independent effects of TCC on the autonomic nervous modulation of TCC practitioners are an increase in vagal modulation and HR, and a decrease in mean RR interval. The mechanism underlying the parallel increase in HR and vagal modulation in TCC practitioners is not understood yet at present.",success
23375926,True,"Clinical Trial;Journal Article;Research Support, Non-U.S. Gov't",NCT00798356,databank,NCT00798356,NCT00798356,NCT00798356,NCT00798356|databank,NCT00798356|databank,True,"The purpose of this study was to examine the impact of yoga on atrial fibrillation (AF) burden, quality of life (QoL), depression, and anxiety scores. Yoga is known to have significant benefit on cardiovascular health. The effect of yoga in reducing AF burden is unknown. This single-center, pre-post study enrolled patients with symptomatic paroxysmal AF with an initial 3-month noninterventional observation period followed by twice-weekly 60-min yoga training for next 3 months. AF episodes during the control and study periods as well as SF-36, Zung self-rated anxiety, and Zung self-rated depression scores at baseline, before, and after the study phase were assessed. Yoga training reduced symptomatic AF episodes (3.8 ± 3 vs. 2.1 ± 2.6, p < 0.001), symptomatic non-AF episodes (2.9 ± 3.4 vs. 1.4 ± 2.0; p < 0.001), asymptomatic AF episodes (0.12 ± 0.44 vs. 0.04 ± 0.20; p < 0.001), and depression and anxiety (p < 0.001), and improved the QoL parameters of physical functioning, general health, vitality, social functioning, and mental health domains on SF-36 (p = 0.017, p < 0.001, p < 0.001, p = 0.019, and p < 0.001, respectively). There was significant decrease in heart rate, and systolic and diastolic blood pressure before and after yoga (p < 0.001). In patients with paroxysmal AF, yoga improves symptoms, arrhythmia burden, heart rate, blood pressure, anxiety and depression scores, and several domains of QoL.",success
31300334,False,"Journal Article;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"There is a scarcity of published data on the global prevalence of obstructive sleep apnoea, a disorder associated with major neurocognitive and cardiovascular sequelae. We used publicly available data and contacted key opinion leaders to estimate the global prevalence of obstructive sleep apnoea. We searched PubMed and Embase to identify published studies reporting the prevalence of obstructive sleep apnoea based on objective testing methods. A conversion algorithm was created for studies that did not use the American Academy of Sleep Medicine (AASM) 2012 scoring criteria to identify obstructive sleep apnoea, allowing determination of an equivalent apnoea-hypopnoea index (AHI) for publications that used different criteria. The presence of symptoms was not specifically analysed because of scarce information about symptoms in the reference studies and population data. Prevalence estimates for obstructive sleep apnoea across studies using different diagnostic criteria were standardised with a newly developed algorithm. Countries without obstructive sleep apnoea prevalence data were matched to a similar country with available prevalence data; population similarity was based on the population body-mass index, race, and geographical proximity. The primary outcome was prevalence of obstructive sleep apnoea based on AASM 2012 diagnostic criteria in individuals aged 30-69 years (as this age group generally had available data in the published studies and related to information from the UN for all countries). Reliable prevalence data for obstructive sleep apnoea were available for 16 countries, from 17 studies. Using AASM 2012 diagnostic criteria and AHI threshold values of five or more events per h and 15 or more events per h, we estimated that 936 million (95% CI 903-970) adults aged 30-69 years (men and women) have mild to severe obstructive sleep apnoea and 425 million (399-450) adults aged 30-69 years have moderate to severe obstructive sleep apnoea globally. The number of affected individuals was highest in China, followed by the USA, Brazil, and India. To our knowledge, this is the first study to report global prevalence of obstructive sleep apnoea; with almost 1 billion people affected, and with prevalence exceeding 50% in some countries, effective diagnostic and treatment strategies are needed to minimise the negative health impacts and to maximise cost-effectiveness. ResMed.",success
29657903,False,Journal Article,,,,,,,,True,"To conducted a meta-analysis assessing the relationship between Obstructive Sleep Apnea (OSA) and the risk of Atrial Fibrillation (AF). We searched PUBMED, Medline, and Cochrane Library using the keywords ""atrial fibrillation"", ""obstructive sleep apnea"" and ""sleep disordered breathing (SDB)"". All subjects included had established diagnosis of OSA/SDB. We then compared the occurrence of AF versus no AF. Analysis done with Comprehensive Meta-Analysis package V3 (Biostat, USA). A total of 579 results were generated. Duplicates were removed and 372 records were excluded based on irrelevant abstracts, titles, study design not consistent with the stated outcome, or full-text unavailable. Twelve studies meeting the inclusion criteria were reviewed in full-text; 2 of these articles were eventually removed due to unconfirmed OSA diagnostic modality, and one was also removed based on a control group inconsistent with the other studies. Therefore, a total of 9 studies were included (n=19,837). Sample sizes ranged from n=160 patients to n=6841 patients. The risk of AF was found to be higher among OSA/SDB versus control group (OR; 2.120, C.I: 1.845-2.436, Z; 10.598 p: <0.001). The heterogeneity observed for the pooled analysis was Q-value; 22.487 df (Q); 8 P-value; 0.004, I-squared; 64.424 Tau2; 0.098, suggesting appropriate study selection and moderate heterogeneity. OSA/SDB is strongly associated with AFib confirming the notion that OSA/SDB populations are high risk for development of AF. Prospective studies are needed to ascertain the effect of the treatment of OSA/SDB for the prevention of AF, a growing health burden with serious consequences.",success
29541763,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Review",,,,,,,,True,"Obstructive sleep apnea (OSA) is the most common clinically significant breathing abnormality during sleep. It is highly prevalent among patients with atrial fibrillation (AF), and it promotes arrhythmogenesis and impairs treatment efficacy. The prevalence of OSA ranges from 3% to 49% in population-based studies and from 21% to 74% in patients with AF. Diagnosis and treatment of OSA in patients with AF requires a close interdisciplinary collaboration between electrophysiologists, cardiologists, and sleep specialists. Because the prevalence of OSA is high in patients with AF and most do not report daytime sleepiness, sleep-study evaluation may be reasonable for patients being considered for rhythm control strategy. Acute, transient apnea-associated atrial electrophysiological changes and increased occurrence of AF triggers associated with short episodes of intermittent deoxygenation and reoxygenation, intrathoracic pressure changes during obstructed breathing efforts, and sympathovagal activation combine to create a stimulus for AF triggers and a complex and dynamic substrate for AF during sleep. Repeated episodes of long-term OSA are eventually associated with structural remodeling and changes in electrical conduction in the atrium. Observational data suggest OSA reduces the efficacy of catheter-based and pharmacological antiarrhythmic therapy. Nonrandomized studies have shown that treatment of OSA by continuous positive airway pressure can help to maintain a sinus rhythm after electrical cardioversion and catheter ablation in patients with AF. However, it remains unclear which sleep apnea metric should be used to determine severity and guide such treatment in patients with AF. Data from nonrandomized studies of patients with AF suggest that treatment of OSA by continuous positive airway pressure may help to maintain sinus rhythm after electrical cardioversion and improve catheter ablation success rates. Randomized clinical trials are needed to confirm the association between OSA and AF the benefits of treatment of OSA and the need for and cost-effectiveness of routine OSA screening and treatment.",success
18515807,False,Journal Article,,,,,,,,True,"Recent studies have suggested an emerging link between sleep apnoea and atrial fibrillation (AF). These studies included patients with reduced left ventricular (LV) function which may cause both AF and sleep disordered breathing (SDB). We examined the prevalence of SDB in a population of patients with AF and normal LV function. Ninety patients with paroxysmal or persistent AF and 45 controls were prospectively enrolled and matched 2:1 for age (AF 56 +/- 12 years; controls 54 +/- 11years) and sex. All patients had normal LV function. SDB was diagnosed using all-night portable polysomnography. Apnoea-hypopnoea index (AHI) in AF patients was higher than in controls (23.19 +/- 19.26 vs. 14.66 +/- 12.43, P = 0.01). The proportion with significant SDB (AHI > 15) was also greater in AF patients (62 vs. 38%, P = 0.01). After adjustment for relevant covariates, the odds ratio for the association between AF and SDB (AHI > 15) was 3.04 (95% CI 1.24-7.46, P = 0.02). The paroxysmal AF group was classified as either 'low-frequency AF' (< or =6) or 'high-frequency AF' (>6) episodes in the past year. High-frequency AF was associated with a higher prevalence (75 vs. 43%, P = 0.012) and severity (mean AHI 28.08 +/- 22.94 vs. 16.69 +/- 15.06, P = 0.028) of SDB when compared with those with low-frequency AF. A high prevalence of SDB is found in relatively young patients with both paroxysmal and persistent AF with normal LV function. This AF population warrants careful consideration for the presence of SDB.",success
25566942,False,"Journal Article;Observational Study;Research Support, Non-U.S. Gov't",,,,,,,,True,"Prior studies suggested that obstructive sleep apnea (OSA) promotes recurrence of arrhythmia in patients after atrial fibrillation (AF) ablation. In this prospective, long-term, observational study, we enrolled 290 consecutive patients admitted for AF ablation. Prior to the ablation, all patients underwent a polygraphy sleep study for the diagnosis of OSA. After the procedure, patients were followed up for mean time of 30 months for AF reoccurrence. OSA was diagnosed when apnea-hypopnea index (AHI) was ≥5. Patients were subsequently divided into groups according to the OSA severity: mild OSA (AHI 5-15/h), moderate OSA (AHI >15 and ≤30/h), and severe (AHI >30/h). After excluding patients disqualified from the procedure, and those with central sleep apnea, the study population consisted of 251 patients, mean age 57.6 years [163 (64.9%) male]. OSA was present in 115 (45.8%) patients, while in 137 (54.6%) cases, we observed reoccurrence of AF. Recurrence was more often in patients with, than without, OSA (65.2 vs. 45.6%; p = 0.003). We also observed that along with rising OSA severity rose also the number of patients in whom AF was detected during the follow-up period (45.6 vs. 66.2 vs. 57.6 vs. 81.8%; p = 0.005; for non-OSA, mild, moderate, and severe, respectively). OSA is highly prevalent in AF patients. The presence of OSA lowers chances on successful AF ablation. Early screening, and treatment for OSA in AF patients, may improve low success rates of AF ablation procedures.",success
15249509,False,"Comparative Study;Journal Article;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, P.H.S.",,,,,,,,True,"Obstructive sleep apnea (OSA) is associated with recurrent atrial fibrillation (AF) after electrocardioversion. OSA is highly prevalent in patients who are male, obese, and/or hypertensive, but its prevalence in patients with AF is unknown. We prospectively studied consecutive patients undergoing electrocardioversion for AF (n=151) and consecutive patients without past or current AF referred to a general cardiology practice (n=312). OSA was diagnosed with the Berlin questionnaire, which is validated to identify patients with OSA. We also assessed its accuracy compared with polysomnography in a sample of the study population. Groups were compared with the 2-tailed t, Wilcoxon, and chi2 tests. Logistic regression modeled the association of AF and OSA after adjustment for relevant covariates. Patients in each group had similar age, gender, body mass index, and rates of diabetes, hypertension, and congestive heart failure. The questionnaire performed with 0.86 sensitivity, 0.89 specificity, and 0.97 positive predictive value in our sample. The proportion of patients with OSA was significantly higher in the AF group than in the general cardiology group (49% versus 32%, P=0.0004). The adjusted odds ratio for the association between AF and OSA was 2.19 (95% CI 1.40 to 3.42, P=0.0006). The novel finding of this study is that a strong association exists between OSA and AF, such that OSA is strikingly more prevalent in patients with AF than in high-risk patients with multiple other cardiovascular diseases. The coinciding epidemics of obesity and AF underscore the clinical importance of these results.",success
17276180,False,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",,,,,,,,True,"This study sought to identify whether obesity and obstructive sleep apnea (OSA) independently predict incident atrial fibrillation/flutter (AF). Obesity is a risk factor for AF, and OSA is highly prevalent in obesity. Obstructive sleep apnea is associated with AF, but it is unknown whether OSA predicts new-onset AF independently of obesity. We conducted a retrospective cohort study of 3,542 Olmsted County adults without past or current AF who were referred for an initial diagnostic polysomnogram from 1987 to 2003. New-onset AF was assessed and confirmed by electrocardiography during a mean follow-up of 4.7 years. Incident AF occurred in 133 subjects (cumulative probability 14%, 95% confidence interval [CI] 9% to 19%). Univariate predictors of AF were age, male gender, hypertension, coronary artery disease, heart failure, smoking, body mass index, OSA (hazard ratio 2.18, 95% CI 1.34 to 3.54) and multiple measures of OSA severity. In subjects <65 years old, independent predictors of incident AF were age, male gender, coronary artery disease, body mass index (per 1 kg/m2, hazard ratio 1.07, 95% CI 1.05 to 1.10), and the decrease in nocturnal oxygen saturation (per 0.5 U log change, hazard ratio 3.29, 95% CI 1.35 to 8.04). Heart failure, but neither obesity nor OSA, predicted incident AF in subjects > or =65 years of age. Obesity and the magnitude of nocturnal oxygen desaturation, which is an important pathophysiological consequence of OSA, are independent risk factors for incident AF in individuals <65 years of age.",success
29745973,False,Journal Article;Observational Study,,,,,,,,True,"Obstructive sleep apnea (OSA) is a systemic disorder associated with significant cardiovascular complications. OSA may play a role in the initiation and worsening of atrial fibrillation (AF). This study aimed to determine the prevalence and clinical predictors of OSA in patients with AF. OSA is underdiagnosed in a large number of patients with AF and may not be predicted by conventional clinical indices. Consecutive nonselected patients with AF were recruited from different arrhythmia clinics in Toronto, Ontario, Canada. Patients with previous diagnosis and/or treatment of OSA were excluded. Patients underwent 2 consecutive nights of ambulatory sleep testing with full electroencephalogram recording. OSA was defined as an Apnea-Hypopnea Index (AHI) score ≥ 5 per hour of sleep. 123 patients with AF were recruited, with 100 patients included in the final analysis. OSA was detected in 85% of these patients. 27% of patients with normal overall AHI had an increased AHI during rapid eye movement sleep. Only age and male sex were independent predictors of the presence of OSA in these patients. OSA is common and often undetected in patients with AF, especially in nonobese and/or female patients. Patients may have a normal overall AHI but an abnormal AHI during rapid eye movement sleep. The clinical relevance and therapeutic implications in this subgroup should be further investigated. The clinical features of OSA are not reliable predictors of OSA in patients with AF. A low threshold for detection of OSA, with sleep studies, in these patients may be merited.",success
20714922,False,Comparative Study;Journal Article,,,,,,,,True,"To address the question whether obstructive sleep apnea (OSA) is associated with the recurrence of paroxysmal atrial fibrillation (AF) in patients treated with ≥2 pulmonary vein isolation procedures. In this study, we included adults with therapy-resistant symptomatic paroxysmal AF, defined as AF recurring after ≥2 PV-isolation procedures (n = 23). For comparison, we selected another cohort of patients being successfully treated by one PV isolation without AF recurrence within 6 months (n = 23). PV isolation was performed by radiofrequency with an open irrigated tip catheter. Each of the 46 participants completed an overnight polygraphic study. The two groups were matched for age, gender, and ejection fraction. Patients were late middle-aged (65 ± 7 vs 63 ± 10 years, P = 0.23), white (100%), and overweight (BMI 27.3 ± 3.6 vs. 27.2 ± 4.6 kg/m(2), P = 0.97). The prevalence of sleep apnea, defined as an apnea-hypopnea index (AHI) of >5 per hour of sleep, was 87% in patients with therapy-resistant AF compared to 48% in the control cohort (P = 0.005). In addition, OSA was more severe in the resistant AF group indicated by a significantly higher AHI (27 ± 22 vs 12 ± 16, P = 0.01). The extraordinarily high prevalence of sleep apnea in patients with recurrent paroxysmal AF supports its presumable role in the pathogenesis of AF and demands further controlled prospective trials. Moreover, OSA should inherently be considered in patients with therapy-resistant AF.",success
