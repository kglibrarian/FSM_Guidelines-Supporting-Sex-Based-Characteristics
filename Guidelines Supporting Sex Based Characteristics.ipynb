{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83d4e244-ad4a-4133-82f6-947a1a4a3a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "✓ ALL IMPORTS SUCCESSFUL\n",
      "======================================================================\n",
      "Python modules loaded:\n",
      "  ✓ Data processing: pandas 2.2.3\n",
      "  ✓ Bio/Entrez: karen.gutzman@gmail.com\n",
      "  ✓ Validation functions: 8 validators\n",
      "  ✓ Output folder: output\n",
      "  ✓ Checkpoint system: Available\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SETUP: Import Libraries and Configure Environment\n",
    "# ============================================================================\n",
    "# Purpose: Load all required libraries and validate environment\n",
    "# Run this: Once at the start of the notebook\n",
    "# Re-run if: Kernel restarts or imports fail\n",
    "# ============================================================================\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Standard Library Imports\n",
    "# ----------------------------------------------------------------------------\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "import pickle\n",
    "import logging\n",
    "import shutil\n",
    "import json\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Data Processing & Analysis\n",
    "# ----------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np  # Add if you use it anywhere\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Progress Bars & Visualization\n",
    "# ----------------------------------------------------------------------------\n",
    "from tqdm.notebook import tqdm  # For Jupyter notebooks (includes regular tqdm functionality)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Excel File Handling\n",
    "# ----------------------------------------------------------------------------\n",
    "import xlsxwriter  # For creating Excel files\n",
    "import openpyxl    # For reading/modifying Excel files\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# External APIs & Web Requests\n",
    "# ----------------------------------------------------------------------------\n",
    "import requests                    # General HTTP requests\n",
    "from Bio import Entrez            # PubMed/NCBI API\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Natural Language Processing\n",
    "# ----------------------------------------------------------------------------\n",
    "import spacy                      # Text analysis (if using NLP features)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Geolocation\n",
    "# ----------------------------------------------------------------------------\n",
    "from geopy.geocoders import Nominatim  # Geographic lookups (if needed)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Custom Modules (Project-Specific)\n",
    "# ----------------------------------------------------------------------------\n",
    "# API Configuration\n",
    "from config import (\n",
    "    ENTREZ_EMAIL,\n",
    "    ENTREZ_API_KEY,\n",
    "    SCOPUS_API_KEY\n",
    ")\n",
    "\n",
    "# Checkpoint System\n",
    "from normalized_checkpoint_system import cleanup_all_checkpoints\n",
    "\n",
    "# Pipeline Validation\n",
    "from pipeline_validation_checks import (\n",
    "    # Core validation functions\n",
    "    check_row_count_match,\n",
    "    check_no_duplicates,\n",
    "    check_cartesian_product,\n",
    "    check_column_values,\n",
    "    check_merge_integrity,\n",
    "    \n",
    "    # Phase-specific validators\n",
    "    validate_phase1,\n",
    "    validate_phase2,\n",
    "    validate_phase3,\n",
    "    validate_phase4,\n",
    "    validate_phase5,\n",
    "    validate_phase6,\n",
    "    validate_phase7,\n",
    "    validate_phase7b,\n",
    "    \n",
    "    # Master function\n",
    "    run_all_validations,\n",
    "    \n",
    "    # Quick check\n",
    "    quick_check_after_phase,\n",
    "    \n",
    "    # Globals\n",
    "    OUTPUT_FOLDER,\n",
    "    WARNINGS,\n",
    "    ERRORS\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Configuration & Setup\n",
    "# ----------------------------------------------------------------------------\n",
    "# Set pandas display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Configure Entrez (PubMed) API\n",
    "Entrez.email = ENTREZ_EMAIL\n",
    "Entrez.api_key = ENTREZ_API_KEY\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "    print(f\"✓ Created output folder: {OUTPUT_FOLDER}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Validation Summary\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"=\"*70)\n",
    "print(\"✓ ALL IMPORTS SUCCESSFUL\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Python modules loaded:\")\n",
    "print(f\"  ✓ Data processing: pandas {pd.__version__}\")\n",
    "print(f\"  ✓ Bio/Entrez: {Entrez.email}\")\n",
    "print(f\"  ✓ Validation functions: {len([f for f in dir() if f.startswith('validate_')])} validators\")\n",
    "print(f\"  ✓ Output folder: {OUTPUT_FOLDER}\")\n",
    "print(f\"  ✓ Checkpoint system: Available\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a6dadcc-0675-434a-b306-30bdad88f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Clean ALL checkpoints before starting\n",
    "# ============================================================================\n",
    "\n",
    "# Define OUTPUT_FOLDER (or use hardcoded path)\n",
    "OUTPUT_FOLDER = 'output'  \n",
    "\n",
    "# ============================================================================\n",
    "## Run to delete all previous checkpoints\n",
    "# ============================================================================\n",
    "\n",
    "#cleanup_all_checkpoints(confirm=False)  # Auto-confirm, no prompt\n",
    "\n",
    "# ============================================================================\n",
    "## Or run to clean specific phases:\n",
    "# ============================================================================\n",
    "\n",
    "# checkpoint_dir = os.path.join(OUTPUT_FOLDER, 'checkpoints', 'phase3_trials')\n",
    "\n",
    "# if os.path.exists(checkpoint_dir):\n",
    "#     print(f\"Removing old Phase 3 checkpoint directory...\")\n",
    "#     shutil.rmtree(checkpoint_dir)\n",
    "#     print(f\"✓ Checkpoint cleared\")\n",
    "# else:\n",
    "#     print(\"No checkpoint found (already clean)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e730b54e-6491-4f6d-a7f1-d1542ee79bed",
   "metadata": {},
   "source": [
    "# Phase 1: PubMed Guidelines Collection\n",
    "\n",
    "**Input:** `data/final_guidelines.csv` (list of guideline PMIDs)  \n",
    "**Output:** `phase1_pubmed_guidelines.csv` (~60 guidelines with metadata)\n",
    "\n",
    "**What this does:**\n",
    "- Fetches PubMed metadata for each guideline\n",
    "- Retrieves titles, abstracts, publication dates, journals\n",
    "- Saves guideline information for citation analysis\n",
    "\n",
    "**Key steps:**\n",
    "1. Load guideline PMID list\n",
    "2. Query PubMed API in chunks\n",
    "3. Extract metadata from PubMed XML\n",
    "4. Save complete guideline dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e97b5a-dd15-4f6d-ae9a-0989c76ed450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Phase 1 Configuration complete\n",
      "  Output folder: output\n",
      "  Chunks folder: output\\phase1_chunks\n",
      "  Log file: output\\pubmed_errors.log\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 1: Step 1: CONFIGURATION & SETUP\n",
    "# ============================================================================\n",
    "# Purpose: Set up folders, logging, and basic configuration\n",
    "# Run this: ONCE at the start\n",
    "# Re-run if: You need to change the output folder\n",
    "\n",
    "## Refernece folder if you have not yet\n",
    "OUTPUT_FOLDER = 'output'  \n",
    "\n",
    "# Chunks subdirectory for Phase 1\n",
    "CHUNKS_FOLDER = os.path.join(OUTPUT_FOLDER, 'phase1_chunks')\n",
    "\n",
    "# Create folders if they don't exist\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(CHUNKS_FOLDER, exist_ok=True)\n",
    "\n",
    "# Set up logging (save to folder)\n",
    "log_file = os.path.join(OUTPUT_FOLDER, 'pubmed_errors.log')\n",
    "logging.basicConfig(\n",
    "    filename=log_file, \n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "print(f\"✓ Phase 1 Configuration complete\")\n",
    "print(f\"  Output folder: {OUTPUT_FOLDER}\")\n",
    "print(f\"  Chunks folder: {CHUNKS_FOLDER}\")\n",
    "print(f\"  Log file: {log_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04b9beb7-6622-4e63-88f1-b251b3ce1141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Entrez configured\n",
      "  Email: karen.gutzman@gmail.com\n",
      "  API Key: ********************07b08\n",
      "  Batch size: 200\n",
      "  Checkpoint interval: 50\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 1: Step 2 - Entrez & Checkpoint Setup\n",
    "# ============================================================================\n",
    "# Purpose: Configure API access and import checkpoint system\n",
    "# Run this: ONCE after Step 1\n",
    "# Re-run if: You need to reload checkpoint functions\n",
    "\n",
    "# Configure Entrez (your API credentials)\n",
    "Entrez.email = ENTREZ_EMAIL\n",
    "Entrez.api_key = ENTREZ_API_KEY\n",
    "\n",
    "# Import normalized checkpoint system\n",
    "from normalized_checkpoint_system import (\n",
    "    save_phase1_checkpoint,\n",
    "    load_phase1_checkpoint,\n",
    "    CHECKPOINT_INTERVAL\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "print(f\"✓ Entrez configured\")\n",
    "print(f\"  Email: {Entrez.email}\")\n",
    "print(f\"  API Key: {'*' * 20}{Entrez.api_key[-5:]}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Checkpoint interval: {CHECKPOINT_INTERVAL}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c9f80c1-e8b5-4050-885f-6d29198f11e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 1: Step 3 - Helper Functions\n",
    "# ============================================================================\n",
    "# Purpose: Define functions used in processing\n",
    "# Run this: ONCE after Step 2\n",
    "# Re-run if: You modify the fetch function\n",
    "\n",
    "def fetch_records_from_history(webenv, query_key, retstart, retmax, max_retries=3):\n",
    "    \"\"\"Fetch records using the history server\"\"\"\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            handle = Entrez.efetch(\n",
    "                db=\"pubmed\",\n",
    "                rettype=\"xml\",\n",
    "                retmode=\"xml\",\n",
    "                retstart=retstart,\n",
    "                retmax=retmax,\n",
    "                webenv=webenv,\n",
    "                query_key=query_key\n",
    "            )\n",
    "            records = Entrez.read(handle)\n",
    "            handle.close()\n",
    "            return records\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            wait_time = 2 ** retries\n",
    "            logging.error(f\"Error fetching records at position {retstart} (attempt {retries}/{max_retries}): {e}\")\n",
    "            time.sleep(wait_time)\n",
    "            if retries == max_retries:\n",
    "                logging.error(f\"Failed after {max_retries} retries\")\n",
    "                return None\n",
    "\n",
    "\n",
    "def fetch_pubmed_record(pubmed_id):\n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=pubmed_id, rettype=\"xml\")\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    return record\n",
    "\n",
    "\n",
    "def get_journal_volume_issue(record):\n",
    "    try:      \n",
    "        journal_volume_issue = record['PubmedArticle'][0]['MedlineCitation']['Article']['Journal']['JournalIssue']\n",
    "        volume = journal_volume_issue.get('Volume', '')\n",
    "        issue = journal_volume_issue.get('Issue', '')\n",
    "        return volume, issue\n",
    "    except KeyError:\n",
    "        return None, None\n",
    "\n",
    "   \n",
    "\n",
    "def get_article_title_page(record):\n",
    "    try:      \n",
    "        article_title_page = record['PubmedArticle'][0]['MedlineCitation']['Article']\n",
    "        article_title= article_title_page.get('ArticleTitle', '')\n",
    "        page_start = article_title_page.get('Pagination', {}).get('MedlinePgn', '').split('-')[0]\n",
    "        page_end = article_title_page.get('Pagination', {}).get('MedlinePgn', '').split('-')[-1]\n",
    "        return article_title, page_start, page_end\n",
    "    except KeyError:\n",
    "        return None, None, None\n",
    "\n",
    "def get_journal_title(record):\n",
    "    try:\n",
    "        journal_title= record['PubmedArticle'][0]['MedlineCitation']['Article']['Journal']\n",
    "        #print(\"Journal Title: \", journal_title_pmid)\n",
    "        title = journal_title.get('Title', '')\n",
    "        return title\n",
    "    except KeyError:\n",
    "        return None, None, \n",
    "    \n",
    "def get_authors(record):\n",
    "    \"\"\"Get all authors including corporate/collective names\"\"\"\n",
    "    try:\n",
    "        authors = record['PubmedArticle'][0]['MedlineCitation']['Article']['AuthorList']\n",
    "        author_list = []\n",
    "        \n",
    "        for author in authors:\n",
    "            # Check for collective/corporate name first\n",
    "            if 'CollectiveName' in author:\n",
    "                collective_name = author.get('CollectiveName', '')\n",
    "                if collective_name:\n",
    "                    author_list.append(str(collective_name))\n",
    "            # Otherwise get individual author name\n",
    "            elif 'LastName' in author:\n",
    "                last_name = author.get('LastName', '')\n",
    "                initials = author.get('Initials', '')\n",
    "                if last_name:\n",
    "                    author_list.append(f\"{last_name} {initials}\".strip())\n",
    "        \n",
    "        return ', '.join(author_list) if author_list else None\n",
    "    except KeyError:\n",
    "        return None\n",
    "    \n",
    "def get_publication_date_year(record):\n",
    "    try:\n",
    "        date = record['PubmedArticle'][0]['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']\n",
    "        return date.get('Year', '') if 'Year' in date else None\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def get_publication_date_month_year(record):\n",
    "    try:\n",
    "        date = record['PubmedArticle'][0]['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']\n",
    "        year = date.get('Year', '')\n",
    "        month = date.get('Month', '')\n",
    "        return f\"{month} {year}\" if month and year else None\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def get_publication_date_month_day_year(record):\n",
    "    try:\n",
    "        date = record['PubmedArticle'][0]['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']\n",
    "        year = date.get('Year', '')\n",
    "        month = date.get('Month', '')\n",
    "        day = date.get('Day', '')\n",
    "\n",
    "        # Mapping of month abbreviations to numbers\n",
    "        month_mapping = {\n",
    "            'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04', 'May': '05', 'Jun': '06',\n",
    "            'Jul': '07', 'Aug': '08', 'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'\n",
    "        }\n",
    "\n",
    "        # Replace the month abbreviation with the corresponding number\n",
    "        month_number = month_mapping.get(month, month)\n",
    "\n",
    "        return f\"{month_number}/{day}/{year}\" if month and day and year else None\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def get_abstract(record):\n",
    "    \"\"\"Extract abstract text from PubMed record\"\"\"\n",
    "    try:\n",
    "        abstract_texts = record['PubmedArticle'][0]['MedlineCitation']['Article'].get('Abstract', {}).get('AbstractText', [])\n",
    "        if isinstance(abstract_texts, list):\n",
    "            # Handle structured abstracts\n",
    "            abstract = ' '.join(str(text) for text in abstract_texts)\n",
    "        else:\n",
    "            abstract = str(abstract_texts)\n",
    "        return abstract if abstract else None\n",
    "    except (KeyError, IndexError):\n",
    "        return None\n",
    "        \n",
    "def get_pmid_pmcid_doi(record):\n",
    "    try:\n",
    "        pmid = next(\n",
    "            (id_ for id_ in record.get('PubmedArticle', [{}])[0].get('PubmedData', {}).get('ArticleIdList', []) if id_.attributes.get('IdType') == 'pubmed'),\n",
    "            None\n",
    "        )\n",
    "        #print(\"PMID: \", pmid)\n",
    "\n",
    "        pmcid = next(\n",
    "            (id_ for id_ in record.get('PubmedArticle', [{}])[0].get('PubmedData', {}).get('ArticleIdList', []) if id_.attributes.get('IdType') == 'pmc'),\n",
    "            None\n",
    "        )\n",
    "        #print(\"PMCID: \", pmcid)\n",
    "\n",
    "        doi = next(\n",
    "            (id_ for id_ in record.get('PubmedArticle', [{}])[0].get('PubmedData', {}).get('ArticleIdList', []) if id_.attributes.get('IdType') == 'doi'),\n",
    "            None\n",
    "        )\n",
    "        #print(\"DOI: \", doi)\n",
    "\n",
    "        return pmid, pmcid, doi\n",
    "    except (IndexError, KeyError):\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "\n",
    "def get_authors_with_affiliation_name_full(record, affiliations_to_check):\n",
    "    try:\n",
    "        authors = record['PubmedArticle'][0]['MedlineCitation']['Article']['AuthorList']\n",
    "        authors_with_affiliation_name_full = []\n",
    "              \n",
    "        for author in authors:\n",
    "            author_affiliations = author.get('AffiliationInfo', [])\n",
    "\n",
    "            if not author_affiliations:\n",
    "                affiliations = [author.get('Affiliation', '').lower()]\n",
    "            else:\n",
    "                affiliations = [affiliation.get('Affiliation', '').lower() for affiliation in author_affiliations]\n",
    "\n",
    "            # Check if any phrase in affiliations_to_check is a substring of affiliation\n",
    "            if any(phrase.lower() in affiliation for phrase in affiliations_to_check for affiliation in affiliations):\n",
    "                # Handle collective name\n",
    "                if 'CollectiveName' in author:\n",
    "                    full_name = author.get('CollectiveName', '')\n",
    "                else:\n",
    "                    full_name = author.get('LastName', '') + ' ' + author.get('ForeName', '')\n",
    "                \n",
    "                if full_name.strip():\n",
    "                    authors_with_affiliation_name_full.append(full_name.strip())\n",
    "                              \n",
    "        return authors_with_affiliation_name_full if authors_with_affiliation_name_full else None\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_authors_with_affiliation_name_initial(record, affiliations_to_check):\n",
    "    try:\n",
    "        authors = record['PubmedArticle'][0]['MedlineCitation']['Article']['AuthorList']\n",
    "        authors_with_affiliation_name_initial = []\n",
    "              \n",
    "        for author in authors:\n",
    "            author_affiliations = author.get('AffiliationInfo', [])\n",
    "\n",
    "            if not author_affiliations:\n",
    "                affiliations = [author.get('Affiliation', '').lower()]\n",
    "            else:\n",
    "                affiliations = [affiliation.get('Affiliation', '').lower() for affiliation in author_affiliations]\n",
    "\n",
    "            # Check if any phrase in affiliations_to_check is a substring of affiliation\n",
    "            if any(phrase.lower() in affiliation for phrase in affiliations_to_check for affiliation in affiliations):\n",
    "                # Handle collective name\n",
    "                if 'CollectiveName' in author:\n",
    "                    initial_name = author.get('CollectiveName', '')\n",
    "                else:\n",
    "                    initial_name = author.get('LastName', '') + ' ' + author.get('Initials', '')\n",
    "                \n",
    "                if initial_name.strip():\n",
    "                    authors_with_affiliation_name_initial.append(initial_name.strip())\n",
    "                              \n",
    "        return authors_with_affiliation_name_initial if authors_with_affiliation_name_initial else None\n",
    "    except KeyError:\n",
    "        return None\n",
    "                                                                             \n",
    "def get_authors_with_affiliation_affiliation(record, affiliations_to_check):\n",
    "    try:\n",
    "        authors = record['PubmedArticle'][0]['MedlineCitation']['Article']['AuthorList']\n",
    "        authors_with_affiliation_affiliation = []\n",
    "        for author in authors:\n",
    "            author_affiliations = author.get('AffiliationInfo', [])\n",
    "\n",
    "            if not author_affiliations:\n",
    "                affiliations = [author.get('Affiliation', '').lower()]\n",
    "            else:\n",
    "                affiliations = [affiliation.get('Affiliation', '').lower() for affiliation in author_affiliations]\n",
    "\n",
    "            if any(phrase.lower() in affiliation for phrase in affiliations_to_check for affiliation in affiliations):\n",
    "                authors_with_affiliation_affiliation.append(affiliations)\n",
    "\n",
    "        return authors_with_affiliation_affiliation if authors_with_affiliation_affiliation else None\n",
    "    except KeyError:\n",
    "        return None\n",
    "                                                                             \n",
    "def get_authors_with_affiliation_formatted(record, authors_with_affiliation):\n",
    "    #print(authors_with_affiliation)\n",
    "    if authors_with_affiliation:\n",
    "        return [f\"{author.split()[0]} {author.split()[1][0]}\" for author in authors_with_affiliation]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "        \n",
    "def get_all_affiliations(record):\n",
    "    try:\n",
    "        authors = record['PubmedArticle'][0]['MedlineCitation']['Article']['AuthorList']\n",
    "        all_affiliations = set()\n",
    "\n",
    "        for author in authors:\n",
    "            author_affiliations = author.get('AffiliationInfo', [])\n",
    "            \n",
    "            if not author_affiliations:\n",
    "                all_affiliations.add(author.get('Affiliation', '').lower())\n",
    "            else:\n",
    "                all_affiliations.update([affiliation.get('Affiliation', '').lower() for affiliation in author_affiliations])\n",
    "\n",
    "        return list(all_affiliations)\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def get_mesh_terms(record):\n",
    "    \"\"\"Extract MeSH terms from PubMed record\"\"\"\n",
    "    try:\n",
    "        mesh_list = record['PubmedArticle'][0]['MedlineCitation'].get('MeshHeadingList', [])\n",
    "        if not mesh_list:\n",
    "            return None\n",
    "        \n",
    "        mesh_terms = []\n",
    "        for mesh in mesh_list:\n",
    "            descriptor = mesh.get('DescriptorName', '')\n",
    "            if descriptor:\n",
    "                mesh_terms.append(str(descriptor))\n",
    "        \n",
    "        return '; '.join(mesh_terms) if mesh_terms else None\n",
    "    except (KeyError, IndexError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_mesh_terms_major_only(record):\n",
    "    \"\"\"Extract only Major MeSH terms (main topics of the article)\"\"\"\n",
    "    try:\n",
    "        mesh_list = record['PubmedArticle'][0]['MedlineCitation'].get('MeshHeadingList', [])\n",
    "        if not mesh_list:\n",
    "            return None\n",
    "        \n",
    "        major_mesh = []\n",
    "        for mesh in mesh_list:\n",
    "            descriptor = mesh.get('DescriptorName', '')\n",
    "            # Check if this is a Major Topic (MajorTopicYN attribute = 'Y')\n",
    "            if descriptor and descriptor.attributes.get('MajorTopicYN') == 'Y':\n",
    "                major_mesh.append(str(descriptor))\n",
    "        \n",
    "        return '; '.join(major_mesh) if major_mesh else None\n",
    "    except (KeyError, IndexError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_mesh_with_qualifiers(record):\n",
    "    \"\"\"Extract MeSH terms with their qualifiers (subheadings)\"\"\"\n",
    "    try:\n",
    "        mesh_list = record['PubmedArticle'][0]['MedlineCitation'].get('MeshHeadingList', [])\n",
    "        if not mesh_list:\n",
    "            return None\n",
    "        \n",
    "        mesh_terms = []\n",
    "        for mesh in mesh_list:\n",
    "            descriptor = mesh.get('DescriptorName', '')\n",
    "            qualifiers = mesh.get('QualifierName', [])\n",
    "            \n",
    "            if descriptor:\n",
    "                if qualifiers:\n",
    "                    # If there are qualifiers, combine them with the descriptor\n",
    "                    qualifier_strs = [str(q) for q in qualifiers]\n",
    "                    mesh_terms.append(f\"{descriptor}/{', '.join(qualifier_strs)}\")\n",
    "                else:\n",
    "                    mesh_terms.append(str(descriptor))\n",
    "        \n",
    "        return '; '.join(mesh_terms) if mesh_terms else None\n",
    "    except (KeyError, IndexError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_keywords(record):\n",
    "    \"\"\"Extract author-supplied keywords\"\"\"\n",
    "    try:\n",
    "        keyword_list = record['PubmedArticle'][0]['MedlineCitation'].get('KeywordList', [])\n",
    "        if not keyword_list:\n",
    "            return None\n",
    "        \n",
    "        # KeywordList is a list of lists, so we need to flatten it\n",
    "        all_keywords = []\n",
    "        for keyword_group in keyword_list:\n",
    "            for keyword in keyword_group:\n",
    "                all_keywords.append(str(keyword))\n",
    "        \n",
    "        return '; '.join(all_keywords) if all_keywords else None\n",
    "    except (KeyError, IndexError):\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_document_type(record):\n",
    "    try:\n",
    "        document_types = record['PubmedArticle'][0]['MedlineCitation']['Article']['PublicationTypeList']\n",
    "        return ', '.join(document_type for document_type in document_types)\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "   \n",
    "def process_pubmed_record(record, affiliations_to_check):\n",
    "    # Extract relevant information from the PubMed record\n",
    "    pubmed_data = {\n",
    "        \"Authors\": get_authors(record),\n",
    "        \"AuthorsWithAffiliationNameFull\": get_authors_with_affiliation_name_full(record, affiliations_to_check),\n",
    "        \"AuthorsWithAffiliationNameInitial\": get_authors_with_affiliation_name_initial(record, affiliations_to_check),\n",
    "        \"AuthorsWithAffiliationAffiliation\": get_authors_with_affiliation_affiliation(record, affiliations_to_check),\n",
    "        \"AllAffiliations\": get_all_affiliations(record),\n",
    "        \"Abstract\": get_abstract(record),\n",
    "        \"date_year\": get_publication_date_year(record),\n",
    "        \"date_monthY\": get_publication_date_month_year(record),\n",
    "        \"date_mdY\": get_publication_date_month_day_year(record),\n",
    "        \"PMID\": get_pmid_pmcid_doi(record)[0],\n",
    "        \"PMCID\": get_pmid_pmcid_doi(record)[1],\n",
    "        \"DOI\":get_pmid_pmcid_doi(record)[2],\n",
    "        \"JournalTitle\": get_journal_title(record),\n",
    "        \"ArticleTitle\": get_article_title_page(record)[0],\n",
    "        \"PageStart\": get_article_title_page(record)[1],\n",
    "        \"PageEnd\": get_article_title_page(record)[2],\n",
    "        \"Volume\": get_journal_volume_issue(record)[0],\n",
    "        \"Issue\": get_journal_volume_issue(record)[1],\n",
    "        \"MeSH_Terms\": get_mesh_terms(record),\n",
    "        \"MeSH_Major\": get_mesh_terms_major_only(record),\n",
    "        \"MeSH_with_Qualifiers\": get_mesh_with_qualifiers(record),\n",
    "        \"Keywords\": get_keywords(record),\n",
    "        \"DocumentType\": get_document_type(record)\n",
    "    }\n",
    "\n",
    "    return pubmed_data\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23878b0b-cace-44f3-937e-f7a1d29d54ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PMIDs to query: 75\n",
      "✓ Query prepared\n",
      "  Date ranges: 51\n",
      "  Affiliations to check: ['Northwestern University', 'Feinberg School of Medicine']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 1: Step 4 - Build Query & Date Ranges\n",
    "# ============================================================================\n",
    "# Purpose: Load your PMID list and prepare the search query\n",
    "# Run this: ONCE after Step 3\n",
    "# Re-run if: Your input CSV changes or you modify date ranges\n",
    "\n",
    "# Read your CSV with guidelines\n",
    "df = pd.read_csv('data/final_guidelines.csv')\n",
    "\n",
    "# Get list of PMIDs (remove any NaN values and convert to strings)\n",
    "pmid_list = df['PMID'].dropna().astype(str).tolist()\n",
    "print(f\"Total PMIDs to query: {len(pmid_list):,}\")\n",
    "\n",
    "# ========================================\n",
    "# BUILD BASE QUERY with {DATE_FILTER} placeholder\n",
    "# ========================================\n",
    "pmid_query_part = \" OR \".join([f\"{pmid}[uid]\" for pmid in pmid_list])\n",
    "base_query = f\"({pmid_query_part}) AND {{DATE_FILTER}}\"\n",
    "\n",
    "# DATE RANGES - Process data in 6-month chunks\n",
    "date_ranges = [\n",
    "    (\"2000/01/01\", \"2000/06/30\"), (\"2000/07/01\", \"2000/12/31\"),\n",
    "    (\"2001/01/01\", \"2001/06/30\"), (\"2001/07/01\", \"2001/12/31\"),\n",
    "    (\"2002/01/01\", \"2002/06/30\"), (\"2002/07/01\", \"2002/12/31\"),\n",
    "    (\"2003/01/01\", \"2003/06/30\"), (\"2003/07/01\", \"2003/12/31\"),\n",
    "    (\"2004/01/01\", \"2004/06/30\"), (\"2004/07/01\", \"2004/12/31\"),\n",
    "    (\"2005/01/01\", \"2005/06/30\"), (\"2005/07/01\", \"2005/12/31\"),\n",
    "    (\"2006/01/01\", \"2006/06/30\"), (\"2006/07/01\", \"2006/12/31\"),\n",
    "    (\"2007/01/01\", \"2007/06/30\"), (\"2007/07/01\", \"2007/12/31\"),\n",
    "    (\"2008/01/01\", \"2008/06/30\"), (\"2008/07/01\", \"2008/12/31\"),\n",
    "    (\"2009/01/01\", \"2009/06/30\"), (\"2009/07/01\", \"2009/12/31\"),\n",
    "    (\"2010/01/01\", \"2010/06/30\"), (\"2010/07/01\", \"2010/12/31\"),\n",
    "    (\"2011/01/01\", \"2011/06/30\"), (\"2011/07/01\", \"2011/12/31\"),\n",
    "    (\"2012/01/01\", \"2012/06/30\"), (\"2012/07/01\", \"2012/12/31\"),\n",
    "    (\"2013/01/01\", \"2013/06/30\"), (\"2013/07/01\", \"2013/12/31\"),\n",
    "    (\"2014/01/01\", \"2014/06/30\"), (\"2014/07/01\", \"2014/12/31\"),\n",
    "    (\"2015/01/01\", \"2015/06/30\"), (\"2015/07/01\", \"2015/12/31\"),\n",
    "    (\"2016/01/01\", \"2016/06/30\"), (\"2016/07/01\", \"2016/12/31\"),\n",
    "    (\"2017/01/01\", \"2017/06/30\"), (\"2017/07/01\", \"2017/12/31\"),\n",
    "    (\"2018/01/01\", \"2018/06/30\"), (\"2018/07/01\", \"2018/12/31\"),\n",
    "    (\"2019/01/01\", \"2019/06/30\"), (\"2019/07/01\", \"2019/12/31\"),\n",
    "    (\"2020/01/01\", \"2020/06/30\"), (\"2020/07/01\", \"2020/12/31\"),\n",
    "    (\"2021/01/01\", \"2021/06/30\"), (\"2021/07/01\", \"2021/12/31\"),\n",
    "    (\"2022/01/01\", \"2022/06/30\"), (\"2022/07/01\", \"2022/12/31\"),\n",
    "    (\"2023/01/01\", \"2023/06/30\"), (\"2023/07/01\", \"2023/12/31\"),\n",
    "    (\"2024/01/01\", \"2024/06/30\"), (\"2024/07/01\", \"2024/12/31\"),\n",
    "    (\"2025/01/01\", \"2025/12/03\"),\n",
    "]\n",
    "\n",
    "affiliations_to_check = [\"Northwestern University\", \"Feinberg School of Medicine\"]\n",
    "\n",
    "print(f\"✓ Query prepared\")\n",
    "print(f\"  Date ranges: {len(date_ranges)}\")\n",
    "print(f\"  Affiliations to check: {affiliations_to_check}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d4330d9-b3b5-4a67-b9f8-62306f665769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CHUNK 1/51: 2000/01/01 to 2000/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:19,559 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d659bec13aa5e3e0a66c6, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d659bec13aa5...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 2/51: 2000/07/01 to 2000/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:19,844 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d659b7d1641386106dfc5, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d659b7d16413...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 3/51: 2001/01/01 to 2001/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:20,108 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d659b73d99a77600b4635, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d659b73d99a7...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 4/51: 2001/07/01 to 2001/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:20,365 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d659ced2282075e0d362f, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d659ced22820...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 5/51: 2002/01/01 to 2002/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:20,617 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d659ce99fce118208e6ec, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d659ce99fce1...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 6/51: 2002/07/01 to 2002/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:20,892 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d659cf7bce127ab038bb3, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d659cf7bce12...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 7/51: 2003/01/01 to 2003/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:21,128 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d659c7bc2924bd8051ef8, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d659c7bc2924...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 8/51: 2003/07/01 to 2003/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:21,385 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d659dfe796e3ef909a7b8, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d659dfe796e3...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 9/51: 2004/01/01 to 2004/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:21,638 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d659d16cfa2e3430be6fa, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d659d16cfa2e...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 10/51: 2004/07/01 to 2004/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:21,901 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d659d17efc4e29a0794a8, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d659d17efc4e...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 11/51: 2005/01/01 to 2005/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:22,140 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d659e1af9e253750f1026, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d659e1af9e25...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 12/51: 2005/07/01 to 2005/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:22,400 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d659ea7fe7c1f3802252d, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d659ea7fe7c1...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 13/51: 2006/01/01 to 2006/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:22,668 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d659eac1a4aa70c001af6, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d659eac1a4aa...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 14/51: 2006/07/01 to 2006/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:22,932 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d659e40dc715f5c00885d, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d659e40dc715...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 15/51: 2007/01/01 to 2007/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:23,180 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d659fb40e276113036a65, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d659fb40e276...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 16/51: 2007/07/01 to 2007/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:23,439 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d659f16cfa2e3430be6fc, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d659f16cfa2e...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 17/51: 2008/01/01 to 2008/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:23,685 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d659f253d7828a10fb111, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d659f253d782...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 18/51: 2008/07/01 to 2008/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:23,932 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d659fdcc7dd51da0c2b9e, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d659fdcc7dd5...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 19/51: 2009/01/01 to 2009/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:24,226 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a011ceb1c0ce0bb618, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a011ceb1c...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 20/51: 2009/07/01 to 2009/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:24,509 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a00f9bb815e7091cc6, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a00f9bb81...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 21/51: 2010/01/01 to 2010/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:24,767 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a0fb5eb1dc44003b05, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a0fb5eb1d...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 22/51: 2010/07/01 to 2010/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:25,010 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a0f818431e800e322d, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a0f818431...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 23/51: 2011/01/01 to 2011/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:25,315 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a117efc4e29a0794aa, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a117efc4e...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 24/51: 2011/07/01 to 2011/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:25,615 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a16d9ce3cc4402af36, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a16d9ce3c...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 25/51: 2012/01/01 to 2012/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:25,857 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a1a7fe7c1f3802252f, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a1a7fe7c1...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 26/51: 2012/07/01 to 2012/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:26,104 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a1e0054276170dc648, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a1e005427...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 27/51: 2013/01/01 to 2013/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:26,380 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a2fdccc10202075c47, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a2fdccc10...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 28/51: 2013/07/01 to 2013/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:26,648 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a270c4a9d4e70debc1, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a270c4a9d...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 29/51: 2014/01/01 to 2014/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:26,890 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a2a9f55a0e22094e88, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a2a9f55a0...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 30/51: 2014/07/01 to 2014/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:27,196 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a260b7ad9398016afb, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a260b7ad9...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 31/51: 2015/01/01 to 2015/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:27,463 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a39a3842b3840091b2, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a39a3842b...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 32/51: 2015/07/01 to 2015/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:27,751 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a32e6faa957502132f, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a32e6faa9...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 33/51: 2016/01/01 to 2016/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:28,096 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a3cedd078a070bb1f8, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a3cedd078...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 34/51: 2016/07/01 to 2016/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:28,347 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a4484044f9b80d2a3d, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a4484044f...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 35/51: 2017/01/01 to 2017/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:28,628 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a405f1d1cfaf0df432, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a405f1d1c...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 36/51: 2017/07/01 to 2017/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:28,868 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a4e99fce118208e6ee, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a4e99fce1...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 37/51: 2018/01/01 to 2018/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:29,155 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a566e9605c850ff7ba, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a566e9605...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 38/51: 2018/07/01 to 2018/12/31\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:29,416 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a5ab89de790f08bf13, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a5ab89de7...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 39/51: 2019/01/01 to 2019/06/30\n",
      "======================================================================\n",
      "\n",
      "Posting search to NCBI history server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:29,680 - INFO - Search posted to history server. Count: 0, WebEnv: MCID_695d65a556fc0ab62a0dc3c9, QueryKey: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 0\n",
      "WebEnv: MCID_695d65a556fc0ab...\n",
      "QueryKey: 1\n",
      "\n",
      "======================================================================\n",
      "CHUNK 40/51: 2019/07/01 to 2019/12/31\n",
      "======================================================================\n",
      "\n",
      "✓ Chunk 40 already exists, skipping...\n",
      "\n",
      "======================================================================\n",
      "CHUNK 41/51: 2020/01/01 to 2020/06/30\n",
      "======================================================================\n",
      "\n",
      "✓ Chunk 41 already exists, skipping...\n",
      "\n",
      "======================================================================\n",
      "CHUNK 42/51: 2020/07/01 to 2020/12/31\n",
      "======================================================================\n",
      "\n",
      "✓ Chunk 42 already exists, skipping...\n",
      "\n",
      "======================================================================\n",
      "CHUNK 43/51: 2021/01/01 to 2021/06/30\n",
      "======================================================================\n",
      "\n",
      "✓ Chunk 43 already exists, skipping...\n",
      "\n",
      "======================================================================\n",
      "CHUNK 44/51: 2021/07/01 to 2021/12/31\n",
      "======================================================================\n",
      "\n",
      "✓ Chunk 44 already exists, skipping...\n",
      "\n",
      "======================================================================\n",
      "CHUNK 45/51: 2022/01/01 to 2022/06/30\n",
      "======================================================================\n",
      "\n",
      "✓ Chunk 45 already exists, skipping...\n",
      "\n",
      "======================================================================\n",
      "CHUNK 46/51: 2022/07/01 to 2022/12/31\n",
      "======================================================================\n",
      "\n",
      "✓ Chunk 46 already exists, skipping...\n",
      "\n",
      "======================================================================\n",
      "CHUNK 47/51: 2023/01/01 to 2023/06/30\n",
      "======================================================================\n",
      "\n",
      "✓ Chunk 47 already exists, skipping...\n",
      "\n",
      "======================================================================\n",
      "CHUNK 48/51: 2023/07/01 to 2023/12/31\n",
      "======================================================================\n",
      "\n",
      "✓ Chunk 48 already exists, skipping...\n",
      "\n",
      "======================================================================\n",
      "CHUNK 49/51: 2024/01/01 to 2024/06/30\n",
      "======================================================================\n",
      "\n",
      "✓ Chunk 49 already exists, skipping...\n",
      "\n",
      "======================================================================\n",
      "CHUNK 50/51: 2024/07/01 to 2024/12/31\n",
      "======================================================================\n",
      "\n",
      "✓ Chunk 50 already exists, skipping...\n",
      "\n",
      "======================================================================\n",
      "CHUNK 51/51: 2025/01/01 to 2025/12/03\n",
      "======================================================================\n",
      "\n",
      "✓ Chunk 51 already exists, skipping...\n",
      "\n",
      "✓ All chunks processed!\n",
      "  Total chunk files: 12\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 1: Step 5 - Main Processing Loop (LONG RUNNING TIME)\n",
    "# ============================================================================\n",
    "# Purpose: Process all date chunks and collect data\n",
    "# Run this: After all previous steps\n",
    "# Re-run if: You need to resume or restart processing\n",
    "# NOTE: This step takes the longest time - several hours potentially\n",
    "# Checkpoints are saved to: output/checkpoints/phase1_pubmed/\n",
    "\n",
    "# Store all chunk data\n",
    "all_chunk_files = []\n",
    "\n",
    "# ========================================\n",
    "#  MAIN LOOP - Process each date range chunk\n",
    "# ========================================\n",
    "\n",
    "for chunk_num, (start_date, end_date) in enumerate(date_ranges, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"CHUNK {chunk_num}/{len(date_ranges)}: {start_date} to {end_date}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Check if chunk file already exists (using CHUNKS_FOLDER)\n",
    "    chunk_filename = os.path.join(CHUNKS_FOLDER, f'guideline_chunk_{chunk_num:02d}_{start_date.replace(\"/\", \"-\")}_{end_date.replace(\"/\", \"-\")}.csv')\n",
    "    \n",
    "    if os.path.exists(chunk_filename):\n",
    "        print(f\"✓ Chunk {chunk_num} already exists, skipping...\")\n",
    "        all_chunk_files.append(chunk_filename)\n",
    "        continue\n",
    "    \n",
    "    # Create query for this date range\n",
    "    date_filter = f\"{start_date}:{end_date}[pdat]\"\n",
    "    search_query = base_query.replace(\"{DATE_FILTER}\", date_filter)\n",
    "    \n",
    "    # Post search to history server\n",
    "    print(\"Posting search to NCBI history server...\")\n",
    "    try:\n",
    "        search_handle = Entrez.esearch(\n",
    "            db=\"pubmed\",\n",
    "            term=search_query,\n",
    "            usehistory=\"y\",\n",
    "            retmax=0\n",
    "        )\n",
    "        search_results = Entrez.read(search_handle)\n",
    "        search_handle.close()\n",
    "        \n",
    "        count = int(search_results[\"Count\"])\n",
    "        webenv = search_results[\"WebEnv\"]\n",
    "        query_key = search_results[\"QueryKey\"]\n",
    "        \n",
    "        print(f\"Total results: {count:,}\")\n",
    "        print(f\"WebEnv: {webenv[:20]}...\")\n",
    "        print(f\"QueryKey: {query_key}\")\n",
    "        logging.info(f\"Search posted to history server. Count: {count}, WebEnv: {webenv}, QueryKey: {query_key}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to post search: {e}\")\n",
    "        print(f\"Error: {e}\")\n",
    "        count = 0\n",
    "    \n",
    "    # Check for existing checkpoint\n",
    "    checkpoint = load_phase1_checkpoint()\n",
    "    \n",
    "    if checkpoint and checkpoint['total_count'] == count:\n",
    "        pubmed_data = checkpoint['pubmed_data']\n",
    "        failed_batches = checkpoint['failed_batches']\n",
    "        start_index = checkpoint['batch_index']\n",
    "        print(f\"\\n✓ Resuming from checkpoint: {len(pubmed_data):,} records already processed\")\n",
    "        print(f\"  Starting from record {start_index:,}\")\n",
    "    else:\n",
    "        pubmed_data = []\n",
    "        failed_batches = []\n",
    "        start_index = 0\n",
    "    \n",
    "    if count > 0:\n",
    "        print(f\"\\nProcessing {count:,} records in batches of {BATCH_SIZE}...\")\n",
    "        \n",
    "        # Process records using history server\n",
    "        for start in tqdm(range(start_index, count, BATCH_SIZE), desc=\"Processing records\"):\n",
    "            try:\n",
    "                batch_records = fetch_records_from_history(webenv, query_key, start, BATCH_SIZE)\n",
    "                \n",
    "                if batch_records and 'PubmedArticle' in batch_records:\n",
    "                    for article in batch_records['PubmedArticle']:\n",
    "                        try:\n",
    "                            # Process each article\n",
    "                            processed = process_pubmed_record({'PubmedArticle': [article]}, affiliations_to_check)\n",
    "                            pubmed_data.append(processed)\n",
    "                        except Exception as e:\n",
    "                            try:\n",
    "                                pmid = article['MedlineCitation']['PMID']\n",
    "                            except:\n",
    "                                pmid = 'Unknown'\n",
    "                            logging.error(f\"Error processing PMID {pmid}: {e}\")\n",
    "                else:\n",
    "                    failed_batches.append((start, min(start + BATCH_SIZE, count)))\n",
    "                    logging.warning(f\"Batch at position {start} failed\")\n",
    "                \n",
    "                # Save checkpoint every 50 batches\n",
    "                batch_number = (start // BATCH_SIZE) + 1\n",
    "                if batch_number % CHECKPOINT_INTERVAL == 0:\n",
    "                    save_phase1_checkpoint(start + BATCH_SIZE, pubmed_data, failed_batches, count)\n",
    "                    print(f\"\\n💾 Checkpoint saved at batch {batch_number} ({len(pubmed_data):,} records)\")\n",
    "                \n",
    "                # Rate limiting\n",
    "                time.sleep(0.1 if Entrez.api_key else 0.34)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error at position {start}: {e}\")\n",
    "                failed_batches.append((start, min(start + BATCH_SIZE, count)))\n",
    "                time.sleep(2)\n",
    "        \n",
    "        # Save final checkpoint\n",
    "        save_phase1_checkpoint(count, pubmed_data, failed_batches, count)\n",
    "    \n",
    "        # Retry failed batches\n",
    "        if failed_batches:\n",
    "            print(f\"\\nRetrying {len(failed_batches)} failed batches...\")\n",
    "            for start, end in tqdm(failed_batches, desc=\"Retrying failed batches\"):\n",
    "                try:\n",
    "                    batch_records = fetch_records_from_history(webenv, query_key, start, end - start, max_retries=5)\n",
    "                    \n",
    "                    if batch_records and 'PubmedArticle' in batch_records:\n",
    "                        for article in batch_records['PubmedArticle']:\n",
    "                            try:\n",
    "                                processed = process_pubmed_record({'PubmedArticle': [article]}, affiliations_to_check)\n",
    "                                pubmed_data.append(processed)\n",
    "                            except Exception as e:\n",
    "                                try:\n",
    "                                    pmid = article['MedlineCitation']['PMID']\n",
    "                                except:\n",
    "                                    pmid = 'Unknown'\n",
    "                                logging.error(f\"Error processing PMID {pmid}: {e}\")\n",
    "                    \n",
    "                    time.sleep(0.5)\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Failed retry at position {start}: {e}\")\n",
    "        \n",
    "        # Save this chunk's data (using OUTPUT_FOLDER)\n",
    "        if pubmed_data:\n",
    "            chunk_df = pd.DataFrame(pubmed_data)\n",
    "            chunk_df.to_csv(chunk_filename, index=False)\n",
    "            all_chunk_files.append(chunk_filename)\n",
    "            print(f\"\\n✓ Chunk {chunk_num} complete: {len(chunk_df):,} records saved to {chunk_filename}\")\n",
    "            logging.info(f\"Chunk {chunk_num} saved: {len(chunk_df)} records\")\n",
    "        \n",
    "        # Brief pause between chunks\n",
    "        time.sleep(2)\n",
    "\n",
    "print(f\"\\n✓ All chunks processed!\")\n",
    "print(f\"  Total chunk files: {len(all_chunk_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc75bc18-f619-4fb2-9921-315dc2595f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:29,777 - INFO - All 12 chunks combined: 75 unique records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMBINING ALL CHUNKS\n",
      "======================================================================\n",
      "\n",
      "Loaded guideline_chunk_40_2019-07-01_2019-12-31.csv: 3 records\n",
      "Loaded guideline_chunk_41_2020-01-01_2020-06-30.csv: 7 records\n",
      "Loaded guideline_chunk_42_2020-07-01_2020-12-31.csv: 9 records\n",
      "Loaded guideline_chunk_43_2021-01-01_2021-06-30.csv: 10 records\n",
      "Loaded guideline_chunk_44_2021-07-01_2021-12-31.csv: 9 records\n",
      "Loaded guideline_chunk_45_2022-01-01_2022-06-30.csv: 6 records\n",
      "Loaded guideline_chunk_46_2022-07-01_2022-12-31.csv: 13 records\n",
      "Loaded guideline_chunk_47_2023-01-01_2023-06-30.csv: 9 records\n",
      "Loaded guideline_chunk_48_2023-07-01_2023-12-31.csv: 4 records\n",
      "Loaded guideline_chunk_49_2024-01-01_2024-06-30.csv: 9 records\n",
      "Loaded guideline_chunk_50_2024-07-01_2024-12-31.csv: 5 records\n",
      "Loaded guideline_chunk_51_2025-01-01_2025-12-03.csv: 9 records\n",
      "\n",
      "======================================================================\n",
      "✓ PHASE 1 COMPLETE!\n",
      "======================================================================\n",
      "Total chunks processed: 12\n",
      "Total unique records: 75\n",
      "Final output: output\\phase1_pubmed_guidelines.csv\n",
      "Chunks location: output\\phase1_chunks\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 1: Step 6 - Combine All Chunks\n",
    "# ============================================================================\n",
    "# Purpose: Merge all chunk files into final output\n",
    "# Run this: After Step 5 completes successfully\n",
    "# Re-run if: You need to regenerate the final file\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"COMBINING ALL CHUNKS\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Auto-discover chunk files if not in memory (allows running Step 6 independently)\n",
    "if not all_chunk_files:\n",
    "    print(\"No chunk files in memory - reading from chunks folder...\")\n",
    "    all_chunk_files = sorted([\n",
    "        os.path.join(CHUNKS_FOLDER, f) \n",
    "        for f in os.listdir(CHUNKS_FOLDER) \n",
    "        if f.startswith('guideline_chunk_') and f.endswith('.csv')\n",
    "    ])\n",
    "    print(f\"Found {len(all_chunk_files)} chunk files in {CHUNKS_FOLDER}\")\n",
    "\n",
    "if all_chunk_files:\n",
    "    all_dfs = []\n",
    "    for filename in all_chunk_files:\n",
    "        df = pd.read_csv(filename)\n",
    "        all_dfs.append(df)\n",
    "        print(f\"Loaded {os.path.basename(filename)}: {len(df):,} records\")\n",
    "    \n",
    "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    combined_df = combined_df.drop_duplicates(subset='PMID', keep='first')\n",
    "    \n",
    "    # Save final output (to OUTPUT_FOLDER, not CHUNKS_FOLDER!)\n",
    "    final_output = os.path.join(OUTPUT_FOLDER, 'phase1_pubmed_guidelines.csv')\n",
    "    combined_df.to_csv(final_output, index=False)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"✓ PHASE 1 COMPLETE!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total chunks processed: {len(all_chunk_files)}\")\n",
    "    print(f\"Total unique records: {len(combined_df):,}\")\n",
    "    print(f\"Final output: {final_output}\")\n",
    "    print(f\"Chunks location: {CHUNKS_FOLDER}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    logging.info(f\"All {len(all_chunk_files)} chunks combined: {len(combined_df)} unique records\")\n",
    "else:\n",
    "    print(\"\\n⚠ No chunk files found!\")\n",
    "    print(f\"  Expected location: {CHUNKS_FOLDER}\")\n",
    "    logging.warning(\"No chunks found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6edb24ef-085c-4ec0-908f-400e52d1d75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:42:29,861 - INFO - All 12 chunks combined: 75 unique records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMBINING ALL CHUNKS\n",
      "======================================================================\n",
      "\n",
      "Loaded output\\phase1_chunks\\guideline_chunk_40_2019-07-01_2019-12-31.csv: 3 records\n",
      "Loaded output\\phase1_chunks\\guideline_chunk_41_2020-01-01_2020-06-30.csv: 7 records\n",
      "Loaded output\\phase1_chunks\\guideline_chunk_42_2020-07-01_2020-12-31.csv: 9 records\n",
      "Loaded output\\phase1_chunks\\guideline_chunk_43_2021-01-01_2021-06-30.csv: 10 records\n",
      "Loaded output\\phase1_chunks\\guideline_chunk_44_2021-07-01_2021-12-31.csv: 9 records\n",
      "Loaded output\\phase1_chunks\\guideline_chunk_45_2022-01-01_2022-06-30.csv: 6 records\n",
      "Loaded output\\phase1_chunks\\guideline_chunk_46_2022-07-01_2022-12-31.csv: 13 records\n",
      "Loaded output\\phase1_chunks\\guideline_chunk_47_2023-01-01_2023-06-30.csv: 9 records\n",
      "Loaded output\\phase1_chunks\\guideline_chunk_48_2023-07-01_2023-12-31.csv: 4 records\n",
      "Loaded output\\phase1_chunks\\guideline_chunk_49_2024-01-01_2024-06-30.csv: 9 records\n",
      "Loaded output\\phase1_chunks\\guideline_chunk_50_2024-07-01_2024-12-31.csv: 5 records\n",
      "Loaded output\\phase1_chunks\\guideline_chunk_51_2025-01-01_2025-12-03.csv: 9 records\n",
      "\n",
      "======================================================================\n",
      "✓ PHASE 1 COMPLETE!\n",
      "======================================================================\n",
      "Total chunks processed: 12\n",
      "Total unique records: 75\n",
      "Final output: output\\phase1_pubmed_guidelines.csv\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 1: Step 6 - Combine All Chunks\n",
    "# ============================================================================\n",
    "# Purpose: Merge all chunk files into final output\n",
    "# Run this: After Step 5 completes successfully\n",
    "# Re-run if: You need to regenerate the final file\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"COMBINING ALL CHUNKS\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "if all_chunk_files:\n",
    "    all_dfs = []\n",
    "    for filename in all_chunk_files:\n",
    "        df = pd.read_csv(filename)\n",
    "        all_dfs.append(df)\n",
    "        print(f\"Loaded {filename}: {len(df):,} records\")\n",
    "    \n",
    "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    combined_df = combined_df.drop_duplicates(subset='PMID', keep='first')\n",
    "    \n",
    "    # Save final output (using OUTPUT_FOLDER)\n",
    "    final_output = os.path.join(OUTPUT_FOLDER, 'phase1_pubmed_guidelines.csv')\n",
    "    combined_df.to_csv(final_output, index=False)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"✓ PHASE 1 COMPLETE!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total chunks processed: {len(all_chunk_files)}\")\n",
    "    print(f\"Total unique records: {len(combined_df):,}\")\n",
    "    print(f\"Final output: {final_output}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    logging.info(f\"All {len(all_chunk_files)} chunks combined: {len(combined_df)} unique records\")\n",
    "else:\n",
    "    print(\"\\n⚠ No data retrieved from any chunks!\")\n",
    "    logging.warning(\"No chunks produced data\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3d70193-b733-4c3a-9e37-f4f19d365f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 Final Validation Check:\n",
      "\n",
      "==================================================\n",
      "QUICK CHECK: Phase 1\n",
      "==================================================\n",
      "Rows: 75\n",
      "Columns: 23\n",
      "==================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "VALIDATING PHASE 1: PubMed Guidelines Collection\n",
      "======================================================================\n",
      "✓ Phase 1: No duplicates on ['PMID'] (Each PMID should appear once)\n",
      "✓ Phase 1: Critical columns present (PMID)\n",
      "  ✓ Title column(s) found: ['JournalTitle', 'ArticleTitle']\n",
      "  ✓ Journal column(s) found: ['JournalTitle']\n",
      "✓ Phase 1: No null PMIDs\n",
      "\n",
      "Phase 1 Final Output Verification:\n",
      "  Total records: 75\n",
      "  Columns: ['Authors', 'AuthorsWithAffiliationNameFull', 'AuthorsWithAffiliationNameInitial', 'AuthorsWithAffiliationAffiliation', 'AllAffiliations', 'Abstract', 'date_year', 'date_monthY', 'date_mdY', 'PMID', 'PMCID', 'DOI', 'JournalTitle', 'ArticleTitle', 'PageStart', 'PageEnd', 'Volume', 'Issue', 'MeSH_Terms', 'MeSH_Major', 'MeSH_with_Qualifiers', 'Keywords', 'DocumentType']\n",
      "\n",
      "Data types:\n",
      "Authors                               object\n",
      "AuthorsWithAffiliationNameFull        object\n",
      "AuthorsWithAffiliationNameInitial     object\n",
      "AuthorsWithAffiliationAffiliation     object\n",
      "AllAffiliations                       object\n",
      "Abstract                              object\n",
      "date_year                              int64\n",
      "date_monthY                           object\n",
      "date_mdY                              object\n",
      "PMID                                   int64\n",
      "PMCID                                 object\n",
      "DOI                                   object\n",
      "JournalTitle                          object\n",
      "ArticleTitle                          object\n",
      "PageStart                             object\n",
      "PageEnd                               object\n",
      "Volume                               float64\n",
      "Issue                                 object\n",
      "MeSH_Terms                            object\n",
      "MeSH_Major                            object\n",
      "MeSH_with_Qualifiers                  object\n",
      "Keywords                              object\n",
      "DocumentType                          object\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "Authors                               2\n",
      "AuthorsWithAffiliationNameFull       74\n",
      "AuthorsWithAffiliationNameInitial    74\n",
      "AuthorsWithAffiliationAffiliation    74\n",
      "AllAffiliations                       2\n",
      "Abstract                              9\n",
      "date_year                             0\n",
      "date_monthY                           0\n",
      "date_mdY                             20\n",
      "PMID                                  0\n",
      "PMCID                                53\n",
      "DOI                                   0\n",
      "JournalTitle                          0\n",
      "ArticleTitle                          0\n",
      "PageStart                             1\n",
      "PageEnd                               1\n",
      "Volume                                1\n",
      "Issue                                 1\n",
      "MeSH_Terms                            2\n",
      "MeSH_Major                           12\n",
      "MeSH_with_Qualifiers                  2\n",
      "Keywords                              7\n",
      "DocumentType                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 1: Step 7 - Verify Output (OPTIONAL)\n",
    "# ============================================================================\n",
    "# Purpose: Quick check of the final output\n",
    "# Run this: After Step 6 to verify results\n",
    "\n",
    "phase1_df = pd.read_csv(os.path.join(OUTPUT_FOLDER, 'phase1_pubmed_guidelines.csv'))\n",
    "\n",
    "print(\"Phase 1 Final Validation Check:\")\n",
    "quick_check_after_phase(1, phase1_df)\n",
    "validate_phase1(phase1_df)\n",
    "\n",
    "print(\"\\nPhase 1 Final Output Verification:\")\n",
    "print(f\"  Total records: {len(phase1_df):,}\")\n",
    "print(f\"  Columns: {list(phase1_df.columns)}\")\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(phase1_df.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(phase1_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b34c9a-a15f-46e5-9f81-255bb0c74491",
   "metadata": {},
   "source": [
    "# Phase 2: CrossRef Citations Collection\n",
    "\n",
    "**Input:** `phase1_pubmed_guidelines.csv` (guideline PMIDs)  \n",
    "**Output:** `phase2_crossref_guidelines_and_references.csv` (~8,148 citations)\n",
    "\n",
    "**What this does:**\n",
    "- Finds all references cited by each guideline via CrossRef API\n",
    "- Creates citation edges: guideline → reference (PMID pairs)\n",
    "- Filters to journal articles, removes self-citations\n",
    "\n",
    "**Key steps:**\n",
    "1. Query CrossRef for each guideline DOI\n",
    "2. Extract reference PMIDs from citations\n",
    "3. Filter to journal articles only\n",
    "4. Deduplicate citation pairs\n",
    "5. Save citation network\n",
    "\n",
    "**Note:** One guideline can cite many references = many rows per guideline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1eacdf9-5626-4ada-bb0c-cd15a7d3d8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Phase 2 Configuration complete\n",
      "  Output folder: output\n",
      "  Will read: output\\phase1_pubmed_guidelines.csv\n",
      "  Will create: output\\phase2_crossref_guidelines_and_references_with_dups_no_PMID_enrichment.csv\n",
      "  Will create: output\\phase2_crossref_guidelines_and_references.csv\n",
      "  Will create: output\\phase2_crossref_guidelines_WITHOUT_references.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 2: Step 1 - Configuration & Setup\n",
    "# ============================================================================\n",
    "# Purpose: Ensure configuration is consistent with Phase 1\n",
    "# Run this: ONCE at the start of Phase 2\n",
    "# Re-run if: You need to verify configuration\n",
    "\n",
    "OUTPUT_FOLDER = 'output'\n",
    "# This should be the SAME as Phase 1 so all outputs are together\n",
    "# ========================================\n",
    "\n",
    "# Verify output folder exists\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "print(f\"✓ Phase 2 Configuration complete\")\n",
    "print(f\"  Output folder: {OUTPUT_FOLDER}\")\n",
    "print(f\"  Will read: {os.path.join(OUTPUT_FOLDER, 'phase1_pubmed_guidelines.csv')}\")\n",
    "print(f\"  Will create: {os.path.join(OUTPUT_FOLDER, 'phase2_crossref_guidelines_and_references_with_dups_no_PMID_enrichment.csv')}\")\n",
    "print(f\"  Will create: {os.path.join(OUTPUT_FOLDER, 'phase2_crossref_guidelines_and_references.csv')}\")\n",
    "print(f\"  Will create: {os.path.join(OUTPUT_FOLDER, 'phase2_crossref_guidelines_WITHOUT_references.csv')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b8868d3-202c-4677-8486-31a47399d6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint system imported\n",
      "✓ Entrez configured for PMID lookup\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 2: Step 2 - Import Checkpoint System & Helper Functions\n",
    "# ============================================================================\n",
    "# Purpose: Set up checkpoint system and define utility functions\n",
    "# Run this: ONCE after Step 1\n",
    "# Re-run if: You modify any functions\n",
    "\n",
    "# Import normalized checkpoint system\n",
    "from normalized_checkpoint_system import (\n",
    "    save_phase2_checkpoint,\n",
    "    load_phase2_checkpoint\n",
    ")\n",
    "\n",
    "# Configure Entrez (for PMID enrichment in Step 4)\n",
    "Entrez.email = ENTREZ_EMAIL\n",
    "Entrez.api_key = ENTREZ_API_KEY\n",
    "\n",
    "print(\"✓ Checkpoint system imported\")\n",
    "print(\"✓ Entrez configured for PMID lookup\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c835f009-8d89-46ba-86b9-d37d0261ce9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Helper functions defined:\n",
      "  - get_crossref_references()\n",
      "  - lookup_pmid_from_doi()\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 2: Step 3 - Define Helper Functions\n",
    "# ============================================================================\n",
    "# Purpose: Define functions for CrossRef and PMID lookup\n",
    "# Run this: ONCE after Step 2\n",
    "# Re-run if: You modify function logic\n",
    "\n",
    "def get_crossref_references(doi, polite_email=\"karen.gutzman@northwestern.edu\"):\n",
    "    \"\"\"\n",
    "    Fetch references for a given DOI from CrossRef API\n",
    "    Returns list of reference dictionaries or None if error/no refs\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # CrossRef API endpoint\n",
    "        url = f\"https://api.crossref.org/works/{doi}\"\n",
    "        \n",
    "        # Headers for polite pool (faster, more reliable)\n",
    "        headers = {\n",
    "            'User-Agent': f'PythonScript/1.0 (mailto:{polite_email})'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        # Navigate to references\n",
    "        try:\n",
    "            ref_list = data['message'].get('reference', [])\n",
    "        except (KeyError, TypeError):\n",
    "            return None\n",
    "        \n",
    "        if not ref_list:\n",
    "            return None\n",
    "        \n",
    "        references = []\n",
    "        \n",
    "        for i, ref in enumerate(ref_list):\n",
    "            ref_info = {\n",
    "                'ref_number': ref.get('key', i + 1),\n",
    "                'ref_title': ref.get('article-title', None),\n",
    "                'ref_authors': None,  # Will extract below\n",
    "                'ref_year': ref.get('year', None),\n",
    "                'ref_sourcetitle': ref.get('journal-title', None) or ref.get('volume-title', None),\n",
    "                'ref_doi': ref.get('DOI', None),\n",
    "                'ref_pmid': None,  # CrossRef doesn't provide PMIDs directly\n",
    "                'ref_volume': ref.get('volume', None),\n",
    "                'ref_issue': ref.get('issue', None),\n",
    "                'ref_pages': ref.get('first-page', None),\n",
    "                'ref_type': None,\n",
    "                'cited_by_count': None,\n",
    "                'ref_unstructured': ref.get('unstructured', None)  # Full citation string\n",
    "            }\n",
    "            \n",
    "            # Extract authors\n",
    "            try:\n",
    "                author_list = ref.get('author', [])\n",
    "                if author_list:\n",
    "                    author_names = []\n",
    "                    for author in author_list:\n",
    "                        if 'family' in author:\n",
    "                            name = author['family']\n",
    "                            if 'given' in author:\n",
    "                                name = f\"{author['family']}, {author['given']}\"\n",
    "                            author_names.append(name)\n",
    "                    ref_info['ref_authors'] = '; '.join(author_names) if author_names else None\n",
    "            except (AttributeError, TypeError):\n",
    "                pass\n",
    "            \n",
    "            references.append(ref_info)\n",
    "        \n",
    "        return references\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching references for DOI {doi}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for DOI {doi}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def lookup_pmid_from_doi(doi):\n",
    "    \"\"\"\n",
    "    Look up PMID from DOI using PubMed's ID Converter API\n",
    "    This fills in the missing PMIDs from CrossRef\n",
    "    \"\"\"\n",
    "    if not doi:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Search PubMed for the DOI\n",
    "        handle = Entrez.esearch(db=\"pubmed\", term=f\"{doi}[DOI]\", retmax=1)\n",
    "        record = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        \n",
    "        if record['IdList']:\n",
    "            return record['IdList'][0]\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "print(\"✓ Helper functions defined:\")\n",
    "print(\"  - get_crossref_references()\")\n",
    "print(\"  - lookup_pmid_from_doi()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72cf77c0-b067-4846-948b-ce28af99b763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 Loaded Phase 2 checkpoint:\n",
      "   Last guideline index: 69\n",
      "   References collected: 8,877\n",
      "   Timestamp: 2026-01-05T14:21:17.213225\n",
      "\n",
      "\n",
      "✓ Resuming from checkpoint\n",
      "  Already processed: 70 guidelines\n",
      "  References collected: 8,877\n",
      "\n",
      "Extracting references for 75 guidelines using CrossRef...\n",
      "Starting from guideline 70\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3256cfdcb847d3a70242a2b775989d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching references:  93%|#########3| 70/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ PMID 40966736: Retrieved 63 references\n",
      "  ✓ PMID 40526054: Retrieved 121 references\n",
      "  ✓ PMID 40373524: Retrieved 172 references\n",
      "  ✓ PMID 40371484: Retrieved 92 references\n",
      "  ✓ PMID 39782908: Retrieved 53 references\n",
      "\n",
      "======================================================================\n",
      "✓ CROSSREF EXTRACTION COMPLETE\n",
      "======================================================================\n",
      "Total guidelines: 75\n",
      "Guidelines WITH references: 75\n",
      "Guidelines WITHOUT references: 0\n",
      "\n",
      "Total references extracted: 9,378\n",
      "Average per guideline: 125.0\n",
      "References with DOIs: 8,603\n",
      "References with PMIDs: 0\n",
      "\n",
      "Main output: output\\phase2_crossref_guidelines_and_references_with_dups_no_PMID_enrichment.csv\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 2: Step 4 - Extract All CrossRef References (LONG RUNNING TIME)\n",
    "# ============================================================================\n",
    "# Purpose: Extract references from CrossRef for all guidelines\n",
    "# Run this: After Steps 1-3\n",
    "# Re-run if: Interrupted - will resume from last checkpoint\n",
    "# Runtime: ~30-60 minutes (depends on number of guidelines)\n",
    "# Checkpoints saved to: output/checkpoints/phase2_crossref/\n",
    "\n",
    "def extract_all_crossref_references():\n",
    "    \"\"\"\n",
    "    Extract ALL references using CrossRef API (free, complete)\n",
    "    Tracks which guidelines have no reference data\n",
    "    \"\"\"\n",
    "    # Load checkpoint if exists\n",
    "    checkpoint = load_phase2_checkpoint()\n",
    "    \n",
    "    if checkpoint:\n",
    "        all_references = checkpoint['references']\n",
    "        start_idx = checkpoint['last_idx'] + 1\n",
    "        guidelines_without_refs = checkpoint.get('no_refs', [])\n",
    "        print(f\"\\n✓ Resuming from checkpoint\")\n",
    "        print(f\"  Already processed: {start_idx:,} guidelines\")\n",
    "        print(f\"  References collected: {len(all_references):,}\")\n",
    "    else:\n",
    "        all_references = []\n",
    "        start_idx = 0\n",
    "        guidelines_without_refs = []\n",
    "        print(\"\\n✓ Starting fresh (no checkpoint found)\")\n",
    "    \n",
    "    # Read guidelines (using OUTPUT_FOLDER)\n",
    "    guidelines_df = pd.read_csv(os.path.join(OUTPUT_FOLDER, 'phase1_pubmed_guidelines.csv'))\n",
    "    guidelines_df['DOI_clean'] = guidelines_df['DOI'].str.replace('https://doi.org/', '').str.strip()\n",
    "    \n",
    "    print(f\"\\nExtracting references for {len(guidelines_df):,} guidelines using CrossRef...\")\n",
    "    print(f\"Starting from guideline {start_idx:,}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Extract references\n",
    "    try:\n",
    "        for idx, row in tqdm(guidelines_df.iterrows(), \n",
    "                            total=len(guidelines_df), \n",
    "                            initial=start_idx,\n",
    "                            desc=\"Fetching references\"):\n",
    "            \n",
    "            if idx < start_idx:\n",
    "                continue\n",
    "            \n",
    "            guideline_pmid = row['PMID']\n",
    "            guideline_doi = row['DOI_clean']\n",
    "            guideline_title = row.get('ArticleTitle', '')\n",
    "            \n",
    "            if pd.notna(guideline_doi) and guideline_doi:\n",
    "                try:\n",
    "                    # Get references from CrossRef\n",
    "                    references = get_crossref_references(guideline_doi)\n",
    "                    \n",
    "                    if references:\n",
    "                        # Add guideline metadata to each reference\n",
    "                        for ref in references:\n",
    "                            ref['guideline_pmid'] = guideline_pmid\n",
    "                            ref['guideline_doi'] = guideline_doi\n",
    "                            ref['guideline_title'] = guideline_title\n",
    "                        \n",
    "                        all_references.extend(references)\n",
    "                        print(f\"  ✓ PMID {guideline_pmid}: Retrieved {len(references)} references\")\n",
    "                    else:\n",
    "                        # Track guidelines with no references\n",
    "                        guidelines_without_refs.append({\n",
    "                            'pmid': guideline_pmid,\n",
    "                            'doi': guideline_doi,\n",
    "                            'title': guideline_title,\n",
    "                            'reason': 'No references in CrossRef'\n",
    "                        })\n",
    "                        print(f\"  ⚠ PMID {guideline_pmid}: No references found in CrossRef\")\n",
    "                    \n",
    "                    # Save checkpoint every 10 guidelines\n",
    "                    if (idx + 1) % 10 == 0:\n",
    "                        save_phase2_checkpoint(idx, all_references, guidelines_without_refs)\n",
    "                        print(f\"\\n💾 Checkpoint: {len(all_references):,} references, {len(guidelines_without_refs)} without refs\\n\")\n",
    "                    \n",
    "                    # Rate limiting (be polite to CrossRef - 1 request per second)\n",
    "                    time.sleep(1.0)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  ✗ Error processing PMID {guideline_pmid}: {e}\")\n",
    "                    guidelines_without_refs.append({\n",
    "                        'pmid': guideline_pmid,\n",
    "                        'doi': guideline_doi,\n",
    "                        'title': guideline_title,\n",
    "                        'reason': f'Error: {str(e)[:100]}'\n",
    "                    })\n",
    "                    continue\n",
    "            else:\n",
    "                # Track guidelines with no DOI\n",
    "                guidelines_without_refs.append({\n",
    "                    'pmid': guideline_pmid,\n",
    "                    'doi': None,\n",
    "                    'title': guideline_title,\n",
    "                    'reason': 'No DOI available'\n",
    "                })\n",
    "                print(f\"  ⚠ PMID {guideline_pmid}: No DOI available\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n⚠️ Interrupted! Saving checkpoint...\")\n",
    "        save_phase2_checkpoint(idx - 1, all_references, guidelines_without_refs)\n",
    "        print(f\"💾 Progress saved: {len(all_references):,} references\")\n",
    "        print(\"\\nYou can re-run this cell to resume from checkpoint.\")\n",
    "        raise\n",
    "    \n",
    "    # Save results (using OUTPUT_FOLDER)\n",
    "    references_df = pd.DataFrame(all_references)\n",
    "    \n",
    "    # Reorder columns for readability (guideline info first, then reference info)\n",
    "    guideline_cols = ['guideline_pmid', 'guideline_doi', 'guideline_title']\n",
    "    reference_cols = [\n",
    "        'ref_number', \n",
    "        'ref_title', \n",
    "        'ref_authors', \n",
    "        'ref_year', \n",
    "        'ref_sourcetitle',\n",
    "        'ref_doi', \n",
    "        'ref_pmid', \n",
    "        'ref_volume', \n",
    "        'ref_issue', \n",
    "        'ref_pages', \n",
    "        'ref_type', \n",
    "        'ref_cited_by_count', \n",
    "        'ref_unstructured'\n",
    "    ]\n",
    "    \n",
    "    desired_order = guideline_cols + reference_cols\n",
    "    existing_cols = references_df.columns.tolist()\n",
    "    extra_cols = [col for col in existing_cols if col not in desired_order]\n",
    "    final_col_order = [col for col in desired_order if col in existing_cols] + extra_cols\n",
    "    \n",
    "    references_df = references_df[final_col_order]\n",
    "    \n",
    "    references_df.to_csv(\n",
    "        os.path.join(OUTPUT_FOLDER, 'phase2_crossref_guidelines_and_references_with_dups_no_PMID_enrichment.csv'), \n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    # Save list of guidelines without references (using OUTPUT_FOLDER)\n",
    "    if guidelines_without_refs:\n",
    "        no_refs_df = pd.DataFrame(guidelines_without_refs)\n",
    "        no_refs_df.to_csv(os.path.join(OUTPUT_FOLDER, 'phase2_crossref_guidelines_WITHOUT_references.csv'), index=False)\n",
    "    \n",
    "    # Summary report\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"✓ CROSSREF EXTRACTION COMPLETE\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total guidelines: {len(guidelines_df):,}\")\n",
    "    print(f\"Guidelines WITH references: {len(guidelines_df) - len(guidelines_without_refs):,}\")\n",
    "    print(f\"Guidelines WITHOUT references: {len(guidelines_without_refs):,}\")\n",
    "    print(f\"\\nTotal references extracted: {len(references_df):,}\")\n",
    "    print(f\"Average per guideline: {len(references_df) / max(len(guidelines_df) - len(guidelines_without_refs), 1):.1f}\")\n",
    "    print(f\"References with DOIs: {references_df['ref_doi'].notna().sum():,}\")\n",
    "    print(f\"References with PMIDs: {references_df['ref_pmid'].notna().sum():,}\")\n",
    "    \n",
    "    if guidelines_without_refs:\n",
    "        print(f\"\\n⚠ WARNING: {len(guidelines_without_refs)} guidelines have no references\")\n",
    "        print(f\"See details in: {os.path.join(OUTPUT_FOLDER, 'phase2_crossref_guidelines_WITHOUT_references.csv')}\")\n",
    "        print(\"\\nBreakdown by reason:\")\n",
    "        no_refs_df = pd.DataFrame(guidelines_without_refs)\n",
    "        print(no_refs_df['reason'].value_counts())\n",
    "    \n",
    "    print(f\"\\nMain output: {os.path.join(OUTPUT_FOLDER, 'phase2_crossref_guidelines_and_references_with_dups_no_PMID_enrichment.csv')}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return references_df, guidelines_without_refs\n",
    "\n",
    "\n",
    "# Run the extraction\n",
    "references_df, guidelines_without_refs = extract_all_crossref_references()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1f201fa-766c-478c-8a13-5f1cd03b3ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ENRICHING REFERENCES WITH PMIDs (OPTIMIZED)...\n",
      "======================================================================\n",
      "======================================================================\n",
      "PHASE 2: PMID ENRICHMENT (OPTIMIZED)\n",
      "======================================================================\n",
      "\n",
      "Current status:\n",
      "  Total references: 9,378\n",
      "  References with PMIDs: 8,291 (88.4%)\n",
      "\n",
      "References needing PMID lookup: 312\n",
      "Estimated time: ~1.6 minutes (with batching)\n",
      "======================================================================\n",
      "\n",
      "📁 Loaded checkpoint: 7,725 PMIDs already looked up\n",
      "Looking up 309 new DOIs...\n",
      "(Skipping 7,725 already looked up)\n",
      "\n",
      "Processing DOIs 1-309...\n",
      "💾 Checkpoint saved: 7,725 PMIDs looked up\n",
      "\n",
      "======================================================================\n",
      "Applying results to DataFrame...\n",
      "\n",
      "======================================================================\n",
      "✓ PMID ENRICHMENT COMPLETE\n",
      "======================================================================\n",
      "PMIDs before: 8,291\n",
      "PMIDs after: 8,291\n",
      "New PMIDs added: 0\n",
      "Success rate: 0.0%\n",
      "\n",
      "Input:  output\\phase2_crossref_guidelines_and_references_with_dups_no_PMID_enrichment.csv\n",
      "Output: output\\phase2_crossref_guidelines_and_references.csv\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "✓ PHASE 2 COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Final file: output\\phase2_crossref_guidelines_and_references.csv\n",
      "Total references: 9,378\n",
      "References with PMIDs: 8,291\n",
      "\n",
      "✓ Ready for Phase 3 (Clinical Trial Identification)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 2: Step 5 - Enrich References with PMIDs (OPTIMIZED VERSION)\n",
    "# ============================================================================\n",
    "# Purpose: Look up PMIDs for references that have DOIs\n",
    "# Optimizations: Checkpointing, batch processing, resume capability\n",
    "# Runtime: ~5-15 minutes (was 10-30 minutes)\n",
    "\n",
    "# ============================================================================\n",
    "# CHECKPOINT FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def save_pmid_checkpoint(pmid_map, checkpoint_file):\n",
    "    \"\"\"Save PMID lookup progress to checkpoint file\"\"\"\n",
    "    with open(checkpoint_file, 'w') as f:\n",
    "        json.dump(pmid_map, f)\n",
    "    print(f\"💾 Checkpoint saved: {len(pmid_map):,} PMIDs looked up\")\n",
    "\n",
    "def load_pmid_checkpoint(checkpoint_file):\n",
    "    \"\"\"Load PMID lookup progress from checkpoint file\"\"\"\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        with open(checkpoint_file, 'r') as f:\n",
    "            pmid_map = json.load(f)\n",
    "        print(f\"📁 Loaded checkpoint: {len(pmid_map):,} PMIDs already looked up\")\n",
    "        return pmid_map\n",
    "    return {}\n",
    "\n",
    "# ============================================================================\n",
    "# BATCH PMID LOOKUP (FASTER!)\n",
    "# ============================================================================\n",
    "\n",
    "def lookup_pmids_batch(dois, batch_size=200):\n",
    "    \"\"\"\n",
    "    Look up PMIDs for multiple DOIs at once using PubMed's batch capability\n",
    "    This is MUCH faster than one-by-one lookups!\n",
    "    \"\"\"\n",
    "    pmid_map = {}\n",
    "    \n",
    "    for i in range(0, len(dois), batch_size):\n",
    "        batch_dois = dois[i:i+batch_size]\n",
    "        \n",
    "        try:\n",
    "            # Create search query with OR between DOIs\n",
    "            query = ' OR '.join([f'\"{doi}\"[ref_doi]' for doi in batch_dois])\n",
    "            \n",
    "            # Search PubMed\n",
    "            handle = Entrez.esearch(\n",
    "                db=\"pubmed\",\n",
    "                term=query,\n",
    "                retmax=batch_size,\n",
    "                retmode=\"xml\"\n",
    "            )\n",
    "            record = Entrez.read(handle)\n",
    "            handle.close()\n",
    "            \n",
    "            pmids = record.get(\"IdList\", [])\n",
    "            \n",
    "            # Now fetch details to match DOIs to PMIDs\n",
    "            if pmids:\n",
    "                fetch_handle = Entrez.efetch(\n",
    "                    db=\"pubmed\",\n",
    "                    id=','.join(pmids),\n",
    "                    rettype=\"medline\",\n",
    "                    retmode=\"text\"\n",
    "                )\n",
    "                fetch_result = fetch_handle.read()\n",
    "                fetch_handle.close()\n",
    "                \n",
    "                # Parse MEDLINE format to extract DOI-PMID pairs\n",
    "                current_pmid = None\n",
    "                for line in fetch_result.split('\\n'):\n",
    "                    if line.startswith('PMID- '):\n",
    "                        current_pmid = line.replace('PMID- ', '').strip()\n",
    "                    elif line.startswith('AID - ') and '[doi]' in line.lower():\n",
    "                        doi = line.split('[doi]')[0].replace('AID - ', '').strip()\n",
    "                        if doi in batch_dois and current_pmid:\n",
    "                            pmid_map[doi] = int(current_pmid)\n",
    "            \n",
    "            # Rate limiting\n",
    "            time.sleep(0.34)  # PubMed rate limit\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠️ Batch lookup error: {e}\")\n",
    "            # Fall back to individual lookups for this batch\n",
    "            for doi in batch_dois:\n",
    "                pmid = lookup_pmid_from_doi(doi)\n",
    "                if pmid:\n",
    "                    pmid_map[doi] = pmid\n",
    "                time.sleep(0.11)\n",
    "    \n",
    "    return pmid_map\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN ENRICHMENT FUNCTION \n",
    "# ============================================================================\n",
    "\n",
    "def enrich_references_with_pmids_optimized(checkpoint_interval=500):\n",
    "    \"\"\"\n",
    "    Look up PMIDs for references that have DOIs\n",
    "    OPTIMIZED with checkpointing and batch processing\n",
    "    \"\"\"\n",
    "    \n",
    "    # Setup checkpoint directory\n",
    "    checkpoint_dir = os.path.join(OUTPUT_FOLDER, 'checkpoints', 'phase2_pmid_enrichment')\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_file = os.path.join(checkpoint_dir, 'pmid_lookup_progress.json')\n",
    "\n",
    "    #Define separate INPUT and OUTPUT files\n",
    "    input_file = os.path.join(OUTPUT_FOLDER, 'phase2_crossref_guidelines_and_references_with_dups_no_PMID_enrichment.csv')\n",
    "    output_file = os.path.join(OUTPUT_FOLDER, 'phase2_crossref_guidelines_and_references.csv')\n",
    "    \n",
    "    # Read CrossRef references\n",
    "    df = pd.read_csv(input_file) \n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"PHASE 2: PMID ENRICHMENT (OPTIMIZED)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # CHECK: Skip if already done\n",
    "    current_pmids = df['ref_pmid'].notna().sum()\n",
    "    total_refs = len(df)\n",
    "    pmid_coverage = (current_pmids / total_refs * 100) if total_refs > 0 else 0\n",
    "    \n",
    "    print(f\"\\nCurrent status:\")\n",
    "    print(f\"  Total references: {total_refs:,}\")\n",
    "    print(f\"  References with PMIDs: {current_pmids:,} ({pmid_coverage:.1f}%)\")\n",
    "    \n",
    "    # If coverage is already high, offer to skip\n",
    "    if pmid_coverage > 95:\n",
    "        print(f\"\\n✓ PMID coverage already high ({pmid_coverage:.1f}%)\")\n",
    "        print(\"Skipping enrichment step (already complete)\")\n",
    "        return df\n",
    "    \n",
    "    # Filter to references that need PMIDs\n",
    "    needs_pmid = df[(df['ref_doi'].notna()) & (df['ref_pmid'].isna())].copy()\n",
    "    \n",
    "    if len(needs_pmid) == 0:\n",
    "        print(\"\\n✓ No references need PMID lookup\")\n",
    "        return df\n",
    "    \n",
    "    print(f\"\\nReferences needing PMID lookup: {len(needs_pmid):,}\")\n",
    "    print(f\"Estimated time: ~{len(needs_pmid) * 0.005:.1f} minutes (with batching)\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Load checkpoint if exists\n",
    "    pmid_map = load_pmid_checkpoint(checkpoint_file)\n",
    "    \n",
    "    # Get DOIs that still need lookup\n",
    "    already_looked_up = set(pmid_map.keys())\n",
    "    dois_to_lookup = [doi for doi in needs_pmid['ref_doi'].unique() \n",
    "                      if doi not in already_looked_up]\n",
    "    \n",
    "    if len(dois_to_lookup) == 0:\n",
    "        print(\"✓ All DOIs already looked up (using checkpoint)\")\n",
    "    else:\n",
    "        print(f\"Looking up {len(dois_to_lookup):,} new DOIs...\")\n",
    "        print(f\"(Skipping {len(already_looked_up):,} already looked up)\\n\")\n",
    "        \n",
    "        # Process in chunks with checkpointing\n",
    "        for i in range(0, len(dois_to_lookup), checkpoint_interval):\n",
    "            chunk = dois_to_lookup[i:i+checkpoint_interval]\n",
    "            \n",
    "            print(f\"Processing DOIs {i+1:,}-{min(i+checkpoint_interval, len(dois_to_lookup)):,}...\")\n",
    "            \n",
    "            # Batch lookup\n",
    "            chunk_results = lookup_pmids_batch(chunk, batch_size=200)\n",
    "            pmid_map.update(chunk_results)\n",
    "            \n",
    "            # Save checkpoint\n",
    "            save_pmid_checkpoint(pmid_map, checkpoint_file)\n",
    "    \n",
    "    # Update DataFrame with all results\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"Applying results to DataFrame...\")\n",
    "    \n",
    "    # Convert DOIs to PMIDs\n",
    "    doi_to_pmid = {k: v for k, v in pmid_map.items() if v is not None}\n",
    "    df.loc[df['ref_doi'].isin(doi_to_pmid.keys()), 'ref_pmid'] = df['ref_doi'].map(doi_to_pmid)\n",
    "    \n",
    "    # Save enriched version\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Final statistics\n",
    "    final_pmids = df['ref_pmid'].notna().sum()\n",
    "    new_pmids = final_pmids - current_pmids\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"✓ PMID ENRICHMENT COMPLETE\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"PMIDs before: {current_pmids:,}\")\n",
    "    print(f\"PMIDs after: {final_pmids:,}\")\n",
    "    print(f\"New PMIDs added: {new_pmids:,}\")\n",
    "    print(f\"Success rate: {(new_pmids / len(needs_pmid) * 100):.1f}%\")\n",
    "    print(f\"\\nInput:  {input_file}\")   # ✅ Show both files\n",
    "    print(f\"Output: {output_file}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ============================================================================\n",
    "# RUN ENRICHMENT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ENRICHING REFERENCES WITH PMIDs (OPTIMIZED)...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "references_df = enrich_references_with_pmids_optimized()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ PHASE 2 COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nFinal file: {os.path.join(OUTPUT_FOLDER, 'phase2_crossref_guidelines_and_references.csv')}\")\n",
    "print(f\"Total references: {len(references_df):,}\")\n",
    "print(f\"References with PMIDs: {references_df['ref_pmid'].notna().sum():,}\")\n",
    "print(f\"\\n✓ Ready for Phase 3 (Clinical Trial Identification)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe8434a1-80ed-4b40-a9c9-8c48003978e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SOPHISTICATED DEDUPLICATION: Phase 2\n",
      "======================================================================\n",
      "\n",
      "Loaded Phase 2 data from: output\\phase2_crossref_guidelines_and_references.csv\n",
      "Starting rows: 9,378\n",
      "\n",
      "Separated data:\n",
      "  Citations WITH PMID: 8,291\n",
      "  Citations WITHOUT PMID: 1,087\n",
      "\n",
      "======================================================================\n",
      "DEDUPLICATING GUIDELINE-REFERENCE CITATIONS WITH PMIDs\n",
      "======================================================================\n",
      "\n",
      "Before dedup, Guideline-ref_pmid pair: 8,291 rows\n",
      "Duplicate (guideline-ref_pmid) pairs: 231\n",
      "\n",
      "Example duplicates being removed:\n",
      "  Guideline 33081524, Ref PMID 24084923.0: 2 copies (keeping 1)\n",
      "\n",
      "After dedup: 8,149 rows\n",
      "Removed: 231 duplicate pairs\n",
      "✓ Preserved all unique (guideline, PMID) linkages\n",
      "\n",
      "======================================================================\n",
      "DEDUPLICATING CITATIONS WITHOUT PMIDs\n",
      "======================================================================\n",
      "\n",
      "Strategy: Use DOI or title to identify unique references\n",
      "  → Different refs without PMID will be preserved\n",
      "\n",
      "Before dedup: 1,087 rows\n",
      "Duplicate (guideline, reference_key) pairs: 50\n",
      "\n",
      "Example duplicates being removed:\n",
      "  Guideline 33070654, Ref key 'unstructured:deleted in proof.': 2 copies (keeping 1)\n",
      "\n",
      "After dedup: 1,055 rows\n",
      "Removed: 50 duplicate pairs\n",
      "✓ Preserved citations with different DOIs/titles\n",
      "\n",
      "======================================================================\n",
      "COMBINING DEDUPLICATED DATA\n",
      "======================================================================\n",
      "\n",
      "Final combined data: 9,204 rows\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: Checking Guideline-Reference Linkages\n",
      "======================================================================\n",
      "\n",
      "Checking linkage preservation:\n",
      "  Citations with PMID:\n",
      "    Original unique linkages: 8,149\n",
      "    After dedup linkages: 8,149\n",
      "    Linkages lost: 0\n",
      "    ✅ All unique linkages preserved!\n",
      "\n",
      "  References cited by multiple guidelines:\n",
      "    Before: 329 refs cited by 2+ guidelines\n",
      "    After: 329 refs cited by 2+ guidelines\n",
      "    ✅ All cross-guideline citations preserved!\n",
      "\n",
      "======================================================================\n",
      "DEDUPLICATION COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Summary:\n",
      "  Starting rows: 9,378\n",
      "  Final rows: 9,204\n",
      "  Rows removed: 174 (1.9%)\n",
      "\n",
      "What was removed:\n",
      "  ✓ 231 duplicate (guideline, PMID) pairs\n",
      "  ✓ 50 duplicate (guideline, DOI/title) pairs\n",
      "\n",
      "What was preserved:\n",
      "  ✓ All unique (guideline, reference) linkages\n",
      "  ✓ All references cited by multiple guidelines\n",
      "  ✓ All different references (even without PMIDs)\n",
      "\n",
      "✓ Ready to save clean Phase 2 data\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "REORDERING COLUMNS FOR READABILITY\n",
      "======================================================================\n",
      "\n",
      "✓ Reordered columns:\n",
      "  Guideline columns first: 3\n",
      "  Reference columns next: 12\n",
      "  Additional columns: 1 (cited_by_count)\n",
      "\n",
      "✓ Saved deduplicated Phase 2 to: output\\phase2_crossref_guidelines_and_references.csv\n",
      "  Total rows: 9,204\n",
      "  Column order: Guideline info → Reference info → Other\n",
      "  Ready for Phase 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 2 Step 6: DEDUPLICATION by Guideline-Reference pair\n",
    "# ============================================================================\n",
    "# Purpose: Remove duplicate (guideline, reference) pairs while preserving:\n",
    "#   - All unique guideline-reference linkages\n",
    "#   - References cited by multiple guidelines\n",
    "#   - Different references that lack PMIDs\n",
    "# Strategy:\n",
    "#   1. Refs WITH PMIDs: Deduplicate on (guideline, PMID)\n",
    "#   2. Refs WITHOUT PMIDs: Deduplicate on (guideline, DOI/title)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SOPHISTICATED DEDUPLICATION: Phase 2\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 0: Load Phase 2 data (from previous step or from file)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Option 1: If you just ran Phase 2 Step 5 and have the df in memory\n",
    "# Uncomment and use the actual variable name from your Step 5:\n",
    "# phase2_citations_df = your_phase2_step5_dataframe.copy()\n",
    "\n",
    "# Option 2: Load from file\n",
    "phase2_file = os.path.join(OUTPUT_FOLDER, 'phase2_crossref_guidelines_and_references.csv')\n",
    "phase2_citations_df = pd.read_csv(phase2_file)\n",
    "\n",
    "print(f\"Loaded Phase 2 data from: {phase2_file}\")\n",
    "print(f\"Starting rows: {len(phase2_citations_df):,}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 1: Separate refs WITH and WITHOUT PMIDs\n",
    "# -----------------------------------------------------------------------------\n",
    "citations_with_pmid = phase2_citations_df[phase2_citations_df['ref_pmid'].notna()].copy()\n",
    "citations_without_pmid = phase2_citations_df[phase2_citations_df['ref_pmid'].isna()].copy()\n",
    "\n",
    "print(f\"\\nSeparated data:\")\n",
    "print(f\"  Citations WITH PMID: {len(citations_with_pmid):,}\")\n",
    "print(f\"  Citations WITHOUT PMID: {len(citations_without_pmid):,}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 2: Deduplicate citations WITH PMIDs (on guideline + PMID)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"DEDUPLICATING GUIDELINE-REFERENCE CITATIONS WITH PMIDs\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "duplicates_with_pmid_count = citations_with_pmid.duplicated(\n",
    "    subset=['guideline_pmid', 'ref_pmid'], \n",
    "    keep=False\n",
    ").sum()\n",
    "\n",
    "print(f\"\\nBefore dedup, Guideline-ref_pmid pair: {len(citations_with_pmid):,} rows\")\n",
    "print(f\"Duplicate (guideline-ref_pmid) pairs: {duplicates_with_pmid_count:,}\")\n",
    "\n",
    "if duplicates_with_pmid_count > 0:\n",
    "    # Show examples of what's being removed\n",
    "    duplicate_examples = citations_with_pmid[\n",
    "        citations_with_pmid.duplicated(subset=['guideline_pmid', 'ref_pmid'], keep=False)\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nExample duplicates being removed:\")\n",
    "    for (guideline_id, ref_id), citation_group in duplicate_examples.groupby(['guideline_pmid', 'ref_pmid']):\n",
    "        if len(citation_group) > 1:\n",
    "            print(f\"  Guideline {guideline_id}, Ref PMID {ref_id}: {len(citation_group)} copies (keeping 1)\")\n",
    "            # Show first 3 examples\n",
    "            if duplicate_examples.groupby(['guideline_pmid', 'ref_pmid']).ngroups >= 3:\n",
    "                break\n",
    "    \n",
    "    # Deduplicate\n",
    "    citations_with_pmid_deduped = citations_with_pmid.drop_duplicates(\n",
    "        subset=['guideline_pmid', 'ref_pmid'],\n",
    "        keep='first'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nAfter dedup: {len(citations_with_pmid_deduped):,} rows\")\n",
    "    print(f\"Removed: {duplicates_with_pmid_count:,} duplicate pairs\")\n",
    "    print(f\"✓ Preserved all unique (guideline, PMID) linkages\")\n",
    "else:\n",
    "    citations_with_pmid_deduped = citations_with_pmid\n",
    "    print(f\"✓ No duplicates found\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 3: Deduplicate citations WITHOUT PMIDs (on guideline + DOI/title)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"DEDUPLICATING CITATIONS WITHOUT PMIDs\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(f\"\\nStrategy: Use DOI or title to identify unique references\")\n",
    "print(f\"  → Different refs without PMID will be preserved\")\n",
    "\n",
    "# Create a composite key for refs without PMID\n",
    "def create_reference_key(row):\n",
    "    \"\"\"\n",
    "    Create unique key for references without PMID.\n",
    "    Priority: DOI > title > row hash\n",
    "    \"\"\"\n",
    "    if pd.notna(row['ref_doi']) and str(row['ref_doi']).strip() != '':\n",
    "        return f\"doi:{str(row['ref_doi']).strip()}\"\n",
    "    elif pd.notna(row['ref_title']) and str(row['ref_title']).strip() != '':\n",
    "        # Use first 100 chars of normalized title\n",
    "        title_normalized = str(row['ref_title'])[:100].lower().strip()\n",
    "        return f\"title:{title_normalized}\"\n",
    "    else:\n",
    "        # No DOI or title - use unstructured citation if available\n",
    "        if pd.notna(row.get('ref_unstructured')) and str(row.get('ref_unstructured')).strip() != '':\n",
    "            unstructured_normalized = str(row['ref_unstructured'])[:100].lower().strip()\n",
    "            return f\"unstructured:{unstructured_normalized}\"\n",
    "        else:\n",
    "            # Last resort: create hash of row contents\n",
    "            return f\"hash:{hash(tuple(row.values))}\"\n",
    "\n",
    "citations_without_pmid['reference_key'] = citations_without_pmid.apply(create_reference_key, axis=1)\n",
    "\n",
    "duplicates_without_pmid_count = citations_without_pmid.duplicated(\n",
    "    subset=['guideline_pmid', 'reference_key'], \n",
    "    keep=False\n",
    ").sum()\n",
    "\n",
    "print(f\"\\nBefore dedup: {len(citations_without_pmid):,} rows\")\n",
    "print(f\"Duplicate (guideline, reference_key) pairs: {duplicates_without_pmid_count:,}\")\n",
    "\n",
    "if duplicates_without_pmid_count > 0:\n",
    "    # Show what's being deduplicated\n",
    "    duplicate_examples = citations_without_pmid[\n",
    "        citations_without_pmid.duplicated(subset=['guideline_pmid', 'reference_key'], keep=False)\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nExample duplicates being removed:\")\n",
    "    for (guideline_id, ref_key), citation_group in duplicate_examples.groupby(['guideline_pmid', 'reference_key']):\n",
    "        if len(citation_group) > 1:\n",
    "            key_display = ref_key[:60] + \"...\" if len(ref_key) > 60 else ref_key\n",
    "            print(f\"  Guideline {guideline_id}, Ref key '{key_display}': {len(citation_group)} copies (keeping 1)\")\n",
    "            if duplicate_examples.groupby(['guideline_pmid', 'reference_key']).ngroups >= 3:\n",
    "                break\n",
    "    \n",
    "    # Deduplicate on composite key\n",
    "    citations_without_pmid_deduped = citations_without_pmid.drop_duplicates(\n",
    "        subset=['guideline_pmid', 'reference_key'],\n",
    "        keep='first'\n",
    "    )\n",
    "    \n",
    "    # Drop the temporary reference_key column\n",
    "    citations_without_pmid_deduped = citations_without_pmid_deduped.drop(columns=['reference_key'])\n",
    "    \n",
    "    print(f\"\\nAfter dedup: {len(citations_without_pmid_deduped):,} rows\")\n",
    "    print(f\"Removed: {duplicates_without_pmid_count:,} duplicate pairs\")\n",
    "    print(f\"✓ Preserved citations with different DOIs/titles\")\n",
    "else:\n",
    "    citations_without_pmid_deduped = citations_without_pmid.drop(columns=['reference_key'])\n",
    "    print(f\"✓ No duplicates found\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 4: Combine back together\n",
    "# -----------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"COMBINING DEDUPLICATED DATA\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "phase2_citations_deduped = pd.concat(\n",
    "    [citations_with_pmid_deduped, citations_without_pmid_deduped], \n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "print(f\"Final combined data: {len(phase2_citations_deduped):,} rows\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 5: VERIFY no unique linkages were lost\n",
    "# -----------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"VERIFICATION: Checking Guideline-Reference Linkages\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "print(\"Checking linkage preservation:\")\n",
    "\n",
    "# Refs with PMID\n",
    "original_pmid_linkages = citations_with_pmid.groupby(['guideline_pmid', 'ref_pmid']).size()\n",
    "deduped_pmid_linkages = citations_with_pmid_deduped.groupby(['guideline_pmid', 'ref_pmid']).size()\n",
    "\n",
    "print(f\"  Citations with PMID:\")\n",
    "print(f\"    Original unique linkages: {len(original_pmid_linkages):,}\")\n",
    "print(f\"    After dedup linkages: {len(deduped_pmid_linkages):,}\")\n",
    "print(f\"    Linkages lost: {len(original_pmid_linkages) - len(deduped_pmid_linkages)}\")\n",
    "\n",
    "if len(original_pmid_linkages) == len(deduped_pmid_linkages):\n",
    "    print(f\"    ✅ All unique linkages preserved!\")\n",
    "else:\n",
    "    print(f\"    ⚠️ Some linkages lost (this should be 0!)\")\n",
    "\n",
    "# Check different guidelines citing same reference\n",
    "shared_refs_before = (original_pmid_linkages.groupby(level='ref_pmid').size() > 1).sum()\n",
    "shared_refs_after = (deduped_pmid_linkages.groupby(level='ref_pmid').size() > 1).sum()\n",
    "\n",
    "print(f\"\\n  References cited by multiple guidelines:\")\n",
    "print(f\"    Before: {shared_refs_before:,} refs cited by 2+ guidelines\")\n",
    "print(f\"    After: {shared_refs_after:,} refs cited by 2+ guidelines\")\n",
    "\n",
    "if shared_refs_before == shared_refs_after:\n",
    "    print(f\"    ✅ All cross-guideline citations preserved!\")\n",
    "else:\n",
    "    print(f\"    ⚠️ Lost some cross-guideline citations!\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 6: Summary statistics\n",
    "# -----------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"DEDUPLICATION COMPLETE\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "original_count = len(phase2_citations_df)\n",
    "final_count = len(phase2_citations_deduped)\n",
    "removed_count = original_count - final_count\n",
    "\n",
    "print(f\"Summary:\")\n",
    "print(f\"  Starting rows: {original_count:,}\")\n",
    "print(f\"  Final rows: {final_count:,}\")\n",
    "print(f\"  Rows removed: {removed_count:,} ({removed_count/original_count*100:.1f}%)\")\n",
    "print(f\"\\nWhat was removed:\")\n",
    "print(f\"  ✓ {duplicates_with_pmid_count:,} duplicate (guideline, PMID) pairs\")\n",
    "print(f\"  ✓ {duplicates_without_pmid_count:,} duplicate (guideline, DOI/title) pairs\")\n",
    "print(f\"\\nWhat was preserved:\")\n",
    "print(f\"  ✓ All unique (guideline, reference) linkages\")\n",
    "print(f\"  ✓ All references cited by multiple guidelines\")\n",
    "print(f\"  ✓ All different references (even without PMIDs)\")\n",
    "\n",
    "print(f\"\\n✓ Ready to save clean Phase 2 data\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 7: Reorder columns for readability & Save deduplicated data\n",
    "# -----------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"REORDERING COLUMNS FOR READABILITY\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Define desired column order\n",
    "guideline_cols = [\n",
    "    'guideline_pmid',\n",
    "    'guideline_doi', \n",
    "    'guideline_title'\n",
    "]\n",
    "\n",
    "reference_cols = [\n",
    "    'ref_number',\n",
    "    'ref_title',\n",
    "    'ref_authors',\n",
    "    'ref_year',\n",
    "    'ref_sourcetitle',\n",
    "    'ref_doi',\n",
    "    'ref_pmid',\n",
    "    'ref_volume',\n",
    "    'ref_issue',\n",
    "    'ref_pages',\n",
    "    'ref_type',\n",
    "    'ref_cited_by_count',\n",
    "    'ref_unstructured'\n",
    "]\n",
    "\n",
    "# Combine in desired order\n",
    "desired_order = guideline_cols + reference_cols\n",
    "\n",
    "# Get any extra columns that weren't in our lists (preserve them at the end)\n",
    "existing_cols = phase2_citations_deduped.columns.tolist()\n",
    "extra_cols = [col for col in existing_cols if col not in desired_order]\n",
    "\n",
    "# Build final column order (prioritized + extras)\n",
    "final_col_order = [col for col in desired_order if col in existing_cols] + extra_cols\n",
    "\n",
    "# Reorder\n",
    "phase2_citations_deduped = phase2_citations_deduped[final_col_order]\n",
    "\n",
    "print(f\"✓ Reordered columns:\")\n",
    "print(f\"  Guideline columns first: {len([c for c in guideline_cols if c in existing_cols])}\")\n",
    "print(f\"  Reference columns next: {len([c for c in reference_cols if c in existing_cols])}\")\n",
    "if extra_cols:\n",
    "    print(f\"  Additional columns: {len(extra_cols)} ({', '.join(extra_cols[:3])}{'...' if len(extra_cols) > 3 else ''})\")\n",
    "print()\n",
    "\n",
    "# Save deduplicated data with reordered columns\n",
    "output_file = os.path.join(OUTPUT_FOLDER, 'phase2_crossref_guidelines_and_references.csv')\n",
    "phase2_citations_deduped.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✓ Saved deduplicated Phase 2 to: {output_file}\")\n",
    "print(f\"  Total rows: {len(phase2_citations_deduped):,}\")\n",
    "print(f\"  Column order: Guideline info → Reference info → Other\")\n",
    "print(f\"  Ready for Phase 3\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8de24dc-954d-4ae1-bbe1-eaba75b1ba4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL PHASE 2 FILE CHECK:\n",
      "Total rows: 9,204\n",
      "✅ 0 duplicates - FILE IS CLEAN\n"
     ]
    }
   ],
   "source": [
    "# Final verification\n",
    "phase2_df = pd.read_csv(os.path.join(OUTPUT_FOLDER, 'phase2_crossref_guidelines_and_references.csv'))\n",
    "\n",
    "print(\"FINAL PHASE 2 FILE CHECK:\")\n",
    "print(f\"Total rows: {len(phase2_df):,}\")\n",
    "\n",
    "dups = phase2_df[phase2_df['ref_pmid'].notna()].duplicated(\n",
    "    subset=['guideline_pmid', 'ref_pmid'], keep=False\n",
    ").sum()\n",
    "\n",
    "if dups == 0:\n",
    "    print(f\"✅ {dups:,} duplicates - FILE IS CLEAN\")\n",
    "else:\n",
    "    print(f\"❌ {dups:,} duplicates - STEP 6 DIDN'T WORK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7effe87d-0192-4589-a39b-96e143e3bb20",
   "metadata": {},
   "source": [
    "# Phase 3: Identify References that are Clinical Trials\n",
    "\n",
    "**Input:** `phase2_crossref_guidelines_and_references.csv` (all citations)  \n",
    "**Output:** `phase3_references_with_trials.csv` (~8,148 citations + trial flags)\n",
    "\n",
    "**What this does:**\n",
    "- Checks each reference and records if it is a clinical trial publication type from MeSH\n",
    "- Reviews each references and extracts trial registry IDs from these fields:\n",
    "    1. SecondarySourceID - PubMed curated (MOST AUTHORITATIVE)\n",
    "    2. DataBankList - Explicit registry links\n",
    "    3. Abstract - Text extraction (LEAST RELIABLE)\n",
    "- Store both PRIMARY NCT and ALL NCTs found (order-preserving)\n",
    "- Preserves citation structure (which guideline cited which trial)\n",
    "\n",
    "**Key steps:**\n",
    "1. Load all citation pairs from Phase 2\n",
    "2. For each unique reference PMID:\n",
    "   - Query PubMed for publication type\n",
    "   - Check if publication type = \"Clinical Trial\"\n",
    "   - Extract NCT numbers from relevant fields\n",
    "3. Merge trial data back to ALL citations\n",
    "4. Save citation-level data with trial flags\n",
    "\n",
    "**Critical:** Maintains citation structure - each (guideline, reference) pair = one row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52c1fe50-7849-4c75-997b-7bebd3f542ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Phase 3 Configuration complete\n",
      "  Output folder: output\n",
      "  Will read: output\\phase2_crossref_guidelines_and_references.csv\n",
      "  Will create: output\\phase3_missing_pmids.csv ((pmids that are not able to be found in PubMed)\n",
      "  Will create: output\\phase3_references_with_trials.csv (PMID-level: one row per ref_pmid)\n",
      "  Will create: output\\phase3_pmid_nct_pairs.csv(PMID-NCT pairs: exploded for multi-NCT analysis)\n",
      "  Will create: output\\ phase3_extra_nct_audit.csv ((audit trail for extra NCTs beyond primary)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 3: Step 1 - Configuration & Setup\n",
    "# ============================================================================\n",
    "# Purpose: Ensure configuration is consistent with Phase 1 & 2\n",
    "# Run this: ONCE at the start of Phase 3\n",
    "# Re-run if: You need to verify configuration\n",
    "\n",
    "UTPUT_FOLDER = 'output'\n",
    "# This should be the SAME as Phase 1 & 2 so all outputs are together\n",
    "# ========================================\n",
    "\n",
    "# Verify output folder exists\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "print(f\"✓ Phase 3 Configuration complete\")\n",
    "print(f\"  Output folder: {OUTPUT_FOLDER}\")\n",
    "print(f\"  Will read: {os.path.join(OUTPUT_FOLDER, 'phase2_crossref_guidelines_and_references.csv')}\")\n",
    "print(f\"  Will create: {os.path.join(OUTPUT_FOLDER, 'phase3_missing_pmids.csv')} ((pmids that are not able to be found in PubMed)\")\n",
    "print(f\"  Will create: {os.path.join(OUTPUT_FOLDER, 'phase3_references_with_trials.csv')} (PMID-level: one row per ref_pmid)\")\n",
    "print(f\"  Will create: {os.path.join(OUTPUT_FOLDER, 'phase3_pmid_nct_pairs.csv')}(PMID-NCT pairs: exploded for multi-NCT analysis)\")\n",
    "\n",
    "print(f\"  Will create: {os.path.join(OUTPUT_FOLDER, ' phase3_extra_nct_audit.csv')} ((audit trail for extra NCTs beyond primary)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62072bc5-7319-4bb6-b75c-35ea60351479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint system imported\n",
      "  Checkpoint interval: 50 references\n",
      "✓ Entrez configured\n",
      "  Email: karen.gutzman@gmail.com\n",
      "  API Key: ********************07b08\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 3: Step 2 - Import Checkpoint System & Configure Entrez\n",
    "# ============================================================================\n",
    "# Purpose: Set up checkpoint system and configure PubMed API\n",
    "# Run this: ONCE after Step 1\n",
    "# Re-run if: Checkpoint system is updated\n",
    "\n",
    "# Import normalized checkpoint system\n",
    "from normalized_checkpoint_system import (\n",
    "    save_phase3_checkpoint,\n",
    "    load_phase3_checkpoint,\n",
    "    CHECKPOINT_INTERVAL\n",
    ")\n",
    "\n",
    "# Configure Entrez\n",
    "Entrez.email = ENTREZ_EMAIL\n",
    "Entrez.api_key = ENTREZ_API_KEY\n",
    "\n",
    "print(\"✓ Checkpoint system imported\")\n",
    "print(f\"  Checkpoint interval: {CHECKPOINT_INTERVAL} references\")\n",
    "print(f\"✓ Entrez configured\")\n",
    "print(f\"  Email: {Entrez.email}\")\n",
    "print(f\"  API Key: {'*' * 20}{Entrez.api_key[-5:]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e0ff973-ed44-4405-88f1-ba65ce36e926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PHASE 3: STEP 4 - IDENTIFY CLINICAL TRIALS (BATCH OPTIMIZED)\n",
      "======================================================================\n",
      "\n",
      "STEP 4.1 — Configuration\n",
      "======================================================================\n",
      "BATCH_SIZE: 200\n",
      "SLEEP_PER_BATCH: 0.34 seconds\n",
      "CHECKPOINT_INTERVAL: Every 500 rows\n",
      "Trial keyword phrases: 9 loaded\n",
      "✓ Configuration complete\n",
      "\n",
      "STEP 4.2 — Loading Helper Functions\n",
      "======================================================================\n",
      "✓ Helper functions loaded:\n",
      "\n",
      "STEP 4.3 — Loading Core Extraction Function\n",
      "======================================================================\n",
      "✓ extract_trial_info() defined\n",
      "  Extracts from 3 sources with priority: SecondarySourceID > DataBankList > Abstract\n",
      "\n",
      "STEP 4.4 — Load Phase 2 & Identify Unique PMIDs\n",
      "======================================================================\n",
      "Loaded Phase 2: 9,204 rows (citation-level)\n",
      "  Note: Phase 2 is citation-level (one row per guideline-reference pair)\n",
      "  Phase 3 deduplicates to PMID-level (one row per unique PMID)\n",
      "\n",
      "PMID Summary:\n",
      "  Citation rows with usable PMIDs: 8,149\n",
      "  UNIQUE ref_pmids to check: 7,725\n",
      "  Total batches (200 PMIDs/batch): 39\n",
      "  Estimated minimum runtime: ~0.2 minutes (sleep time only)\n",
      "\n",
      "STEP 4.5 — Check for Existing Checkpoints\n",
      "======================================================================\n",
      "Found 13 checkpoint file(s)\n",
      "  Loading existing progress...\n",
      "  ✓ Loaded 7,724 already-processed PMIDs from checkpoints\n",
      "PMIDs remaining to process: 1\n",
      "\n",
      "STEP 4.6 — Batch Processing: Fetch from PubMed & Extract Trial Info\n",
      "======================================================================\n",
      "Processing 1 PMIDs in batches of 200...\n",
      "Progress bar shows batch completion (not individual PMIDs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db02b554484d43f991d38895e7d3b44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved final checkpoint\n",
      "\n",
      "Batch Processing Summary:\n",
      "Output is trial_data (list of dicts, one per ref_pmid fetch result)\n",
      "  New articles parsed: 1\n",
      "  New missing PMIDs: 0\n",
      "  New batch errors: 0\n",
      "\n",
      "  Total articles parsed (all runs): 7,722\n",
      "  Total missing PMIDs (all runs): 3\n",
      "  Total batch errors (all runs): 0\n",
      "\n",
      "\n",
      "======================================================================\n",
      "STEP 4.7 — Canonicalization: Ensure One Row Per PMID\n",
      "======================================================================\n",
      "  Canonicalization complete: 7,725 → 7,725 rows\n",
      "  Duplicate NCT instances within PMID: 0 (should be 0)\n",
      "\n",
      "  ✓ Columns reordered: 14 standard columns\n",
      "\n",
      "✓ Saved MASTER PMID-level table: output\\phase3_references_with_trials_unique_refs.csv\n",
      "  Rows (unique PMIDs): 7,725\n",
      "  │\n",
      "  ├── Classified as clinical trials (ref_is_clinical_trial_pt_type=True): 1,455 (18.8%)\n",
      "  └── NOT classified as clinical trials (ref_is_clinical_trial_pt_type=False): 6,270 (81.2%)\n",
      "  \n",
      "  PMIDs with NCT numbers (ref_has_nct=True): 588 (7.6%)\n",
      "  │\n",
      "  ├── Clinical trials with NCTs: 508\n",
      "  │   (intersection: ref_is_clinical_trial_pt_type=True AND ref_has_nct=True)\n",
      "  │\n",
      "  └── Non-trials with NCTs: 80\n",
      "      (Reviews, meta-analyses, commentaries about trials)\n",
      "\n",
      "\n",
      "======================================================================\n",
      "MISSING/PROBLEMATIC PMIDs\n",
      "======================================================================\n",
      "✓ Saved missing PMIDs: output\\phase3_missing_pmids.csv\n",
      "  PMIDs missing from PubMed: 3\n",
      "  Sample: ['31940160', '25927121', '35258870']\n",
      "\n",
      "✓ No batch errors (all fetches successful)\n",
      "\n",
      "✓ Saved MASTER PMID–NCT pairs table: output\\phase3_pmid_nct_pairs_master.csv\n",
      "\n",
      "======================================================================\n",
      "STEP 4.9 — Summary Statistics (PMID-level + NCT-level)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "A) Compute TRIALS-ONLY NCT subcounts from PAIRS (for tree injection)\n",
      "======================================================================\n",
      "Trials-only breakdown (computed from trials-only pairs):\n",
      "  PMIDs with NCT(s): 508\n",
      "    ├── PMIDs with ONLY a primary NCT (exactly 1 NCT): 493\n",
      "    └── PMIDs with primary + ≥1 additional NCT (2+ NCTs): 15\n",
      "  [Filter note] Filtered using pairs_df.ref_is_pubmed_clinical_trial\n",
      "\n",
      "\n",
      "======================================================================\n",
      "B) PMID-LEVEL TREE (Canonical MASTER: phase3_trials_unique_refs_df)\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "PMID-LEVEL RESULTS TREE — MASTER (All unique PMIDs)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "📋 TREE 1: Clinical Trial Classification (ref_is_clinical_trial_pt_type)\n",
      "----------------------------------------------------------------------\n",
      "7,725 PMIDs in table (see: phase2_references_with_trials_unique_refs.csv)\n",
      "│\n",
      "├── 1,455 PubMed-classified clinical trial PMIDs (ref_is_clinical_trial_pt_type=True)\n",
      "│   ├── 541 PMIDs that mention ANY registry ID (ref_is_clinical_trial_pt_type = True AND ref_all_registry_ids NOT NAN)\n",
      "│   │   ├── ⭐ 508 PMIDs with NCT(s) (ref_is_clinical_trial_pt_type = True AND ref_all_registry_ids NOT NAN AND ref_primary_nct_number NOT BLANK)\n",
      "│   │   │   ├── 493 PMIDs with ONLY a primary NCT (i.e., exactly 1 NCT in pairs: all_nct_numbers has only one NCT)\n",
      "│   │   │   └── 15 PMIDs with primary + ≥1 additional NCT (i.e., 2+ NCTs in pairs: all_nct_numbers has more than one NCT)\n",
      "│   │   └── 33 PMIDs with registry IDs but NO PRIMARY NCT (ref_is_clinical_trial_pt_type = True AND ref_all_registry_ids NOT NAN AND primary_nct_number IS BLANK)\n",
      "│   └── 914 PMIDs with NO registry ID mentioned (count where ref_is_clinical_trial_pt_type = True AND ref_all_registry_ids = NAN)\n",
      "│\n",
      "│\n",
      "└── 6,270 NOT PubMed-classified clinical trial PMIDs  (= 7,725 - 1,455, ref_is_clinical_trial_pt_type=False)\n",
      "    └── 93 non-trial PMIDs that mention registry IDs anyway (ref_is_clinical_trial_pt_type=False, ref_all_registry_ids NOT NAN)\n",
      "        ├── 80 of those mention NCT(s) (ref_is_clinical_trial_pt_type=False, ref_all_registry_ids NOT NAN, ref_all_nct_numbers NOT Blank)\n",
      "        └── 13 of those have registry IDs but NO NCT (ref_is_clinical_trial_pt_type=False, ref_all_registry_ids NOT NAN, ref_all_nct_numbers IS Blank)\n",
      "\n",
      "\n",
      "🔗 TREE 2: Registry ID Mentions (ref_all_registry_ids field)\n",
      "----------------------------------------------------------------------\n",
      "7,725 PMIDs in table (see: phase2_references_with_trials_unique_refs.csv)\n",
      "│\n",
      "├── 634 PMIDs that mention ANY registry ID (ref_all_registry_ids NOT NAN)\n",
      "│   │   (includes both publication-type-trials and non-trials)\n",
      "│   │\n",
      "│   ├── 588 PMIDs with NCT number(s) (ref_all_registry_ids NOT NAN AND ref_all_nct_numbers NOT Blank )\n",
      "│   │   ├── From trials: 508 (ref_all_registry_ids NOT NAN AND ref_all_nct_numbers NOT NAN AND ref_is_clinical_trial_pt_type True) \n",
      "│   │   └── From non-trials: 80, (ref_all_registry_ids NOT NAN AND ref_all_nct_numbers NOT NAN AND ref_is_clinical_trial_pt_type False)\n",
      "│   │\n",
      "│   └── 46 PMIDs with registry IDs but NO NCT numbers (ref_all_registry_ids NOT NAN AND ref_all_nct_numbers IS Blank)\n",
      "│       ├── From trials: 33 (ref_all_registry_ids NOT NAN AND ref_all_nct_numbers IS Blank AND ref_is_clinical_trial_pt_type True)\n",
      "│       └── From non-trials: 13 (ref_all_registry_ids NOT NAN AND ref_all_nct_numbers IS Blank AND ref_is_clinical_trial_pt_type False)\n",
      "│\n",
      "└── 7,091 PMIDs with NO registry IDs mentioned (ref_all_registry_ids IS NAN)\n",
      "    ├── From trials: 914 (ref_all_registry_ids IS NAN AND ref_is_clinical_trial_pt_type True)\n",
      "    └── From non-trials: 6,177 (ref_all_registry_ids IS NAN AND ref_is_clinical_trial_pt_type False)\n",
      "\n",
      "\n",
      "HOW THESE NUMBERS RELATE (helper text):\n",
      "----------------------------------------------------------------------\n",
      "TREE 1 (Clinical Trial Classification):\n",
      "  • Trial partition (adds up exactly): 7,725 = 1,455 (trials) + 6,270 (non-trials)\n",
      "  • Within trials: 1,455 = 541 (with registry) + 914 (no registry)\n",
      "\n",
      "TREE 2 (Registry ID Mentions):\n",
      "  • Registry partition (adds up exactly): 7,725 = 634 (with registry) + 7,091 (no registry)\n",
      "  • Within registry mentions: 634 = 588 (with NCT) + 46 (no NCT)\n",
      "\n",
      "RELATIONSHIP BETWEEN TREES:\n",
      "  • These are INDEPENDENT axes - an article can be:\n",
      "    - A trial WITH registry IDs (most common for trials)\n",
      "    - A trial WITHOUT registry IDs (underreported trials)\n",
      "    - NOT a trial but WITH registry IDs (reviews/meta-analyses)\n",
      "    - NOT a trial and NO registry IDs (other literature)\n",
      "\n",
      "⭐ HIGHLIGHTED COHORT:\n",
      "  • 508 trials with NCT(s) = the main analysis cohort\n",
      "  • This is the intersection of Tree 1 (trials) and Tree 2 (NCT mentions)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "C) PAIRS / NCT-LEVEL TREE (MASTER pairs: ALL PMIDs with ≥1 NCT)\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "PAIRS / NCT-LEVEL TREE — MASTER (All PMIDs with ≥1 NCT; trial + non-trial)\n",
      "----------------------------------------------------------------------\n",
      "Pairs table (PMID–NCT rows)\n",
      "│\n",
      "├── 588 unique PMIDs represented (must have ≥1 NCT)\n",
      "│\n",
      "├── 784 total PMID–NCT pairs\n",
      "│   └── (extra rows happen because some PMIDs have 2+ NCTs)\n",
      "│       → 196 additional pair rows beyond 1-per-PMID\n",
      "│\n",
      "└── 684 unique NCTs represented\n",
      "    └── (unique NCTs < total pairs because some NCTs repeat across PMIDs)\n",
      "\n",
      "    PRIMARY vs SECONDARY NCTs (unique counts):\n",
      "      ├── 505 unique PRIMARY NCTs\n",
      "      └── 188 unique SECONDARY (non-primary) NCTs\n",
      "          (note: a secondary NCT can still be the primary NCT of a different PMID)\n",
      "\n",
      "784 total PMID–NCT pairs (i.e. NCTs per PMID):\n",
      "  ├── 561 PMIDs with exactly 1 NCT\n",
      "  │   └── Contributes 561 pairs (all primary)\n",
      "  │\n",
      "  ├── 15 PMIDs with exactly 2 NCTs\n",
      "  │   └── Contributes 30 pairs (15 primary + 15 non-primary)\n",
      "  │\n",
      "  └── 12 PMIDs with 3+ NCTs\n",
      "      └── Contributes 193 pairs (12 primary + 181 non-primary)\n",
      "\n",
      "======================================================================\n",
      "D) PAIRS / NCT-LEVEL TREE (TRIALS-ONLY pairs: the 508 PMIDs)\n",
      "======================================================================\n",
      "[Filter note] Filtered using pairs_df.is_pubmed_clinical_trial\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "PAIRS / NCT-LEVEL TREE — TRIALS-ONLY (pairs restricted to PubMed clinical trial PMIDs)\n",
      "----------------------------------------------------------------------\n",
      "Pairs table (PMID–NCT rows)\n",
      "│\n",
      "├── 508 unique PMIDs represented (must have ≥1 NCT)\n",
      "│\n",
      "├── 529 total PMID–NCT pairs\n",
      "│   └── (extra rows happen because some PMIDs have 2+ NCTs)\n",
      "│       → 21 additional pair rows beyond 1-per-PMID\n",
      "│\n",
      "└── 465 unique NCTs represented\n",
      "    └── (unique NCTs < total pairs because some NCTs repeat across PMIDs)\n",
      "\n",
      "    PRIMARY vs SECONDARY NCTs (unique counts):\n",
      "      ├── 451 unique PRIMARY NCTs\n",
      "      └── 19 unique SECONDARY (non-primary) NCTs\n",
      "          (note: a secondary NCT can still be the primary NCT of a different PMID)\n",
      "\n",
      "529 total PMID–NCT pairs (i.e. NCTs per PMID):\n",
      "  ├── 493 PMIDs with exactly 1 NCT\n",
      "  │   └── Contributes 493 pairs (all primary)\n",
      "  │\n",
      "  ├── 11 PMIDs with exactly 2 NCTs\n",
      "  │   └── Contributes 22 pairs (11 primary + 11 non-primary)\n",
      "  │\n",
      "  └── 4 PMIDs with 3+ NCTs\n",
      "      └── Contributes 14 pairs (4 primary + 10 non-primary)\n",
      "\n",
      "======================================================================\n",
      "E) CROSS-CHECKS + SCOPE NOTES\n",
      "======================================================================\n",
      "Starred cohort reconciliation (trial PMIDs with NCTs):\n",
      "----------------------------------------------------------------------\n",
      "PMID-level starred count (trial PMIDs with NCTs): 508\n",
      "Pairs-level trials-only unique PMIDs:            508\n",
      "Pairs-derived trials-only PMIDs with NCT(s):     508\n",
      "✓ These match exactly (good sign).\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Scope clarity: MASTER unique NCTs vs TRIALS-ONLY unique NCTs\n",
      "----------------------------------------------------------------------\n",
      "MASTER pairs:    684 unique NCTs (all PMIDs with NCTs: trial + non-trial)\n",
      "TRIALS-ONLY pairs:465 unique NCTs (only the 508 trial PMIDs with NCTs)\n",
      "Interpretation:\n",
      "  • The MASTER NCT count is NOT 'the NCTs for the 508 PMIDs'.\n",
      "  • The TRIALS-ONLY NCT count IS the NCTs associated with those 508 PMIDs.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Optional: unique NCTs that appear ONLY in non-trial PMIDs (MASTER minus TRIALS-ONLY):\n",
      "  54 unique NCTs appear only in non-trial PMIDs\n",
      "\n",
      "======================================================================\n",
      "STEP 4.10 — Generate Summary Tables\n",
      "======================================================================\n",
      "\n",
      "📋 TABLE 1: PMID-Level Summary\n",
      "----------------------------------------------------------------------\n",
      "                                               Metric  Count Percentage\n",
      "                                          Total PMIDs   7725     100.0%\n",
      "Clinical trial PMIDs (is_clinical_trial_pt_type=True)   1455      18.8%\n",
      "                                      Non-trial PMIDs   6270      81.2%\n",
      "                           PMIDs with any registry ID    634       8.2%\n",
      "                PMIDs with NCT numbers (has_nct=True)    588       7.6%\n",
      "                Trial PMIDs with NCTs (⭐ main cohort)    508       6.6%\n",
      "                            Non-trial PMIDs with NCTs     80       1.0%\n",
      "\n",
      "✓ Saved: output\\phase3_summary_pmid_level.csv\n",
      "\n",
      "\n",
      "🔗 TABLE 2: NCT-Level Comparison (MASTER vs TRIALS-ONLY)\n",
      "----------------------------------------------------------------------\n",
      "                         Metric  MASTER (All PMIDs)  TRIALS-ONLY\n",
      "       Unique PMIDs represented                 588          508\n",
      "           Total PMID-NCT pairs                 784          529\n",
      "Extra pairs (beyond 1-per-PMID)                 196           21\n",
      "              Unique NCTs (ALL)                 684          465\n",
      "            Unique PRIMARY NCTs                 505          451\n",
      "          Unique SECONDARY NCTs                 188           19\n",
      "       PMIDs with exactly 1 NCT                 561          493\n",
      "      PMIDs with exactly 2 NCTs                  15           11\n",
      "             PMIDs with 3+ NCTs                  12            4\n",
      "\n",
      "✓ Saved: output\\phase3_summary_nct_level_comparison.csv\n",
      "\n",
      "\n",
      "📊 TABLE 3: Pairs Breakdown by Reference PMID + NCT Count\n",
      "----------------------------------------------------------------------\n",
      "            PMID Category MASTER (All) TRIALS-ONLY\n",
      " PMIDs with exactly 1 NCT          561         493\n",
      "      → Pairs contributed          561         493\n",
      "          → Primary pairs          561         493\n",
      "      → Non-primary pairs            0           0\n",
      "                                                  \n",
      "PMIDs with exactly 2 NCTs           15          11\n",
      "      → Pairs contributed           30          22\n",
      "          → Primary pairs           15          11\n",
      "      → Non-primary pairs           15          11\n",
      "                                                  \n",
      "       PMIDs with 3+ NCTs           12           4\n",
      "      → Pairs contributed          193          14\n",
      "          → Primary pairs           12           4\n",
      "      → Non-primary pairs          181          10\n",
      "                                                  \n",
      "                    TOTAL          784         529\n",
      "\n",
      "✓ Saved: output\\phase3_summary_pairs_breakdown.csv\n",
      "\n",
      "======================================================================\n",
      "✓ PHASE 3 — STEP 4.10 COMPLETE (Summary tables generated)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "✓ PHASE 3 — STEP 4 COMPLETE (PMID-level + NCT-level reporting)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PHASE 3: STEP 4 - IDENTIFY REFERENCES THAT ARE CLINICAL TRIALS \n",
    "# ============================================================================\n",
    "# Purpose:\n",
    "#   For each UNIQUE reference PMID from Phase 2:\n",
    "#     1) Classify as clinical trial (based on PubMed PublicationTypeList)\n",
    "#     2) Extract trial registry IDs (NCT, ISRCTN, EUCTR, etc.)\n",
    "#     3) Store both PRIMARY NCT and ALL NCTs found (order-preserving)\n",
    "#\n",
    "# Inputs:\n",
    "#   - phase2_crossref_guidelines_and_references.csv (citation-level)\n",
    "#\n",
    "# Outputs:\n",
    "#   - phase3_1_missing_pmids.csv\n",
    "#   - phase3_2_references_with_trials_unique_refs.csv (PMID-level: one row per ref_pmid)\n",
    "#   - phase3_pmid_nct_pairs.csv (PMID-NCT pairs: exploded for multi-NCT analysis)\n",
    "#   - checkpoints/phase3_trials/checkpoint_*.csv (resumable progress saves)\n",
    "#   - phase3_extra_nct_audit.csv (audit trail for extra NCTs beyond primary)\n",
    "#\n",
    "# Key Features:\n",
    "#   - Batch processing (200 PMIDs at once) for speed\n",
    "#   - Checkpoints allow resuming after interruption\n",
    "#   - Multi-NCT support: one PMID can link to multiple trials\n",
    "#   - Primary NCT selection: SecondarySourceID > DataBankList > Abstract\n",
    "#   - Order-preserving deduplication within each PMID\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PHASE 3: STEP 4 - IDENTIFY CLINICAL TRIALS (BATCH OPTIMIZED)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 1: CONFIGURATION & SETUP\n",
    "# ============================================================================\n",
    "print(\"STEP 4.1 — Configuration\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Batch processing parameters\n",
    "BATCH_SIZE = 200           # PMIDs per API call (max efficiency)\n",
    "SLEEP_PER_BATCH = 0.34     # Seconds between batches (rate limiting)\n",
    "CHECKPOINT_INTERVAL = 500  # Save progress every N rows\n",
    "\n",
    "# Regex for NCT number matching (NCT followed by 8 digits)\n",
    "NCT_REGEX = re.compile(r\"\\bNCT\\d{8}\\b\", flags=re.IGNORECASE)\n",
    "\n",
    "# PubMed publication type keywords that indicate clinical trials\n",
    "# Source: https://www.nlm.nih.gov/mesh/pubtypes.html\n",
    "trial_keywords = {\n",
    "    \"clinical trial\",\n",
    "    \"randomized controlled trial\",\n",
    "    \"controlled clinical trial\",\n",
    "    \"multicenter study\",\n",
    "    \"pragmatic clinical trial\",\n",
    "    \"clinical trial, phase i\",\n",
    "    \"clinical trial, phase ii\",\n",
    "    \"clinical trial, phase iii\",\n",
    "    \"clinical trial, phase iv\",\n",
    "}\n",
    "trial_keywords = {k.lower() for k in trial_keywords}\n",
    "\n",
    "print(f\"BATCH_SIZE: {BATCH_SIZE}\")\n",
    "print(f\"SLEEP_PER_BATCH: {SLEEP_PER_BATCH} seconds\")\n",
    "print(f\"CHECKPOINT_INTERVAL: Every {CHECKPOINT_INTERVAL} rows\")\n",
    "print(f\"Trial keyword phrases: {len(trial_keywords)} loaded\")\n",
    "print(f\"✓ Configuration complete\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 2: HELPER FUNCTIONS (Consolidated - No Duplicates)\n",
    "# ============================================================================\n",
    "print(\"STEP 4.2 — Loading Helper Functions\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2.1: Input Cleanup Helpers\n",
    "# Purpose: Normalize identifiers used for joins, grouping, and deduplication\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# ---- Normalize a PMID to a clean digit-only string (or None) ----\n",
    "def _norm_pmid(x):\n",
    "    \"\"\"\n",
    "    Normalize PMIDs from various formats to clean strings.\n",
    "    \n",
    "    Handles:\n",
    "      - Floats with .0 suffix: '23644082.0' → '23644082'\n",
    "      - String PMIDs: '23644082' → '23644082'\n",
    "      - Invalid/missing: None, 'nan', '' → None\n",
    "    \n",
    "    Returns: str or None\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    s = str(x).strip()\n",
    "    if s == \"\" or s.lower() in {\"none\", \"nan\", \"null\"}:\n",
    "        return None\n",
    "    # Handle \"23644082.0\" → convert to int then string\n",
    "    try:\n",
    "        f = float(s)\n",
    "        i = int(f)\n",
    "        if f == i and i > 0:\n",
    "            return str(i)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Return if already digits\n",
    "    return s if s.isdigit() else None\n",
    "\n",
    "# Alias for consistency with existing code\n",
    "clean_pmid = _norm_pmid\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2.2: Field Parsing Helpers\n",
    "# Purpose: Parse semicolon-delimited fields and extract NCT IDs from text\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# ---- Split semicolon-delimited fields into clean tokens ----\n",
    "def _split_semicolon(s, uppercase=False):\n",
    "    \"\"\"\n",
    "    Split semicolon-delimited string into cleaned tokens.\n",
    "    \n",
    "    Args:\n",
    "        s: String like \"NCT00111111;NCT00222222;NCT00333333\"\n",
    "        uppercase: If True, return uppercase tokens\n",
    "    \n",
    "    Returns:\n",
    "        List of cleaned tokens (order-preserving)\n",
    "    \n",
    "    Examples:\n",
    "        _split_semicolon(\"NCT00111;NCT00222\") → ['NCT00111', 'NCT00222']\n",
    "        _split_semicolon(\"nct00111\", uppercase=True) → ['NCT00111']\n",
    "    \"\"\"\n",
    "    if pd.isna(s):\n",
    "        return []\n",
    "    s = str(s).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    tokens = [tok.strip() for tok in s.split(\";\") if tok and str(tok).strip()]\n",
    "    if uppercase:\n",
    "        tokens = [t.upper() for t in tokens]\n",
    "    return tokens\n",
    "\n",
    "# Aliases for backward compatibility\n",
    "_split_semicolon_tokens = lambda s: _split_semicolon(s, uppercase=False)\n",
    "split_semicolon = lambda s: _split_semicolon(s, uppercase=True)\n",
    "\n",
    "# ---- Extract NCT IDs from free text using regex ----\n",
    "def _extract_ncts_from_string(s):\n",
    "    \"\"\"\n",
    "    Extract all NCT numbers from a string using regex.\n",
    "    \n",
    "    Args:\n",
    "        s: Any string that might contain NCT numbers\n",
    "    \n",
    "    Returns:\n",
    "        List of uppercase NCT numbers found\n",
    "    \n",
    "    Examples:\n",
    "        _extract_ncts_from_string(\"NCT00123456 and NCT00789012\") \n",
    "        → ['NCT00123456', 'NCT00789012']\n",
    "    \"\"\"\n",
    "    if pd.isna(s):\n",
    "        return []\n",
    "    return [m.upper() for m in NCT_REGEX.findall(str(s))]\n",
    "\n",
    "# Alias for backward compatibility\n",
    "_extract_ncts = _extract_ncts_from_string\n",
    "_extract_ncts_from_any_string = _extract_ncts_from_string\n",
    "\n",
    "# ---- Filter a token list to valid NCT IDs only (order-preserving, deduped) ----\n",
    "def extract_ncts_from_token_list(tokens):\n",
    "    \"\"\"\n",
    "    Filter a list of tokens to NCT numbers only (order-preserving, deduped).\n",
    "    \n",
    "    Args:\n",
    "        tokens: List of strings that might be NCT numbers\n",
    "    \n",
    "    Returns:\n",
    "        List of valid NCT numbers (deduped, first occurrence kept)\n",
    "    \n",
    "    Examples:\n",
    "        extract_ncts_from_token_list(['NCT00111', 'ISRCTN123', 'NCT00111'])\n",
    "        → ['NCT00111']  # Deduped, non-NCT removed\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    seen = set()\n",
    "    for t in tokens:\n",
    "        if not t:\n",
    "            continue\n",
    "        m = NCT_REGEX.search(str(t))\n",
    "        if m:\n",
    "            n = m.group(0).upper()\n",
    "            if n not in seen:\n",
    "                out.append(n)\n",
    "                seen.add(n)\n",
    "    return out\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2.3: Canonicalization Helpers\n",
    "# Purpose: Deduplicate values while preserving semantic encounter order\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# ---- Remove duplicates while preserving first encounter order ----\n",
    "def _dedupe_preserve_order(seq):\n",
    "    \"\"\"\n",
    "    Remove duplicates from sequence while preserving first encounter order.\n",
    "    \n",
    "    Critical for preventing duplicate NCTs within a single PMID.\n",
    "    Normalizes to uppercase for case-insensitive matching.\n",
    "    \n",
    "    Args:\n",
    "        seq: List that may contain duplicates\n",
    "    \n",
    "    Returns:\n",
    "        List with duplicates removed (first occurrence kept)\n",
    "    \n",
    "    Examples:\n",
    "        _dedupe_preserve_order(['NCT001', 'nct002', 'NCT001'])\n",
    "        → ['NCT001', 'NCT002']\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for x in seq:\n",
    "        if x is None:\n",
    "            continue\n",
    "        v = str(x).strip()\n",
    "        if not v:\n",
    "            continue\n",
    "        v = v.upper()\n",
    "        if v not in seen:\n",
    "            seen.add(v)\n",
    "            out.append(v)\n",
    "    return out\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2.4: Legacy / Convenience Helpers\n",
    "# Purpose: Simple primary-selection heuristics for ordered NCT lists\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# ---- Choose a primary NCT (first in encounter order) ----\n",
    "def _pick_primary_nct(nct_list):\n",
    "    \"\"\"\n",
    "    Choose a 'primary' NCT from a list.\n",
    "    \n",
    "    Rule: First in the (deduplicated) encounter order.\n",
    "    This maintains consistency with source priority already applied.\n",
    "    \n",
    "    Args:\n",
    "        nct_list: List of NCT numbers (already ordered by source priority)\n",
    "    \n",
    "    Returns:\n",
    "        Single NCT string or None\n",
    "    \"\"\"\n",
    "    return nct_list[0] if nct_list else None\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2.5: DataFrame/Reporting Helpers\n",
    "# Purpose: Boolean flags + NCT source-pair parsing used in canonicalization and reporting\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def _series_nonempty(s: pd.Series) -> pd.Series:\n",
    "    return s.fillna(\"\").astype(str).str.strip().ne(\"\")\n",
    "\n",
    "def _has_any_registry_id_from_field(s: pd.Series) -> pd.Series:\n",
    "    # \"any registry id present\" = non-empty all_registry_ids\n",
    "    return _series_nonempty(s)\n",
    "\n",
    "def _has_any_nct_from_field(s: pd.Series) -> pd.Series:\n",
    "    # robust: check tokens for NCT regex (handles semicolon lists cleanly)\n",
    "    return s.fillna(\"\").apply(lambda x: any(NCT_REGEX.search(tok) for tok in split_semicolon(x)))\n",
    "\n",
    "def _choose_primary_nct_from_sources(row, nct_list):\n",
    "    \"\"\"\n",
    "    Choose primary NCT from a merged list.\n",
    "    - If an existing primary (row['nct_number']) is valid and in the merged list, keep it.\n",
    "    - Else pick the first from merged list (already order-preserving).\n",
    "    \"\"\"\n",
    "    if not nct_list:\n",
    "        return None, None\n",
    "\n",
    "    existing_primary = row.get(\"ref_nct_number\")\n",
    "    if pd.notna(existing_primary):\n",
    "        p = str(existing_primary).strip().upper()\n",
    "        if p in nct_list:\n",
    "            return p, row.get(\"ref_nct_source\")\n",
    "\n",
    "    return nct_list[0], (row.get(\"ref_nct_source\") or \"merged\")\n",
    "def _split_semicolon_tokens_safe(val):\n",
    "    return _split_semicolon_tokens(val) if pd.notna(val) else []\n",
    "\n",
    "def _parse_nct_source_pairs(val):\n",
    "    \"\"\"\n",
    "    Parse 'NCTxxxx|source;NCTyyyy|source' into ordered dict-like list.\n",
    "    Returns list of tuples [(nct, source), ...] preserving first occurrence.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    seen = set()\n",
    "    for tok in _split_semicolon_tokens_safe(val):\n",
    "        t = str(tok).strip()\n",
    "        if not t or \"|\" not in t:\n",
    "            continue\n",
    "        nct, src = t.split(\"|\", 1)\n",
    "        nct = nct.strip().upper()\n",
    "        src = src.strip()\n",
    "        if not nct:\n",
    "            continue\n",
    "        # validate nct\n",
    "        m = NCT_REGEX.search(nct)\n",
    "        if not m:\n",
    "            continue\n",
    "        nct = m.group(0).upper()\n",
    "        if nct not in seen:\n",
    "            out.append((nct, src))\n",
    "            seen.add(nct)\n",
    "    return out\n",
    "\n",
    "def _merge_nct_source_pairs(series_vals):\n",
    "    \"\"\"\n",
    "    Merge multiple NCT|source strings into one, first-source-wins per NCT.\n",
    "    Returns: 'NCT..|src;NCT..|src' or None\n",
    "    \"\"\"\n",
    "    merged = []\n",
    "    seen = set()\n",
    "    for v in series_vals:\n",
    "        for nct, src in _parse_nct_source_pairs(v):\n",
    "            if nct not in seen:\n",
    "                merged.append((nct, src))\n",
    "                seen.add(nct)\n",
    "    return \";\".join([f\"{n}|{s}\" for n, s in merged]) if merged else None\n",
    "\n",
    "\n",
    "print(\"✓ Helper functions loaded:\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 3: CORE EXTRACTION FUNCTION\n",
    "# ============================================================================\n",
    "print(\"STEP 4.3 — Loading Core Extraction Function\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def extract_trial_info(pubmed_article):\n",
    "    \"\"\"\n",
    "    Extract clinical trial information from a PubMed article record.\n",
    "    \n",
    "    This is the CORE function that processes each PubMed article to:\n",
    "      1. Identify if it's a clinical trial (via PublicationTypeList)\n",
    "      2. Extract ALL registry IDs (NCT, ISRCTN, EUCTR, etc.)\n",
    "      3. Extract ALL NCT numbers from multiple sources\n",
    "      4. Select a PRIMARY NCT using source priority\n",
    "    \n",
    "    Source Priority (for primary NCT selection):\n",
    "      1. SecondarySourceID - PubMed curated (MOST AUTHORITATIVE)\n",
    "      2. DataBankList - Explicit registry links\n",
    "      3. Abstract - Text extraction (LEAST RELIABLE)\n",
    "    \n",
    "    Within each source, the FIRST encountered NCT becomes primary.\n",
    "    \n",
    "    Args:\n",
    "        pubmed_article: Dict from Entrez.read() containing article metadata\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (pmid, is_trial, pub_types_str, nct_number, nct_source, \n",
    "                  all_registry_ids_str, all_nct_numbers_str)\n",
    "        \n",
    "        Where:\n",
    "          pmid: PubMed ID as string\n",
    "          is_trial: Boolean (classified based on publication types)\n",
    "          pub_types_str: Semicolon-delimited publication types\n",
    "          nct_number: PRIMARY NCT (single value)\n",
    "          nct_source: Where primary was found ('secondary_source_id', 'databank', 'abstract')\n",
    "          all_registry_ids_str: ALL registry IDs (semicolon-delimited)\n",
    "          all_nct_numbers_str: ALL NCTs found (semicolon-delimited, order-preserving)\n",
    "    \n",
    "    Example Return:\n",
    "        ('12345678', True, 'Clinical Trial;Randomized Controlled Trial',\n",
    "         'NCT00123456', 'secondary_source_id', \n",
    "         'NCT00123456;NCT00789012', 'NCT00123456;NCT00789012')\n",
    "    \"\"\"\n",
    "    pmid = None\n",
    "    pub_types = []\n",
    "    is_trial = False\n",
    "\n",
    "    nct_number = None          # PRIMARY NCT (for legacy compatibility)\n",
    "    nct_source = None          # Where primary NCT was found\n",
    "\n",
    "    # Order-preserving containers + deduplication tracking\n",
    "    registry_ids = []          # ALL registry IDs (any type)\n",
    "    registry_ids_seen = set()\n",
    "\n",
    "    ncts_secondary = []        # NCTs from SecondarySourceID (priority 1)\n",
    "    ncts_databank = []         # NCTs from DataBankList (priority 2)\n",
    "    ncts_abstract = []         # NCTs from Abstract (priority 3)\n",
    "\n",
    "    nct_seen = set()           # Global NCT deduplication tracker\n",
    "    nct_first_source = {}  # { \"NCT01234567\": \"databank\" }\n",
    "\n",
    "    def add_registry_id(val):\n",
    "        \"\"\"Add a registry ID (deduped, order-preserving).\"\"\"\n",
    "        if val is None:\n",
    "            return\n",
    "        v = str(val).strip().upper()\n",
    "        if not v:\n",
    "            return\n",
    "        if v not in registry_ids_seen:\n",
    "            registry_ids.append(v)\n",
    "            registry_ids_seen.add(v)\n",
    "\n",
    "    def add_nct(target_list, nct_val, source_label):\n",
    "        \"\"\"\n",
    "        Add an NCT to a source-specific list (deduped globally).\n",
    "        Also record first-source provenance for that NCT.\n",
    "        \"\"\"\n",
    "        if nct_val is None:\n",
    "            return\n",
    "        m = NCT_REGEX.search(str(nct_val).strip())\n",
    "        if not m:\n",
    "            return\n",
    "        n = m.group(0).upper()\n",
    "\n",
    "        if n not in nct_seen:\n",
    "            target_list.append(n)\n",
    "            nct_seen.add(n)\n",
    "            nct_first_source[n] = source_label\n",
    "\n",
    "    try:\n",
    "        medline = pubmed_article.get(\"MedlineCitation\", {}) or {}\n",
    "        pmid_raw = medline.get(\"PMID\", \"\")\n",
    "        pmid = str(pmid_raw) if pmid_raw is not None else None\n",
    "\n",
    "        article = medline.get(\"Article\", {}) or {}\n",
    "        # ----------------------------------------------------------------\n",
    "        # Step 1: Classify as Clinical Trial (Publication Types)\n",
    "        # ----------------------------------------------------------------\n",
    "        pt_list = article.get(\"PublicationTypeList\", []) or []\n",
    "        pub_types = [str(pt) for pt in pt_list if pt is not None]\n",
    "        pub_types_lower = [pt.lower() for pt in pub_types]\n",
    "        is_trial = any(any(k in pt for k in trial_keywords) for pt in pub_types_lower)\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        # Step 2: Extract from SecondarySourceID (Priority 1 - MOST AUTHORITATIVE)\n",
    "        # ----------------------------------------------------------------\n",
    "        # This is PubMed's curated list of trial registry IDs\n",
    "        secondary_ids = medline.get(\"SecondarySourceID\", []) or []\n",
    "        for sid in secondary_ids:\n",
    "            sid_str = str(sid).strip().upper()\n",
    "            if not sid_str:\n",
    "                continue\n",
    "            add_registry_id(sid_str)\n",
    "            add_nct(ncts_secondary, sid_str, \"secondary_source_id\")\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        # Step 3: Extract from DataBankList (Priority 2)\n",
    "        # ----------------------------------------------------------------\n",
    "        # Explicit trial registry links/accession numbers\n",
    "        databanks = article.get(\"DataBankList\", []) or []\n",
    "        for db in databanks:\n",
    "            try:\n",
    "                accession_list = db.get(\"AccessionNumberList\", []) or []\n",
    "            except Exception:\n",
    "                accession_list = []\n",
    "\n",
    "            for acc in accession_list:\n",
    "                acc_str = str(acc).strip().upper()\n",
    "                if not acc_str:\n",
    "                    continue\n",
    "                add_registry_id(acc_str)\n",
    "                add_nct(ncts_databank, acc_str, \"databank\")\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        # Step 4: Extract from Abstract (Priority 3 - LEAST RELIABLE)\n",
    "        # ----------------------------------------------------------------\n",
    "        # Regex fallback - only used if no structured IDs found\n",
    "        abstract_text = \"\"\n",
    "        abstract = article.get(\"Abstract\", {})\n",
    "        if isinstance(abstract, dict):\n",
    "            abstract_text_list = abstract.get(\"AbstractText\", []) or []\n",
    "            abstract_text = \" \".join(str(x) for x in abstract_text_list if x is not None).strip()\n",
    "\n",
    "        if abstract_text:\n",
    "            for m in NCT_REGEX.finditer(abstract_text):\n",
    "                n = m.group(0).upper()\n",
    "                add_nct(ncts_abstract, n, \"abstract\")\n",
    "                add_registry_id(n)\n",
    "        # ----------------------------------------------------------------\n",
    "        # Step 5: Select PRIMARY NCT (Source Priority + Encounter Order)\n",
    "        # ----------------------------------------------------------------\n",
    "        if ncts_secondary:\n",
    "            nct_number = ncts_secondary[0]\n",
    "            nct_source = \"secondary_source_id\"\n",
    "        elif ncts_databank:\n",
    "            nct_number = ncts_databank[0]\n",
    "            nct_source = \"databank\"\n",
    "        elif ncts_abstract:\n",
    "            nct_number = ncts_abstract[0]\n",
    "            nct_source = \"abstract\"\n",
    "\n",
    "  # ----------------------------------------------------------------\n",
    "        # Step 6: Build ALL NCT numbers (Order-Preserving, Deduped)\n",
    "        # ----------------------------------------------------------------\n",
    "        # Merge in source priority order: secondary → databank → abstract\n",
    "        all_ncts_ordered = []\n",
    "        for source_list in (ncts_secondary, ncts_databank, ncts_abstract):\n",
    "            for n in source_list:\n",
    "                if n not in all_ncts_ordered:\n",
    "                    all_ncts_ordered.append(n)\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        # Step 7: Build STRUCTURED-ONLY NCT numbers (SecondarySourceID + DataBankList ONLY)\n",
    "        # ----------------------------------------------------------------\n",
    "        structured_ncts_ordered = []\n",
    "        for source_list in (ncts_secondary, ncts_databank):  # NO abstract\n",
    "            for n in source_list:\n",
    "                if n not in structured_ncts_ordered:\n",
    "                    structured_ncts_ordered.append(n)\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        # Step 8: Build NCT->SOURCE mapping strings (pairs)\n",
    "        # Format: \"NCTxxxx|secondary_source_id;NCTyyyy|databank;...\"\n",
    "        # First-source-wins per NCT\n",
    "        # ----------------------------------------------------------------\n",
    "        def _pairs_from_sources(nct_list, source_label):\n",
    "            return [(str(n).upper(), source_label) for n in (nct_list or [])]\n",
    "\n",
    "        pairs_all = []\n",
    "        pairs_all.extend(_pairs_from_sources(ncts_secondary, \"secondary_source_id\"))\n",
    "        pairs_all.extend(_pairs_from_sources(ncts_databank, \"databank\"))\n",
    "        pairs_all.extend(_pairs_from_sources(ncts_abstract, \"abstract\"))\n",
    "\n",
    "        seen = set()\n",
    "        pairs_all_dedup = []\n",
    "        for n, src in pairs_all:\n",
    "            m = NCT_REGEX.search(n)\n",
    "            if not m:\n",
    "                continue\n",
    "            nct = m.group(0).upper()\n",
    "            if nct not in seen:\n",
    "                pairs_all_dedup.append((nct, src))\n",
    "                seen.add(nct)\n",
    "\n",
    "        all_nct_source_pairs_str = (\n",
    "            \";\".join([f\"{n}|{src}\" for n, src in pairs_all_dedup]) if pairs_all_dedup else None\n",
    "        )\n",
    "\n",
    "        pairs_struct = []\n",
    "        pairs_struct.extend(_pairs_from_sources(ncts_secondary, \"secondary_source_id\"))\n",
    "        pairs_struct.extend(_pairs_from_sources(ncts_databank, \"databank\"))\n",
    "\n",
    "        seen = set()\n",
    "        pairs_struct_dedup = []\n",
    "        for n, src in pairs_struct:\n",
    "            m = NCT_REGEX.search(n)\n",
    "            if not m:\n",
    "                continue\n",
    "            nct = m.group(0).upper()\n",
    "            if nct not in seen:\n",
    "                pairs_struct_dedup.append((nct, src))\n",
    "                seen.add(nct)\n",
    "\n",
    "        all_structured_nct_source_pairs_str = (\n",
    "            \";\".join([f\"{n}|{src}\" for n, src in pairs_struct_dedup]) if pairs_struct_dedup else None\n",
    "        )\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        # Step 9: Serialize fields\n",
    "        # ----------------------------------------------------------------\n",
    "        pub_types_str = \";\".join(pub_types) if pub_types else None\n",
    "        all_registry_ids_str = \";\".join(registry_ids) if registry_ids else None\n",
    "        all_nct_numbers_str = \";\".join(all_ncts_ordered) if all_ncts_ordered else None\n",
    "        all_structured_nct_numbers_str = (\n",
    "            \";\".join(structured_ncts_ordered) if structured_ncts_ordered else None\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            pmid,\n",
    "            is_trial,\n",
    "            pub_types_str,\n",
    "            nct_number,\n",
    "            nct_source,\n",
    "            all_registry_ids_str,\n",
    "            all_nct_numbers_str,\n",
    "            all_structured_nct_numbers_str,\n",
    "            all_nct_source_pairs_str,\n",
    "            all_structured_nct_source_pairs_str,\n",
    "            abstract_text,\n",
    "        )\n",
    "\n",
    "\n",
    "    except Exception:\n",
    "        # Safe defaults if anything goes sideways\n",
    "        return pmid, False, None, None, None, None, None, None, None, None\n",
    "\n",
    "print(\"✓ extract_trial_info() defined\")\n",
    "print(\"  Extracts from 3 sources with priority: SecondarySourceID > DataBankList > Abstract\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 4: LOAD PHASE 2 DATA & IDENTIFY UNIQUE PMIDs\n",
    "# ============================================================================\n",
    "print(\"STEP 4.4 — Load Phase 2 & Identify Unique PMIDs\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "phase2_file = os.path.join(OUTPUT_FOLDER, \"phase2_crossref_guidelines_and_references.csv\")\n",
    "references_df = pd.read_csv(phase2_file)\n",
    "\n",
    "print(f\"Loaded Phase 2: {len(references_df):,} rows (citation-level)\")\n",
    "print(\"  Note: Phase 2 is citation-level (one row per guideline-reference pair)\")\n",
    "print(\"  Phase 3 deduplicates to PMID-level (one row per unique PMID)\")\n",
    "\n",
    "# Clean PMIDs and filter to rows with valid PMIDs\n",
    "references_df[\"ref_pmid_clean\"] = references_df[\"ref_pmid\"].apply(clean_pmid)\n",
    "refs_with_pmid = references_df[references_df[\"ref_pmid_clean\"].notna()].copy()\n",
    "\n",
    "# Get unique PMIDs (this is what we'll process)\n",
    "unique_ref_pmids = refs_with_pmid[\"ref_pmid_clean\"].unique().tolist()\n",
    "total_unique = len(unique_ref_pmids)\n",
    "\n",
    "print(f\"\\nPMID Summary:\")\n",
    "print(f\"  Citation rows with usable PMIDs: {len(refs_with_pmid):,}\")\n",
    "print(f\"  UNIQUE ref_pmids to check: {total_unique:,}\")\n",
    "print(f\"  Total batches ({BATCH_SIZE} PMIDs/batch): {(total_unique + BATCH_SIZE - 1) // BATCH_SIZE:,}\")\n",
    "print(f\"  Estimated minimum runtime: ~{((total_unique + BATCH_SIZE - 1) // BATCH_SIZE) * SLEEP_PER_BATCH / 60:.1f} minutes (sleep time only)\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 5: CHECKPOINT SYSTEM (Resume Capability)\n",
    "# ============================================================================\n",
    "print(\"STEP 4.5 — Check for Existing Checkpoints\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "checkpoint_dir = os.path.join(OUTPUT_FOLDER, \"checkpoints\", \"phase3_trials\")\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Find existing checkpoint files\n",
    "checkpoint_files = sorted([\n",
    "    f for f in os.listdir(checkpoint_dir)\n",
    "    if f.startswith(\"checkpoint_\") and f.endswith(\".csv\")\n",
    "])\n",
    "\n",
    "trial_data = []\n",
    "processed_pmids = set()\n",
    "\n",
    "if checkpoint_files:\n",
    "    print(f\"Found {len(checkpoint_files)} checkpoint file(s)\")\n",
    "    print(\"  Loading existing progress...\")\n",
    "    \n",
    "    dfs = []\n",
    "    for checkpoint_file in checkpoint_files:\n",
    "        dfs.append(pd.read_csv(\n",
    "            os.path.join(checkpoint_dir, checkpoint_file),\n",
    "            dtype={\"ref_pmid\": str}\n",
    "        ))\n",
    "    \n",
    "    if dfs:\n",
    "        ckpt_df = pd.concat(dfs, ignore_index=True)\n",
    "        processed_pmids.update(ckpt_df[\"ref_pmid\"].astype(str))\n",
    "        trial_data.extend(ckpt_df.to_dict(\"records\"))\n",
    "    \n",
    "    print(f\"  ✓ Loaded {len(processed_pmids):,} already-processed PMIDs from checkpoints\")\n",
    "else:\n",
    "    print(\"No checkpoints found — starting fresh\")\n",
    "\n",
    "remaining_pmids = [pmid for pmid in unique_ref_pmids if pmid not in processed_pmids]\n",
    "print(f\"PMIDs remaining to process: {len(remaining_pmids):,}\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 6: BATCH PROCESSING (Main PubMed Fetching Loop)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"STEP 4.6 — Batch Processing: Fetch from PubMed & Extract Trial Info\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6.0 — Normalize existing trial_data (from checkpoints) so totals are correct\n",
    "# -----------------------------------------------------------------------------\n",
    "# NOTE: This block is mostly fine; I’m only tightening a few edges to avoid\n",
    "# KeyErrors if old checkpoints are missing columns.\n",
    "\n",
    "def _safe_bool_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Convert a series to boolean safely (NaN -> False).\"\"\"\n",
    "    return s.fillna(False).astype(bool)\n",
    "\n",
    "if trial_data:\n",
    "    temp_df = pd.DataFrame(trial_data)\n",
    "\n",
    "    # Ensure columns exist so old checkpoints don't crash this step\n",
    "    for col in [\"ref_fetch_status\", \"ref_publication_types\", \"ref_all_registry_ids\", \"ref_is_clinical_trial_pt_type\"]:\n",
    "        if col not in temp_df.columns:\n",
    "            temp_df[col] = None\n",
    "\n",
    "    if temp_df[\"ref_fetch_status\"].notna().any():\n",
    "        # New checkpoint files with explicit status\n",
    "        total_missing_pmids = int((temp_df[\"ref_fetch_status\"] == \"missing\").sum())\n",
    "        total_batch_errors = int((temp_df[\"ref_fetch_status\"] == \"error\").sum())\n",
    "        total_articles_parsed = int((temp_df[\"ref_fetch_status\"] == \"success\").sum())\n",
    "    else:\n",
    "        # Old checkpoint files without fetch_status - INFER from data\n",
    "        print(\"ℹ️ Inferring problematic PMIDs from data (old checkpoints without fetch_status)\")\n",
    "\n",
    "        # Problematic PMIDs (heuristic): no pub types AND no registry ids AND ref_is_clinical_trial_pt_type=False\n",
    "        is_problematic = (\n",
    "            temp_df[\"ref_publication_types\"].isna()\n",
    "            & temp_df[\"ref_all_registry_ids\"].isna()\n",
    "            & (~_safe_bool_series(temp_df[\"ref_is_clinical_trial_pt_type\"]))\n",
    "        )\n",
    "\n",
    "        total_missing_pmids = int(is_problematic.sum())\n",
    "        total_batch_errors = 0  # Can't distinguish without fetch_status\n",
    "        total_articles_parsed = len(temp_df) - total_missing_pmids\n",
    "\n",
    "        # Add fetch_status column for downstream use\n",
    "        temp_df[\"ref_fetch_status\"] = \"success\"\n",
    "        temp_df.loc[is_problematic, \"ref_fetch_status\"] = \"missing\"\n",
    "        trial_data = temp_df.to_dict(\"records\")\n",
    "\n",
    "        print(f\"  ✓ Identified {total_missing_pmids:,} problematic PMIDs from checkpoint data\")\n",
    "else:\n",
    "    total_articles_parsed = 0\n",
    "    total_missing_pmids = 0\n",
    "    total_batch_errors = 0\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6.1 — Main batch fetch loop \n",
    "# -----------------------------------------------------------------------------\n",
    "if len(remaining_pmids) == 0:\n",
    "    print(\"✓ All PMIDs already processed — skipping batch fetch\\n\")\n",
    "    if trial_data:\n",
    "        print(\"Summary from previous runs:\")\n",
    "        print(f\"  Articles parsed (returned by PubMed): {total_articles_parsed:,}\")\n",
    "        print(f\"  Missing PMIDs (not in PubMed): {total_missing_pmids:,}\")\n",
    "        print(f\"  Batch errors encountered: {total_batch_errors:,}\\n\")\n",
    "else:\n",
    "    print(f\"Processing {len(remaining_pmids):,} PMIDs in batches of {BATCH_SIZE}...\")\n",
    "    print(\"Progress bar shows batch completion (not individual PMIDs)\\n\")\n",
    "\n",
    "    batch_results = []\n",
    "    new_articles_parsed = 0\n",
    "    new_missing_pmids = 0\n",
    "    new_batch_errors = 0\n",
    "\n",
    "    for i in tqdm(range(0, len(remaining_pmids), BATCH_SIZE), desc=\"Processing batches\"):\n",
    "        batch = remaining_pmids[i : i + BATCH_SIZE]\n",
    "\n",
    "        try:\n",
    "            handle = Entrez.efetch(\n",
    "                db=\"pubmed\",\n",
    "                id=\",\".join(batch),\n",
    "                rettype=\"xml\",\n",
    "                retmode=\"xml\",\n",
    "            )\n",
    "            records = Entrez.read(handle)\n",
    "            handle.close()\n",
    "\n",
    "            articles = records.get(\"PubmedArticle\", []) or []\n",
    "            returned_pmids = set()\n",
    "\n",
    "            for art in articles:\n",
    "                (\n",
    "                    pmid,\n",
    "                    is_trial,\n",
    "                    pub_types_str,\n",
    "                    nct, # ← This is the primary from extraction\n",
    "                    nct_source,\n",
    "                    all_registry_ids,\n",
    "                    all_ncts,\n",
    "                    all_structured_ncts,\n",
    "                    all_nct_source_pairs,\n",
    "                    all_structured_nct_source_pairs,\n",
    "                    abstract_text,\n",
    "                ) = extract_trial_info(art)\n",
    "\n",
    "                if pmid is None:\n",
    "                    continue\n",
    "\n",
    "                pmid = str(pmid)\n",
    "                returned_pmids.add(pmid)\n",
    "                new_articles_parsed += 1\n",
    "\n",
    "                result = {\n",
    "                    \"ref_pmid\": pmid,\n",
    "                    \"ref_is_clinical_trial_pt_type\": bool(is_trial),\n",
    "                    \"ref_publication_types\": pub_types_str,\n",
    "                    \"ref_primary_nct_number\": nct,  # \"primary\" per extract_trial_info logic\n",
    "                    \"ref_primary_nct_source\": nct_source,\n",
    "                    \"ref_all_registry_ids\": all_registry_ids,\n",
    "                    \"ref_all_nct_numbers\": all_ncts,\n",
    "                    \"ref_all_structured_nct_numbers\": all_structured_ncts,\n",
    "                    \"ref_all_nct_source_pairs\": all_nct_source_pairs,\n",
    "                    \"ref_all_structured_nct_source_pairs\": all_structured_nct_source_pairs,\n",
    "                    \"ref_has_abstract\": bool(abstract_text and str(abstract_text).strip()),  \n",
    "                    \"ref_abstract\": abstract_text,\n",
    "                    \"ref_fetch_status\": \"success\",\n",
    "                }\n",
    "\n",
    "                batch_results.append(result)\n",
    "                trial_data.append(result)\n",
    "                processed_pmids.add(pmid)\n",
    "\n",
    "            # Missing PMIDs (invalid/deleted)\n",
    "            missing = [pm for pm in batch if str(pm) not in returned_pmids]\n",
    "            new_missing_pmids += len(missing)\n",
    "\n",
    "            for pm in missing:\n",
    "                pm = str(pm)\n",
    "                result = {\n",
    "                    \"ref_pmid\": pm,\n",
    "                    \"ref_is_clinical_trial_pt_type\": False,\n",
    "                    \"ref_publication_types\": None,\n",
    "                    \"ref_primary_nct_number\": None,\n",
    "                    \"ref_primary_nct_source\": None,\n",
    "                    \"ref_all_registry_ids\": None,\n",
    "                    \"ref_all_nct_numbers\": None,\n",
    "                    \"ref_all_structured_nct_numbers\": None,\n",
    "                    \"ref_all_nct_source_pairs\": None,\n",
    "                    \"ref_all_structured_nct_source_pairs\": None,\n",
    "                    \"ref_has_abstract\": False,\n",
    "                    \"ref_abstract\": None,\n",
    "                    \"ref_fetch_status\": \"missing\",\n",
    "                }\n",
    "                batch_results.append(result)\n",
    "                trial_data.append(result)\n",
    "                processed_pmids.add(pm)\n",
    "\n",
    "            # Checkpoint save\n",
    "            if len(batch_results) >= CHECKPOINT_INTERVAL:\n",
    "                checkpoint_file = os.path.join(\n",
    "                    checkpoint_dir, f\"checkpoint_{len(trial_data):06d}.csv\"\n",
    "                )\n",
    "                pd.DataFrame(batch_results).to_csv(checkpoint_file, index=False)\n",
    "                batch_results = []\n",
    "\n",
    "            if SLEEP_PER_BATCH:\n",
    "                time.sleep(SLEEP_PER_BATCH)\n",
    "\n",
    "        except Exception as e:\n",
    "            new_batch_errors += 1\n",
    "            print(f\"\\n⚠️ Error with batch starting PMID {batch[0]}: {e}\")\n",
    "\n",
    "            # Mark entire batch as failed\n",
    "            for pm in batch:\n",
    "                pm = str(pm)\n",
    "                result = {\n",
    "                    \"ref_pmid\": pm,\n",
    "                    \"ref_is_clinical_trial_pt_type\": False,\n",
    "                    \"ref_publication_types\": None,\n",
    "                    \"ref_primary_nct_number\": None,\n",
    "                    \"ref_primary_nct_source\": None,\n",
    "                    \"ref_all_registry_ids\": None,\n",
    "                    \"ref_all_nct_numbers\": None,\n",
    "                    \"ref_all_structured_nct_numbers\": None,\n",
    "                    \"ref_all_nct_source_pairs\": None,\n",
    "                    \"ref_all_structured_nct_source_pairs\": None,\n",
    "                    \"ref_has_abstract\": False,\n",
    "                    \"ref_abstract\": None,\n",
    "                    \"ref_fetch_status\": \"error\",\n",
    "                }\n",
    "                batch_results.append(result)\n",
    "                trial_data.append(result)\n",
    "                processed_pmids.add(pm)\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "    # Final checkpoint\n",
    "    if batch_results:\n",
    "        checkpoint_file = os.path.join(checkpoint_dir, f\"checkpoint_{len(trial_data):06d}.csv\")\n",
    "        pd.DataFrame(batch_results).to_csv(checkpoint_file, index=False)\n",
    "        print(\"\\n✓ Saved final checkpoint\")\n",
    "\n",
    "    total_articles_parsed += new_articles_parsed\n",
    "    total_missing_pmids += new_missing_pmids\n",
    "    total_batch_errors += new_batch_errors\n",
    "\n",
    "    print(\"\\nBatch Processing Summary:\")\n",
    "    print(\"Output is trial_data (list of dicts, one per ref_pmid fetch result)\")\n",
    "    print(f\"  New articles parsed: {new_articles_parsed:,}\")\n",
    "    print(f\"  New missing PMIDs: {new_missing_pmids:,}\")\n",
    "    print(f\"  New batch errors: {new_batch_errors:,}\")\n",
    "    print()\n",
    "    print(f\"  Total articles parsed (all runs): {total_articles_parsed:,}\")\n",
    "    print(f\"  Total missing PMIDs (all runs): {total_missing_pmids:,}\")\n",
    "    print(f\"  Total batch errors (all runs): {total_batch_errors:,}\")\n",
    "    print()\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 7: CANONICALIZATION (Clean & Deduplicate) + Core Flags\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 4.7 — Canonicalization: Ensure One Row Per PMID\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "phase3_trials_unique_refs_df = pd.DataFrame(trial_data)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7.0 — Small helpers used only in canonicalization / pairs\n",
    "# -----------------------------------------------------------------------------\n",
    "def _none_like_to_none(x):\n",
    "    \"\"\"Normalize 'NONE'/'nan'/'null'/'' to real None (prevents literal 'NONE').\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    s = str(x).strip()\n",
    "    if s == \"\" or s.lower() in {\"none\", \"nan\", \"null\"}:\n",
    "        return None\n",
    "    return s\n",
    "\n",
    "def _parse_pairs_to_list(pairs_str):\n",
    "    \"\"\"\n",
    "    Parse \"NCT...|source;NCT...|source\" into ordered list of tuples [(nct, src), ...].\n",
    "    First occurrence wins (your upstream already enforces, but we guard anyway).\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    seen = set()\n",
    "    if pd.isna(pairs_str):\n",
    "        return out\n",
    "    for tok in str(pairs_str).split(\";\"):\n",
    "        tok = tok.strip()\n",
    "        if not tok or \"|\" not in tok:\n",
    "            continue\n",
    "        n, src = tok.split(\"|\", 1)\n",
    "        n = str(n).strip().upper()\n",
    "        src = str(src).strip()\n",
    "        m = NCT_REGEX.search(n) if n else None\n",
    "        if not m:\n",
    "            continue\n",
    "        nct = m.group(0).upper()\n",
    "        if nct not in seen:\n",
    "            out.append((nct, src))\n",
    "            seen.add(nct)\n",
    "    return out\n",
    "\n",
    "def _merge_pairs_first_source_wins(values):\n",
    "    \"\"\"\n",
    "    Merge many mapping strings into one mapping string.\n",
    "    First-source-wins per NCT (order-preserving across the input sequence).\n",
    "    \"\"\"\n",
    "    merged = []\n",
    "    seen = set()\n",
    "    for v in values:\n",
    "        for nct, src in _parse_pairs_to_list(v):\n",
    "            if nct not in seen:\n",
    "                merged.append((nct, src))\n",
    "                seen.add(nct)\n",
    "    return \";\".join([f\"{n}|{s}\" for n, s in merged]) if merged else None\n",
    "\n",
    "def _primary_source_from_pairs(pairs_str, primary_nct):\n",
    "    \"\"\"Look up the source for the chosen primary NCT in the mapping string.\"\"\"\n",
    "    primary_nct = _none_like_to_none(primary_nct)\n",
    "    if not primary_nct or pd.isna(pairs_str):\n",
    "        return None\n",
    "    p = str(primary_nct).strip().upper()\n",
    "    for nct, src in _parse_pairs_to_list(pairs_str):\n",
    "        if nct == p:\n",
    "            return src\n",
    "    return None\n",
    "\n",
    "def _parse_ncts_from_semicol_field(val):\n",
    "    \"\"\"Convert 'NCT1;NCT2' into ['NCT1','NCT2'] (deduped/order-preserving).\"\"\"\n",
    "    toks = split_semicolon(val)  # your helper returns uppercase tokens\n",
    "    return extract_ncts_from_token_list(toks)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7.1 — Canonicalize to exactly 1 row per PMID (FIXED + MUCH CLEANER)\n",
    "# -----------------------------------------------------------------------------\n",
    "def canonicalize_phase3_unique_refs(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Canonicalize PMID-level data to 1 row per ref_pmid.\n",
    "\n",
    "    Key outputs:\n",
    "      - all_nct_numbers (deduped, order-preserving)\n",
    "      - primary_nct_number (primary NCT = first in all_nct_numbers)\n",
    "      - all_nct_source_pairs (merged mapping)\n",
    "      - nct_source (source for the PRIMARY NCT, derived from mapping string)\n",
    "      - keeps: ref_is_clinical_trial_pt_type, publication_types, fetch_status, registry ids, structured fields\n",
    "\n",
    "    Important:\n",
    "      - We do NOT rename columns here. Keep nct_number/nct_source as canonical outputs.\n",
    "      - If you want \"primary_nct_number\" etc., create them in the *pairs export*.\n",
    "    \"\"\"\n",
    "    df = df_in.copy()\n",
    "\n",
    "    # Ensure columns exist (old checkpoints won’t crash)\n",
    "    required = {\n",
    "        \"ref_pmid\": None,\n",
    "        \"ref_is_clinical_trial_pt_type\": False,\n",
    "        \"ref_publication_types\": None,\n",
    "        \"ref_primary_nct_number\": None,\n",
    "        \"ref_primary_nct_source\": None,\n",
    "        \"ref_all_registry_ids\": None,\n",
    "        \"ref_all_nct_numbers\": None,\n",
    "        \"ref_all_structured_nct_numbers\": None,\n",
    "        \"ref_all_nct_source_pairs\": None,\n",
    "        \"ref_all_structured_nct_source_pairs\": None,\n",
    "        \"ref_fetch_status\": None,\n",
    "    }\n",
    "    for c, default in required.items():\n",
    "        if c not in df.columns:\n",
    "            df[c] = default\n",
    "\n",
    "\n",
    "    # # ================================================================\n",
    "    # # BACKWARD COMPATIBILITY: MIGRATE OLD COLUMN NAMES\n",
    "    # # ================================================================\n",
    "    # print(\"  🔄 Checking for old column names to migrate...\")\n",
    "    \n",
    "    # # ----------------------------------------------------------------\n",
    "    # # MIGRATE: is_clinical_trial → ref_is_clinical_trial_pt_type\n",
    "    # # ----------------------------------------------------------------\n",
    "    # if \"is_clinical_trial\" in df.columns:\n",
    "    #     if \"ref_is_clinical_trial_pt_type\" in df.columns:\n",
    "    #         # Both exist: merge old into new (old data takes precedence if new is empty)\n",
    "    #         mask_new_empty = df[\"ref_is_clinical_trial_pt_type\"].isna() | (df[\"ref_is_clinical_trial_pt_type\"] == False)\n",
    "    #         mask_old_has_data = df[\"is_clinical_trial\"].notna() & (df[\"is_clinical_trial\"] != False)\n",
    "            \n",
    "    #         # Copy old values where new is empty/False and old has True\n",
    "    #         df.loc[mask_new_empty & mask_old_has_data, \"ref_is_clinical_trial_pt_type\"] = df.loc[mask_new_empty & mask_old_has_data, \"is_clinical_trial\"]\n",
    "            \n",
    "    #         # Drop old column\n",
    "    #         df = df.drop(columns=[\"is_clinical_trial\"])\n",
    "    #         print(\"  ✓ Merged is_clinical_trial → ref_is_clinical_trial_pt_type, dropped old column\")\n",
    "    #     else:\n",
    "    #         # Only old exists: rename it\n",
    "    #         df = df.rename(columns={\"is_clinical_trial\": \"ref_is_clinical_trial_pt_type\"})\n",
    "    #         print(\"  ✓ Renamed is_clinical_trial → ref_is_clinical_trial_pt_type\")\n",
    "    \n",
    "    # # ----------------------------------------------------------------\n",
    "    # # MIGRATE: nct_number → primary_nct_number\n",
    "    # # ----------------------------------------------------------------\n",
    "    # if \"nct_number\" in df.columns:\n",
    "    #     if \"ref_primary_nct_number\" in df.columns:\n",
    "    #         # Both exist: merge (prefer new, fill with old if new is empty)\n",
    "    #         df[\"ref_primary_nct_number\"] = df[\"ref_primary_nct_number\"].fillna(df[\"nct_number\"])\n",
    "    #         df = df.drop(columns=[\"nct_number\"])\n",
    "    #         print(\"  ✓ Merged nct_number → ref_primary_nct_number, dropped old column\")\n",
    "    #     else:\n",
    "    #         # Only old exists: rename it\n",
    "    #         df = df.rename(columns={\"nct_number\": \"ref_primary_nct_number\"})\n",
    "    #         print(\"  ✓ Renamed nct_number → ref_primary_nct_number\")\n",
    "    \n",
    "    # # ----------------------------------------------------------------\n",
    "    # # MIGRATE: nct_source → primary_nct_source\n",
    "    # # ----------------------------------------------------------------\n",
    "    # if \"nct_source\" in df.columns:\n",
    "    #     if \"ref_primary_nct_source\" in df.columns:\n",
    "    #         # Both exist: merge\n",
    "    #         df[\"ref_primary_nct_source\"] = df[\"ref_primary_nct_source\"].fillna(df[\"nct_source\"])\n",
    "    #         df = df.drop(columns=[\"nct_source\"])\n",
    "    #         print(\"  ✓ Merged nct_source → primary_nct_source, dropped old column\")\n",
    "    #     else:\n",
    "    #         # Only old exists: rename it\n",
    "    #         df = df.rename(columns={\"nct_source\": \"ref_primary_nct_source\"})\n",
    "    #         print(\"  ✓ Renamed nct_source → ref_primary_nct_source\")\n",
    "    \n",
    "    # print()\n",
    "    # # ================================================================\n",
    "\n",
    "\n",
    "\n",
    "    # Normalize PMID + normalize NONE-like strings for key fields\n",
    "    df[\"ref_pmid\"] = df[\"ref_pmid\"].apply(_norm_pmid)\n",
    "    df[\"ref_primary_nct_number\"] = df[\"ref_primary_nct_number\"].apply(_none_like_to_none)\n",
    "    df[\"ref_primary_nct_source\"] = df[\"ref_primary_nct_source\"].apply(_none_like_to_none)\n",
    "\n",
    "    # Group if duplicates exist\n",
    "    before_rows = len(df)\n",
    "    has_dupes = df.duplicated(subset=[\"ref_pmid\"], keep=False).any()\n",
    "\n",
    "    def _agg_one_group(g: pd.DataFrame) -> pd.Series:\n",
    "        # ref_is_clinical_trial_pt_type: any True wins\n",
    "        is_trial = bool(g[\"ref_is_clinical_trial_pt_type\"].fillna(False).astype(bool).any())\n",
    "\n",
    "        # publication_types: first non-null\n",
    "        pub_types_val = None\n",
    "        pub_types_nonnull = g[\"ref_publication_types\"].dropna()\n",
    "        if len(pub_types_nonnull):\n",
    "            pub_types_val = str(pub_types_nonnull.iloc[0])\n",
    "\n",
    "        # fetch_status: prefer success > missing > error (lowest = best)\n",
    "        status_priority = {\"success\": 1, \"missing\": 2, \"error\": 3}\n",
    "        fetch_status = \"success\"\n",
    "        if \"ref_fetch_status\" in g.columns:\n",
    "            vals = g[\"ref_fetch_status\"].fillna(\"success\").astype(str).str.lower().tolist()\n",
    "            fetch_status = min(vals, key=lambda x: status_priority.get(x, 99))\n",
    "\n",
    "        # Merge mapping strings (first source wins per NCT)\n",
    "        merged_pairs = _merge_pairs_first_source_wins(g[\"ref_all_nct_source_pairs\"].tolist())\n",
    "\n",
    "        merged_struct_pairs = _merge_pairs_first_source_wins(\n",
    "            g[\"ref_all_structured_nct_source_pairs\"].tolist()\n",
    "        )\n",
    "\n",
    "        # Merge NCT lists from all_nct_numbers (dedupe/order-preserve)\n",
    "        nct_lists = g[\"ref_all_nct_numbers\"].apply(_parse_ncts_from_semicol_field).tolist()\n",
    "        merged_ncts = _dedupe_preserve_order([n for lst in nct_lists for n in (lst or [])])\n",
    "        all_nct_numbers = \";\".join(merged_ncts) if merged_ncts else None\n",
    "\n",
    "        # Merge structured-only lists\n",
    "        st_lists = g[\"ref_all_structured_nct_numbers\"].apply(_parse_ncts_from_semicol_field).tolist()\n",
    "        merged_struct_ncts = _dedupe_preserve_order([n for lst in st_lists for n in (lst or [])])\n",
    "        all_structured_nct_numbers = \";\".join(merged_struct_ncts) if merged_struct_ncts else None\n",
    "\n",
    "        # Merge registry IDs (simple merge/dedupe tokens by semicolon)\n",
    "        reg_lists = g[\"ref_all_registry_ids\"].fillna(\"\").astype(str).tolist()\n",
    "        reg_tokens = []\n",
    "        for s in reg_lists:\n",
    "            for tok in str(s).split(\";\"):\n",
    "                t = tok.strip().upper()\n",
    "                if t:\n",
    "                    reg_tokens.append(t)\n",
    "        reg_tokens = _dedupe_preserve_order(reg_tokens)\n",
    "        all_registry_ids = \";\".join(reg_tokens) if reg_tokens else None\n",
    "\n",
    "        # Primary NCT = first in merged list\n",
    "        primary_nct_number = merged_ncts[0] if merged_ncts else None\n",
    "\n",
    "        # Primary source = look up in merged mapping (authoritative)\n",
    "        nct_source = _primary_source_from_pairs(merged_pairs, primary_nct_number)\n",
    "\n",
    "        has_nct = bool(merged_ncts)\n",
    "\n",
    "        # Check if abstract exists (any row in group has non-empty abstract)\n",
    "        has_abstract = False\n",
    "        if \"ref_abstract\" in g.columns:\n",
    "            reference_has_abstract = bool(\n",
    "                g[\"ref_abstract\"].fillna(\"\").astype(str).str.strip().ne(\"\").any()\n",
    "            )\n",
    "\n",
    "        # Representative PMID value\n",
    "        rep_pmid = g[\"ref_pmid\"].iloc[0]\n",
    "\n",
    "        return pd.Series(\n",
    "            {\n",
    "                \"ref_pmid\": rep_pmid,\n",
    "                \"ref_is_clinical_trial_pt_type\": is_trial,\n",
    "                \"ref_publication_types\": pub_types_val,\n",
    "                \"ref_primary_nct_number\": primary_nct_number,\n",
    "                \"ref_primary_nct_source\": nct_source,\n",
    "                \"ref_all_registry_ids\": all_registry_ids,\n",
    "                \"ref_all_nct_numbers\": all_nct_numbers,\n",
    "                \"ref_all_structured_nct_numbers\": all_structured_nct_numbers,\n",
    "                \"ref_all_nct_source_pairs\": merged_pairs,\n",
    "                \"ref_all_structured_nct_source_pairs\": merged_struct_pairs,\n",
    "                \"ref_has_nct\": has_nct,\n",
    "                \"ref_abstract\": g[\"ref_abstract\"].iloc[0] if \"ref_abstract\" in g.columns else None,  # ← ADD THIS\n",
    "                \"ref_has_abstract\": reference_has_abstract,\n",
    "                \"ref_fetch_status\": fetch_status,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if has_dupes:\n",
    "        print(\"⚠️ Duplicate ref_pmid rows found — collapsing to 1 row per PMID...\")\n",
    "        df_out = (\n",
    "            df.groupby(\"ref_pmid\", dropna=False, sort=False)\n",
    "            .apply(_agg_one_group)\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "    else:\n",
    "        # No dupes: still normalize all_nct_numbers and set primary/source consistently\n",
    "        def _fix_row(row):\n",
    "            # Normalize list\n",
    "            ncts = _parse_ncts_from_semicol_field(row.get(\"ref_all_nct_numbers\"))\n",
    "            ncts = _dedupe_preserve_order(ncts)\n",
    "            row[\"ref_all_nct_numbers\"] = \";\".join(ncts) if ncts else None\n",
    "            row[\"ref_has_nct\"] = bool(ncts)\n",
    "\n",
    "            # Handle abstract\n",
    "            if \"ref_abstract\" not in row or pd.isna(row.get(\"ref_abstract\")):\n",
    "                row[\"ref_abstract\"] = None\n",
    "                row[\"ref_has_abstract\"] = False\n",
    "            else:\n",
    "                row[\"ref_has_abstract\"] = bool(str(row[\"ref_abstract\"]).strip())\n",
    "\n",
    "            # Primary NCT = first in list\n",
    "            row[\"ref_primary_nct_number\"] = ncts[0] if ncts else None\n",
    "\n",
    "            # Ensure mapping string normalized\n",
    "            row[\"ref_all_nct_source_pairs\"] = _merge_pairs_first_source_wins([row.get(\"ref_all_nct_source_pairs\")])\n",
    "\n",
    "            # Primary source from mapping string\n",
    "            row[\"ref_primary_nct_source\"] = _primary_source_from_pairs(row.get(\"ref_all_nct_source_pairs\"), row.get(\"ref_primary_nct_number\"))\n",
    "\n",
    "            # Defaults\n",
    "            if pd.isna(row.get(\"ref_fetch_status\")):\n",
    "                row[\"ref_fetch_status\"] = \"success\"\n",
    "            if pd.isna(row.get(\"ref_is_clinical_trial_pt_type\")):\n",
    "                row[\"ref_is_clinical_trial_pt_type\"] = False\n",
    "\n",
    "            # Structured list normalize (optional)\n",
    "            st = _parse_ncts_from_semicol_field(row.get(\"ref_all_structured_nct_numbers\"))\n",
    "            st = _dedupe_preserve_order(st)\n",
    "            row[\"ref_all_structured_nct_numbers\"] = \";\".join(st) if st else None\n",
    "\n",
    "            # Structured pairs normalize\n",
    "            row[\"ref_all_structured_nct_source_pairs\"] = _merge_pairs_first_source_wins([row.get(\"ref_all_structured_nct_source_pairs\")])\n",
    "\n",
    "            # Registry IDs normalize (optional)\n",
    "            reg = []\n",
    "            for tok in str(row.get(\"ref_all_registry_ids\") or \"\").split(\";\"):\n",
    "                t = tok.strip().upper()\n",
    "                if t:\n",
    "                    reg.append(t)\n",
    "            reg = _dedupe_preserve_order(reg)\n",
    "            row[\"ref_all_registry_ids\"] = \";\".join(reg) if reg else None\n",
    "\n",
    "            return row\n",
    "\n",
    "        df_out = df.apply(_fix_row, axis=1).drop_duplicates(subset=[\"ref_pmid\"], keep=\"first\")\n",
    "\n",
    "    after_rows = len(df_out)\n",
    "\n",
    "    # Quick internal sanity check: no duplicate NCT per PMID after canonicalization\n",
    "    ex = df_out[[\"ref_pmid\", \"ref_all_nct_numbers\"]].copy()\n",
    "    ex[\"__nct\"] = ex[\"ref_all_nct_numbers\"].apply(lambda s: _parse_ncts_from_semicol_field(s))\n",
    "    ex2 = ex.explode(\"__nct\").dropna(subset=[\"__nct\"])\n",
    "    dup_nct_instances = ex2.duplicated(subset=[\"ref_pmid\", \"__nct\"]).sum()\n",
    "\n",
    "    print(f\"  Canonicalization complete: {before_rows:,} → {after_rows:,} rows\")\n",
    "    print(f\"  Duplicate NCT instances within PMID: {dup_nct_instances:,} (should be 0)\")\n",
    "    print()\n",
    "\n",
    "        # ================================================================\n",
    "    # FINAL CLEANUP: Remove any lingering old columns + reorder\n",
    "    # ================================================================\n",
    "    \n",
    "    # Drop any old column names that shouldn't exist\n",
    "    old_columns_to_drop = [\"nct_source\", \"nct_number\", \"is_clinical_trial\"]\n",
    "    for col in old_columns_to_drop:\n",
    "        if col in df_out.columns:\n",
    "            df_out = df_out.drop(columns=[col])\n",
    "            print(f\"  🗑️  Dropped lingering old column: {col}\")\n",
    "    \n",
    "    # Define desired column order\n",
    "    desired_order = [\n",
    "        \"ref_pmid\",\n",
    "        \"ref_publication_types\",\n",
    "        \"ref_is_clinical_trial_pt_type\",\n",
    "        \"ref_primary_nct_number\",\n",
    "        \"ref_primary_nct_source\",\n",
    "        \"ref_all_registry_ids\",\n",
    "        \"ref_all_nct_numbers\",\n",
    "        \"ref_all_structured_nct_numbers\",\n",
    "        \"ref_all_nct_source_pairs\",\n",
    "        \"ref_all_structured_nct_source_pairs\",\n",
    "        \"ref_fetch_status\",\n",
    "        \"ref_has_nct\",\n",
    "        \"ref_abstract\",\n",
    "        \"ref_has_abstract\",\n",
    "    ]\n",
    "    \n",
    "    # Get any extra columns not in desired order (preserve them at end)\n",
    "    existing_cols = df_out.columns.tolist()\n",
    "    extra_cols = [col for col in existing_cols if col not in desired_order]\n",
    "    \n",
    "    # Build final column order (prioritized + extras)\n",
    "    final_col_order = [col for col in desired_order if col in existing_cols] + extra_cols\n",
    "    \n",
    "    # Reorder\n",
    "    df_out = df_out[final_col_order]\n",
    "    \n",
    "    if extra_cols:\n",
    "        print(f\"  ℹ️  Extra columns (not in desired order): {', '.join(extra_cols)}\")\n",
    "    \n",
    "    print(f\"  ✓ Columns reordered: {len(desired_order)} standard columns\")\n",
    "    print()\n",
    "\n",
    "    return df_out\n",
    "\n",
    "# Run canonicalization\n",
    "phase3_trials_unique_refs_df = canonicalize_phase3_unique_refs(phase3_trials_unique_refs_df)\n",
    "\n",
    "# Save canonical PMID-level file (MASTER universe)\n",
    "phase3_trials_unique_refs_output = os.path.join(\n",
    "    OUTPUT_FOLDER, \"phase3_references_with_trials_unique_refs.csv\"\n",
    ")\n",
    "phase3_trials_unique_refs_df.to_csv(phase3_trials_unique_refs_output, index=False)\n",
    "\n",
    "print(f\"✓ Saved MASTER PMID-level table: {phase3_trials_unique_refs_output}\")\n",
    "# Calculate enhanced metrics\n",
    "total_pmids = len(phase3_trials_unique_refs_df)\n",
    "is_trial_count = int(phase3_trials_unique_refs_df['ref_is_clinical_trial_pt_type'].fillna(False).astype(bool).sum())\n",
    "not_trial_count = total_pmids - is_trial_count\n",
    "has_nct_count = int(phase3_trials_unique_refs_df['ref_has_nct'].fillna(False).astype(bool).sum())\n",
    "\n",
    "# NEW: Calculate intersection of trials and NCTs\n",
    "pmids_trials_with_nct = int(\n",
    "    (phase3_trials_unique_refs_df['ref_is_clinical_trial_pt_type'].fillna(False).astype(bool) & \n",
    "     phase3_trials_unique_refs_df['ref_has_nct'].fillna(False).astype(bool)).sum()\n",
    ")\n",
    "pmids_non_trials_with_nct = has_nct_count - pmids_trials_with_nct\n",
    "\n",
    "# Display enhanced tree\n",
    "print(f\"  Rows (unique PMIDs): {total_pmids:,}\")\n",
    "print(f\"  │\")\n",
    "print(f\"  ├── Classified as clinical trials (ref_is_clinical_trial_pt_type=True): {is_trial_count:,} ({is_trial_count/total_pmids*100:.1f}%)\")\n",
    "print(f\"  └── NOT classified as clinical trials (ref_is_clinical_trial_pt_type=False): {not_trial_count:,} ({not_trial_count/total_pmids*100:.1f}%)\")\n",
    "print(f\"  \")\n",
    "print(f\"  PMIDs with NCT numbers (ref_has_nct=True): {has_nct_count:,} ({has_nct_count/total_pmids*100:.1f}%)\")\n",
    "print(f\"  │\")\n",
    "print(f\"  ├── Clinical trials with NCTs: {pmids_trials_with_nct:,}\")\n",
    "print(f\"  │   (intersection: ref_is_clinical_trial_pt_type=True AND ref_has_nct=True)\")\n",
    "print(f\"  │\")\n",
    "print(f\"  └── Non-trials with NCTs: {pmids_non_trials_with_nct:,}\")\n",
    "print(f\"      (Reviews, meta-analyses, commentaries about trials)\")\n",
    "print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7.2 — Export missing/problematic PMIDs (optional)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MISSING/PROBLEMATIC PMIDs\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if \"ref_fetch_status\" in phase3_trials_unique_refs_df.columns:\n",
    "    missing_pmids_df = phase3_trials_unique_refs_df.loc[\n",
    "        phase3_trials_unique_refs_df[\"ref_fetch_status\"].astype(str).str.lower().eq(\"missing\"),\n",
    "        [\"ref_pmid\"],\n",
    "    ].copy()\n",
    "\n",
    "    error_pmids_df = phase3_trials_unique_refs_df.loc[\n",
    "        phase3_trials_unique_refs_df[\"ref_fetch_status\"].astype(str).str.lower().eq(\"error\"),\n",
    "        [\"ref_pmid\"],\n",
    "    ].copy()\n",
    "\n",
    "    if len(missing_pmids_df) > 0:\n",
    "        missing_output = os.path.join(OUTPUT_FOLDER, \"phase3_missing_pmids.csv\")\n",
    "        missing_pmids_df.to_csv(missing_output, index=False)\n",
    "        print(f\"✓ Saved missing PMIDs: {missing_output}\")\n",
    "        print(f\"  PMIDs missing from PubMed: {len(missing_pmids_df):,}\")\n",
    "        print(f\"  Sample: {missing_pmids_df['ref_pmid'].head(10).tolist()}\")\n",
    "    else:\n",
    "        print(\"✓ No missing PMIDs (all found in PubMed)\")\n",
    "\n",
    "    if len(error_pmids_df) > 0:\n",
    "        error_output = os.path.join(OUTPUT_FOLDER, \"phase3_error_pmids.csv\")\n",
    "        error_pmids_df.to_csv(error_output, index=False)\n",
    "        print(f\"\\n✓ Saved error PMIDs: {error_output}\")\n",
    "        print(f\"  PMIDs with fetch errors: {len(error_pmids_df):,}\")\n",
    "        print(f\"  Sample: {error_pmids_df['ref_pmid'].head(10).tolist()}\")\n",
    "    else:\n",
    "        print(\"\\n✓ No batch errors (all fetches successful)\")\n",
    "else:\n",
    "    print(\"ℹ️ No fetch_status column found — treating all PMIDs as successfully fetched\")\n",
    "\n",
    "print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7.3 — Build PMID–NCT pairs (MASTER) with per-NCT provenance (SIMPLIFIED)\n",
    "# -----------------------------------------------------------------------------\n",
    "def build_phase3_pmid_nct_pairs_master(phase3_unique_pmids_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    One row per (PMID, NCT) from the canonical Phase 3 table.\n",
    "\n",
    "    Outputs include:\n",
    "      - primary_nct_number / primary_nct_source (PMID-level)\n",
    "      - nct_source (per-NCT source from all_nct_source_pairs)\n",
    "      - is_primary_nct_for_pmid\n",
    "      - nct_order_in_pmid (encounter order in all_nct_numbers)\n",
    "    \"\"\"\n",
    "    df = phase3_unique_pmids_df.copy()\n",
    "\n",
    "    # Ensure required cols exist\n",
    "    for col, default in {\n",
    "        \"ref_pmid\": None,\n",
    "        \"ref_all_nct_numbers\": None,\n",
    "        \"ref_primary_nct_number\": None,            # canonical primary\n",
    "        \"ref_primary_nct_source\": None,            # canonical primary source\n",
    "        \"ref_all_nct_source_pairs\": None,  # per-NCT mapping string\n",
    "        \"ref_is_clinical_trial_pt_type\": False,\n",
    "        \"ref_publication_types\": None,\n",
    "    }.items():\n",
    "        if col not in df.columns:\n",
    "            df[col] = default\n",
    "\n",
    "    # Normalize\n",
    "    df[\"ref_pmid\"] = df[\"ref_pmid\"].apply(_norm_pmid)\n",
    "    df[\"ref_primary_nct_number\"] = df[\"ref_primary_nct_number\"].apply(_none_like_to_none)\n",
    "    df[\"ref_primary_nct_source\"] = df[\"ref_primary_nct_source\"].apply(_none_like_to_none)\n",
    "\n",
    "    # Build list of NCTs per PMID in the canonical order\n",
    "    df[\"__nct_list\"] = df[\"ref_all_nct_numbers\"].apply(_parse_ncts_from_semicol_field)\n",
    "\n",
    "    # Primary fields (clean and never \"NONE\")\n",
    "    df[\"ref_primary_nct_number\"] = df[\"ref_primary_nct_number\"].apply(lambda x: str(x).strip().upper() if _none_like_to_none(x) else None)\n",
    "    df[\"ref_primary_nct_source\"] = df[\"ref_primary_nct_source\"].apply(lambda x: str(x).strip() if _none_like_to_none(x) else None)\n",
    "\n",
    "    # Build PMID -> {NCT: source} dict using the mapping string\n",
    "    def _pairs_to_dict(pairs_str):\n",
    "        out = {}\n",
    "        for nct, src in _parse_pairs_to_list(pairs_str):\n",
    "            if nct not in out:\n",
    "                out[nct] = src\n",
    "        return out\n",
    "\n",
    "    pmid_to_map = (\n",
    "        df[[\"ref_pmid\", \"ref_all_nct_source_pairs\"]]\n",
    "        .drop_duplicates(subset=[\"ref_pmid\"])\n",
    "        .assign(__map=lambda d: d[\"ref_all_nct_source_pairs\"].apply(_pairs_to_dict))\n",
    "        .set_index(\"ref_pmid\")[\"__map\"]\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    # Explode\n",
    "    pairs = df[\n",
    "        [\"ref_pmid\", \"__nct_list\", \"ref_primary_nct_number\", \"ref_primary_nct_source\", \"ref_is_clinical_trial_pt_type\", \"ref_publication_types\"]\n",
    "    ].explode(\"__nct_list\")\n",
    "\n",
    "    pairs = pairs.rename(\n",
    "        columns={\n",
    "            \"__nct_list\": \"ref_nct_number\",\n",
    "            \"ref_is_clinical_trial_pt_type\": \"ref_is_pubmed_clinical_trial\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    pairs = pairs.loc[pairs[\"ref_primary_nct_number\"].notna()].copy()\n",
    "    pairs[\"ref_primary_nct_number\"] = pairs[\"ref_primary_nct_number\"].astype(str).str.upper().str.strip()\n",
    "\n",
    "    # Per-NCT source\n",
    "    pairs[\"ref_nct_source\"] = pairs.apply(\n",
    "        lambda r: pmid_to_map.get(r[\"ref_pmid\"], {}).get(r[\"ref_primary_nct_number\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Primary flag + order\n",
    "    pairs[\"ref_is_primary_nct_for_pmid\"] = pairs[\"ref_nct_number\"].eq(pairs[\"ref_primary_nct_number\"])\n",
    "    pairs[\"ref_nct_order_in_pmid\"] = pairs.groupby(\"ref_pmid\").cumcount() + 1\n",
    "\n",
    "    # Nice sort\n",
    "    pairs = pairs.sort_values([\"ref_pmid\", \"ref_nct_order_in_pmid\"], ascending=[True, True]).reset_index(drop=True)\n",
    "    return pairs\n",
    "\n",
    "# Build + save MASTER pairs\n",
    "phase3_pmid_nct_pairs_master_df = build_phase3_pmid_nct_pairs_master(phase3_trials_unique_refs_df)\n",
    "\n",
    "pairs_output = os.path.join(OUTPUT_FOLDER, \"phase3_pmid_nct_pairs_master.csv\")\n",
    "phase3_pmid_nct_pairs_master_df.to_csv(pairs_output, index=False)\n",
    "print(f\"✓ Saved MASTER PMID–NCT pairs table: {pairs_output}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 9: SUMMARY STATISTICS — PMID-LEVEL (CANONICAL) + NCT-LEVEL (PAIRS)\n",
    "# =============================================================================\n",
    "# Purpose:\n",
    "#   - Produce human-readable “trees” that explain Phase 3 coverage:\n",
    "#       (A) PMID-level: trials vs registry IDs vs NCT mentions\n",
    "#       (B) NCT-level (pairs table): unique PMIDs / total pairs / unique NCTs\n",
    "#       (C) A second NCT-level tree restricted to PubMed clinical trials\n",
    "#\n",
    "# Design principles:\n",
    "#   - DO NOT permanently add flags/columns to your master dfs\n",
    "#   - Fail fast if expected objects/columns are missing\n",
    "#   - Provide “helper text” that shows how counts relate (adds/subtracts)\n",
    "#   - Keep concepts distinct:\n",
    "#       • \"PubMed clinical trial\" is determined by ref_is_clinical_trial_pt_type\n",
    "#       • \"Mentions registry ID\" is about text fields (all_registry_ids)\n",
    "#       • \"Mentions NCT\" is about NCT tokens present (prefer all_nct_numbers)\n",
    "#       • \"Pairs table\" includes ONLY PMIDs with ≥1 NCT (by construction)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 4.9 — Summary Statistics (PMID-level + NCT-level)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 9.0 — REQUIRED OBJECTS (fail fast)\n",
    "# -----------------------------------------------------------------------------\n",
    "required_globals = [\n",
    "    \"phase3_trials_unique_refs_df\",        # canonical PMID-level table (MASTER)\n",
    "    \"phase3_pmid_nct_pairs_master_df\",     # canonical pairs table (MASTER)\n",
    "    \"NCT_REGEX\",\n",
    "    \"split_semicolon\",\n",
    "    \"pd\",\n",
    "]\n",
    "missing = [g for g in required_globals if g not in globals()]\n",
    "if missing:\n",
    "    raise NameError(\n",
    "        \"Missing required objects for Section 9:\\n\"\n",
    "        + \"\\n\".join([f\"  - {g}\" for g in missing])\n",
    "        + \"\\n\\nExpected you to have already created:\"\n",
    "        + \"\\n  - phase3_trials_unique_refs_df (canonical PMID table)\"\n",
    "        + \"\\n  - phase3_pmid_nct_pairs_master_df (PMID–NCT pairs table)\"\n",
    "    )\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 9.1 — SMALL SAFE HELPERS\n",
    "# -----------------------------------------------------------------------------\n",
    "def _series_nonempty(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"True only for meaningful values (treat placeholder strings as empty).\"\"\"\n",
    "    s = series.fillna(\"\").astype(str).str.strip()\n",
    "    empty_like = {\"\", \"nan\", \"none\", \"null\", \"<na>\", \"na\"}\n",
    "    return ~s.str.lower().isin(empty_like)\n",
    "\n",
    "def _safe_bool(series: pd.Series) -> pd.Series:\n",
    "    return series.fillna(False).astype(bool)\n",
    "\n",
    "def _series_has_any_nct(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"True if any semicolon token matches NCT_REGEX.\"\"\"\n",
    "    return series.fillna(\"\").apply(\n",
    "        lambda x: any(NCT_REGEX.search(tok) for tok in split_semicolon(x))\n",
    "    )\n",
    "\n",
    "def _normalize_pmid_str(series: pd.Series) -> pd.Series:\n",
    "    return series.fillna(\"\").astype(str).str.strip()\n",
    "\n",
    "def _normalize_nct_str(series: pd.Series) -> pd.Series:\n",
    "    return series.fillna(\"\").astype(str).str.upper().str.strip()\n",
    "\n",
    "def _get_primary_colname(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Some versions store the canonical primary as primary_nct_number;\n",
    "    some store it as nct_number. Prefer primary_nct_number if present.\n",
    "    \"\"\"\n",
    "    if \"primary_nct_number\" in df.columns:\n",
    "        return \"primary_nct_number\"\n",
    "    return \"primary_nct_number\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 9.2 — TRIALS-ONLY NCT SUBCOUNTS (computed from PAIRS)\n",
    "# -----------------------------------------------------------------------------\n",
    "def _compute_trials_only_pmid_nct_breakdown(pairs_df: pd.DataFrame, pmid_df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Computes the two numbers you wanted for the tree injection:\n",
    "\n",
    "      508 PMIDs with NCT(s)\n",
    "      ├── ___ PMIDs with ONLY a primary NCT\n",
    "      └── ___ PMIDs with primary + ≥1 additional NCT\n",
    "\n",
    "    Definitions:\n",
    "      - \"PMID with NCT(s)\" in pairs == PMID appears at least once in pairs table.\n",
    "      - \"ONLY a primary NCT\" == exactly 1 distinct NCT for that PMID.\n",
    "      - \"primary + ≥1 additional\" == 2+ distinct NCTs for that PMID.\n",
    "\n",
    "    Trial restriction:\n",
    "      - If pairs_df has ref_is_pubmed_clinical_trial, use it.\n",
    "      - Else, fall back to pmid_df.ref_is_clinical_trial_pt_type by PMID join/set.\n",
    "    \"\"\"\n",
    "    df = pairs_df.copy()\n",
    "\n",
    "    # Required columns\n",
    "    for c in [\"ref_pmid\", \"ref_primary_nct_number\"]:\n",
    "        if c not in df.columns:\n",
    "            raise KeyError(f\"Pairs table missing required column: {c}\")\n",
    "\n",
    "    df[\"ref_pmid\"] = _normalize_pmid_str(df[\"ref_pmid\"])\n",
    "    df[\"ref_primary_nct_number\"] = _normalize_nct_str(df[\"ref_primary_nct_number\"])\n",
    "\n",
    "    # Remove empty rows defensively\n",
    "    df = df.loc[(df[\"ref_pmid\"] != \"\") & (df[\"ref_primary_nct_number\"] != \"\")].copy()\n",
    "\n",
    "    # Restrict to trials\n",
    "    if \"ref_is_pubmed_clinical_trial\" in df.columns:\n",
    "        df_trials = df.loc[df[\"ref_is_pubmed_clinical_trial\"].fillna(False).astype(bool)].copy()\n",
    "        trials_filter_note = \"Filtered using pairs_df.ref_is_pubmed_clinical_trial\"\n",
    "    else:\n",
    "        if \"ref_pmid\" not in pmid_df.columns or \"ref_is_clinical_trial_pt_type\" not in pmid_df.columns:\n",
    "            raise KeyError(\"Need ref_pmid + ref_is_clinical_trial_pt_type in PMID table to filter pairs to trials.\")\n",
    "        tmp = pmid_df[[\"ref_pmid\", \"ref_is_clinical_trial_pt_type\"]].copy()\n",
    "        tmp[\"ref_pmid\"] = _normalize_pmid_str(tmp[\"ref_pmid\"])\n",
    "        tmp[\"ref_is_clinical_trial_pt_type\"] = tmp[\"ref_is_clinical_trial_pt_type\"].fillna(False).astype(bool)\n",
    "        trial_set = set(tmp.loc[tmp[\"ref_is_clinical_trial_pt_type\"], \"ref_pmid\"].tolist())\n",
    "        df_trials = df.loc[df[\"ref_pmid\"].isin(trial_set)].copy()\n",
    "        trials_filter_note = \"Filtered using PMID table ref_is_clinical_trial_pt_type (fallback)\"\n",
    "\n",
    "    # Count distinct NCTs per PMID (trials-only)\n",
    "    ncts_per_pmid = df_trials.groupby(\"ref_pmid\")[\"ref_nct_number\"].nunique()\n",
    "\n",
    "    pmids_with_ncts = int(ncts_per_pmid.shape[0])        # expected: 508\n",
    "    pmids_only_primary = int((ncts_per_pmid == 1).sum()) # exactly 1 NCT\n",
    "    pmids_primary_plus = int((ncts_per_pmid >= 2).sum()) # 2+ NCTs\n",
    "\n",
    "    return {\n",
    "        \"pmids_with_ncts\": pmids_with_ncts,\n",
    "        \"pmids_only_primary\": pmids_only_primary,\n",
    "        \"pmids_primary_plus\": pmids_primary_plus,\n",
    "        \"trials_filter_note\": trials_filter_note,\n",
    "    }\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 9.3 — PMID-LEVEL TREE (canonical PMID table)\n",
    "# -----------------------------------------------------------------------------\n",
    "def print_pmid_tree(df_in: pd.DataFrame, label: str, trials_only_subcounts: dict = None) -> dict:\n",
    "    \"\"\"\n",
    "    Prints the PMID-level tree and injects the trials-only breakdown under:\n",
    "      \"⭐ ___ PMIDs with NCT(s)\"\n",
    "    in the trial+registry branch.\n",
    "\n",
    "    Important scope notes:\n",
    "      - \"PubMed clinical trial\" comes from is_clinical_trial_pt_type.\n",
    "      - \"Mentions registry ID\" comes from all_registry_ids non-empty.\n",
    "      - \"Mentions NCT\" comes from all_nct_numbers if present; else regex scan of all_registry_ids.\n",
    "    \"\"\"\n",
    "    df = df_in.copy()\n",
    "\n",
    "    # Safe defaults\n",
    "    if \"ref_pmid\" not in df.columns:\n",
    "        df[\"ref_pmid\"] = None\n",
    "    if \"ref_is_clinical_trial_pt_type\" not in df.columns:\n",
    "        df[\"ref_is_clinical_trial_pt_type\"] = False\n",
    "    if \"ref_all_registry_ids\" not in df.columns:\n",
    "        df[\"ref_all_registry_ids\"] = None\n",
    "    if \"ref_all_nct_numbers\" not in df.columns:\n",
    "        df[\"ref_all_nct_numbers\"] = None\n",
    "\n",
    "    primary_col = _get_primary_colname(df)\n",
    "    if primary_col not in df.columns:\n",
    "        df[primary_col] = None\n",
    "\n",
    "    df[\"ref_pmid\"] = _normalize_pmid_str(df[\"ref_pmid\"])\n",
    "\n",
    "    # Core masks\n",
    "    m_trial = _safe_bool(df[\"ref_is_clinical_trial_pt_type\"])\n",
    "    m_has_registry = _series_nonempty(df[\"ref_all_registry_ids\"]).astype(bool)\n",
    "\n",
    "    # Prefer all_nct_numbers if it has any real values; else fallback\n",
    "    if _series_nonempty(df[\"ref_all_nct_numbers\"]).any():\n",
    "        m_has_nct = _series_has_any_nct(df[\"ref_all_nct_numbers\"]).astype(bool)\n",
    "        nct_detection_note = \"NCT mention detected from all_nct_numbers (preferred).\"\n",
    "    else:\n",
    "        m_has_nct = _series_has_any_nct(df[\"ref_all_registry_ids\"]).astype(bool)\n",
    "        nct_detection_note = \"NCT mention detected by regex scanning all_registry_ids (fallback).\"\n",
    "\n",
    "    m_registry_no_nct = m_has_registry & (~m_has_nct)\n",
    "\n",
    "    # Trial branch\n",
    "    m_trial_registry = m_trial & m_has_registry\n",
    "    m_trial_nct = m_trial & m_has_nct\n",
    "    m_trial_registry_no_nct = m_trial & m_registry_no_nct\n",
    "    m_trial_no_registry = m_trial & (~m_has_registry)\n",
    "\n",
    "    # Non-trial branch\n",
    "    m_nontrial = ~m_trial\n",
    "    m_nontrial_registry = m_nontrial & m_has_registry\n",
    "    m_nontrial_nct = m_nontrial & m_has_nct\n",
    "    m_nontrial_registry_no_nct = m_nontrial & m_registry_no_nct\n",
    "\n",
    "    # Optional: primary highlight (trial PMIDs with a primary field non-empty)\n",
    "    m_has_primary = _series_nonempty(df[primary_col]).astype(bool)\n",
    "    m_trial_primary = m_trial & m_has_primary\n",
    "\n",
    "    # Counts\n",
    "    total_pmids = int((df[\"ref_pmid\"] != \"\").sum())\n",
    "    n_trials = int(m_trial.sum())\n",
    "    n_nontrials = int(m_nontrial.sum())\n",
    "\n",
    "    n_trial_registry = int(m_trial_registry.sum())\n",
    "    n_trial_nct = int(m_trial_nct.sum())\n",
    "    n_trial_registry_no_nct = int(m_trial_registry_no_nct.sum())\n",
    "    n_trial_no_registry = int(m_trial_no_registry.sum())\n",
    "\n",
    "    n_registry_any = int(m_has_registry.sum())\n",
    "    n_nct_any = int(m_has_nct.sum())\n",
    "    n_registry_no_nct = int(m_registry_no_nct.sum())\n",
    "\n",
    "    n_nontrial_registry = int(m_nontrial_registry.sum())\n",
    "    n_nontrial_nct = int(m_nontrial_nct.sum())\n",
    "    n_nontrial_registry_no_nct = int(m_nontrial_registry_no_nct.sum())\n",
    "\n",
    "    n_trials_with_primary = int(m_trial_primary.sum())\n",
    "\n",
    "    # Print tree\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(f\"PMID-LEVEL RESULTS TREE — {label}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# TREE 1: CLINICAL TRIAL CLASSIFICATION (Publication Type)\n",
    "# ================================================================\n",
    "    print(\"\\n📋 TREE 1: Clinical Trial Classification (ref_is_clinical_trial_pt_type)\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "   \n",
    "    lines = [\n",
    "        f\"{total_pmids:,} PMIDs in table (see: phase2_references_with_trials_unique_refs.csv)\",\n",
    "        \"│\",\n",
    "        f\"├── {n_trials:,} PubMed-classified clinical trial PMIDs (ref_is_clinical_trial_pt_type=True)\",\n",
    "        # f\"│   ├── {n_trials_with_primary:,} PMIDs with a PRIMARY NCT field populated ({primary_col} non-empty)\",\n",
    "        f\"│   ├── {n_trial_registry:,} PMIDs that mention ANY registry ID (ref_is_clinical_trial_pt_type = True AND ref_all_registry_ids NOT NAN)\",\n",
    "        f\"│   │   ├── ⭐ {n_trial_nct:,} PMIDs with NCT(s) (ref_is_clinical_trial_pt_type = True AND ref_all_registry_ids NOT NAN AND ref_primary_nct_number NOT BLANK)\",\n",
    "    ]\n",
    "\n",
    "    # Inject the requested breakdown if provided\n",
    "    if trials_only_subcounts is not None:\n",
    "        a = trials_only_subcounts[\"pmids_only_primary\"]\n",
    "        b = trials_only_subcounts[\"pmids_primary_plus\"]\n",
    "        lines.extend([\n",
    "            f\"│   │   │   ├── {a:,} PMIDs with ONLY a primary NCT (i.e., exactly 1 NCT in pairs: all_nct_numbers has only one NCT)\",\n",
    "            f\"│   │   │   └── {b:,} PMIDs with primary + ≥1 additional NCT (i.e., 2+ NCTs in pairs: all_nct_numbers has more than one NCT)\",\n",
    "            #f\"│   │   │       (check: {a:,} + {b:,} = {(a+b):,})\",\n",
    "        ])\n",
    "\n",
    "    lines.extend([\n",
    "        f\"│   │   └── {n_trial_registry_no_nct:,} PMIDs with registry IDs but NO PRIMARY NCT (ref_is_clinical_trial_pt_type = True AND ref_all_registry_ids NOT NAN AND primary_nct_number IS BLANK)\",\n",
    "        f\"│   └── {n_trial_no_registry:,} PMIDs with NO registry ID mentioned (count where ref_is_clinical_trial_pt_type = True AND ref_all_registry_ids = NAN)\",\n",
    "        \"│\",\n",
    "        # f\"├── {n_registry_any:,} PMIDs that mention SOME registry ID (any type)  (all_registry_ids NOT NAN)\",\n",
    "        # f\"│   ├── {n_nct_any:,} PMIDs with any NCT(s) mentioned (all_registry_ids NOT NAN AND all_NCT_numbers NOT Blank)\",\n",
    "        # f\"│   └── {n_registry_no_nct:,} PMIDs with any registry IDs but NO NCT numbers (all_registry_ids NOT NAN AND all_NCT_numbers IS Blank)\",\n",
    "        \"│\",\n",
    "        f\"└── {n_nontrials:,} NOT PubMed-classified clinical trial PMIDs  (= {total_pmids:,} - {n_trials:,}, ref_is_clinical_trial_pt_type=False)\",\n",
    "        f\"    └── {n_nontrial_registry:,} non-trial PMIDs that mention registry IDs anyway (ref_is_clinical_trial_pt_type=False, ref_all_registry_ids NOT NAN)\",\n",
    "        f\"        ├── {n_nontrial_nct:,} of those mention NCT(s) (ref_is_clinical_trial_pt_type=False, ref_all_registry_ids NOT NAN, ref_all_nct_numbers NOT Blank)\",\n",
    "        f\"        └── {n_nontrial_registry_no_nct:,} of those have registry IDs but NO NCT (ref_is_clinical_trial_pt_type=False, ref_all_registry_ids NOT NAN, ref_all_nct_numbers IS Blank)\",\n",
    "    ])\n",
    "\n",
    "    print(\"\\n\".join(lines))\n",
    "\n",
    "    # ================================================================\n",
    "    # TREE 2: REGISTRY ID MENTIONS (All PMIDs, regardless of trial classification)\n",
    "    # ================================================================\n",
    "    print(\"\\n\\n🔗 TREE 2: Registry ID Mentions (ref_all_registry_ids field)\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    registry_lines = [\n",
    "        f\"{total_pmids:,} PMIDs in table (see: phase2_references_with_trials_unique_refs.csv)\",\n",
    "        \"│\",\n",
    "        f\"├── {n_registry_any:,} PMIDs that mention ANY registry ID (ref_all_registry_ids NOT NAN)\",\n",
    "        f\"│   │   (includes both publication-type-trials and non-trials)\",\n",
    "        f\"│   │\",\n",
    "        f\"│   ├── {n_nct_any:,} PMIDs with NCT number(s) (ref_all_registry_ids NOT NAN AND ref_all_nct_numbers NOT Blank )\",\n",
    "        f\"│   │   ├── From trials: {n_trial_nct:,} (ref_all_registry_ids NOT NAN AND ref_all_nct_numbers NOT NAN AND ref_is_clinical_trial_pt_type True) \",\n",
    "        f\"│   │   └── From non-trials: {n_nontrial_nct:,}, (ref_all_registry_ids NOT NAN AND ref_all_nct_numbers NOT NAN AND ref_is_clinical_trial_pt_type False)\",\n",
    "        f\"│   │\",\n",
    "        f\"│   └── {n_registry_no_nct:,} PMIDs with registry IDs but NO NCT numbers (ref_all_registry_ids NOT NAN AND ref_all_nct_numbers IS Blank)\",\n",
    "        f\"│       ├── From trials: {n_trial_registry_no_nct:,} (ref_all_registry_ids NOT NAN AND ref_all_nct_numbers IS Blank AND ref_is_clinical_trial_pt_type True)\",\n",
    "        f\"│       └── From non-trials: {n_nontrial_registry_no_nct:,} (ref_all_registry_ids NOT NAN AND ref_all_nct_numbers IS Blank AND ref_is_clinical_trial_pt_type False)\",\n",
    "        \"│\",\n",
    "        f\"└── {total_pmids - n_registry_any:,} PMIDs with NO registry IDs mentioned (ref_all_registry_ids IS NAN)\",\n",
    "        f\"    ├── From trials: {n_trial_no_registry:,} (ref_all_registry_ids IS NAN AND ref_is_clinical_trial_pt_type True)\",\n",
    "        f\"    └── From non-trials: {n_nontrials - n_nontrial_registry:,} (ref_all_registry_ids IS NAN AND ref_is_clinical_trial_pt_type False)\",\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\".join(registry_lines))\n",
    "\n",
    "    # Helper text (with arithmetic + scope reminders)\n",
    "    print(\"\\n\\nHOW THESE NUMBERS RELATE (helper text):\")\n",
    "    print(\"-\" * 70)\n",
    "    print(\"TREE 1 (Clinical Trial Classification):\")\n",
    "    print(f\"  • Trial partition (adds up exactly): {total_pmids:,} = {n_trials:,} (trials) + {n_nontrials:,} (non-trials)\")\n",
    "    print(f\"  • Within trials: {n_trials:,} = {n_trial_registry:,} (with registry) + {n_trial_no_registry:,} (no registry)\")\n",
    "    print()\n",
    "    print(\"TREE 2 (Registry ID Mentions):\")\n",
    "    print(f\"  • Registry partition (adds up exactly): {total_pmids:,} = {n_registry_any:,} (with registry) + {total_pmids - n_registry_any:,} (no registry)\")\n",
    "    print(f\"  • Within registry mentions: {n_registry_any:,} = {n_nct_any:,} (with NCT) + {n_registry_no_nct:,} (no NCT)\")\n",
    "    print()\n",
    "    print(\"RELATIONSHIP BETWEEN TREES:\")\n",
    "    print(\"  • These are INDEPENDENT axes - an article can be:\")\n",
    "    print(\"    - A trial WITH registry IDs (most common for trials)\")\n",
    "    print(\"    - A trial WITHOUT registry IDs (underreported trials)\")\n",
    "    print(\"    - NOT a trial but WITH registry IDs (reviews/meta-analyses)\")\n",
    "    print(\"    - NOT a trial and NO registry IDs (other literature)\")\n",
    "    print()\n",
    "    print(\"⭐ HIGHLIGHTED COHORT:\")\n",
    "    print(f\"  • {n_trial_nct:,} trials with NCT(s) = the main analysis cohort\")\n",
    "    print(\"  • This is the intersection of Tree 1 (trials) and Tree 2 (NCT mentions)\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    return {\n",
    "        \"total_pmids\": total_pmids,\n",
    "        \"trial_pmids\": n_trials,\n",
    "        \"trial_pmids_with_nct_tree\": n_trial_nct,\n",
    "        \"pmids_with_any_nct_tree\": n_nct_any,\n",
    "        \"pmids_with_any_registry_tree\": n_registry_any,\n",
    "    }\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 9.4 — PAIRS / NCT-LEVEL TREE (with PRIMARY vs SECONDARY unique NCT branch)\n",
    "# -----------------------------------------------------------------------------\n",
    "def print_pairs_tree(pairs_df: pd.DataFrame, label: str) -> dict:\n",
    "    \"\"\"\n",
    "    Prints a pairs/NCT-level tree and nests PRIMARY vs SECONDARY unique NCT counts under:\n",
    "        \"unique NCTs represented\"\n",
    "\n",
    "    Definitions:\n",
    "      - unique PRIMARY NCTs: unique primary_nct_number values across PMIDs represented\n",
    "      - unique SECONDARY NCTs: unique nct_number values in non-primary rows\n",
    "      - Note: a secondary NCT can still be the primary NCT of a different PMID.\n",
    "    \"\"\"\n",
    "    df = pairs_df.copy()\n",
    "\n",
    "    # Required columns\n",
    "    for col in [\"ref_pmid\", \"ref_nct_number\"]:\n",
    "        if col not in df.columns:\n",
    "            raise KeyError(f\"Pairs table missing required column: {col}\")\n",
    "\n",
    "    # Optional columns for primary logic\n",
    "    # (If missing, we can still print the basic tree, but primary/secondary counts will be limited.)\n",
    "    has_primary_cols = (\"ref_primary_nct_number\" in df.columns) and (\"ref_is_primary_nct_for_pmid\" in df.columns)\n",
    "\n",
    "    # Normalize & filter empties\n",
    "    df = df.loc[df[\"ref_pmid\"].notna() & df[\"ref_nct_number\"].notna()].copy()\n",
    "    df[\"ref_pmid\"] = _normalize_pmid_str(df[\"ref_pmid\"])\n",
    "    df[\"ref_nct_number\"] = _normalize_nct_str(df[\"ref_nct_number\"])  # ✅ This is the exploded NCT\n",
    "    df = df.loc[(df[\"ref_pmid\"] != \"\") & (df[\"ref_nct_number\"] != \"\")].copy()\n",
    "    \n",
    "    total_pairs = int(len(df))\n",
    "    unique_pmids = int(df[\"ref_pmid\"].nunique())\n",
    "    unique_ncts = int(df[\"ref_nct_number\"].nunique())  # ✅ CHANGE THIS - count all NCTs\n",
    "    extra_pairs = total_pairs - unique_pmids\n",
    "    \n",
    "    # NCTs per PMID distribution\n",
    "    ncts_per_pmid = df.groupby(\"ref_pmid\")[\"ref_nct_number\"].nunique()  # ✅ Already correct\n",
    "    n_pmid_1 = int((ncts_per_pmid == 1).sum())\n",
    "    n_pmid_2 = int((ncts_per_pmid == 2).sum())\n",
    "    n_pmid_3plus = int((ncts_per_pmid >= 3).sum())\n",
    "\n",
    "    # Calculate pairs contributed by each group\n",
    "    pairs_from_1nct = n_pmid_1 * 1\n",
    "    pairs_from_2nct = n_pmid_2 * 2\n",
    "    pairs_from_3plus = total_pairs - pairs_from_1nct - pairs_from_2nct\n",
    "\n",
    "    # Calculate primary vs non-primary for each group\n",
    "    primary_from_3plus = n_pmid_3plus\n",
    "    nonprimary_from_3plus = pairs_from_3plus - primary_from_3plus\n",
    "\n",
    "    # Primary vs secondary unique-NCT counts\n",
    "    unique_primary_ncts = None\n",
    "    unique_secondary_ncts = None\n",
    "\n",
    "    if has_primary_cols:\n",
    "        tmp = df.copy()\n",
    "        tmp[\"ref_primary_nct_number\"] = _normalize_nct_str(tmp[\"ref_primary_nct_number\"]).replace(\n",
    "            {\"\": None, \"NONE\": None, \"NAN\": None, \"NULL\": None, \"<NA>\": None}\n",
    "        )\n",
    "        tmp[\"ref_is_primary_nct_for_pmid\"] = tmp[\"ref_is_primary_nct_for_pmid\"].fillna(False).astype(bool)\n",
    "    \n",
    "        # Unique primary NCTs: from primary column (PMID-level primary)\n",
    "        unique_primary_ncts = int(tmp[\"ref_primary_nct_number\"].dropna().nunique())\n",
    "    \n",
    "        # Unique secondary NCTs: from non-primary rows\n",
    "        unique_secondary_ncts = int(tmp.loc[~tmp[\"ref_is_primary_nct_for_pmid\"], \"ref_nct_number\"].dropna().nunique())\n",
    "\n",
    "\n",
    "        # (Sanity) union of primary column + secondary rows should cover all unique NCTs,\n",
    "        # but overlaps are possible (same NCT can appear in both sets).\n",
    "        # So we do NOT enforce equality; we show a note.\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(f\"PAIRS / NCT-LEVEL TREE — {label}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    lines = [\n",
    "        \"Pairs table (PMID–NCT rows)\",\n",
    "        \"│\",\n",
    "        f\"├── {unique_pmids:,} unique PMIDs represented (must have ≥1 NCT)\",\n",
    "        \"│\",\n",
    "        f\"├── {total_pairs:,} total PMID–NCT pairs\",\n",
    "        f\"│   └── (extra rows happen because some PMIDs have 2+ NCTs)\",\n",
    "        f\"│       → {extra_pairs:,} additional pair rows beyond 1-per-PMID\",\n",
    "        \"│\",\n",
    "        f\"└── {unique_ncts:,} unique NCTs represented\",\n",
    "        f\"    └── (unique NCTs < total pairs because some NCTs repeat across PMIDs)\",\n",
    "    ]\n",
    "\n",
    "    # Nest the PRIMARY vs SECONDARY breakdown under the \"unique NCTs represented\" branch\n",
    "    if has_primary_cols:\n",
    "        lines.extend([\n",
    "            \"\",\n",
    "            \"    PRIMARY vs SECONDARY NCTs (unique counts):\",\n",
    "            f\"      ├── {unique_primary_ncts:,} unique PRIMARY NCTs\",\n",
    "            f\"      └── {unique_secondary_ncts:,} unique SECONDARY (non-primary) NCTs\",\n",
    "            \"          (note: a secondary NCT can still be the primary NCT of a different PMID)\",\n",
    "        ])\n",
    "    else:\n",
    "        lines.extend([\n",
    "            \"\",\n",
    "            \"    PRIMARY vs SECONDARY NCTs:\",\n",
    "            \"      (skipped — pairs table is missing ref_primary_nct_number and/or ref_is_primary_nct_for_pmid)\",\n",
    "        ])\n",
    "\n",
    "    # Add a simple duplication explainer (PMIDs by # NCTs)\n",
    "    lines.extend([\n",
    "        \"\",\n",
    "        f\"{total_pairs:,} total PMID–NCT pairs (i.e. NCTs per PMID):\",\n",
    "        f\"  ├── {n_pmid_1:,} PMIDs with exactly 1 NCT\",\n",
    "        f\"  │   └── Contributes {pairs_from_1nct:,} pairs (all primary)\",\n",
    "        f\"  │\",\n",
    "        f\"  ├── {n_pmid_2:,} PMIDs with exactly 2 NCTs\",\n",
    "        f\"  │   └── Contributes {pairs_from_2nct:,} pairs ({n_pmid_2:,} primary + {n_pmid_2:,} non-primary)\",\n",
    "        f\"  │\",\n",
    "        f\"  └── {n_pmid_3plus:,} PMIDs with 3+ NCTs\",\n",
    "        f\"      └── Contributes {pairs_from_3plus:,} pairs ({primary_from_3plus:,} primary + {nonprimary_from_3plus:,} non-primary)\",\n",
    "    ])\n",
    "\n",
    "    print(\"\\n\".join(lines))\n",
    "\n",
    "    # Return key counts so we can reconcile MASTER vs TRIALS-ONLY scopes\n",
    "    out = {\n",
    "        \"total_pairs\": total_pairs,\n",
    "        \"unique_pmids\": unique_pmids,\n",
    "        \"unique_ncts\": unique_ncts,\n",
    "        \"n_pmid_1\": n_pmid_1,\n",
    "        \"n_pmid_2\": n_pmid_2,\n",
    "        \"n_pmid_3plus\": n_pmid_3plus,\n",
    "    }\n",
    "    if has_primary_cols:\n",
    "        out.update({\n",
    "            \"unique_primary_ncts\": unique_primary_ncts,\n",
    "            \"unique_secondary_ncts\": unique_secondary_ncts,\n",
    "        })\n",
    "    return out\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 9.5 — BUILD TRIALS-ONLY PAIRS (deterministic)\n",
    "# -----------------------------------------------------------------------------\n",
    "def build_trials_only_pairs(pairs_master_df: pd.DataFrame, pmid_df: pd.DataFrame) -> (pd.DataFrame, str):\n",
    "    \"\"\"\n",
    "    Returns (pairs_trials_only_df, note_about_filter_source)\n",
    "    \"\"\"\n",
    "    df = pairs_master_df.copy()\n",
    "\n",
    "    # Normalize required cols defensively\n",
    "    df[\"ref_pmid\"] = _normalize_pmid_str(df[\"ref_pmid\"])\n",
    "    df[\"ref_primary_nct_number\"] = _normalize_nct_str(df[\"ref_primary_nct_number\"])\n",
    "\n",
    "    df = df.loc[(df[\"ref_pmid\"] != \"\") & (df[\"ref_primary_nct_number\"] != \"\")].copy()\n",
    "\n",
    "    if \"ref_is_pubmed_clinical_trial\" in df.columns:\n",
    "        out = df.loc[df[\"ref_is_pubmed_clinical_trial\"].fillna(False).astype(bool)].copy()\n",
    "        return out, \"Filtered using pairs_df.is_pubmed_clinical_trial\"\n",
    "    else:\n",
    "        tmp = pmid_df[[\"ref_pmid\", \"ref_is_clinical_trial_pt_type\"]].copy()\n",
    "        tmp[\"ref_pmid\"] = _normalize_pmid_str(tmp[\"ref_pmid\"])\n",
    "        tmp[\"ref_is_clinical_trial_pt_type\"] = tmp[\"ref_is_clinical_trial_pt_type\"].fillna(False).astype(bool)\n",
    "        trial_set = set(tmp.loc[tmp[\"ref_is_clinical_trial_pt_type\"], \"ref_pmid\"].tolist())\n",
    "        out = df.loc[df[\"ref_pmid\"].isin(trial_set)].copy()\n",
    "        return out, \"Filtered using PMID table ref_is_clinical_trial_pt_type (fallback)\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 9.6 — RUN REPORTS\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"A) Compute TRIALS-ONLY NCT subcounts from PAIRS (for tree injection)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "trials_subcounts = _compute_trials_only_pmid_nct_breakdown(\n",
    "    phase3_pmid_nct_pairs_master_df,\n",
    "    phase3_trials_unique_refs_df\n",
    ")\n",
    "\n",
    "print(\"Trials-only breakdown (computed from trials-only pairs):\")\n",
    "print(f\"  PMIDs with NCT(s): {trials_subcounts['pmids_with_ncts']:,}\")\n",
    "print(f\"    ├── PMIDs with ONLY a primary NCT (exactly 1 NCT): {trials_subcounts['pmids_only_primary']:,}\")\n",
    "print(f\"    └── PMIDs with primary + ≥1 additional NCT (2+ NCTs): {trials_subcounts['pmids_primary_plus']:,}\")\n",
    "print(f\"  [Filter note] {trials_subcounts['trials_filter_note']}\")\n",
    "print()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"B) PMID-LEVEL TREE (Canonical MASTER: phase3_trials_unique_refs_df)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "pmid_counts = print_pmid_tree(\n",
    "    phase3_trials_unique_refs_df,\n",
    "    \"MASTER (All unique PMIDs)\",\n",
    "    trials_only_subcounts=trials_subcounts\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"C) PAIRS / NCT-LEVEL TREE (MASTER pairs: ALL PMIDs with ≥1 NCT)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "pairs_master_counts = print_pairs_tree(\n",
    "    phase3_pmid_nct_pairs_master_df,\n",
    "    \"MASTER (All PMIDs with ≥1 NCT; trial + non-trial)\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"D) PAIRS / NCT-LEVEL TREE (TRIALS-ONLY pairs: the 508 PMIDs)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "pairs_trials_only_df, trials_pairs_note = build_trials_only_pairs(\n",
    "    phase3_pmid_nct_pairs_master_df,\n",
    "    phase3_trials_unique_refs_df\n",
    ")\n",
    "print(f\"[Filter note] {trials_pairs_note}\\n\")\n",
    "\n",
    "pairs_trials_counts = print_pairs_tree(\n",
    "    pairs_trials_only_df,\n",
    "    \"TRIALS-ONLY (pairs restricted to PubMed clinical trial PMIDs)\"\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 9.7 — CROSS-CHECKS + SCOPE CLARITY (helps explain confusing numbers)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"E) CROSS-CHECKS + SCOPE NOTES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1) Reconcile the starred trial-PMID-with-NCT count:\n",
    "print(\"Starred cohort reconciliation (trial PMIDs with NCTs):\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"PMID-level starred count (trial PMIDs with NCTs): {pmid_counts['trial_pmids_with_nct_tree']:,}\")\n",
    "print(f\"Pairs-level trials-only unique PMIDs:            {pairs_trials_counts['unique_pmids']:,}\")\n",
    "print(f\"Pairs-derived trials-only PMIDs with NCT(s):     {trials_subcounts['pmids_with_ncts']:,}\")\n",
    "\n",
    "d_star_1 = pmid_counts[\"trial_pmids_with_nct_tree\"] - pairs_trials_counts[\"unique_pmids\"]\n",
    "d_star_2 = pmid_counts[\"trial_pmids_with_nct_tree\"] - trials_subcounts[\"pmids_with_ncts\"]\n",
    "\n",
    "if d_star_1 == 0 and d_star_2 == 0:\n",
    "    print(\"✓ These match exactly (good sign).\")\n",
    "else:\n",
    "    print(\"⚠️ Mismatch detected.\")\n",
    "    if d_star_1 != 0:\n",
    "        print(f\"  • PMID-tree vs trials-only pairs differs by {d_star_1:,}.\")\n",
    "    if d_star_2 != 0:\n",
    "        print(f\"  • PMID-tree vs pairs-derived subcount differs by {d_star_2:,}.\")\n",
    "    print(\"  Common cause: PMID-tree detects NCTs from a different source (fallback scan) than the pairs build.\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# 2) Explicitly answer the \"684 vs 465\" scope question:\n",
    "print(\"\\nScope clarity: MASTER unique NCTs vs TRIALS-ONLY unique NCTs\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"MASTER pairs:    {pairs_master_counts['unique_ncts']:,} unique NCTs (all PMIDs with NCTs: trial + non-trial)\")\n",
    "print(f\"TRIALS-ONLY pairs:{pairs_trials_counts['unique_ncts']:,} unique NCTs (only the {pairs_trials_counts['unique_pmids']:,} trial PMIDs with NCTs)\")\n",
    "print(\"Interpretation:\")\n",
    "print(\"  • The MASTER NCT count is NOT 'the NCTs for the 508 PMIDs'.\")\n",
    "print(\"  • The TRIALS-ONLY NCT count IS the NCTs associated with those 508 PMIDs.\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# 3) Optional: “non-trial-only” NCT count (nice sanity check)\n",
    "#    This answers: how many unique NCTs appear ONLY outside trials?\n",
    "try:\n",
    "    master_ncts = set(_normalize_nct_str(phase3_pmid_nct_pairs_master_df[\"ref_primary_nct_number\"]).tolist())\n",
    "    trial_ncts = set(_normalize_nct_str(pairs_trials_only_df[\"ref_primary_nct_number\"]).tolist())\n",
    "    master_ncts.discard(\"\")\n",
    "    trial_ncts.discard(\"\")\n",
    "    nontrial_only_ncts = master_ncts - trial_ncts\n",
    "    print(\"\\nOptional: unique NCTs that appear ONLY in non-trial PMIDs (MASTER minus TRIALS-ONLY):\")\n",
    "    print(f\"  {len(nontrial_only_ncts):,} unique NCTs appear only in non-trial PMIDs\")\n",
    "except Exception as e:\n",
    "    print(\"\\n(Optional non-trial-only NCT check skipped due to error):\", e)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 10: GENERATE SUMMARY TABLES FROM TREES\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 4.10 — Generate Summary Tables\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Table 1: PMID-Level Summary (from Tree 1 & Tree 2)\n",
    "# -----------------------------------------------------------------------------\n",
    "pmid_summary_data = {\n",
    "    'Metric': [\n",
    "        'Total PMIDs',\n",
    "        'Clinical trial PMIDs (is_clinical_trial_pt_type=True)',\n",
    "        'Non-trial PMIDs',\n",
    "        'PMIDs with any registry ID',\n",
    "        'PMIDs with NCT numbers (has_nct=True)',\n",
    "        'Trial PMIDs with NCTs (⭐ main cohort)',\n",
    "        'Non-trial PMIDs with NCTs',\n",
    "    ],\n",
    "    'Count': [\n",
    "        pmid_counts['total_pmids'],\n",
    "        pmid_counts['trial_pmids'],\n",
    "        pmid_counts['total_pmids'] - pmid_counts['trial_pmids'],\n",
    "        pmid_counts['pmids_with_any_registry_tree'],\n",
    "        pmid_counts['pmids_with_any_nct_tree'],\n",
    "        pmid_counts['trial_pmids_with_nct_tree'],\n",
    "        pmid_counts['pmids_with_any_nct_tree'] - pmid_counts['trial_pmids_with_nct_tree'],\n",
    "    ],\n",
    "    'Percentage': [\n",
    "        100.0,\n",
    "        (pmid_counts['trial_pmids'] / pmid_counts['total_pmids'] * 100),\n",
    "        ((pmid_counts['total_pmids'] - pmid_counts['trial_pmids']) / pmid_counts['total_pmids'] * 100),\n",
    "        (pmid_counts['pmids_with_any_registry_tree'] / pmid_counts['total_pmids'] * 100),\n",
    "        (pmid_counts['pmids_with_any_nct_tree'] / pmid_counts['total_pmids'] * 100),\n",
    "        (pmid_counts['trial_pmids_with_nct_tree'] / pmid_counts['total_pmids'] * 100),\n",
    "        ((pmid_counts['pmids_with_any_nct_tree'] - pmid_counts['trial_pmids_with_nct_tree']) / pmid_counts['total_pmids'] * 100),\n",
    "    ]\n",
    "}\n",
    "\n",
    "pmid_summary_df = pd.DataFrame(pmid_summary_data)\n",
    "pmid_summary_df['Percentage'] = pmid_summary_df['Percentage'].apply(lambda x: f\"{x:.1f}%\")\n",
    "\n",
    "print(\"\\n📋 TABLE 1: PMID-Level Summary\")\n",
    "print(\"-\" * 70)\n",
    "print(pmid_summary_df.to_string(index=False))\n",
    "\n",
    "pmid_summary_output = os.path.join(OUTPUT_FOLDER, \"phase3_summary_pmid_level.csv\")\n",
    "pmid_summary_df.to_csv(pmid_summary_output, index=False)\n",
    "print(f\"\\n✓ Saved: {pmid_summary_output}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Table 2: NCT-Level Comparison (MASTER vs TRIALS-ONLY)\n",
    "# -----------------------------------------------------------------------------\n",
    "nct_comparison_data = {\n",
    "    'Metric': [\n",
    "        'Unique PMIDs represented',\n",
    "        'Total PMID-NCT pairs',\n",
    "        'Extra pairs (beyond 1-per-PMID)',\n",
    "        'Unique NCTs (ALL)',\n",
    "        'Unique PRIMARY NCTs',\n",
    "        'Unique SECONDARY NCTs',\n",
    "        'PMIDs with exactly 1 NCT',\n",
    "        'PMIDs with exactly 2 NCTs',\n",
    "        'PMIDs with 3+ NCTs',\n",
    "    ],\n",
    "    'MASTER (All PMIDs)': [\n",
    "        pairs_master_counts['unique_pmids'],\n",
    "        pairs_master_counts['total_pairs'],\n",
    "        pairs_master_counts['total_pairs'] - pairs_master_counts['unique_pmids'],\n",
    "        pairs_master_counts['unique_ncts'],\n",
    "        pairs_master_counts.get('unique_primary_ncts', 'N/A'),\n",
    "        pairs_master_counts.get('unique_secondary_ncts', 'N/A'),\n",
    "        pairs_master_counts['n_pmid_1'],\n",
    "        pairs_master_counts['n_pmid_2'],\n",
    "        pairs_master_counts['n_pmid_3plus'],\n",
    "    ],\n",
    "    'TRIALS-ONLY': [\n",
    "        pairs_trials_counts['unique_pmids'],\n",
    "        pairs_trials_counts['total_pairs'],\n",
    "        pairs_trials_counts['total_pairs'] - pairs_trials_counts['unique_pmids'],\n",
    "        pairs_trials_counts['unique_ncts'],\n",
    "        pairs_trials_counts.get('unique_primary_ncts', 'N/A'),\n",
    "        pairs_trials_counts.get('unique_secondary_ncts', 'N/A'),\n",
    "        pairs_trials_counts['n_pmid_1'],\n",
    "        pairs_trials_counts['n_pmid_2'],\n",
    "        pairs_trials_counts['n_pmid_3plus'],\n",
    "    ]\n",
    "}\n",
    "\n",
    "nct_comparison_df = pd.DataFrame(nct_comparison_data)\n",
    "\n",
    "print(\"\\n\\n🔗 TABLE 2: NCT-Level Comparison (MASTER vs TRIALS-ONLY)\")\n",
    "print(\"-\" * 70)\n",
    "print(nct_comparison_df.to_string(index=False))\n",
    "\n",
    "nct_comparison_output = os.path.join(OUTPUT_FOLDER, \"phase3_summary_nct_level_comparison.csv\")\n",
    "nct_comparison_df.to_csv(nct_comparison_output, index=False)\n",
    "print(f\"\\n✓ Saved: {nct_comparison_output}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Table 3: Pairs Breakdown by PMID NCT Count\n",
    "# -----------------------------------------------------------------------------\n",
    "# Calculate for MASTER\n",
    "master_pairs_from_1nct = pairs_master_counts['n_pmid_1'] * 1\n",
    "master_pairs_from_2nct = pairs_master_counts['n_pmid_2'] * 2\n",
    "master_pairs_from_3plus = pairs_master_counts['total_pairs'] - master_pairs_from_1nct - master_pairs_from_2nct\n",
    "\n",
    "# Calculate for TRIALS-ONLY\n",
    "trials_pairs_from_1nct = pairs_trials_counts['n_pmid_1'] * 1\n",
    "trials_pairs_from_2nct = pairs_trials_counts['n_pmid_2'] * 2\n",
    "trials_pairs_from_3plus = pairs_trials_counts['total_pairs'] - trials_pairs_from_1nct - trials_pairs_from_2nct\n",
    "\n",
    "pairs_breakdown_data = {\n",
    "    'PMID Category': [\n",
    "        'PMIDs with exactly 1 NCT',\n",
    "        '  → Pairs contributed',\n",
    "        '  → Primary pairs',\n",
    "        '  → Non-primary pairs',\n",
    "        '',\n",
    "        'PMIDs with exactly 2 NCTs',\n",
    "        '  → Pairs contributed',\n",
    "        '  → Primary pairs',\n",
    "        '  → Non-primary pairs',\n",
    "        '',\n",
    "        'PMIDs with 3+ NCTs',\n",
    "        '  → Pairs contributed',\n",
    "        '  → Primary pairs',\n",
    "        '  → Non-primary pairs',\n",
    "        '',\n",
    "        'TOTAL',\n",
    "    ],\n",
    "    'MASTER (All)': [\n",
    "        pairs_master_counts['n_pmid_1'],\n",
    "        master_pairs_from_1nct,\n",
    "        pairs_master_counts['n_pmid_1'],\n",
    "        0,\n",
    "        '',\n",
    "        pairs_master_counts['n_pmid_2'],\n",
    "        master_pairs_from_2nct,\n",
    "        pairs_master_counts['n_pmid_2'],\n",
    "        pairs_master_counts['n_pmid_2'],\n",
    "        '',\n",
    "        pairs_master_counts['n_pmid_3plus'],\n",
    "        master_pairs_from_3plus,\n",
    "        pairs_master_counts['n_pmid_3plus'],\n",
    "        master_pairs_from_3plus - pairs_master_counts['n_pmid_3plus'],\n",
    "        '',\n",
    "        pairs_master_counts['total_pairs'],\n",
    "    ],\n",
    "    'TRIALS-ONLY': [\n",
    "        pairs_trials_counts['n_pmid_1'],\n",
    "        trials_pairs_from_1nct,\n",
    "        pairs_trials_counts['n_pmid_1'],\n",
    "        0,\n",
    "        '',\n",
    "        pairs_trials_counts['n_pmid_2'],\n",
    "        trials_pairs_from_2nct,\n",
    "        pairs_trials_counts['n_pmid_2'],\n",
    "        pairs_trials_counts['n_pmid_2'],\n",
    "        '',\n",
    "        pairs_trials_counts['n_pmid_3plus'],\n",
    "        trials_pairs_from_3plus,\n",
    "        pairs_trials_counts['n_pmid_3plus'],\n",
    "        trials_pairs_from_3plus - pairs_trials_counts['n_pmid_3plus'],\n",
    "        '',\n",
    "        pairs_trials_counts['total_pairs'],\n",
    "    ]\n",
    "}\n",
    "\n",
    "pairs_breakdown_df = pd.DataFrame(pairs_breakdown_data)\n",
    "\n",
    "print(\"\\n\\n📊 TABLE 3: Pairs Breakdown by Reference PMID + NCT Count\")\n",
    "print(\"-\" * 70)\n",
    "print(pairs_breakdown_df.to_string(index=False))\n",
    "\n",
    "pairs_breakdown_output = os.path.join(OUTPUT_FOLDER, \"phase3_summary_pairs_breakdown.csv\")\n",
    "pairs_breakdown_df.to_csv(pairs_breakdown_output, index=False)\n",
    "print(f\"\\n✓ Saved: {pairs_breakdown_output}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✓ PHASE 3 — STEP 4.10 COMPLETE (Summary tables generated)\")\n",
    "print(\"=\" * 70)\n",
    "    \n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✓ PHASE 3 — STEP 4 COMPLETE (PMID-level + NCT-level reporting)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4bb767a-bc0d-42ef-abb5-97bb988c5c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PHASE 3: Step 5 - Join Trial Data to Citations\n",
      "======================================================================\n",
      "Inputs:\n",
      "  A) phase3_2_references_with_trials_unique_refs.csv  (PMID-level, one row per ref_pmid)\n",
      "  B) phase2_crossref_guidelines_and_references.csv  (citation-level, guideline–ref pairs)\n",
      "Outputs:\n",
      "  - phase3_references_with_trials.csv               (citation-level, enriched)\n",
      "  - phase3_guideline_reference_nct_pairs.csv        (optional, NCT-expanded if USE_ALL_NCTS=True)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "STEP 5.1 — Loaded Helper Functions\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "STEP 5.2 — Loaded PMID-level trial lookup\n",
      "======================================================================\n",
      "File: output\\phase3_references_with_trials_unique_refs.csv\n",
      "Rows (unique ref PMIDs): 7,725\n",
      "\n",
      "======================================================================\n",
      "STEP 5.3 — Loaded citation-level guideline–reference pairs\n",
      "======================================================================\n",
      "File: output\\phase2_crossref_guidelines_and_references.csv\n",
      "Rows (guideline–reference pairs): 9,204\n",
      "Note: The same ref_pmid can appear multiple times if cited by multiple guidelines.\n",
      "\n",
      "======================================================================\n",
      "STEP 5.4 — Joining trial lookup onto citation rows\n",
      "======================================================================\n",
      "Join complete.\n",
      "Rows (still citation-level): 9,204\n",
      "\n",
      "======================================================================\n",
      "STEP 5.5 — Renamed Keys to canonical column names\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "STEP 5.6 — Data quality check: dedupe by guideline_pmid + ref_pmid\n",
      "======================================================================\n",
      "Before: 9,204\n",
      "Duplicate guideline–ref pairs: 983\n",
      "After:  8,221\n",
      "Removed: 983 duplicate guideline–ref pairs\n",
      "Note: Different guidelines citing the same reference are preserved (expected).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keg827\\AppData\\Local\\Temp\\ipykernel_28568\\2475253809.py:130: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  phase3_final[\"ref_is_clinical_trial_pt_type\"] = phase3_final[\"ref_is_clinical_trial_pt_type\"].fillna(False).astype(bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 5.7 — Saved citation-level enriched table\n",
      "======================================================================\n",
      "Output: output\\phase3_references_with_trials.csv\n",
      "\n",
      "======================================================================\n",
      "✓ PHASE 3 STEP 5 COMPLETE\n",
      "======================================================================\n",
      "Total guideline–ref citation rows: 8,221\n",
      "Unique ref PMIDs: 7,725\n",
      "Unique guideline PMIDs: 75\n",
      "\n",
      "Clinical Trials (publication-type flag at PMID-level, joined onto citations):\n",
      "  Citation rows marked clinical trial: 1,527 (18.6%)\n",
      "  Unique ref PMIDs marked clinical trial: 1,455\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 3: Step 5 - Join Trial Data to ALL Citations\n",
    "# ============================================================================\n",
    "# Goal:\n",
    "#   - Input A (PMID-level): phase3_references_with_trials_unique_refs.csv\n",
    "#       One row per unique PubMed reference (ref_pmid), with trial + registry fields.\n",
    "#   - Input B (Citation-level): phase2_crossref_guidelines_and_references.csv\n",
    "#       One row per guideline–reference pair (guideline_pmid, ref_pmid).\n",
    "#\n",
    "# Output (Legacy / unchanged):\n",
    "#   - phase3_2_references_with_trials.csv\n",
    "#       Citation-level table enriched with trial + NCT fields.\n",
    "#\n",
    "# Optional output (only if USE_ALL_NCTS=True):\n",
    "#   - phase3_guideline_reference_nct_pairs.csv\n",
    "#       Citation-level table expanded to one row per guideline–reference–NCT.\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PHASE 3: Step 5 - Join Trial Data to Citations\")\n",
    "print(f\"{'='*70}\")\n",
    "print(\"Inputs:\")\n",
    "print(\"  A) phase3_2_references_with_trials_unique_refs.csv  (PMID-level, one row per ref_pmid)\")\n",
    "print(\"  B) phase2_crossref_guidelines_and_references.csv  (citation-level, guideline–ref pairs)\")\n",
    "print(\"Outputs:\")\n",
    "print(\"  - phase3_references_with_trials.csv               (citation-level, enriched)\")\n",
    "print(\"  - phase3_guideline_reference_nct_pairs.csv        (optional, NCT-expanded if USE_ALL_NCTS=True)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Step 5.1 — Helper: standard PMID cleaning (kept exactly as you had it)\n",
    "# ---------------------------------------------------------------------------\n",
    "def clean_pmid(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    s = str(x).strip()\n",
    "    if s == \"\" or s.lower() in {\"none\", \"nan\", \"null\"}:\n",
    "        return None\n",
    "    try:\n",
    "        f = float(s)\n",
    "        i = int(f)\n",
    "        if f == i and i > 0:\n",
    "            return str(i)\n",
    "    except Exception:\n",
    "        pass\n",
    "    if s.isdigit():\n",
    "        return s\n",
    "    return None\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"STEP 5.1 — Loaded Helper Functions\")\n",
    "print(f\"{'='*70}\")\n",
    "# ---------------------------------------------------------------------------\n",
    "# Step 5.2 — Load Step 4 output (PMID-level: one row per ref_pmid)\n",
    "# ---------------------------------------------------------------------------\n",
    "phase3_unique_path = os.path.join(OUTPUT_FOLDER, \"phase3_references_with_trials_unique_refs.csv\")\n",
    "phase3_trials_unique_refs_df = pd.read_csv(phase3_unique_path)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"STEP 5.2 — Loaded PMID-level trial lookup\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"File: {phase3_unique_path}\")\n",
    "print(f\"Rows (unique ref PMIDs): {len(phase3_trials_unique_refs_df):,}\")\n",
    "\n",
    "if len(phase3_trials_unique_refs_df) == 0:\n",
    "    raise ValueError(\"No trial data loaded. Check Phase 3 Step 4 completed successfully.\")\n",
    "\n",
    "# Create clean merge key\n",
    "phase3_trials_unique_refs_df[\"ref_pmid_clean\"] = phase3_trials_unique_refs_df[\"ref_pmid\"].apply(clean_pmid)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Step 5.3 — Load Phase 2 citations (citation-level: guideline–reference pairs)\n",
    "# ---------------------------------------------------------------------------\n",
    "phase2_path = os.path.join(OUTPUT_FOLDER, \"phase2_crossref_guidelines_and_references.csv\")\n",
    "phase2_df = pd.read_csv(phase2_path)\n",
    "\n",
    "# Clean PMIDs for merge keys\n",
    "phase2_df[\"ref_pmid_clean\"] = phase2_df[\"ref_pmid\"].apply(clean_pmid)\n",
    "phase2_df[\"guideline_pmid_clean\"] = phase2_df[\"guideline_pmid\"].apply(clean_pmid)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"STEP 5.3 — Loaded citation-level guideline–reference pairs\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"File: {phase2_path}\")\n",
    "print(f\"Rows (guideline–reference pairs): {len(phase2_df):,}\")\n",
    "print(\"Note: The same ref_pmid can appear multiple times if cited by multiple guidelines.\")\n",
    "\n",
    "# Keep everything BUT the original (possibly messy) PMID columns to avoid conflicts,\n",
    "# but keep the cleaned columns we just created.\n",
    "phase2_cols_to_keep = [c for c in phase2_df.columns if c not in [\"guideline_pmid\", \"ref_pmid\"]]\n",
    "phase2_for_merge = phase2_df[phase2_cols_to_keep].copy()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Step 5.4 — Merge PMID-level trial data onto citation-level pairs\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"STEP 5.4 — Joining trial lookup onto citation rows\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "trial_cols = [\n",
    "    \"ref_pmid_clean\",\n",
    "    \"ref_is_clinical_trial_pt_type\",\n",
    "    \"ref_publication_types\",\n",
    "    \"ref_primary_nct_number\",\n",
    "    \"ref_primary_nct_source\",\n",
    "    \"ref_all_registry_ids\",\n",
    "    \"ref_all_nct_numbers\",\n",
    "    \"ref_all_structured_nct_numbers\",\n",
    "    \"ref_all_nct_source_pairs\",\t\n",
    "    \"ref_all_structured_nct_source_pairs\",\n",
    "    \"ref_fetch_status\",\t\n",
    "    \"ref_has_nct\",\t\n",
    "    \"ref_abstract\",\n",
    "    \"ref_has_abstract\",\n",
    "]\n",
    "trial_cols = [c for c in trial_cols if c in phase3_trials_unique_refs_df.columns]\n",
    "\n",
    "phase3_final = phase2_for_merge.merge(\n",
    "    phase3_trials_unique_refs_df[trial_cols],\n",
    "    on=\"ref_pmid_clean\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Ensure boolean field exists + is boolean\n",
    "if \"ref_is_clinical_trial_pt_type\" not in phase3_final.columns:\n",
    "    phase3_final[\"ref_is_clinical_trial_pt_type\"] = False\n",
    "phase3_final[\"ref_is_clinical_trial_pt_type\"] = phase3_final[\"ref_is_clinical_trial_pt_type\"].fillna(False).astype(bool)\n",
    "\n",
    "print(f\"Join complete.\")\n",
    "print(f\"Rows (still citation-level): {len(phase3_final):,}\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Step 5.5 — Rename cleaned keys back to canonical column names\n",
    "# ---------------------------------------------------------------------------\n",
    "phase3_final = phase3_final.rename(columns={\n",
    "    \"ref_pmid_clean\": \"ref_pmid\",\n",
    "    \"guideline_pmid_clean\": \"guideline_pmid\",\n",
    "})\n",
    "\n",
    "# Guard against duplicated column names (rare, but safe)\n",
    "duplicate_cols = phase3_final.columns[phase3_final.columns.duplicated()].tolist()\n",
    "if duplicate_cols:\n",
    "    print(f\"⚠️ Duplicate columns detected: {duplicate_cols}\")\n",
    "    phase3_final = phase3_final.loc[:, ~phase3_final.columns.duplicated()]\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"STEP 5.5 — Renamed Keys to canonical column names\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Step 5.6 — Deduplicate guideline–ref pairs (safety net)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"STEP 5.6 — Data quality check: dedupe by guideline_pmid + ref_pmid\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "before = len(phase3_final)\n",
    "dups = phase3_final.duplicated(subset=[\"guideline_pmid\", \"ref_pmid\"]).sum()\n",
    "print(f\"Before: {before:,}\")\n",
    "print(f\"Duplicate guideline–ref pairs: {dups:,}\")\n",
    "\n",
    "if dups > 0:\n",
    "    phase3_final = phase3_final.drop_duplicates(subset=[\"guideline_pmid\", \"ref_pmid\"], keep=\"first\")\n",
    "    after = len(phase3_final)\n",
    "    print(f\"After:  {after:,}\")\n",
    "    print(f\"Removed: {before - after:,} duplicate guideline–ref pairs\")\n",
    "    print(\"Note: Different guidelines citing the same reference are preserved (expected).\")\n",
    "else:\n",
    "    print(\"✓ No duplicates found.\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Step 5.7 — Save legacy output (unchanged behavior)\n",
    "# ---------------------------------------------------------------------------\n",
    "output_file = os.path.join(OUTPUT_FOLDER, \"phase3_references_with_trials.csv\")\n",
    "phase3_final.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"STEP 5.7 — Saved citation-level enriched table\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Output: {output_file}\")\n",
    "\n",
    "\n",
    "# # ============================================================================\n",
    "# # Step 5.8 (OPTIONAL) — Guideline–Reference–NCT expansion (toggle-controlled)\n",
    "# # ============================================================================\n",
    "# # This does NOT change phase3_references_with_trials.csv.\n",
    "# # It only creates an additional expanded table when USE_ALL_NCTS=True.\n",
    "\n",
    "# try:\n",
    "#     USE_ALL_NCTS\n",
    "# except NameError:\n",
    "#     USE_ALL_NCTS = False\n",
    "\n",
    "# print(f\"\\n{'='*70}\")\n",
    "# print(\"STEP 5.8 (OPTIONAL) — Guideline–Reference–NCT expansion\")\n",
    "# print(f\"{'='*70}\")\n",
    "# print(f\"USE_ALL_NCTS = {USE_ALL_NCTS}\")\n",
    "\n",
    "# guideline_reference_nct_pairs_df = None\n",
    "\n",
    "# if USE_ALL_NCTS:\n",
    "#     # Load pairs from memory or disk (created in Step 4)\n",
    "#     if \"phase3_pmid_nct_pairs_df\" not in globals():\n",
    "#         pairs_path = os.path.join(OUTPUT_FOLDER, \"phase3_pmid_nct_pairs.csv\")\n",
    "#         print(\"phase3_pmid_nct_pairs_df not found in memory.\")\n",
    "#         print(f\"Attempting to load: {pairs_path}\")\n",
    "\n",
    "#         if not os.path.exists(pairs_path):\n",
    "#             raise ValueError(\n",
    "#                 \"USE_ALL_NCTS=True but phase3_pmid_nct_pairs.csv was not found. \"\n",
    "#                 \"Run Step 4 through the NCT MODE section (and save pairs), or set USE_ALL_NCTS=False.\"\n",
    "#             )\n",
    "\n",
    "#         phase3_pmid_nct_pairs_df = pd.read_csv(pairs_path, dtype={\"ref_pmid\": str})\n",
    "\n",
    "#     # Minimal columns for the expansion\n",
    "#     pairs_cols = [\"ref_pmid\", \"nct_number\"]\n",
    "#     for col in [\"is_analysis_primary_nct\", \"nct_order_in_pmid\"]:\n",
    "#         if col in phase3_pmid_nct_pairs_df.columns:\n",
    "#             pairs_cols.append(col)\n",
    "\n",
    "#     guideline_reference_nct_pairs_df = phase3_final.merge(\n",
    "#         phase3_pmid_nct_pairs_df[pairs_cols],\n",
    "#         on=\"ref_pmid\",\n",
    "#         how=\"left\"\n",
    "#     )\n",
    "\n",
    "#     # Ensure helper fields exist (for consistent downstream expectations)\n",
    "#     if \"is_analysis_primary_nct\" not in guideline_reference_nct_pairs_df.columns:\n",
    "#         guideline_reference_nct_pairs_df[\"is_analysis_primary_nct\"] = False\n",
    "#     if \"nct_order_in_pmid\" not in guideline_reference_nct_pairs_df.columns:\n",
    "#         guideline_reference_nct_pairs_df[\"nct_order_in_pmid\"] = np.nan\n",
    "\n",
    "#     print(f\"Rows (guideline–reference pairs) (PMID-level): {len(phase3_final):,}\")\n",
    "#     print(f\"Rows (guideline–reference–NCT)   (NCT-level):  {len(guideline_reference_nct_pairs_df):,}\")\n",
    "\n",
    "#     out_pairs = os.path.join(OUTPUT_FOLDER, \"phase3_3_guideline_reference_nct_pairs.csv\")\n",
    "#     guideline_reference_nct_pairs_df.to_csv(out_pairs, index=False)\n",
    "#     print(f\"✓ Saved: {out_pairs}\")\n",
    "\n",
    "# else:\n",
    "#     # Primary-only mode: no row expansion; keep 1 row per guideline–reference\n",
    "#     guideline_reference_nct_pairs_df = phase3_final.copy()\n",
    "#     guideline_reference_nct_pairs_df[\"nct_number\"] = guideline_reference_nct_pairs_df.get(\"nct_number\", None)\n",
    "#     guideline_reference_nct_pairs_df[\"is_analysis_primary_nct\"] = True\n",
    "#     guideline_reference_nct_pairs_df[\"nct_order_in_pmid\"] = 1\n",
    "\n",
    "#     print(\"Primary-only mode: no expansion performed (1 row per guideline–reference pair).\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Step 5.8 — Quick end-of-step summary (same stats you already had)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✓ PHASE 3 STEP 5 COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total guideline–ref citation rows: {len(phase3_final):,}\")\n",
    "print(f\"Unique ref PMIDs: {phase3_final['ref_pmid'].nunique():,}\")\n",
    "print(f\"Unique guideline PMIDs: {phase3_final['guideline_pmid'].nunique():,}\")\n",
    "\n",
    "ct_citations = int(phase3_final[\"ref_is_clinical_trial_pt_type\"].sum())\n",
    "ct_unique = int(phase3_final.loc[phase3_final[\"ref_is_clinical_trial_pt_type\"], \"ref_pmid\"].nunique())\n",
    "\n",
    "print(\"\\nClinical Trials (publication-type flag at PMID-level, joined onto citations):\")\n",
    "print(f\"  Citation rows marked clinical trial: {ct_citations:,} ({ct_citations/len(phase3_final)*100:.1f}%)\")\n",
    "print(f\"  Unique ref PMIDs marked clinical trial: {ct_unique:,}\")\n",
    "print(f\"{'='*70}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6825d85-ebb1-4356-a67d-f506e2a34fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PHASE 3: Step 6 — Final Validation & Sanity Checks\n",
      "======================================================================\n",
      "\n",
      "Loaded files:\n",
      "  Phase 2: output\\phase2_crossref_guidelines_and_references.csv  (9,204 rows)\n",
      "  Phase 3: output\\phase3_references_with_trials.csv  (8,221 rows)\n",
      "\n",
      "======================================================================\n",
      "RUNNING VALIDATION FUNCTIONS\n",
      "======================================================================\n",
      "Phase 3 Final Validation Check:\n",
      "\n",
      "==================================================\n",
      "QUICK CHECK: Phase 3\n",
      "==================================================\n",
      "Rows: 8,221\n",
      "Columns: 29\n",
      "Change from previous: -983 rows (-10.7%)\n",
      "⚠️ WARNING: -983 rows different from expected (10.7%)\n",
      "==================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "VALIDATING PHASE 3: Clinical Trial Identification (Updated for multi-NCT + NCT flags)\n",
      "======================================================================\n",
      "\n",
      "ℹ️ Baseline row counts:\n",
      "  Phase 2 total rows:           9,204\n",
      "  Phase 2 rows WITH ref_pmid:   8,149\n",
      "  Phase 3 citation rows:        8,221\n",
      "  Difference (Phase3 - Phase2): +72 rows (+0.9%)\n",
      "✓ Phase 3: Row count OK (8,221 rows, 0.9% diff from expected)\n",
      "\n",
      "📦 Structure checks:\n",
      "  ✓ Required columns present: ['guideline_pmid', 'ref_pmid']\n",
      "  ✓ No 'guideline_pmids' column (consistent with citation-level structure)\n",
      "✓ Phase 3: No duplicates on ['guideline_pmid', 'ref_pmid'] (Each guideline–reference pair should be unique (cartesian products show up here))\n",
      "⚠️ Phase 3: Missing 'is_clinical_trial' column; defaulting to False for validation.\n",
      "\n",
      "📊 Citation statistics:\n",
      "  Total citation rows:         8,221\n",
      "  Unique ref_pmid:             7,725\n",
      "  Unique guideline_pmid:       75\n",
      "  Citations per reference avg: 1.06\n",
      "  ✓ Citation ratio looks reasonable\n",
      "\n",
      "🧪 Trial classification vs NCT linkage:\n",
      "  PubMed-labeled clinical trial (is_clinical_trial=True):\n",
      "    - Citation rows: 0\n",
      "    - Unique refs:   0 (0.0% of unique refs)\n",
      "  NCT-linked articles (has_nct=True):\n",
      "    - Citation rows: 0\n",
      "    - Unique refs:   0 (0.0% of unique refs)\n",
      "  Analysis trial universe (is_clinical_trial OR has_nct):\n",
      "    - Citation rows: 0\n",
      "    - Unique refs:   0 (0.0% of unique refs)\n",
      "ℹ️ Phase 3: Very low PubMed-labeled clinical trial rate (0.0%). This can be normal.\n",
      "\n",
      "🔎 NCT format + duplication checks:\n",
      "  ℹ️ No NCT columns found to validate (nct_number / all_nct_numbers missing).\n",
      "  ℹ️ No parsed NCTs to check for within-PMID duplication.\n",
      "\n",
      "ℹ️ No references with ≥10 NCTs parsed.\n",
      "\n",
      "✓ No NCT-linked rows where is_clinical_trial=False (fine, but not required).\n",
      "\n",
      "📊 Guideline coverage:\n",
      "  Guidelines total:                         75\n",
      "  Guidelines citing trial-universe refs:     0 (0.0%)\n",
      "  (trial-universe = is_clinical_trial OR has_nct)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "✓ Phase 3 validation complete (no critical errors).\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "PHASE 3 OUTPUT SUMMARY (Citation-Level)\n",
      "======================================================================\n",
      "Total citation rows (guideline–reference pairs): 8,221\n",
      "✓ Required columns present\n",
      "Unique references (unique ref_pmid): 7,725\n",
      "Unique guidelines (unique guideline_pmid): 75\n",
      "\n",
      "======================================================================\n",
      "CLINICAL TRIAL & NCT STATISTICS\n",
      "======================================================================\n",
      "Citation-level counts:\n",
      "  Trial citation rows (ref_is_clinical_trial_pt_type=True): 1,527\n",
      "  Citation rows with ANY NCT number:           630\n",
      "\n",
      "Unique-reference counts:\n",
      "  Unique refs marked as trials:                1,455\n",
      "  Unique refs with ANY NCT number:             588\n",
      "\n",
      "Percent of unique refs marked trial: 18.8%\n",
      "\n",
      "======================================================================\n",
      "PUBLICATION TYPE DISTRIBUTION (Trials only — top 10)\n",
      "======================================================================\n",
      "ref_publication_types\n",
      "Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't                                        125\n",
      "Journal Article;Randomized Controlled Trial                                                                         116\n",
      "Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't                      111\n",
      "Journal Article;Multicenter Study                                                                                    94\n",
      "Journal Article;Multicenter Study;Research Support, Non-U.S. Gov't                                                   76\n",
      "Comparative Study;Journal Article;Multicenter Study;Randomized Controlled Trial;Research Support, Non-U.S. Gov't     70\n",
      "Journal Article;Multicenter Study;Randomized Controlled Trial                                                        56\n",
      "Comparative Study;Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't                       36\n",
      "Clinical Trial;Journal Article                                                                                       27\n",
      "Clinical Trial;Journal Article;Randomized Controlled Trial;Research Support, Non-U.S. Gov't                          26\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "SPOT CHECK: First few trial citations\n",
      "======================================================================\n",
      "      ref_pmid ref_primary_nct_number  \\\n",
      "8   30280640.0            NCT01626079   \n",
      "9   30145927.0            NCT01920698   \n",
      "10  26550689.0            NCT00807040   \n",
      "11  23136163.0            NCT00413998   \n",
      "17  19679246.0            NCT00209274   \n",
      "18  26718672.0            NCT00209274   \n",
      "20  19660613.0                    NaN   \n",
      "21  19597051.0                    NaN   \n",
      "22  20031729.0                    NaN   \n",
      "23  21251638.0                    NaN   \n",
      "\n",
      "                                            ref_title  guideline_pmid  \n",
      "8   Transcatheter mitral-valve repair in patients ...        31857196  \n",
      "9   Percutaneous repair or medical treatment for s...        31857196  \n",
      "10  Two-year outcomes of surgical treatment of sev...        31857196  \n",
      "11  Coronary artery bypass surgery with or without...        31857196  \n",
      "17  Percutaneous mitral repair with the MitraClip ...        31857196  \n",
      "18  Randomized comparison of percutaneous repair a...        31857196  \n",
      "20  Effectiveness and safety of percutaneous coron...        31857196  \n",
      "21  Percutaneous mitral annuloplasty for functiona...        31857196  \n",
      "22  Percutaneous transvenous mitral annuloplasty: ...        31857196  \n",
      "23                                                NaN        31857196  \n",
      "\n",
      "======================================================================\n",
      "GUIDELINE COVERAGE\n",
      "======================================================================\n",
      "Guidelines citing ≥1 clinical trial: 70 / 75\n",
      "(93.3%)\n",
      "\n",
      "======================================================================\n",
      "GUIDELINES WITHOUT CLINICAL TRIAL CITATIONS\n",
      "======================================================================\n",
      "\n",
      "Found 5 guidelines without clinical trial citations.\n",
      "✓ Saved summary to: output\\phase3_guidelines_WITHOUT_trials.csv\n",
      "\n",
      "Summary preview (top 10):\n",
      " guideline_pmid                                                                                                                                                 guideline_title  total_references  references_with_pmids                        guideline_doi\n",
      "       32453156                                                                                               Update: AHA guidelines for CPR and emergency cardiovascular care.                 5                      4 10.1097/01.NURSE.0000659320.66070.a9\n",
      "       33028085                                     Assessing and Addressing Cardiovascular Health in LGBTQ Adults: A Scientific Statement From the American Heart Association.                53                     52         10.1161/CIR.0000000000000914\n",
      "       33417901                                             Society for Maternal-Fetal Medicine Special Statement: Checklist for initial management of amniotic fluid embolism.                14                     14           10.1016/j.ajog.2021.01.001\n",
      "       33840208 Nonprofit Advocacy at the American Heart Association: Creating a Visionary Way Forward at Our 40th Anniversary: An American Heart Association Policy Statement.                27                     26         10.1161/CIR.0000000000000972\n",
      "       33934611                            Preclinical Models of Cancer Therapy-Associated Cardiovascular Toxicity: A Scientific Statement From the American Heart Association.                52                     51         10.1161/RES.0000000000000473\n",
      "\n",
      "======================================================================\n",
      "GUIDELINES WITH TRIALS BUT NO NCT NUMBERS\n",
      "======================================================================\n",
      "\n",
      "Found 9 guidelines that cite trials but NONE have NCT numbers.\n",
      "✓ Saved summary to: output\\phase3_guidelines_WITHOUT_nct_numbers.csv\n",
      "\n",
      "Summary preview (top 10):\n",
      " guideline_pmid                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 guideline_title  total_references  ref_clinical_trials_cited  ref_trials_with_nct                   guideline_doi\n",
      "       31838890                                                                                                                                                                                                                                                                                                                                                                                                                            Dietary Cholesterol and Cardiovascular Risk: A Science Advisory From the American Heart Association.                59                          9                    0    10.1161/CIR.0000000000000743\n",
      "       33070654                                                                                                                                                                                                                                                                                                                                                              The American Heart Association's Call to Action for Reducing the Global Burden of Rheumatic Heart Disease: A Policy Statement From the American Heart Association.                49                          2                    0    10.1161/CIR.0000000000000922\n",
      "       33170755                                                                                                                                                                                                                                                                                                                                                                                   Call to Action: Structural Racism as a Fundamental Driver of Health Disparities: A Presidential Advisory From the American Heart Association.                38                          1                    0    10.1161/CIR.0000000000000936\n",
      "       33250265                                                                                                                                                                                                                                                                     2021 ACC/AHA Key Data Elements and Definitions for Heart Failure: A Report of the American College of Cardiology/American Heart Association Task Force on Clinical Data Standards (Writing Committee to Develop Clinical Data Standards for Heart Failure).                52                          1                    0      10.1016/j.jacc.2020.11.012\n",
      "       34074137                                                                                                                                                                                                                                                                                                                                  Physical Activity as a Critical Component of First-Line Treatment for Elevated Blood Pressure or Cholesterol: Who, What, and How?: A Scientific Statement From the American Heart Association.                49                          1                    0    10.1161/HYP.0000000000000196\n",
      "       34648743                                                                                                                                                                                                                                                                                                                                                                                                 Society for Maternal-Fetal Medicine Special Statement: A quality metric for evaluating timely treatment of severe hypertension.                14                          1                    0      10.1016/j.ajog.2021.10.007\n",
      "       35072519 2022 Interim Guidance to Health Care Providers for Basic and Advanced Cardiac Life Support in Adults, Children, and Neonates With Suspected or Confirmed COVID-19: From the Emergency Cardiovascular Care Committee and Get With The Guidelines-Resuscitation Adult and Pediatric Task Forces of the American Heart Association in Collaboration With the American Academy of Pediatrics, American Association for Respiratory Care, the Society of Critical Care Anesthesiologists, and American Society of Anesthesiologists.                36                          8                    0 10.1161/CIRCOUTCOMES.122.008900\n",
      "       36120864                                                                                                                                                                                                                                                                                                                                                                                                             Physician Wellness in Academic Cardiovascular Medicine: A Scientific Statement From the American Heart Association.                43                          1                    0    10.1161/CIR.0000000000001093\n",
      "       41164866                                                                                                                                                                                                                                                                                                                                                                         Targeted Nursing Interventions for Improving Stroke Care and Outcomes in the Rural Setting: A Scientific Statement From the American Heart Association.                64                          1                    0    10.1161/STR.0000000000000495\n",
      "\n",
      "======================================================================\n",
      "COMPLETE GUIDELINE CLASSIFICATION (Phase 3)\n",
      "======================================================================\n",
      "\n",
      "Total guidelines analyzed: 75\n",
      "1) Guidelines with NO clinical trials cited: 5 (6.7%)\n",
      "2) Guidelines citing trials but NONE have NCT numbers: 9 (12.0%)\n",
      "3) Guidelines citing trials WITH NCT numbers: 62 (82.7%)\n",
      "\n",
      "Extra context: Trials cited by 'trials-but-no-NCT' guidelines: 25 (all missing NCT)\n",
      "Likely explanation: older trials published before routine registration/reporting.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 3: Step 6 - Verify Output\n",
    "# ============================================================================\n",
    "# Purpose:\n",
    "#   Quick validation of Phase 3 output (citation-level) after Step 5.\n",
    "#\n",
    "# Structure reminder (IMPORTANT):\n",
    "#   phase3_references_with_trials.csv is CITATION-LEVEL:\n",
    "#     one row per (guideline_pmid, ref_pmid) pair\n",
    "#   Therefore:\n",
    "#     - len(df) == number of guideline–reference citation rows\n",
    "#     - unique refs == df['ref_pmid'].nunique()\n",
    "#     - unique guidelines == df['guideline_pmid'].nunique()\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PHASE 3: Step 6 — Final Validation & Sanity Checks\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 6.1 Load inputs for comparison\n",
    "# ---------------------------------------------------------------------------\n",
    "phase2_path = os.path.join(OUTPUT_FOLDER, 'phase2_crossref_guidelines_and_references.csv')\n",
    "phase3_path = os.path.join(OUTPUT_FOLDER, 'phase3_references_with_trials.csv')\n",
    "\n",
    "phase2_df = pd.read_csv(phase2_path)\n",
    "phase3_df = pd.read_csv(phase3_path)\n",
    "\n",
    "print(\"\\nLoaded files:\")\n",
    "print(f\"  Phase 2: {phase2_path}  ({len(phase2_df):,} rows)\")\n",
    "print(f\"  Phase 3: {phase3_path}  ({len(phase3_df):,} rows)\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 6.2 Quick integrity checks (your existing validators)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"RUNNING VALIDATION FUNCTIONS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(\"Phase 3 Final Validation Check:\")\n",
    "quick_check_after_phase(3, phase3_df, prev_df=phase2_df, expected_count=len(phase2_df))\n",
    "validate_phase3(phase3_df, phase2_df)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 6.3 High-level output summary (citation-level)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PHASE 3 OUTPUT SUMMARY (Citation-Level)\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(f\"Total citation rows (guideline–reference pairs): {len(phase3_df):,}\")\n",
    "\n",
    "# Key columns check\n",
    "required_cols = [\"guideline_pmid\", \"ref_pmid\", \"ref_is_clinical_trial_pt_type\", \"ref_primary_nct_number\"]\n",
    "missing = [c for c in required_cols if c not in phase3_df.columns]\n",
    "if missing:\n",
    "    print(f\"⚠️ Missing expected columns: {missing}\")\n",
    "else:\n",
    "    print(\"✓ Required columns present\")\n",
    "\n",
    "unique_refs = phase3_df[\"ref_pmid\"].dropna().nunique() if \"ref_pmid\" in phase3_df.columns else 0\n",
    "unique_guidelines = phase3_df[\"guideline_pmid\"].dropna().nunique() if \"guideline_pmid\" in phase3_df.columns else 0\n",
    "\n",
    "print(f\"Unique references (unique ref_pmid): {unique_refs:,}\")\n",
    "print(f\"Unique guidelines (unique guideline_pmid): {unique_guidelines:,}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 6.4 Trial and registry statistics (citation-level + unique-ref views)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"CLINICAL TRIAL & NCT STATISTICS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Citation-level counts\n",
    "ct_citation_rows = int(phase3_df[\"ref_is_clinical_trial_pt_type\"].sum()) if \"ref_is_clinical_trial_pt_type\" in phase3_df.columns else 0\n",
    "nct_citation_rows = int(phase3_df[\"ref_primary_nct_number\"].notna().sum()) if \"ref_primary_nct_number\" in phase3_df.columns else 0\n",
    "\n",
    "print(\"Citation-level counts:\")\n",
    "print(f\"  Trial citation rows (ref_is_clinical_trial_pt_type=True): {ct_citation_rows:,}\")\n",
    "print(f\"  Citation rows with ANY NCT number:           {nct_citation_rows:,}\")\n",
    "\n",
    "# Unique-ref counts (often more meaningful)\n",
    "ct_unique_refs = int(phase3_df.loc[phase3_df[\"ref_is_clinical_trial_pt_type\"].eq(True), \"ref_pmid\"].dropna().nunique()) if \"ref_is_clinical_trial_pt_type\" in phase3_df.columns else 0\n",
    "nct_unique_refs = int(phase3_df.loc[phase3_df[\"ref_primary_nct_number\"].notna(), \"ref_pmid\"].dropna().nunique()) if \"ref_primary_nct_number\" in phase3_df.columns else 0\n",
    "\n",
    "print(\"\\nUnique-reference counts:\")\n",
    "print(f\"  Unique refs marked as trials:                {ct_unique_refs:,}\")\n",
    "print(f\"  Unique refs with ANY NCT number:             {nct_unique_refs:,}\")\n",
    "\n",
    "# Percentage based on unique refs (not rows)\n",
    "if unique_refs > 0:\n",
    "    print(f\"\\nPercent of unique refs marked trial: {ct_unique_refs / unique_refs * 100:.1f}%\")\n",
    "else:\n",
    "    print(\"\\nPercent of unique refs marked trial: N/A (no refs)\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 6.5 Publication type distribution (only among trial citations)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PUBLICATION TYPE DISTRIBUTION (Trials only — top 10)\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "if \"ref_publication_types\" in phase3_df.columns and \"ref_is_clinical_trial_pt_type\" in phase3_df.columns:\n",
    "    pub_types = phase3_df.loc[phase3_df[\"ref_is_clinical_trial_pt_type\"].eq(True), \"ref_publication_types\"].value_counts().head(10)\n",
    "    print(pub_types)\n",
    "else:\n",
    "    print(\"ℹ️ ref_publication_types or ref_is_clinical_trial_pt_type not present; skipping.\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 6.6 Sample rows to spot-check (trials only)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SPOT CHECK: First few trial citations\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "sample_cols = [c for c in [\"ref_pmid\", \"ref_primary_nct_number\", \"ref_title\", \"guideline_pmid\"] if c in phase3_df.columns]\n",
    "trials_sample = phase3_df.loc[phase3_df[\"ref_is_clinical_trial_pt_type\"].eq(True), sample_cols].head(10)\n",
    "print(trials_sample)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 6.7 Guideline-level coverage\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"GUIDELINE COVERAGE\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "guidelines_with_trials = int(phase3_df.loc[phase3_df[\"ref_is_clinical_trial_pt_type\"].eq(True), \"guideline_pmid\"].dropna().nunique())\n",
    "total_guidelines = int(phase3_df[\"guideline_pmid\"].dropna().nunique())\n",
    "\n",
    "print(f\"Guidelines citing ≥1 clinical trial: {guidelines_with_trials:,} / {total_guidelines:,}\")\n",
    "if total_guidelines > 0:\n",
    "    print(f\"({guidelines_with_trials / total_guidelines * 100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# GUIDELINES WITHOUT CLINICAL TRIALS\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"GUIDELINES WITHOUT CLINICAL TRIAL CITATIONS\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "all_guidelines = set(phase3_df[\"guideline_pmid\"].dropna().unique())\n",
    "guidelines_citing_trials = set(phase3_df.loc[phase3_df[\"ref_is_clinical_trial_pt_type\"].eq(True), \"guideline_pmid\"].dropna().unique())\n",
    "guidelines_without_trials = all_guidelines - guidelines_citing_trials\n",
    "\n",
    "print(f\"Found {len(guidelines_without_trials):,} guidelines without clinical trial citations.\")\n",
    "\n",
    "if len(guidelines_without_trials) > 0:\n",
    "    guidelines_no_trials_summary = []\n",
    "    for guideline_pmid in sorted(guidelines_without_trials):\n",
    "        guideline_refs = phase3_df[phase3_df[\"guideline_pmid\"] == guideline_pmid]\n",
    "        guidelines_no_trials_summary.append({\n",
    "            \"guideline_pmid\": guideline_pmid,\n",
    "            \"guideline_title\": guideline_refs[\"guideline_title\"].iloc[0] if \"guideline_title\" in guideline_refs.columns else None,\n",
    "            \"total_references\": len(guideline_refs),\n",
    "            \"references_with_pmids\": int(guideline_refs[\"ref_pmid\"].notna().sum()) if \"ref_pmid\" in guideline_refs.columns else None,\n",
    "            \"guideline_doi\": guideline_refs[\"guideline_doi\"].iloc[0] if \"guideline_doi\" in guideline_refs.columns else None\n",
    "        })\n",
    "\n",
    "    guidelines_no_trials_df = pd.DataFrame(guidelines_no_trials_summary)\n",
    "    no_trials_file = os.path.join(OUTPUT_FOLDER, \"phase3_guidelines_WITHOUT_trials.csv\")\n",
    "    guidelines_no_trials_df.to_csv(no_trials_file, index=False)\n",
    "\n",
    "    print(f\"✓ Saved summary to: {no_trials_file}\")\n",
    "    print(\"\\nSummary preview (top 10):\")\n",
    "    print(guidelines_no_trials_df.head(10).to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# GUIDELINES WITH TRIALS BUT NO NCT NUMBERS\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"GUIDELINES WITH TRIALS BUT NO NCT NUMBERS\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "guidelines_with_nct = set(phase3_df.loc[phase3_df[\"ref_primary_nct_number\"].notna(), \"guideline_pmid\"].dropna().unique()) if \"ref_primary_nct_number\" in phase3_df.columns else set()\n",
    "guidelines_with_trials_no_nct = guidelines_citing_trials - guidelines_with_nct\n",
    "\n",
    "print(f\"Found {len(guidelines_with_trials_no_nct):,} guidelines that cite trials but NONE have NCT numbers.\")\n",
    "\n",
    "if len(guidelines_with_trials_no_nct) > 0:\n",
    "    guidelines_no_nct_summary = []\n",
    "    for guideline_pmid in sorted(guidelines_with_trials_no_nct):\n",
    "        guideline_refs = phase3_df[phase3_df[\"guideline_pmid\"] == guideline_pmid]\n",
    "        trials_cited = guideline_refs[guideline_refs[\"ref_is_clinical_trial_pt_type\"].eq(True)]\n",
    "        guidelines_no_nct_summary.append({\n",
    "            \"guideline_pmid\": guideline_pmid,\n",
    "            \"guideline_title\": guideline_refs[\"guideline_title\"].iloc[0] if \"guideline_title\" in guideline_refs.columns else None,\n",
    "            \"total_references\": len(guideline_refs),\n",
    "            \"ref_clinical_trials_cited\": len(trials_cited),\n",
    "            \"ref_trials_with_nct\": 0,\n",
    "            \"guideline_doi\": guideline_refs[\"guideline_doi\"].iloc[0] if \"guideline_doi\" in guideline_refs.columns else None\n",
    "        })\n",
    "\n",
    "    guidelines_no_nct_df = pd.DataFrame(guidelines_no_nct_summary)\n",
    "    no_nct_file = os.path.join(OUTPUT_FOLDER, \"phase3_guidelines_WITHOUT_nct_numbers.csv\")\n",
    "    guidelines_no_nct_df.to_csv(no_nct_file, index=False)\n",
    "\n",
    "    print(f\"✓ Saved summary to: {no_nct_file}\")\n",
    "    print(\"\\nSummary preview (top 10):\")\n",
    "    print(guidelines_no_nct_df.head(10).to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# COMPLETE SUMMARY\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"COMPLETE GUIDELINE CLASSIFICATION (Phase 3)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "print(f\"Total guidelines analyzed: {total_guidelines:,}\")\n",
    "\n",
    "pct_no_trials = (len(guidelines_without_trials)/total_guidelines*100) if total_guidelines else 0\n",
    "pct_trials_no_nct = (len(guidelines_with_trials_no_nct)/total_guidelines*100) if total_guidelines else 0\n",
    "pct_trials_with_nct = (len(guidelines_with_nct)/total_guidelines*100) if total_guidelines else 0\n",
    "\n",
    "print(f\"1) Guidelines with NO clinical trials cited: {len(guidelines_without_trials):,} ({pct_no_trials:.1f}%)\")\n",
    "print(f\"2) Guidelines citing trials but NONE have NCT numbers: {len(guidelines_with_trials_no_nct):,} ({pct_trials_no_nct:.1f}%)\")\n",
    "print(f\"3) Guidelines citing trials WITH NCT numbers: {len(guidelines_with_nct):,} ({pct_trials_with_nct:.1f}%)\")\n",
    "\n",
    "if len(guidelines_with_trials_no_nct) > 0:\n",
    "    total_trials_no_nct = int(sum([\n",
    "        len(phase3_df[(phase3_df[\"guideline_pmid\"] == g) & (phase3_df[\"ref_is_clinical_trial_pt_type\"].eq(True))])\n",
    "        for g in guidelines_with_trials_no_nct\n",
    "    ]))\n",
    "    print(f\"\\nExtra context: Trials cited by 'trials-but-no-NCT' guidelines: {total_trials_no_nct:,} (all missing NCT)\")\n",
    "    print(\"Likely explanation: older trials published before routine registration/reporting.\")\n",
    "print(f\"\\n{'='*70}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddb39b7-a541-467f-97b1-ed4c5132c034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bad701d-81f3-4bf6-b358-6f704cc22499",
   "metadata": {},
   "source": [
    "# Phase 4: ClinicalTrials.gov Registry Data\n",
    "\n",
    "**Input:** `phase3_references_with_trials.csv` (trials with NCT numbers)  \n",
    "**Output:** `phase4_ctgov_trials_detailed.csv` (~684 NCT-registered trials)\n",
    "\n",
    "**What this does:**\n",
    "- Fetches detailed registry data for references that have a clinical trial Publication Type AND have NCT numbers\n",
    "- Gets study design, enrollment, eligibility, outcomes from ClinicalTrials.gov\n",
    "- **Only processes trials that have NCT numbers** (registered trials)\n",
    "\n",
    "**Key steps:**\n",
    "1. Extract unique NCT numbers from Phase 3 (.dropna() filters out non-registered)\n",
    "2. Fetch data from ClinicalTrials.gov API for each NCT\n",
    "3. Parse XML for study details\n",
    "4. Save registry metadata\n",
    "\n",
    "**Critical:** Non-registered trials (no NCT number) are excluded here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ed4f488-105b-45cf-98bc-d542891b8433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Phase 4 Configuration complete\n",
      "  Output folder: output\n",
      "  Will read: output\\phase3_references_with_trials.csv\n",
      "  Will create: output\\phase4_ctgov_trials_detailed.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 4: Step 1 - Configuration & Setup\n",
    "# ============================================================================\n",
    "# Purpose: Ensure configuration is consistent with previous phases\n",
    "# Run this: ONCE at the start of Phase 4\n",
    "# Re-run if: You need to verify configuration\n",
    "\n",
    "OUTPUT_FOLDER = 'output'\n",
    "\n",
    "# This should be the SAME as all previous phases\n",
    "# ========================================\n",
    "\n",
    "# Verify output folder exists\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "print(f\"✓ Phase 4 Configuration complete\")\n",
    "print(f\"  Output folder: {OUTPUT_FOLDER}\")\n",
    "print(f\"  Will read: {os.path.join(OUTPUT_FOLDER, 'phase3_references_with_trials.csv')}\")\n",
    "print(f\"  Will create: {os.path.join(OUTPUT_FOLDER, 'phase4_ctgov_trials_detailed.csv')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfb3e3c9-15d4-409c-97e4-38151cffce02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint system imported\n",
      "  Checkpoint interval: 50 trials\n",
      "  Checkpoints will be saved to: output/checkpoints/phase4_ctgov/\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 4: Step 2 - Import Checkpoint System\n",
    "# ============================================================================\n",
    "# Purpose: Set up checkpoint system for API calls\n",
    "# Run this: ONCE after Step 1\n",
    "# Re-run if: Checkpoint system is updated\n",
    "\n",
    "# import importlib\n",
    "# import normalized_checkpoint_system\n",
    "# importlib.reload(normalized_checkpoint_system)\n",
    "\n",
    "\n",
    "\n",
    "# Import normalized checkpoint system\n",
    "from normalized_checkpoint_system import (\n",
    "    save_phase4_checkpoint,\n",
    "    load_phase4_checkpoint,\n",
    "    CHECKPOINT_INTERVAL\n",
    ")\n",
    "\n",
    "print(\"✓ Checkpoint system imported\")\n",
    "print(f\"  Checkpoint interval: {CHECKPOINT_INTERVAL} trials\")\n",
    "print(f\"  Checkpoints will be saved to: output/checkpoints/phase4_ctgov/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a3c5cdc-72d5-4754-a36c-edb2d9d50000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Creating Canonical Citation-NCT Pairs Table\n",
      "======================================================================\n",
      "Loaded Phase 2: 9,204 citation rows\n",
      "Loaded Phase 3 pairs: 784 PMID-NCT pair rows\n",
      "\n",
      "Cleaning PMIDs for matching...\n",
      "  Phase 2 unique PMIDs: 7,726 unique PMIDs across all guideline reference list citations\n",
      "  Phase 3 unique PMIDs: 588 unique PMIDs with NCT number (ref_all_registry_ids NOT NAN AND ref_all_nct_numbers NOT Blank )\n",
      "  PMIDs that match: 588\n",
      "\n",
      "Merging 9,204 citations with 784 PMID-NCT pairs...\n",
      "  Merged rows: 842\n",
      "  Why are the merged grows greater than 784 PMID-NCT pairs? Because the same PMID was cited by multiple guidelines\n",
      "\n",
      "✓ Saved canonical citation-level NCT table: output\\phase4_guideline_reference_nct_pairs_master.csv\n",
      "  Rows (citation–NCT instances): 842\n",
      "  Unique NCTs: 684\n",
      "  Unique guideline–NCT links: 759\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 4 Step 3: Create Canonical Guideline+Reference PMIDs and NCT Pairs Table \n",
    "# ============================================================================\n",
    "# Purpose: Build the backbone table that links guidelines → references → NCTs\n",
    "# This is the KEY change for supporting multiple NCTs per PMID\n",
    "\n",
    "def clean_pmid(pmid):\n",
    "    \"\"\"Clean PMID string for consistent matching - handles floats correctly\"\"\"\n",
    "    if pd.isna(pmid):\n",
    "        return ''\n",
    "    \n",
    "    # Convert to string\n",
    "    pmid_str = str(pmid).strip().upper()\n",
    "    \n",
    "    # Handle empty strings\n",
    "    if not pmid_str or pmid_str in ['NONE', 'NAN', 'NULL']:\n",
    "        return ''\n",
    "    \n",
    "    # Remove PMID: prefix if present\n",
    "    if pmid_str.startswith('PMID:'):\n",
    "        pmid_str = pmid_str[5:].strip()\n",
    "    \n",
    "    # CRITICAL FIX: Handle floats (e.g., \"24835439.0\")\n",
    "    # Convert to float, then int, to remove decimal\n",
    "    try:\n",
    "        # Try to convert to number first\n",
    "        num = float(pmid_str)\n",
    "        # Convert to int to drop decimal\n",
    "        pmid_int = int(num)\n",
    "        # Back to string\n",
    "        return str(pmid_int)\n",
    "    except (ValueError, OverflowError):\n",
    "        # If not a number, just extract digits\n",
    "        pmid_str = ''.join(c for c in pmid_str if c.isdigit())\n",
    "        return pmid_str\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Creating Canonical Citation-NCT Pairs Table\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Load Phase 2 (citations) and Phase 3 (PMID-NCT pairs)\n",
    "phase2_path = os.path.join(OUTPUT_FOLDER, \"phase2_crossref_guidelines_and_references.csv\")\n",
    "pairs_path = os.path.join(OUTPUT_FOLDER, \"phase3_pmid_nct_pairs_master.csv\")\n",
    "\n",
    "phase2 = pd.read_csv(phase2_path, dtype=str)\n",
    "pairs = pd.read_csv(pairs_path, dtype=str)\n",
    "\n",
    "print(f\"Loaded Phase 2: {len(phase2):,} citation rows\")\n",
    "print(f\"Loaded Phase 3 pairs: {len(pairs):,} PMID-NCT pair rows\")\n",
    "\n",
    "# Clean PMIDs in both dataframes\n",
    "print(\"\\nCleaning PMIDs for matching...\")\n",
    "\n",
    "# Phase 2 - create cleaned version of ref_pmid\n",
    "phase2[\"ref_pmid_clean\"] = phase2[\"ref_pmid\"].apply(clean_pmid)\n",
    "\n",
    "# Phase 3 - clean the ref_pmid column\n",
    "pairs[\"ref_pmid_clean\"] = pairs[\"ref_pmid\"].apply(clean_pmid)\n",
    "\n",
    "# Check for matches before merge\n",
    "phase2_pmids = set(phase2[\"ref_pmid_clean\"].dropna())\n",
    "pairs_pmids = set(pairs[\"ref_pmid_clean\"].dropna())\n",
    "matching_pmids = phase2_pmids & pairs_pmids\n",
    "\n",
    "print(f\"  Phase 2 unique PMIDs: {len(phase2_pmids):,} unique PMIDs across all guideline reference list citations\")\n",
    "print(f\"  Phase 3 unique PMIDs: {len(pairs_pmids):,} unique PMIDs with NCT number (ref_all_registry_ids NOT NAN AND ref_all_nct_numbers NOT Blank )\")\n",
    "print(f\"  PMIDs that match: {len(matching_pmids):,}\")\n",
    "\n",
    "if len(matching_pmids) == 0:\n",
    "    print(\"\\n⚠️ WARNING: No matching PMIDs found!\")\n",
    "    print(\"Sample Phase 2 PMIDs:\", list(phase2_pmids)[:5])\n",
    "    print(\"Sample Phase 3 PMIDs:\", list(pairs_pmids)[:5])\n",
    "    raise ValueError(\"Cannot proceed - no PMID matches between Phase 2 and Phase 3\")\n",
    "\n",
    "# Join citations with PMID-NCT pairs\n",
    "print(f\"\\nMerging {len(phase2):,} citations with {len(pairs):,} PMID-NCT pairs...\")\n",
    "phase3_citation_nct = phase2.merge(\n",
    "    pairs,\n",
    "    on=\"ref_pmid_clean\",\n",
    "    how=\"inner\",  # Use inner to only keep rows that match\n",
    "    suffixes=(\"\", \"_pair\")\n",
    ")\n",
    "\n",
    "print(f\"  Merged rows: {len(phase3_citation_nct):,}\" )\n",
    "print(f\"  Why are the merged grows greater than {len(pairs):,} PMID-NCT pairs? Because the same PMID was cited by multiple guidelines\")\n",
    "\n",
    "# Keep only rows where an NCT exists\n",
    "phase3_citation_nct_with_nct = phase3_citation_nct[\n",
    "    phase3_citation_nct[\"ref_nct_number\"].notna()\n",
    "].copy()\n",
    "\n",
    "# Save the canonical citation-NCT pairs table\n",
    "citation_nct_out = os.path.join(OUTPUT_FOLDER, \"phase4_guideline_reference_nct_pairs_master.csv\")\n",
    "phase3_citation_nct_with_nct.to_csv(citation_nct_out, index=False)\n",
    "\n",
    "print(f\"\\n✓ Saved canonical citation-level NCT table: {citation_nct_out}\")\n",
    "print(f\"  Rows (citation–NCT instances): {len(phase3_citation_nct_with_nct):,}\")\n",
    "print(f\"  Unique NCTs: {phase3_citation_nct_with_nct['ref_nct_number'].nunique():,}\")\n",
    "print(f\"  Unique guideline–NCT links: {phase3_citation_nct_with_nct[['guideline_pmid','ref_nct_number']].drop_duplicates().shape[0]:,}\")\n",
    "print(f\"{'='*70}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ddfdb3-c945-4c8f-82a0-a2468be314e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "380455aa-3dcb-4fb7-9260-7d580da35f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE 4: Clinical Trial Details from ClinicalTrials.gov\n",
      "======================================================================\n",
      "Total citation-NCT instances: 842\n",
      "\n",
      "Deduplication:\n",
      "  Total citation instances: 842\n",
      "  Unique trials (NCTs): 684\n",
      "  Duplicate instances: 158\n",
      "  Trial–guideline linkages: 759\n",
      "\n",
      "✓ Will fetch details for 684 UNIQUE clinical trials\n",
      "  (This saves 158 unnecessary API calls!)\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 4 Step 4: Load Guideline-Reference-NCT Pairs and Extract Unique NCTs\n",
    "# ============================================================================\n",
    "print(f\"{'='*70}\")\n",
    "print(\"PHASE 4: Clinical Trial Details from ClinicalTrials.gov\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Load the canonical citation-NCT pairs table\n",
    "citation_nct_path = os.path.join(OUTPUT_FOLDER, \"phase4_guideline_reference_nct_pairs_master.csv\")\n",
    "citation_nct = pd.read_csv(citation_nct_path, dtype=str)\n",
    "\n",
    "print(f\"Total citation-NCT instances: {len(citation_nct):,}\")\n",
    "\n",
    "# Extract unique NCTs for fetching\n",
    "def get_unique_ncts_for_ctgov(citation_nct_df):\n",
    "    \"\"\"Get unique NCT list preserving first-seen order\"\"\"\n",
    "    ncts = (\n",
    "        citation_nct_df[\"ref_nct_number\"]\n",
    "        .dropna()\n",
    "        .astype(str).str.strip().str.upper()\n",
    "    )\n",
    "    # Preserve first-seen order (useful for debugging)\n",
    "    seen, out = set(), []\n",
    "    for x in ncts.tolist():\n",
    "        if x and x not in seen:\n",
    "            seen.add(x)\n",
    "            out.append(x)\n",
    "    return out\n",
    "\n",
    "nct_list = get_unique_ncts_for_ctgov(citation_nct)\n",
    "\n",
    "# Convert to DataFrame for compatibility\n",
    "unique_nct = pd.DataFrame({'ref_nct_number': nct_list})\n",
    "\n",
    "print(f\"\\nDeduplication:\")\n",
    "print(f\"  Total citation instances: {len(citation_nct):,}\")\n",
    "print(f\"  Unique trials (NCTs): {len(unique_nct):,}\")\n",
    "print(f\"  Duplicate instances: {len(citation_nct) - len(unique_nct):,}\")\n",
    "print(f\"  Trial–guideline linkages: {citation_nct[['guideline_pmid','ref_nct_number']].drop_duplicates().shape[0]:,}\")\n",
    "\n",
    "print(f\"\\n✓ Will fetch details for {len(unique_nct):,} UNIQUE clinical trials\")\n",
    "print(f\"  (This saves {len(citation_nct) - len(unique_nct):,} unnecessary API calls!)\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82b463bf-c40d-469e-906f-78ffe547ed52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Trial fetching function defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 4: Step 5 - Define ClinicalTrials.gov Fetching Function\n",
    "# ============================================================================\n",
    "# Purpose: Define function to fetch trial details from ClinicalTrials.gov\n",
    "\n",
    "def get_trial_details(nct_number):\n",
    "    \"\"\"\n",
    "    Fetch comprehensive trial details from ClinicalTrials.gov API v2\n",
    "    Returns dict with all relevant fields\n",
    "    \"\"\"\n",
    "    url = f\"https://clinicaltrials.gov/api/v2/studies/{nct_number}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        \n",
    "        if response.status_code == 404:\n",
    "            return {\n",
    "                'nct_number': nct_number,\n",
    "                'fetch_status': 'NOT_FOUND',\n",
    "                'error_message': 'Trial not found in ClinicalTrials.gov'\n",
    "            }\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Navigate to protocol section\n",
    "        protocol = data.get('protocolSection', {})\n",
    "        identification = protocol.get('identificationModule', {})\n",
    "        status = protocol.get('statusModule', {})\n",
    "        design = protocol.get('designModule', {})\n",
    "        arms = protocol.get('armsInterventionsModule', {})\n",
    "        outcomes = protocol.get('outcomesModule', {})\n",
    "        eligibility = protocol.get('eligibilityModule', {})\n",
    "        contacts = protocol.get('contactsLocationsModule', {})\n",
    "        \n",
    "        # Extract interventions\n",
    "        interventions = arms.get('interventions', [])\n",
    "        intervention_names = []\n",
    "        intervention_details = []\n",
    "        for intervention in interventions:\n",
    "            int_type = intervention.get('type', 'Unknown')\n",
    "            int_name = intervention.get('name', '')\n",
    "            intervention_names.append(f\"{int_type}: {int_name}\")\n",
    "            intervention_details.append(intervention)\n",
    "        \n",
    "        # Extract outcomes\n",
    "        primary_outcomes = []\n",
    "        for outcome in outcomes.get('primaryOutcomes', []):\n",
    "            primary_outcomes.append(outcome.get('measure', ''))\n",
    "        \n",
    "        secondary_outcomes = []\n",
    "        for outcome in outcomes.get('secondaryOutcomes', []):\n",
    "            secondary_outcomes.append(outcome.get('measure', ''))\n",
    "        \n",
    "        # Extract locations\n",
    "        locations = contacts.get('locations', [])\n",
    "        location_list = []\n",
    "        for loc in locations:\n",
    "            city = loc.get('city', '')\n",
    "            country = loc.get('country', '')\n",
    "            location_list.append(f\"{city}, {country}\")\n",
    "        \n",
    "        trial_info = {\n",
    "            'nct_number': nct_number,\n",
    "            'trial_url': f\"https://clinicaltrials.gov/study/{nct_number}\",\n",
    "            \n",
    "            # Basic Info\n",
    "            'official_title': identification.get('officialTitle', None),\n",
    "            'brief_title': identification.get('briefTitle', None),\n",
    "            'acronym': identification.get('acronym', None),\n",
    "            \n",
    "            # Status\n",
    "            'overall_status': status.get('overallStatus', None),\n",
    "            'start_date': status.get('startDateStruct', {}).get('date', None),\n",
    "            'completion_date': status.get('completionDateStruct', {}).get('date', None),\n",
    "            'last_update': status.get('lastUpdatePostDateStruct', {}).get('date', None),\n",
    "            \n",
    "            # Design\n",
    "            'study_type': design.get('studyType', None),\n",
    "            'phases': '; '.join(design.get('phases', [])) if design.get('phases') else None,\n",
    "            'allocation': design.get('designInfo', {}).get('allocation', None),\n",
    "            'intervention_model': design.get('designInfo', {}).get('interventionModel', None),\n",
    "            'masking': design.get('designInfo', {}).get('maskingInfo', {}).get('masking', None),\n",
    "            'primary_purpose': design.get('designInfo', {}).get('primaryPurpose', None),\n",
    "            \n",
    "            # Sample Size\n",
    "            'enrollment': status.get('enrollmentInfo', {}).get('count', None),\n",
    "            'enrollment_type': status.get('enrollmentInfo', {}).get('type', None),\n",
    "            \n",
    "            # Eligibility\n",
    "            'eligibility_criteria': eligibility.get('eligibilityCriteria', None),\n",
    "            'sex': eligibility.get('sex', None),\n",
    "            'min_age': eligibility.get('minimumAge', None),\n",
    "            'max_age': eligibility.get('maximumAge', None),\n",
    "            'healthy_volunteers': eligibility.get('healthyVolunteers', None),\n",
    "            \n",
    "            # Interventions\n",
    "            'interventions': json.dumps(intervention_details) if intervention_details else None,\n",
    "            'intervention_names': '; '.join(intervention_names) if intervention_names else None,\n",
    "            \n",
    "            # Outcomes\n",
    "            'primary_outcomes': '; '.join(primary_outcomes) if primary_outcomes else None,\n",
    "            'secondary_outcomes': '; '.join(secondary_outcomes) if secondary_outcomes else None,\n",
    "            \n",
    "            # Location\n",
    "            'locations': '; '.join(location_list) if location_list else None,\n",
    "            'n_locations': len(location_list) if location_list else 0,\n",
    "            \n",
    "            # Fetch status\n",
    "            'fetch_status': 'SUCCESS',\n",
    "            'fetch_timestamp': pd.Timestamp.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        return trial_info\n",
    "        \n",
    "    except requests.exceptions.Timeout:\n",
    "        return {\n",
    "            'nct_number': nct_number,\n",
    "            'fetch_status': 'TIMEOUT',\n",
    "            'error_message': 'Request timed out'\n",
    "        }\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\n",
    "            'nct_number': nct_number,\n",
    "            'fetch_status': 'ERROR',\n",
    "            'error_message': str(e)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'nct_number': nct_number,\n",
    "            'fetch_status': 'PARSE_ERROR',\n",
    "            'error_message': str(e)\n",
    "        }\n",
    "\n",
    "print(\"✓ Trial fetching function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e34bd54-d3e9-48e6-a1a7-da0aa107735c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 Loaded Phase 4 checkpoint:\n",
      "   Last trial index: 684\n",
      "   Trials processed: 684 / 684\n",
      "   Timestamp: 2026-01-05T17:02:24.439921\n",
      "   With enrollment data: 0\n",
      "   With sex eligibility: 682\n",
      "\n",
      "\n",
      "✓ Resuming from checkpoint\n",
      "  Already processed: 684 trials\n",
      "  Remaining: 0 trials\n",
      "\n",
      "Processing trials 684 to 684...\n",
      "Estimated time: ~0.0 minutes\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7953009f134968bc7afa4458819347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching trial details: 100%|##########| 684/684 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💾 Saving final checkpoint...\n",
      "\n",
      "✓ All 684 trials fetched!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 4 Step 6: Fetch Trial Details (LONG RUNNING - Can be interrupted and resumed)\n",
    "# ============================================================================\n",
    "total_trials = len(unique_nct)\n",
    "\n",
    "# Load checkpoint if exists\n",
    "checkpoint = load_phase4_checkpoint()\n",
    "\n",
    "if checkpoint:\n",
    "    detailed_trials = checkpoint['detailed_trials']\n",
    "    start_idx = checkpoint['last_idx']\n",
    "    print(f\"\\n✓ Resuming from checkpoint\")\n",
    "    print(f\"  Already processed: {len(detailed_trials):,} trials\")\n",
    "    print(f\"  Remaining: {total_trials - start_idx:,} trials\")\n",
    "else:\n",
    "    detailed_trials = []\n",
    "    start_idx = 0\n",
    "    print(\"\\n✓ Starting fresh (no checkpoint found)\")\n",
    "\n",
    "failed = []\n",
    "\n",
    "print(f\"\\nProcessing trials {start_idx:,} to {total_trials:,}...\")\n",
    "print(f\"Estimated time: ~{(total_trials - start_idx) * 0.5 / 60:.1f} minutes\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Fetch trial details (ONE API CALL PER UNIQUE NCT)\n",
    "try:\n",
    "    for idx in tqdm(range(start_idx, total_trials),\n",
    "                    initial=start_idx,\n",
    "                    total=total_trials,\n",
    "                    desc=\"Fetching trial details\"):\n",
    "        \n",
    "        row = unique_nct.iloc[idx]\n",
    "        nct_number = str(row['nct_number']).strip().upper()\n",
    "        \n",
    "        # Fetch trial details\n",
    "        trial_details = get_trial_details(nct_number)\n",
    "        detailed_trials.append(trial_details)\n",
    "        \n",
    "        # Track failures\n",
    "        if trial_details.get('fetch_status') != 'SUCCESS':\n",
    "            failed.append({\n",
    "                'nct_number': nct_number,\n",
    "                'status': trial_details.get('fetch_status'),\n",
    "                'error': trial_details.get('error_message')\n",
    "            })\n",
    "        \n",
    "        # Save checkpoint at intervals\n",
    "        if (idx + 1) % CHECKPOINT_INTERVAL == 0:\n",
    "            save_phase4_checkpoint(idx + 1, detailed_trials, total_trials)\n",
    "            print(f\"\\n💾 Checkpoint saved: {idx + 1:,}/{total_trials:,} trials fetched\")\n",
    "        \n",
    "        # Rate limiting (3 requests per second)\n",
    "        time.sleep(0.34)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\n⚠️ Interrupted by user!\")\n",
    "    print(\"Saving checkpoint...\")\n",
    "    save_phase4_checkpoint(idx, detailed_trials, total_trials)\n",
    "    print(f\"💾 Progress saved: {len(detailed_trials):,}/{total_trials:,} trials\")\n",
    "    print(\"\\nYou can re-run this cell to resume from checkpoint.\")\n",
    "    raise\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n\\n❌ Error occurred: {e}\")\n",
    "    print(\"Saving checkpoint...\")\n",
    "    save_phase4_checkpoint(idx, detailed_trials, total_trials)\n",
    "    print(f\"💾 Progress saved: {len(detailed_trials):,}/{total_trials:,} trials\")\n",
    "    print(\"\\nFix the error and run again to resume.\")\n",
    "    raise\n",
    "\n",
    "# Save final checkpoint\n",
    "print(\"\\n💾 Saving final checkpoint...\")\n",
    "save_phase4_checkpoint(total_trials, detailed_trials, total_trials)\n",
    "\n",
    "print(f\"\\n✓ All {total_trials:,} trials fetched!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "687f1e79-66ee-47b9-aa97-3b95b853cd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "✓ PHASE 4 COMPLETE: Clinical Trial Details\n",
      "======================================================================\n",
      "Saved to: output\\phase4_ctgov_trials_detailed.csv\n",
      "Total trials: 684\n",
      "\n",
      "Fetch Status Summary:\n",
      "  SUCCESS: 683\n",
      "  NOT_FOUND: 1\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Sample of fetched trials:\n",
      "    nct_number                                 nct_official_title  \\\n",
      "0  NCT01626079  A Clinical Evaluation of the Safety and Effect...   \n",
      "1  NCT01920698  Multicentre Randomized Study of Percutaneous M...   \n",
      "2  NCT00807040  Evaluation of Outcomes Following Mitral Valve ...   \n",
      "3  NCT00413998  Randomized Evaluation of Mitral Annuloplasty D...   \n",
      "4  NCT00209274  Pivotal Study: A Study of the Evalve Cardiovas...   \n",
      "\n",
      "  nct_overall_status  nct_enrollment  \n",
      "0            UNKNOWN             NaN  \n",
      "1          COMPLETED             NaN  \n",
      "2          COMPLETED             NaN  \n",
      "3          COMPLETED             NaN  \n",
      "4          COMPLETED             NaN  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 4 Step 7: Save Results and Show Summary\n",
    "# ============================================================================\n",
    "# Create DataFrame from results\n",
    "detailed_trials_df = pd.DataFrame(detailed_trials)\n",
    "\n",
    "# Add 'trial_' prefix to all columns EXCEPT identifiers\n",
    "columns_to_keep = ['nct_number']  # Keep these as-is\n",
    "columns_to_rename = {\n",
    "    col: f'nct_{col}' \n",
    "    for col in detailed_trials_df.columns \n",
    "    if col not in columns_to_keep\n",
    "}\n",
    "\n",
    "detailed_trials_df = detailed_trials_df.rename(columns=columns_to_rename)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = os.path.join(OUTPUT_FOLDER, 'phase4_ctgov_trials_detailed.csv')\n",
    "detailed_trials_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✓ PHASE 4 COMPLETE: Clinical Trial Details\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Saved to: {output_file}\")\n",
    "print(f\"Total trials: {len(detailed_trials_df):,}\")\n",
    "\n",
    "# Count fetch statuses\n",
    "status_counts = detailed_trials_df['nct_fetch_status'].value_counts()\n",
    "print(f\"\\nFetch Status Summary:\")\n",
    "for status, count in status_counts.items():\n",
    "    print(f\"  {status}: {count:,}\")\n",
    "\n",
    "# Show failed trials if any\n",
    "if failed:\n",
    "    print(f\"\\n⚠️ Failed to fetch {len(failed):,} trials:\")\n",
    "    failed_df = pd.DataFrame(failed)\n",
    "    print(failed_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'='*70}\\n\")\n",
    "\n",
    "# Show sample of successful trials\n",
    "successful = detailed_trials_df[detailed_trials_df['nct_fetch_status'] == 'SUCCESS']\n",
    "if len(successful) > 0:\n",
    "    print(\"Sample of fetched trials:\")\n",
    "    print(successful[['nct_number', 'nct_official_title', 'nct_overall_status', 'nct_enrollment']].head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e26ac242-f28f-4278-82a9-b806e412dd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PHASE 4 STEP 8: Data Integration\n",
      "======================================================================\n",
      "\n",
      "Loaded Phase 2: 9,204 citations\n",
      "Loaded Phase 3 unique refs: 7,725 rows\n",
      "Loaded citation-NCT pairs: 842 rows\n",
      "Loaded registry data: 684 trials\n",
      "\n",
      "Cleaning PMIDs...\n",
      "✓ PMIDs cleaned\n",
      "\n",
      "======================================================================\n",
      "Step 1: Creating TRIALS_ONLY file (citations with NCT + registry data)\n",
      "======================================================================\n",
      "\n",
      "  Merged pairs with Phase 3 abstracts: 842 rows\n",
      "  Merged with registry data: 842 rows\n",
      "\n",
      "TRIALS_ONLY file breakdown:\n",
      "  Total rows: 842\n",
      "  With abstracts: 838 (99.5%)\n",
      "  With registry data: 826 (98.1%)\n",
      "\n",
      "✓ Saved: output\\phase4_guideline_reference_nct_TRIALS_ONLY.csv\n",
      "  Columns: 62\n",
      "\n",
      "======================================================================\n",
      "Step 2: Creating REGISTERED_ONLY file (only citations with successful registry fetch)\n",
      "======================================================================\n",
      "\n",
      "REGISTERED_ONLY file breakdown:\n",
      "  Total rows: 826\n",
      "  With abstracts: 822\n",
      "\n",
      "✓ Saved: output\\phase4_guideline_reference_nct_REGISTERED_ONLY.csv\n",
      "  Columns: 62\n",
      "\n",
      "======================================================================\n",
      "Step 3A: Creating UNIVERSE file (citation-level, ALL citations)\n",
      "======================================================================\n",
      "\n",
      "  Merged Phase 2 + Phase 3: 9,204 rows\n",
      "  Deduplicating registry data (keep first NCT per citation)...\n",
      "    842 rows → 630 rows\n",
      "  Merged with registry: 9,204 rows\n",
      "  ✓ Row count preserved (9,204 citations)\n",
      "\n",
      "✓ Saved UNIVERSE file: output\\phase4_guideline_reference_nct_UNIVERSE.csv\n",
      "  Structure: Citation-level (one row per guideline-reference pair)\n",
      "  Rows: 9,204\n",
      "  Includes: ALL citations (trials and non-trials)\n",
      "  Multi-NCT handling: Shows primary NCT + semicolon-delimited list in ref_all_nct_numbers\n",
      "\n",
      "======================================================================\n",
      "Step 3B: Creating TRIALS_EXPLODED file (NCT-level)\n",
      "======================================================================\n",
      "\n",
      "✓ Saved TRIALS_EXPLODED file: output\\phase4_guideline_reference_nct_EXPLODED.csv\n",
      "  Structure: NCT-level (one row per guideline-reference-NCT triple)\n",
      "  Rows: 842\n",
      "  Includes: Only citations with NCTs (multi-NCT references = multiple rows)\n",
      "  Use for: Network analysis, unique trial counting, per-NCT analysis\n",
      "\n",
      "======================================================================\n",
      "✓ PHASE 4 STEP 8 COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Files created:\n",
      "  1. TRIALS_ONLY:     842 rows (citations with NCT)\n",
      "  2. REGISTERED_ONLY: 826 rows (successful registry fetch)\n",
      "  3. UNIVERSE:        9,204 rows (ALL citations, citation-level)\n",
      "  4. EXPLODED:        842 rows (trials only, NCT-level)\n",
      "\n",
      "Use UNIVERSE for Phase 7 (analyzes all citations)\n",
      "Use EXPLODED for multi-NCT network analysis\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 4 Step 8: Merge data with previous phases (COMPLETE FIX)\n",
    "# ============================================================================\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# SETUP: Load all required data\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PHASE 4 STEP 8: Data Integration\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Load Phase 2 (all citations)\n",
    "phase2_file = os.path.join(OUTPUT_FOLDER, \"phase2_crossref_guidelines_and_references.csv\")\n",
    "phase2_all = pd.read_csv(phase2_file)\n",
    "print(f\"Loaded Phase 2: {len(phase2_all):,} citations\")\n",
    "\n",
    "# Load Phase 3 UNIQUE REFS (has abstracts!)\n",
    "phase3_unique_refs_file = os.path.join(OUTPUT_FOLDER, \"phase3_references_with_trials_unique_refs.csv\")\n",
    "phase3_unique_refs = pd.read_csv(phase3_unique_refs_file)\n",
    "print(f\"Loaded Phase 3 unique refs: {len(phase3_unique_refs):,} rows\")\n",
    "\n",
    "# Load canonical citation-NCT pairs\n",
    "citation_nct_path = os.path.join(OUTPUT_FOLDER, \"phase4_guideline_reference_nct_pairs_master.csv\")\n",
    "citation_nct = pd.read_csv(citation_nct_path, dtype=str)\n",
    "print(f\"Loaded citation-NCT pairs: {len(citation_nct):,} rows\")\n",
    "\n",
    "# Load registry data\n",
    "detailed_trials_path = os.path.join(OUTPUT_FOLDER, \"phase4_ctgov_trials_detailed.csv\")\n",
    "detailed_trials = pd.read_csv(detailed_trials_path, dtype=str)\n",
    "print(f\"Loaded registry data: {len(detailed_trials):,} trials\")\n",
    "\n",
    "# Clean PMIDs for all datasets\n",
    "print(f\"\\nCleaning PMIDs...\")\n",
    "phase2_all['ref_pmid_clean'] = phase2_all['ref_pmid'].apply(clean_pmid)\n",
    "phase2_all['guideline_pmid_clean'] = phase2_all['guideline_pmid'].apply(clean_pmid)\n",
    "\n",
    "phase3_unique_refs['ref_pmid_clean'] = phase3_unique_refs['ref_pmid'].apply(clean_pmid)\n",
    "\n",
    "citation_nct['ref_pmid_clean'] = citation_nct['ref_pmid'].apply(clean_pmid)\n",
    "citation_nct['guideline_pmid_clean'] = citation_nct['guideline_pmid'].apply(clean_pmid)\n",
    "\n",
    "print(f\"✓ PMIDs cleaned\\n\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Step 1: Create TRIALS_ONLY file (with abstracts!)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"{'='*70}\")\n",
    "print(\"Step 1: Creating TRIALS_ONLY file (citations with NCT + registry data)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# First, merge pairs with Phase 3 abstracts\n",
    "citation_nct_with_abstracts = citation_nct.merge(\n",
    "    phase3_unique_refs[[\n",
    "        'ref_pmid_clean',\n",
    "        'ref_abstract',\n",
    "        'ref_has_abstract',\n",
    "        'ref_has_nct',\n",
    "        'ref_fetch_status'\n",
    "    ]],\n",
    "    on='ref_pmid_clean',\n",
    "    how='left',\n",
    "    suffixes=('', '_p3')\n",
    ")\n",
    "print(f\"  Merged pairs with Phase 3 abstracts: {len(citation_nct_with_abstracts):,} rows\")\n",
    "\n",
    "# Then merge with registry data\n",
    "citations_with_registry = citation_nct_with_abstracts.merge(\n",
    "    detailed_trials,\n",
    "    left_on='ref_nct_number',\n",
    "    right_on='nct_number',\n",
    "    how='left',\n",
    "    suffixes=('', '_registry')\n",
    ")\n",
    "print(f\"  Merged with registry data: {len(citations_with_registry):,} rows\")\n",
    "\n",
    "# Check data availability\n",
    "has_abstract = citations_with_registry['ref_abstract'].notna().sum()\n",
    "has_registry = citations_with_registry['nct_official_title'].notna().sum()\n",
    "\n",
    "print(f\"\\nTRIALS_ONLY file breakdown:\")\n",
    "print(f\"  Total rows: {len(citations_with_registry):,}\")\n",
    "print(f\"  With abstracts: {has_abstract:,} ({has_abstract/len(citations_with_registry)*100:.1f}%)\")\n",
    "print(f\"  With registry data: {has_registry:,} ({has_registry/len(citations_with_registry)*100:.1f}%)\")\n",
    "\n",
    "# Save TRIALS_ONLY\n",
    "trials_only_file = os.path.join(OUTPUT_FOLDER, \"phase4_guideline_reference_nct_TRIALS_ONLY.csv\")\n",
    "citations_with_registry.to_csv(trials_only_file, index=False)\n",
    "print(f\"\\n✓ Saved: {trials_only_file}\")\n",
    "print(f\"  Columns: {len(citations_with_registry.columns)}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Step 2: Create REGISTERED_ONLY file (subset of TRIALS_ONLY)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Step 2: Creating REGISTERED_ONLY file (only citations with successful registry fetch)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Filter to only rows with successful registry fetch\n",
    "citations_registered_only = citations_with_registry[\n",
    "    citations_with_registry['nct_official_title'].notna()\n",
    "].copy()\n",
    "\n",
    "print(f\"REGISTERED_ONLY file breakdown:\")\n",
    "print(f\"  Total rows: {len(citations_registered_only):,}\")\n",
    "print(f\"  With abstracts: {citations_registered_only['ref_abstract'].notna().sum():,}\")\n",
    "\n",
    "# Save REGISTERED_ONLY\n",
    "registered_only_file = os.path.join(OUTPUT_FOLDER, \"phase4_guideline_reference_nct_REGISTERED_ONLY.csv\")\n",
    "citations_registered_only.to_csv(registered_only_file, index=False)\n",
    "print(f\"\\n✓ Saved: {registered_only_file}\")\n",
    "print(f\"  Columns: {len(citations_registered_only.columns)}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Step 3A: Create UNIVERSE file (citation-level, ALL citations, no duplicates)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Step 3A: Creating UNIVERSE file (citation-level, ALL citations)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Merge Phase 2 with Phase 3 (abstracts + ref_primary_nct_number)\n",
    "master_citations = phase2_all.merge(\n",
    "    phase3_unique_refs[[\n",
    "        'ref_pmid_clean',\n",
    "        'ref_is_clinical_trial_pt_type',\n",
    "        'ref_publication_types',\n",
    "        'ref_primary_nct_number',\n",
    "        'ref_primary_nct_source',\n",
    "        'ref_all_registry_ids',\n",
    "        'ref_all_nct_numbers',\n",
    "        'ref_all_structured_nct_numbers',\n",
    "        'ref_all_nct_source_pairs',\n",
    "        'ref_all_structured_nct_source_pairs',\n",
    "        'ref_fetch_status',\n",
    "        'ref_has_nct',\n",
    "        'ref_abstract',\n",
    "        'ref_has_abstract'\n",
    "    ]],\n",
    "    on='ref_pmid_clean',\n",
    "    how='left',\n",
    "    suffixes=('', '_phase3')\n",
    ")\n",
    "print(f\"  Merged Phase 2 + Phase 3: {len(master_citations):,} rows\")\n",
    "\n",
    "# Deduplicate registry data for UNIVERSE (one row per citation)\n",
    "print(f\"  Deduplicating registry data (keep first NCT per citation)...\")\n",
    "registry_cols = [col for col in citations_with_registry.columns if col.startswith('nct_')]\n",
    "registry_cols.extend(['guideline_pmid_clean', 'ref_pmid_clean', 'ref_nct_number'])\n",
    "registry_cols = list(set(registry_cols))\n",
    "\n",
    "citations_with_registry_deduped = citations_with_registry[registry_cols].drop_duplicates(\n",
    "    subset=['guideline_pmid_clean', 'ref_pmid_clean'],\n",
    "    keep='first'\n",
    ")\n",
    "print(f\"    {len(citations_with_registry):,} rows → {len(citations_with_registry_deduped):,} rows\")\n",
    "\n",
    "# Merge with deduped registry\n",
    "master_citations = master_citations.merge(\n",
    "    citations_with_registry_deduped,\n",
    "    on=['guideline_pmid_clean', 'ref_pmid_clean'],\n",
    "    how='left',\n",
    "    suffixes=('', '_registry')\n",
    ")\n",
    "print(f\"  Merged with registry: {len(master_citations):,} rows\")\n",
    "\n",
    "# Verify no duplicates\n",
    "if len(master_citations) != len(phase2_all):\n",
    "    print(f\"  ⚠️ WARNING: Row count changed from {len(phase2_all):,} to {len(master_citations):,}\")\n",
    "else:\n",
    "    print(f\"  ✓ Row count preserved ({len(master_citations):,} citations)\")\n",
    "\n",
    "# Clean up duplicate columns\n",
    "duplicate_cols = [col for col in master_citations.columns if col.endswith('_registry') or col.endswith('_phase3')]\n",
    "if duplicate_cols:\n",
    "    print(f\"  Cleaning {len(duplicate_cols)} duplicate columns...\")\n",
    "    for col in duplicate_cols:\n",
    "        base_col = col.replace('_registry', '').replace('_phase3', '')\n",
    "        if base_col in master_citations.columns:\n",
    "            master_citations[base_col] = master_citations[col].fillna(master_citations[base_col])\n",
    "            master_citations = master_citations.drop(columns=[col])\n",
    "    print(f\"  ✓ Cleaned\")\n",
    "\n",
    "# Save UNIVERSE (citation-level)\n",
    "universe_file = os.path.join(OUTPUT_FOLDER, \"phase4_guideline_reference_nct_UNIVERSE.csv\")\n",
    "master_citations.to_csv(universe_file, index=False)\n",
    "\n",
    "print(f\"\\n✓ Saved UNIVERSE file: {universe_file}\")\n",
    "print(f\"  Structure: Citation-level (one row per guideline-reference pair)\")\n",
    "print(f\"  Rows: {len(master_citations):,}\")\n",
    "print(f\"  Includes: ALL citations (trials and non-trials)\")\n",
    "print(f\"  Multi-NCT handling: Shows primary NCT + semicolon-delimited list in ref_all_nct_numbers\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Step 3B: Create TRIALS_EXPLODED file (NCT-level, one row per NCT)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Step 3B: Creating TRIALS_EXPLODED file (NCT-level)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Use the full exploded citations_with_registry (with duplicates)\n",
    "# But add Phase 3 abstract columns\n",
    "trials_exploded = citations_with_registry.merge(\n",
    "    phase3_unique_refs[[\n",
    "        'ref_pmid_clean',\n",
    "        'ref_abstract',\n",
    "        'ref_has_abstract'\n",
    "    ]],\n",
    "    on='ref_pmid_clean',\n",
    "    how='left',\n",
    "    suffixes=('', '_p3')\n",
    ")\n",
    "\n",
    "# Clean duplicate columns\n",
    "duplicate_cols = [col for col in trials_exploded.columns if col.endswith('_p3')]\n",
    "for col in duplicate_cols:\n",
    "    base_col = col.replace('_p3', '')\n",
    "    if base_col in trials_exploded.columns:\n",
    "        trials_exploded[base_col] = trials_exploded[col].fillna(trials_exploded[base_col])\n",
    "        trials_exploded = trials_exploded.drop(columns=[col])\n",
    "\n",
    "# Save TRIALS_EXPLODED\n",
    "exploded_file = os.path.join(OUTPUT_FOLDER, \"phase4_guideline_reference_nct_EXPLODED.csv\")\n",
    "trials_exploded.to_csv(exploded_file, index=False)\n",
    "\n",
    "print(f\"✓ Saved TRIALS_EXPLODED file: {exploded_file}\")\n",
    "print(f\"  Structure: NCT-level (one row per guideline-reference-NCT triple)\")\n",
    "print(f\"  Rows: {len(trials_exploded):,}\")\n",
    "print(f\"  Includes: Only citations with NCTs (multi-NCT references = multiple rows)\")\n",
    "print(f\"  Use for: Network analysis, unique trial counting, per-NCT analysis\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Summary\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✓ PHASE 4 STEP 8 COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  1. TRIALS_ONLY:     {len(citations_with_registry):,} rows (citations with NCT)\")\n",
    "print(f\"  2. REGISTERED_ONLY: {len(citations_registered_only):,} rows (successful registry fetch)\")\n",
    "print(f\"  3. UNIVERSE:        {len(master_citations):,} rows (ALL citations, citation-level)\")\n",
    "print(f\"  4. EXPLODED:        {len(trials_exploded):,} rows (trials only, NCT-level)\")\n",
    "print(f\"\\nUse UNIVERSE for Phase 7 (analyzes all citations)\")\n",
    "print(f\"Use EXPLODED for multi-NCT network analysis\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d1ab4d4-92cc-40bb-b260-d58957295874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DIAGNOSTIC: Finding Missing Columns\n",
      "======================================================================\n",
      "\n",
      "1. Checking Phase 3 unique refs file...\n",
      "   Rows: 7,725\n",
      "   Has 'ref_primary_nct_number': True\n",
      "   Has 'ref_primary_nct_source': True\n",
      "   Non-null ref_primary_nct_number: 588 (7.6%)\n",
      "   Sample values: ['NCT01626079', 'NCT01920698', 'NCT00807040']\n",
      "\n",
      "2. Checking UNIVERSE file...\n",
      "   Rows: 9,204\n",
      "   Has 'ref_primary_nct_number': True\n",
      "   Has 'ref_primary_nct_source': True\n",
      "   Non-null ref_primary_nct_number: 630 (6.8%)\n",
      "   Sample values: ['NCT01626079', 'NCT01920698', 'NCT00807040']\n",
      "\n",
      "3. Columns that ARE in UNIVERSE file:\n",
      "   Found 27 ref_* columns:\n",
      "     - ref_abstract: 7,345 non-null\n",
      "     - ref_all_nct_numbers: 630 non-null\n",
      "     - ref_all_nct_source_pairs: 630 non-null\n",
      "     - ref_all_registry_ids: 8,148 non-null\n",
      "     - ref_all_structured_nct_numbers: 624 non-null\n",
      "     - ref_all_structured_nct_source_pairs: 624 non-null\n",
      "     - ref_authors: 0 non-null\n",
      "     - ref_doi: 8,458 non-null\n",
      "     - ref_fetch_status: 8,149 non-null\n",
      "     - ref_has_abstract: 8,149 non-null\n",
      "     - ref_has_nct: 8,149 non-null\n",
      "     - ref_is_clinical_trial_pt_type: 8,149 non-null\n",
      "     - ref_issue: 275 non-null\n",
      "     - ref_nct_number: 630 non-null\n",
      "     - ref_number: 9,204 non-null\n",
      "     - ref_pages: 1,289 non-null\n",
      "     - ref_pmid: 8,149 non-null\n",
      "     - ref_pmid_clean: 8,149 non-null\n",
      "     - ref_primary_nct_number: 630 non-null\n",
      "     - ref_primary_nct_source: 630 non-null\n",
      "     - ref_publication_types: 8,146 non-null\n",
      "     - ref_sourcetitle: 1,467 non-null\n",
      "     - ref_title: 1,314 non-null\n",
      "     - ref_type: 0 non-null\n",
      "     - ref_unstructured: 660 non-null\n",
      "     - ref_volume: 1,336 non-null\n",
      "     - ref_year: 1,474 non-null\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"DIAGNOSTIC: Finding Missing Columns\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check Phase 3 output (source of ref_primary_nct_number)\n",
    "print(\"\\n1. Checking Phase 3 unique refs file...\")\n",
    "phase3_check = pd.read_csv('output/phase3_references_with_trials_unique_refs.csv')\n",
    "print(f\"   Rows: {len(phase3_check):,}\")\n",
    "print(f\"   Has 'ref_primary_nct_number': {'ref_primary_nct_number' in phase3_check.columns}\")\n",
    "print(f\"   Has 'ref_primary_nct_source': {'ref_primary_nct_source' in phase3_check.columns}\")\n",
    "\n",
    "if 'ref_primary_nct_number' in phase3_check.columns:\n",
    "    non_null = phase3_check['ref_primary_nct_number'].notna().sum()\n",
    "    print(f\"   Non-null ref_primary_nct_number: {non_null:,} ({non_null/len(phase3_check)*100:.1f}%)\")\n",
    "    if non_null > 0:\n",
    "        print(f\"   Sample values: {phase3_check['ref_primary_nct_number'].dropna().head(3).tolist()}\")\n",
    "else:\n",
    "    print(f\"   ❌ PROBLEM: Phase 3 file missing ref_primary_nct_number!\")\n",
    "\n",
    "# Check UNIVERSE file (what Phase 7 is loading)\n",
    "print(\"\\n2. Checking UNIVERSE file...\")\n",
    "universe_check = pd.read_csv('output/phase4_guideline_reference_nct_UNIVERSE.csv')\n",
    "print(f\"   Rows: {len(universe_check):,}\")\n",
    "print(f\"   Has 'ref_primary_nct_number': {'ref_primary_nct_number' in universe_check.columns}\")\n",
    "print(f\"   Has 'ref_primary_nct_source': {'ref_primary_nct_source' in universe_check.columns}\")\n",
    "\n",
    "if 'ref_primary_nct_number' in universe_check.columns:\n",
    "    non_null = universe_check['ref_primary_nct_number'].notna().sum()\n",
    "    print(f\"   Non-null ref_primary_nct_number: {non_null:,} ({non_null/len(universe_check)*100:.1f}%)\")\n",
    "    if non_null > 0:\n",
    "        print(f\"   Sample values: {universe_check['ref_primary_nct_number'].dropna().head(3).tolist()}\")\n",
    "    else:\n",
    "        print(f\"   ⚠️ Column exists but ALL NULL!\")\n",
    "else:\n",
    "    print(f\"   ❌ PROBLEM: UNIVERSE file missing ref_primary_nct_number column!\")\n",
    "\n",
    "# Check what columns ARE in UNIVERSE\n",
    "print(f\"\\n3. Columns that ARE in UNIVERSE file:\")\n",
    "ref_cols = [col for col in universe_check.columns if col.startswith('ref_')]\n",
    "print(f\"   Found {len(ref_cols)} ref_* columns:\")\n",
    "for col in sorted(ref_cols):\n",
    "    non_null = universe_check[col].notna().sum()\n",
    "    print(f\"     - {col}: {non_null:,} non-null\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd335986-1ce3-4138-91dd-9d21087359d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d77636d-fab9-4111-bc27-b1af8e7aa648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2784c81-ace6-4ef1-9e6e-569ff9b5920b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091c5d10-c3d0-4ed1-9f17-ab2744535ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db35a71-2540-443c-97c3-24879073cd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cf9b1e-7c1d-4f72-9408-24978175981b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bf49d6-499c-420c-8a78-1bcf779f547c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88ab06d-b2d3-4141-8e06-d55669f3bdab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee48ee79-70ba-494e-bf5f-7aab0dc2f1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7391819-7cd4-4bc9-b9fb-69ffc4a0aefa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f15de2-3946-456d-9098-dcf77fd513e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64571621-dae1-4bdf-b180-93424e020f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c717ad38-3200-4209-b631-3cc37e91dd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3213214-addc-4183-bc1c-2a2af4ae65d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a85541-5f2c-4636-bf1c-360a71fcdbda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045d804b-e627-41cf-a748-3dd2e36d19e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a42c7ea-2674-4f1a-9686-899b34d9cee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5466c1-352f-480b-89d7-c6f62b1551e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7345bf-4df5-47f4-8bcd-0f318b9a84ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f7486c-fd69-4747-bed5-83b7143d9be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d80f2-d587-4978-9bba-4efd1c7d09c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f29c41f-9ab8-43ef-84aa-9284d9e6bec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8dea1d-57d9-443f-a67f-b2397f7aeba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de8bb04f-2ffe-44e4-be9e-3d9df5d0e051",
   "metadata": {},
   "source": [
    "# Phase 7: Sex Considerations Analysis\n",
    "\n",
    "**Input:**\n",
    "- Citation-level file with registry data (from Phase 4 merge)\n",
    "- Must have: `trial_*` columns (registry), `ref_abstract` (PubMed)\n",
    "\n",
    "**Output:** Citation-level file + ~30 new sex analysis columns\n",
    "\n",
    "**What this does:**\n",
    "- Analyzes trials for sex-based considerations across 3 sources:\n",
    "  1. Article title (from CrossRef)\n",
    "  2. Article abstract (from PubMed)\n",
    "  3. Trial registry fields (from ClinicalTrials.gov)\n",
    "- Detects mentions of sex differences, subgroup analyses, stratification\n",
    "- Identifies pregnancy/menopause/contraception/reproductive health terms\n",
    "- Flags women-specific conditions (PCOS, Turner syndrome, etc.)\n",
    "- Detects gender identity terms (LGBTQ, gender dysphoria)\n",
    "\n",
    "**Key steps:**\n",
    "1. For each citation row, extract:\n",
    "   - `ref_title` (article title)\n",
    "   - `ref_abstract` (article abstract)\n",
    "   - `trial_*` fields (registry data)\n",
    "2. Run comprehensive regex pattern matching\n",
    "3. Set boolean flags for each consideration type\n",
    "4. Capture text snippets as evidence\n",
    "5. Add analysis columns to dataset\n",
    "\n",
    "**Critical:**\n",
    "- Analyzes ALL THREE sources together (comprehensive view)\n",
    "- Boolean flags: `True` = detected, `False` = assessed but not found, `NaN` = no text to assess\n",
    "- New columns have NO prefix (they're analysis results, not source data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "596c559f-afd5-4875-adc4-ca5ef64b50b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Phase 7 Configuration complete\n",
      "  Output folder: output\n",
      "  Will read:\n",
      "    - output\\phase4_guideline_reference_nct_UNIVERSE.csv\n",
      "    - output\\phase4_ctgov_trials_detailed.csv\n",
      "  Will create:\n",
      "    - output\\phase7_trials_sex_analysis_with_duplicates.csv\n",
      "    - output\\phase7_trials_sex_analysis_deduplicated.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 7: Step 1 - Configuration & Setup\n",
    "# ============================================================================\n",
    "# Purpose: Ensure configuration is consistent with all previous phases\n",
    "# Run this: ONCE at the start of Phase 7\n",
    "# Re-run if: You need to verify configuration\n",
    "\n",
    "# ========================================\n",
    "# CONFIGURATION - Should match all previous phases!\n",
    "# ========================================\n",
    "OUTPUT_FOLDER = 'output'\n",
    "# This should be the SAME as all previous phases\n",
    "# ========================================\n",
    "\n",
    "# Verify output folder exists\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "print(f\"✓ Phase 7 Configuration complete\")\n",
    "print(f\"  Output folder: {OUTPUT_FOLDER}\")\n",
    "print(f\"  Will read:\")\n",
    "print(f\"    - {os.path.join(OUTPUT_FOLDER, 'phase4_guideline_reference_nct_UNIVERSE.csv')}\")\n",
    "print(f\"    - {os.path.join(OUTPUT_FOLDER, 'phase4_ctgov_trials_detailed.csv')}\")\n",
    "print(f\"  Will create:\")\n",
    "print(f\"    - {os.path.join(OUTPUT_FOLDER, 'phase7_trials_sex_analysis_with_duplicates.csv')}\")\n",
    "print(f\"    - {os.path.join(OUTPUT_FOLDER, 'phase7_trials_sex_analysis_deduplicated.csv')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6eebf2f5-78e7-4e56-b6c3-df2d5007d4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint system imported\n",
      "  Checkpoint interval: 50 trials\n",
      "  Checkpoints will be saved to: output/checkpoints/phase7_analysis/\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 7: Step 2 - Import Checkpoint System\n",
    "# ============================================================================\n",
    "# Purpose: Set up checkpoint system for analysis processing\n",
    "# Run this: ONCE after Step 1\n",
    "# Re-run if: Checkpoint system is updated\n",
    "\n",
    "# import importlib\n",
    "# import normalized_checkpoint_system\n",
    "# importlib.reload(normalized_checkpoint_system)\n",
    "\n",
    "\n",
    "# Import normalized checkpoint system\n",
    "from normalized_checkpoint_system import (\n",
    "    save_phase7_checkpoint,\n",
    "    load_phase7_checkpoint,\n",
    "    CHECKPOINT_INTERVAL\n",
    ")\n",
    "\n",
    "print(\"✓ Checkpoint system imported\")\n",
    "print(f\"  Checkpoint interval: {CHECKPOINT_INTERVAL} trials\")\n",
    "print(f\"  Checkpoints will be saved to: output/checkpoints/phase7_analysis/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f225440-c34a-402a-8d8d-2b6cd4d2da30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Analysis function defined:\n",
      "  - analyze_sex_considerations_with_article()\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 7: Step 3 - Define Analysis Function\n",
    "# ============================================================================\n",
    "# Purpose: Define comprehensive sex consideration analysis function\n",
    "# Run this: ONCE after Step 2\n",
    "# Re-run if: You modify the function logic\n",
    "\n",
    "# --------------------------\n",
    "# Text normalization helpers\n",
    "# --------------------------\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - '' if missing/empty\n",
    "      - lowercased string otherwise\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    s = str(text).strip()\n",
    "    return s.lower() if s else ''\n",
    "\n",
    "def build_registry_text(trial_row, fields):\n",
    "    \"\"\"\n",
    "    Safer registry text builder:\n",
    "    - ignores NaN\n",
    "    - ignores empty strings\n",
    "    - avoids literal 'nan' tokens\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for f in fields:\n",
    "        v = trial_row.get(f, np.nan)\n",
    "        t = normalize_text(v)\n",
    "        if t:\n",
    "            parts.append(t)\n",
    "    return ' '.join(parts)\n",
    "\n",
    "def regex_any(patterns, text):\n",
    "    \"\"\"Return True if any compiled regex matches text.\"\"\"\n",
    "    return any(p.search(text) for p in patterns)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Compile patterns (faster + consistent)\n",
    "# --------------------------\n",
    "\n",
    "SEX_MENTION_PATTERNS = [re.compile(p) for p in [\n",
    "    r'\\bsex\\b', r'\\bgender\\b',\n",
    "    r'\\bmale\\b', r'\\bfemale\\b',\n",
    "    r'\\bmen\\b', r'\\bwomen\\b',\n",
    "    r'\\bman\\b', r'\\bwoman\\b'\n",
    "]]\n",
    "\n",
    "SEX_DIFF_PATTERNS = [re.compile(p, re.IGNORECASE) for p in [\n",
    "    r'\\bsex[- ]specific\\b',\n",
    "    r'\\bgender[- ]specific\\b',\n",
    "    r'\\bsex[- ]based\\b',\n",
    "    r'\\bgender[- ]based\\b',\n",
    "    r'\\bsex\\s+(difference|differences|disparity|disparities)\\b',\n",
    "    r'\\bgender\\s+(difference|differences|disparity|disparities)\\b',\n",
    "    r'\\bbetween\\s+(men|males)\\s+and\\s+(women|females)\\b',\n",
    "    r'\\bbetween\\s+(women|females)\\s+and\\s+(men|males)\\b',\n",
    "    r'\\bby sex\\b',\n",
    "    r'\\baccording to sex\\b',\n",
    "    r'\\bbetween.*sexes\\b',\n",
    "    r'\\bsex[- ]disaggregated\\b',\n",
    "    r'\\bsex[- ]stratified\\b',\n",
    "    r'\\bgender[- ]stratified\\b',\n",
    "    r'\\bsex as.*variable\\b',\n",
    "    r'\\bgender as.*variable\\b',\n",
    "    r'\\bsex.*analysis\\b',\n",
    "    r'\\bgender.*analysis\\b'\n",
    "]]\n",
    "\n",
    "STRAT_PATTERNS = [re.compile(p, re.IGNORECASE) for p in [\n",
    "    r'\\bstratif\\w*\\s+by\\s+(sex|gender)\\b',\n",
    "    r'\\b(sex|gender)[- ]stratified\\b',\n",
    "    r'\\bstratification\\s+by\\s+(sex|gender)\\b',\n",
    "    r'\\banaly(?:s|z)ed\\s+separately\\s+(for|by)\\s+(sex|gender|men and women)\\b',\n",
    "    r'\\bseparate\\s+analyses?\\s+(for|by)\\s+(sex|gender|men and women)\\b'\n",
    "]]\n",
    "\n",
    "SUBGROUP_PATTERNS = [re.compile(p, re.IGNORECASE) for p in [\n",
    "    r'\\bsubgroup\\s+analysis.*\\b(sex|gender|men|women)\\b',\n",
    "    r'\\b(sex|gender|men|women)\\b.*subgroup\\s+analysis',\n",
    "    r'\\bsubgroup.*by\\s+(sex|gender)\\b',\n",
    "    r'\\b(sex|gender)\\s+subgroup\\b',\n",
    "    r'\\binteraction.*\\b(sex|gender)\\b'\n",
    "]]\n",
    "\n",
    "INTERACTION_PATTERNS = [re.compile(p, re.IGNORECASE) for p in [\n",
    "    r'\\bsex.*interaction\\b',\n",
    "    r'\\bgender.*interaction\\b',\n",
    "    r'\\binteraction.*sex\\b',\n",
    "    r'\\binteraction.*gender\\b',\n",
    "    r'\\binteraction.*between.*sex\\b'\n",
    "]]\n",
    "\n",
    "PREG_PATTERNS = [re.compile(p, re.IGNORECASE) for p in [\n",
    "    r'\\bpregnant\\b', r'\\bpregnancy\\b', r'\\bgestational\\b',\n",
    "    r'\\blactating\\b', r'\\bbreastfeeding\\b', r'\\bpostpartum\\b',\n",
    "    r'\\bantenatal\\b', r'\\bprenatal\\b', r'\\bperinatal\\b', r'\\bobstetric\\b'\n",
    "]]\n",
    "\n",
    "MENO_PATTERNS = [re.compile(p, re.IGNORECASE) for p in [\n",
    "    r'\\bmenopaus\\w*\\b', r'\\bpostmenopaus\\w*\\b', r'\\bperimenopaus\\w*\\b',\n",
    "    r'\\bhot flash\\b', r'\\bhormone replacement\\b', r'\\bclimacteric\\b'\n",
    "]]\n",
    "\n",
    "CONTRA_PATTERNS = [re.compile(p, re.IGNORECASE) for p in [\n",
    "    r'\\bcontraception\\b', r'\\bcontraceptive\\b', r'\\bbirth control\\b',\n",
    "    r'\\beffective contraception\\b', r'\\btwo forms.*contraception\\b',\n",
    "    r'\\bcontraception required\\b', r'\\buse of contraception\\b',\n",
    "    r'\\bchildbearing potential.*contraception\\b'\n",
    "]]\n",
    "\n",
    "HORM_PATTERNS = [re.compile(p, re.IGNORECASE) for p in [\n",
    "    r'\\bhormonal\\b', r'\\bestrogen\\b', r'\\bprogesterone\\b',\n",
    "    r'\\btestosterone\\b', r'\\bhormone level\\b', r'\\bendocrine\\b',\n",
    "    r'\\boral contraceptive\\b', r'\\bhormone replacement\\b',\n",
    "    r'\\bhormonal therapy\\b', r'\\bmenstrual cycle\\b', r'\\bovarian hormone\\b'\n",
    "]]\n",
    "\n",
    "PREG_EXCL_PATTERNS = [re.compile(p, re.IGNORECASE) for p in [\n",
    "    r'exclude.*pregnant',\n",
    "    r'pregnancy.*exclusion',\n",
    "    r'must not be pregnant',\n",
    "    r'cannot be pregnant',\n",
    "    r'negative pregnancy test'\n",
    "]]\n",
    "\n",
    "CBP_EXCL_PATTERNS = [re.compile(p, re.IGNORECASE) for p in [\n",
    "    r'exclude.*women.*childbearing potential',\n",
    "    r'women.*childbearing potential.*excluded',\n",
    "    r'not of childbearing potential'\n",
    "]]\n",
    "\n",
    "# Reproductive health patterns\n",
    "REPRODUCTIVE_PATTERNS = [re.compile(p, re.IGNORECASE) for p in [\n",
    "    r'\\breproductive\\b',\n",
    "    r'\\breproduction\\b',\n",
    "    r'\\bfertility\\b',\n",
    "    r'\\binfertility\\b',\n",
    "    r'\\binfertile\\b',\n",
    "    r'\\bovar(y|ies)\\b',           # ✅ Matches ovary OR ovaries\n",
    "    r'\\bovarian\\b',\n",
    "    r'\\bovulation\\b',\n",
    "    r'\\bconception\\b'\n",
    "]]\n",
    "\n",
    "# Maternal/offspring patterns\n",
    "MATERNAL_OFFSPRING_PATTERNS = [re.compile(p, re.IGNORECASE) for p in [\n",
    "    r'\\bmaternal\\b',\n",
    "    r'\\bmothers?\\b',              # ✅ Matches mother OR mothers\n",
    "    r'\\boffspring\\b',             # Already correct (no plural form)\n",
    "    r'\\bbab(y|ies)\\b',            # ✅ Matches baby OR babies\n",
    "    r'\\bfet(us|al)\\b',            # ✅ Matches fetus OR fetal\n",
    "    r'\\bfoet(us|al)\\b',           # ✅ British spelling\n",
    "    r'\\binfants?\\b',              # ✅ Matches infant OR infants\n",
    "    r'\\bnewborns?\\b',             # ✅ Matches newborn OR newborns\n",
    "    r'\\bneonatal\\b'\n",
    "]]\n",
    "\n",
    "\n",
    "# Lactation/breast patterns\n",
    "LACTATION_BREAST_PATTERNS = [re.compile(p, re.IGNORECASE) for p in [\n",
    "    r'\\bbreasts?\\b',              # ✅ Matches breast OR breasts\n",
    "    r'\\blactation\\b',\n",
    "    r'\\blactating\\b',\n",
    "    r'\\bbreastfeed(ing)?\\b',      # ✅ Matches breastfeed OR breastfeeding\n",
    "    r'\\bnursing mothers?\\b'       # ✅ More specific to avoid \"nursing home\"\n",
    "]]\n",
    "\n",
    "# Women-specific conditions\n",
    "WOMENS_CONDITIONS_PATTERNS = [re.compile(p, re.IGNORECASE) for p in [\n",
    "    r'\\bpcos\\b',\n",
    "    r'\\bpolycystic ovar(y|ies|ian)\\b',  # ✅ Catches all variants\n",
    "    r'\\bfemale athlete triad\\b',\n",
    "    r'\\brelative energy deficiency in sport\\b',\n",
    "    r'\\bred-s\\b',\n",
    "    r'\\bturn?ers? syndrome\\b'     # ✅ Matches Turner/Turners/Turner's\n",
    "]]\n",
    "\n",
    "\n",
    "# Gender identity patterns  \n",
    "GENDER_IDENTITY_PATTERNS = [re.compile(p, re.IGNORECASE) for p in [\n",
    "    r'\\blgbtq\\+?\\b',              # ✅ Matches LGBTQ or LGBTQ+\n",
    "    r'\\blgbt\\b',\n",
    "    r'\\btransgender(ed)?\\b',      # ✅ Both forms (though -ed is less common)\n",
    "    r'\\bgender dysphoria\\b',\n",
    "    r'\\bgender identit(y|ies)\\b', # ✅ Singular and plural\n",
    "    r'\\bgender minorit(y|ies)\\b', # ✅ Singular and plural\n",
    "    r'\\bgender[- ]diverse\\b',     # ✅ Handles hyphen or space\n",
    "    r'\\bnon[- ]?binary\\b'         # ✅ non-binary, nonbinary, or non binary\n",
    "]]\n",
    "\n",
    "def analyze_sex_considerations_with_article(trial_row, article_title=None, article_abstract=None):\n",
    "    \"\"\"\n",
    "    Best-practice version:\n",
    "    - Keeps NaN = not assessable\n",
    "    - If text exists, sets flags to False by default, then True if matched\n",
    "    - Uses regex word-boundary checks (consistent with Phase 7B)\n",
    "    - Avoids 'nan' tokens in registry text\n",
    "    \"\"\"\n",
    "    # Initialize ALL as np.nan (unknown until assessable)\n",
    "# Initialize ALL as np.nan (unknown until assessable)\n",
    "    analysis = {\n",
    "        # Registry eligibility (from nct_sex field)\n",
    "        'sex_eligibility': trial_row.get('nct_sex', np.nan),  # Raw categorical value\n",
    "        'nct_sex_includes_women': np.nan,\n",
    "        'nct_sex_women_only': np.nan,\n",
    "        \n",
    "        # Sex mentions by specific source\n",
    "        'ref_title_mentions_sex': np.nan,\n",
    "        'ref_abstract_mentions_sex': np.nan,\n",
    "        'nct_registry_mentions_sex': np.nan,\n",
    "        \n",
    "        # Cross-source analysis (searches ALL 3 sources)\n",
    "        'any_source_mentions_sex_differences': np.nan,\n",
    "        'any_source_mentions_sex_subgroup': np.nan,\n",
    "        'any_source_mentions_sex_stratification': np.nan,\n",
    "        'any_source_mentions_sex_interaction': np.nan,\n",
    "        \n",
    "        'any_source_pregnancy_related': np.nan,\n",
    "        'any_source_menopause_related': np.nan,\n",
    "        'any_source_contraception_required': np.nan,\n",
    "        'any_source_excludes_pregnant_women': np.nan,\n",
    "        'any_source_excludes_childbearing_potential': np.nan,\n",
    "        \n",
    "        'any_source_reproductive_health': np.nan,\n",
    "        'any_source_maternal_offspring': np.nan,\n",
    "        'any_source_lactation_breast': np.nan,\n",
    "        'any_source_fertility_related': np.nan,\n",
    "        \n",
    "        'any_source_hormonal_related': np.nan,\n",
    "        'any_source_sex_hormone_related': np.nan,\n",
    "        'any_source_menstrual_cycle': np.nan,\n",
    "        \n",
    "        'any_source_womens_conditions': np.nan,\n",
    "        'any_source_gender_identity': np.nan,\n",
    "        \n",
    "        # Evidence snippets\n",
    "        'sex_evidence_snippets': [],\n",
    "        'exclusion_evidence_snippets': []\n",
    "    }\n",
    "\n",
    "    # --------------------------\n",
    "    # Build normalized text blocks\n",
    "    # --------------------------\n",
    "    registry_fields = [\n",
    "        'nct_eligibility_criteria',\n",
    "        'nct_primary_outcomes',\n",
    "        'nct_secondary_outcomes',\n",
    "        'nct_official_title',\n",
    "        'nct_brief_title',\n",
    "        'nct_intervention_names'\n",
    "    ]\n",
    "    trial_registry_text = build_registry_text(trial_row, registry_fields)\n",
    "    title_text = normalize_text(article_title)\n",
    "    abstract_text = normalize_text(article_abstract)\n",
    "\n",
    "    # --------------------------\n",
    "    # Registry-based indicators (only if sex field exists)\n",
    "    # --------------------------\n",
    "    sex = normalize_text(trial_row.get('nct_sex', np.nan))\n",
    "    if sex:\n",
    "        analysis['nct_sex_includes_women'] = sex in ['all', 'female']\n",
    "        analysis['nct_sex_women_only'] = (sex == 'female')\n",
    "\n",
    "    # --------------------------\n",
    "    # BASIC sex/gender mentions by source (True/False/NaN)\n",
    "    # --------------------------\n",
    "    if title_text:\n",
    "        analysis['ref_title_mentions_sex'] = regex_any(SEX_MENTION_PATTERNS, title_text)\n",
    "    if abstract_text:\n",
    "        analysis['ref_abstract_mentions_sex'] = regex_any(SEX_MENTION_PATTERNS, abstract_text)\n",
    "    if trial_registry_text:\n",
    "        analysis['nct_registry_mentions_sex'] = regex_any(SEX_MENTION_PATTERNS, trial_registry_text)\n",
    "\n",
    "    # --------------------------\n",
    "    # Detailed flags:\n",
    "    # If ANY text exists in a source, set defaults to False (assessable),\n",
    "    # then elevate to True if matched. Leave NaN if no text anywhere.\n",
    "    # --------------------------\n",
    "    any_text = bool(trial_registry_text or title_text or abstract_text)\n",
    "    if any_text:\n",
    "        # set to False (assessable) first\n",
    "        for k in [\n",
    "            'any_source_mentions_sex_differences', \n",
    "            'any_source_mentions_sex_subgroup',\n",
    "            'any_source_mentions_sex_stratification',     \n",
    "            'any_source_mentions_sex_interaction',\n",
    "            'any_source_pregnancy_related', \n",
    "            'any_source_menopause_related', \n",
    "            'any_source_contraception_required',\n",
    "            'any_source_excludes_pregnant_women', \n",
    "            'any_source_excludes_childbearing_potential',\n",
    "            'any_source_hormonal_related',\n",
    "            'any_source_sex_hormone_related',     \n",
    "            'any_source_menstrual_cycle',          \n",
    "            'any_source_reproductive_health',             \n",
    "            'any_source_maternal_offspring',              \n",
    "            'any_source_lactation_breast',                \n",
    "            'any_source_womens_conditions', \n",
    "            'any_source_gender_identity',                 \n",
    "            'any_source_fertility_related'                \n",
    "        ]:\n",
    "            analysis[k] = False\n",
    "\n",
    "        all_text = ' '.join([trial_registry_text, title_text, abstract_text]).strip()\n",
    "\n",
    "\n",
    "        # ---- Sex differences (and capture evidence snippets by source) ----\n",
    "        for pattern in SEX_DIFF_PATTERNS:\n",
    "            # title\n",
    "            if title_text:\n",
    "                m = pattern.search(title_text)\n",
    "                if m:\n",
    "                    analysis['any_source_mentions_sex_differences'] = True\n",
    "                    analysis['ref_title_mentions_sex'] = True\n",
    "                    start = max(0, m.start() - 30)\n",
    "                    end = min(len(title_text), m.end() + 30)\n",
    "                    analysis['sex_evidence_snippets'].append(f\"[TITLE] {title_text[start:end].strip()}\")\n",
    "\n",
    "            # abstract\n",
    "            if abstract_text:\n",
    "                m = pattern.search(abstract_text)\n",
    "                if m:\n",
    "                    analysis['any_source_mentions_sex_differences'] = True\n",
    "                    analysis['ref_abstract_mentions_sex'] = True\n",
    "                    start = max(0, m.start() - 50)\n",
    "                    end = min(len(abstract_text), m.end() + 50)\n",
    "                    analysis['sex_evidence_snippets'].append(f\"[ABSTRACT] {abstract_text[start:end].strip()}\")\n",
    "\n",
    "            # registry\n",
    "            if trial_registry_text:\n",
    "                m = pattern.search(trial_registry_text)\n",
    "                if m:\n",
    "                    analysis['any_source_mentions_sex_differences'] = True\n",
    "                    analysis['nct_registry_mentions_sex'] = True\n",
    "                    start = max(0, m.start() - 50)\n",
    "                    end = min(len(trial_registry_text), m.end() + 50)\n",
    "                    analysis['sex_evidence_snippets'].append(f\"[REGISTRY] {trial_registry_text[start:end].strip()}\")\n",
    "\n",
    "        # ---- Interaction terms ----\n",
    "        if all_text and regex_any(INTERACTION_PATTERNS, all_text):\n",
    "            analysis['any_source_mentions_sex_interaction'] = True\n",
    "            analysis['any_source_mentions_sex_differences'] = True\n",
    "\n",
    "        # ---- Stratified/subgroup ----\n",
    "        if all_text and regex_any(STRAT_PATTERNS, all_text):\n",
    "            analysis['any_source_mentions_sex_stratification'] = True\n",
    "        if all_text and regex_any(SUBGROUP_PATTERNS, all_text):\n",
    "            analysis['any_source_mentions_sex_subgroup'] = True\n",
    "            # optional: interaction patterns often overlap subgroup\n",
    "            if analysis['any_source_mentions_sex_differences'] is False:\n",
    "                analysis['any_source_mentions_sex_differences'] = True\n",
    "\n",
    "        # ---- Pregnancy / Menopause / Hormonal / Contraception ----\n",
    "        if all_text and regex_any(PREG_PATTERNS, all_text):\n",
    "            analysis['any_source_pregnancy_related'] = True\n",
    "        if all_text and regex_any(MENO_PATTERNS, all_text):\n",
    "            analysis['any_source_menopause_related'] = True\n",
    "        if all_text and regex_any(HORM_PATTERNS, all_text):\n",
    "            analysis['any_source_hormonal_considerations'] = True\n",
    "        if all_text and regex_any(CONTRA_PATTERNS, all_text):\n",
    "            analysis['any_source_contraception_required'] = True\n",
    "        \n",
    "        if all_text and regex_any(REPRODUCTIVE_PATTERNS, all_text):\n",
    "            analysis['any_source_reproductive_health_related'] = True\n",
    "            analysis['any_source_fertility_considerations'] = True  # Populate this field now!\n",
    "            \n",
    "        if all_text and regex_any(MATERNAL_OFFSPRING_PATTERNS, all_text):\n",
    "            analysis['any_source_maternal_offspring_related'] = True\n",
    "            \n",
    "        if all_text and regex_any(LACTATION_BREAST_PATTERNS, all_text):\n",
    "            analysis['any_source_lactation_breast_related'] = True\n",
    "            \n",
    "        if all_text and regex_any(WOMENS_CONDITIONS_PATTERNS, all_text):\n",
    "            analysis['any_source_womens_conditions'] = True\n",
    "            \n",
    "        if all_text and regex_any(GENDER_IDENTITY_PATTERNS, all_text):\n",
    "            analysis['any_source_gender_identity_related'] = True\n",
    "\n",
    "        # ---- Hormonal / Sex Hormones / Menstrual Cycle ----\n",
    "        if all_text and regex_any(HORM_PATTERNS, all_text):\n",
    "            analysis['any_source_hormonal_related'] = True\n",
    "            \n",
    "            # Check if it's specifically about sex hormones\n",
    "            sex_hormone_patterns = [re.compile(p, re.IGNORECASE) for p in [\n",
    "                r'\\bestrogen\\b', r'\\bprogesterone\\b', r'\\btestosterone\\b',\n",
    "                r'\\bovarian hormone\\b', r'\\bsex hormone\\b'\n",
    "            ]]\n",
    "            if regex_any(sex_hormone_patterns, all_text):\n",
    "                analysis['any_source_sex_hormone_related'] = True\n",
    "            \n",
    "            # Check if it's about menstrual cycle\n",
    "            menstrual_patterns = [re.compile(p, re.IGNORECASE) for p in [\n",
    "                r'\\bmenstrual cycle\\b', r'\\bmenstruation\\b', r'\\bmenses\\b',\n",
    "                r'\\bcycle phase\\b', r'\\bfollicular phase\\b', r'\\bluteal phase\\b',\n",
    "                r'\\bovulation\\b'\n",
    "            ]]\n",
    "            if regex_any(menstrual_patterns, all_text):\n",
    "                analysis['any_source_menstrual_cycle'] = True\n",
    "\n",
    "        # ---- Exclusions evidence ----\n",
    "        if all_text:\n",
    "            for p in PREG_EXCL_PATTERNS:\n",
    "                m = p.search(all_text)\n",
    "                if m:\n",
    "                    analysis['any_source_excludes_pregnant_women'] = True\n",
    "                    start = max(0, m.start() - 50)\n",
    "                    end = min(len(all_text), m.end() + 50)\n",
    "                    analysis['exclusion_evidence_snippets'].append(all_text[start:end].strip())\n",
    "\n",
    "            for p in CBP_EXCL_PATTERNS:\n",
    "                m = p.search(all_text)\n",
    "                if m:\n",
    "                    analysis['any_source_excludes_childbearing_potential'] = True\n",
    "                    start = max(0, m.start() - 50)\n",
    "                    end = min(len(all_text), m.end() + 50)\n",
    "                    analysis['exclusion_evidence_snippets'].append(all_text[start:end].strip())\n",
    "\n",
    "    # Combine evidence snippets\n",
    "    analysis['sex_evidence_snippets'] = ' | '.join(analysis['sex_evidence_snippets']) if analysis['sex_evidence_snippets'] else None\n",
    "    analysis['exclusion_evidence_snippets'] = ' | '.join(analysis['exclusion_evidence_snippets']) if analysis['exclusion_evidence_snippets'] else None\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "print(\"✓ Analysis function defined:\")\n",
    "print(\"  - analyze_sex_considerations_with_article()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c715f5b8-5554-4eeb-a292-0803a879eafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PHASE 7: Sex Consideration Analysis (CITATION-LEVEL)\n",
      "======================================================================\n",
      "\n",
      "Data loaded:\n",
      "  Citation-level data: 9,204 rows\n",
      "  Unique references: 7,725\n",
      "  Unique NCTs: 505\n",
      "  Unique guidelines: 75\n",
      "\n",
      "✓ All required columns present\n",
      "\n",
      "Data availability:\n",
      "  Rows with ref_title: 1,314\n",
      "  Rows with ref_abstract: 7,345\n",
      "  Rows with nct_sex: 629\n",
      "  Rows with nct_eligibility_criteria: 630\n",
      "\n",
      "✓ Citation-level dataset ready for analysis: 9,204 rows\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 7: Step 4 - Load and Merge Data (CITATION-LEVEL)\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PHASE 7: Sex Consideration Analysis (CITATION-LEVEL)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Load Phase 4 UNIVERSE file (citation-level: ALL references)\n",
    "universe_df = pd.read_csv(\n",
    "    os.path.join(OUTPUT_FOLDER, 'phase4_guideline_reference_nct_UNIVERSE.csv'),\n",
    "    dtype=str\n",
    ")\n",
    "\n",
    "print(f\"Data loaded:\")\n",
    "print(f\"  Citation-level data: {len(universe_df):,} rows\")\n",
    "print(f\"  Unique references: {universe_df['ref_pmid'].nunique():,}\")\n",
    "print(f\"  Unique NCTs: {universe_df['ref_primary_nct_number'].dropna().nunique():,}\")\n",
    "print(f\"  Unique guidelines: {universe_df['guideline_pmid'].nunique():,}\")\n",
    "\n",
    "# Check for required columns\n",
    "required_cols = ['ref_title', 'ref_abstract', 'nct_sex', 'nct_eligibility_criteria']\n",
    "missing_cols = [col for col in required_cols if col not in universe_df.columns]\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"\\n⚠️ WARNING: Missing columns: {missing_cols}\")\n",
    "    print(\"  Phase 7 analysis may not work correctly!\")\n",
    "else:\n",
    "    print(f\"\\n✓ All required columns present\")\n",
    "\n",
    "# Show data availability\n",
    "print(f\"\\nData availability:\")\n",
    "print(f\"  Rows with ref_title: {universe_df['ref_title'].notna().sum():,}\")\n",
    "print(f\"  Rows with ref_abstract: {universe_df['ref_abstract'].notna().sum():,}\")\n",
    "print(f\"  Rows with nct_sex: {universe_df['nct_sex'].notna().sum():,}\")\n",
    "print(f\"  Rows with nct_eligibility_criteria: {universe_df['nct_eligibility_criteria'].notna().sum():,}\")\n",
    "\n",
    "# This is what we'll use for analysis\n",
    "combined_data = universe_df\n",
    "total_rows = len(combined_data)\n",
    "\n",
    "print(f\"\\n✓ Citation-level dataset ready for analysis: {total_rows:,} rows\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50081de2-4c21-40fb-8700-d6b9a4e96a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "277243df-5b27-4424-9cb4-0b28ff358e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Running Sex Consideration Analysis\n",
      "======================================================================\n",
      "\n",
      "📁 Loaded Phase 7 checkpoint:\n",
      "   Last analysis index: 9,416\n",
      "   Analyses processed: 9,416 / 9,416\n",
      "   Timestamp: 2026-01-06T09:55:03.246056\n",
      "\n",
      "\n",
      "✓ Resuming from checkpoint\n",
      "  Already processed: 9,416 rows\n",
      "  Remaining: -212 rows\n",
      "\n",
      "Processing rows 9,416 to 9,204...\n",
      "Estimated time: ~-0.4 minutes\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7e888c0977430b83f9947361467db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing sex considerations: 9416it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💾 Saving final checkpoint...\n",
      "\n",
      "✓ All 9,204 rows analyzed!\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 7: Step 5 - Analyze Sex Considerations (LONG RUNNING TIME)\n",
    "# ============================================================================\n",
    "# Purpose: Apply comprehensive sex consideration analysis to all trials\n",
    "print(f\"{'='*70}\")\n",
    "print(\"Running Sex Consideration Analysis\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Load checkpoint if exists\n",
    "checkpoint = load_phase7_checkpoint()\n",
    "if checkpoint:\n",
    "    sex_analyses = checkpoint['sex_analyses']\n",
    "    start_idx = checkpoint['last_idx']\n",
    "    print(f\"\\n✓ Resuming from checkpoint\")\n",
    "    print(f\"  Already processed: {len(sex_analyses):,} rows\")\n",
    "    print(f\"  Remaining: {total_rows - start_idx:,} rows\")\n",
    "else:\n",
    "    sex_analyses = []\n",
    "    start_idx = 0\n",
    "    print(\"\\n✓ Starting fresh (no checkpoint found)\")\n",
    "\n",
    "print(f\"\\nProcessing rows {start_idx:,} to {total_rows:,}...\")\n",
    "print(f\"Estimated time: ~{(total_rows - start_idx) * 0.1 / 60:.1f} minutes\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Apply sex consideration analysis\n",
    "try:\n",
    "    for idx in tqdm(range(start_idx, total_rows),\n",
    "                    initial=start_idx,\n",
    "                    total=total_rows,\n",
    "                    desc=\"Analyzing sex considerations\"):\n",
    "        \n",
    "        row = combined_data.iloc[idx]\n",
    "        \n",
    "        # Perform comprehensive sex consideration analysis\n",
    "        # ✅ FIXED: Use ref_title and ref_abstract\n",
    "        analysis = analyze_sex_considerations_with_article(\n",
    "            row, \n",
    "            article_title=row.get('ref_title'),      # ✅ FIXED\n",
    "            article_abstract=row.get('ref_abstract')  # ✅ FIXED\n",
    "        )\n",
    "        \n",
    "        # Add identifier to results (use whatever ID column exists in your data)\n",
    "        # If analyzing UNIVERSE: has guideline_pmid, ref_pmid, ref_primary_nct_number\n",
    "        # If analyzing REGISTERED_ONLY: has guideline_pmid, ref_pmid, nct_number\n",
    "        \n",
    "        if 'nct_number' in row.index and pd.notna(row['nct_number']):\n",
    "            analysis['nct_number'] = row['nct_number']\n",
    "        if 'ref_primary_nct_number' in row.index and pd.notna(row['ref_primary_nct_number']):  # ✅ if runs independently\n",
    "            analysis['ref_primary_nct_number'] = row['ref_primary_nct_number']\n",
    "        if 'ref_primary_nct_source' in row.index and pd.notna(row['ref_primary_nct_source']):  # ✅ Add source too\n",
    "            analysis['ref_primary_nct_source'] = row['ref_primary_nct_source']\n",
    "        \n",
    "        # Always include guideline and reference identifiers for linking back\n",
    "        if 'guideline_pmid' in row.index:\n",
    "            analysis['guideline_pmid'] = row['guideline_pmid']\n",
    "        if 'ref_pmid' in row.index:\n",
    "            analysis['ref_pmid'] = row['ref_pmid']\n",
    "        \n",
    "        sex_analyses.append(analysis)\n",
    "        \n",
    "        # Save checkpoint at intervals\n",
    "        if (idx + 1) % CHECKPOINT_INTERVAL == 0:\n",
    "            save_phase7_checkpoint(idx + 1, sex_analyses, total_rows)\n",
    "            print(f\"\\n💾 Checkpoint saved: {idx + 1:,}/{total_rows:,} rows analyzed\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\n⚠️ Interrupted by user!\")\n",
    "    print(\"Saving checkpoint...\")\n",
    "    save_phase7_checkpoint(idx, sex_analyses, total_rows)\n",
    "    print(f\"💾 Progress saved: {len(sex_analyses):,}/{total_rows:,} rows\")\n",
    "    print(\"\\nYou can re-run this cell to resume from checkpoint.\")\n",
    "    raise\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n\\n❌ Error occurred: {e}\")\n",
    "    print(\"Saving checkpoint...\")\n",
    "    save_phase7_checkpoint(idx, sex_analyses, total_rows)\n",
    "    print(f\"💾 Progress saved: {len(sex_analyses):,}/{total_rows:,} rows\")\n",
    "    print(\"\\nFix the error and run again to resume.\")\n",
    "    raise\n",
    "\n",
    "# Save final checkpoint\n",
    "print(\"\\n💾 Saving final checkpoint...\")\n",
    "save_phase7_checkpoint(total_rows, sex_analyses, total_rows)\n",
    "\n",
    "print(f\"\\n✓ All {total_rows:,} rows analyzed!\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12dddae0-923a-4269-b9e7-23bffb612163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Converting Analysis Results to DataFrame\n",
      "======================================================================\n",
      "\n",
      "Analysis results:\n",
      "  Total rows analyzed: 9,416\n",
      "  Unique NCTs: 684\n",
      "  Unique references: 7,724\n",
      "  Unique guidelines: 75\n",
      "\n",
      "Analysis columns created: 33\n",
      "  Sample: sex_eligibility, nct_sex_includes_women, nct_sex_women_only, ref_title_mentions_sex, ref_abstract_mentions_sex...\n",
      "\n",
      "✓ All columns have some data\n",
      "\n",
      "Key metrics:\n",
      "  nct_sex_includes_women:\n",
      "    True: 831, False: 9, Null: 8,576\n",
      "  ref_title_mentions_sex:\n",
      "    True: 43, False: 1,282, Null: 8,091\n",
      "  any_source_mentions_sex_differences:\n",
      "    True: 248, False: 7,788, Null: 1,380\n",
      "  any_source_pregnancy_related:\n",
      "    True: 867, False: 7,169, Null: 1,380\n",
      "\n",
      "✓ Analysis DataFrame ready for merging\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 7: Step 5.5 - Convert Analysis Results to DataFrame\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Converting Analysis Results to DataFrame\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Convert list of dictionaries to DataFrame\n",
    "sex_analysis_df = pd.DataFrame(sex_analyses)\n",
    "\n",
    "print(f\"Analysis results:\")\n",
    "print(f\"  Total rows analyzed: {len(sex_analysis_df):,}\")\n",
    "\n",
    "# Show identifiers\n",
    "if 'nct_number' in sex_analysis_df.columns:\n",
    "    unique_ncts = sex_analysis_df['nct_number'].dropna().nunique()\n",
    "    print(f\"  Unique NCTs: {unique_ncts:,}\")\n",
    "if 'ref_pmid' in sex_analysis_df.columns:\n",
    "    unique_refs = sex_analysis_df['ref_pmid'].dropna().nunique()\n",
    "    print(f\"  Unique references: {unique_refs:,}\")\n",
    "if 'guideline_pmid' in sex_analysis_df.columns:\n",
    "    unique_guidelines = sex_analysis_df['guideline_pmid'].dropna().nunique()\n",
    "    print(f\"  Unique guidelines: {unique_guidelines:,}\")\n",
    "\n",
    "# Show analysis columns created\n",
    "analysis_cols = [col for col in sex_analysis_df.columns \n",
    "                 if col not in ['nct_number', 'ref_pmid', 'guideline_pmid', 'ref_primary_nct_number']]\n",
    "print(f\"\\nAnalysis columns created: {len(analysis_cols)}\")\n",
    "print(f\"  Sample: {', '.join(analysis_cols[:5])}...\")\n",
    "\n",
    "# Data quality check - look for completely null columns\n",
    "null_cols = [col for col in sex_analysis_df.columns if sex_analysis_df[col].isna().all()]\n",
    "if null_cols:\n",
    "    print(f\"\\n⚠️ WARNING: {len(null_cols)} columns are completely null:\")\n",
    "    print(f\"  {null_cols}\")\n",
    "else:\n",
    "    print(f\"\\n✓ All columns have some data\")\n",
    "\n",
    "# Check key boolean flags\n",
    "print(f\"\\nKey metrics:\")\n",
    "for col in ['nct_sex_includes_women', 'ref_title_mentions_sex', \n",
    "            'any_source_mentions_sex_differences', 'any_source_pregnancy_related']:\n",
    "    if col in sex_analysis_df.columns:\n",
    "        true_count = (sex_analysis_df[col] == True).sum()\n",
    "        false_count = (sex_analysis_df[col] == False).sum()\n",
    "        null_count = sex_analysis_df[col].isna().sum()\n",
    "        print(f\"  {col}:\")\n",
    "        print(f\"    True: {true_count:,}, False: {false_count:,}, Null: {null_count:,}\")\n",
    "\n",
    "print(f\"\\n✓ Analysis DataFrame ready for merging\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e7690-23d6-4086-89b9-5e8d0a48d69e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1fc1177-e3ab-49b0-a847-e9a200ce3a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Phase 7 Step 6: Merging with Proper NaN Handling\n",
      "======================================================================\n",
      "\n",
      "Understanding the data:\n",
      "  8,149 citations with PMID (already unique) ✓\n",
      "  1,055 citations without PMID (340 are duplicates)\n",
      "  Expected after deduplication: ~8,864 unique citations\n",
      "\n",
      "Creating citation keys...\n",
      "\n",
      "Key type distribution:\n",
      "  PMID             8,149 ( 88.6%)\n",
      "  DOI                309 (  3.4%)\n",
      "  Title+Year         252 (  2.7%)\n",
      "  Row Index          492 (  5.3%)\n",
      "\n",
      "Deduplicating...\n",
      "  combined_data: 9,202 → 9,202 (removed 2)\n",
      "  sex_analysis_df: 8,220 → 8,220 (removed 1,196)\n",
      "\n",
      "Verification:\n",
      "  ✓ combined_data is now truly unique: 9,202 rows\n",
      "  ✓ sex_analysis_df is now truly unique: 8,220 rows\n",
      "\n",
      "Merging...\n",
      "  ✓ Merged successfully!\n",
      "  Result: 9,202 rows\n",
      "  ✓ Perfect 1:1 merge (row count preserved)\n",
      "  Citations with analysis: 7,503 (81.5%)\n",
      "\n",
      "Cleaning 5 duplicate columns...\n",
      "  ✓ Done\n",
      "\n",
      "======================================================================\n",
      "✓ MERGE COMPLETE\n",
      "======================================================================\n",
      "Final dataset: 9,202 unique citations\n",
      "Expected: ~8,864 (8,149 with PMID + 715 unique without PMID)\n",
      "Match: ⚠️\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 7: Step 6 - FINAL FIX (Handling NaN PMID Properly)\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Phase 7 Step 6: Merging with Proper NaN Handling\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "print(\"Understanding the data:\")\n",
    "print(f\"  8,149 citations with PMID (already unique) ✓\")\n",
    "print(f\"  1,055 citations without PMID (340 are duplicates)\")\n",
    "print(f\"  Expected after deduplication: ~8,864 unique citations\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Create robust citation identifier\n",
    "# ============================================================================\n",
    "\n",
    "def create_citation_key(df):\n",
    "    \"\"\"\n",
    "    Create unique key for each citation using available metadata\n",
    "    Handles NaN PMIDs properly (unlike drop_duplicates)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['citation_key'] = None\n",
    "    \n",
    "    # Method 1: Use PMID if available (8,149 citations)\n",
    "    has_pmid = df['ref_pmid'].notna()\n",
    "    df.loc[has_pmid, 'citation_key'] = (\n",
    "        'P_' + \n",
    "        df.loc[has_pmid, 'guideline_pmid'].astype(str) + '_' + \n",
    "        df.loc[has_pmid, 'ref_pmid'].astype(str)\n",
    "    )\n",
    "    \n",
    "    # Method 2: Use DOI if no PMID (~309 citations)\n",
    "    no_pmid = df['ref_pmid'].isna()\n",
    "    if 'ref_doi' in df.columns:\n",
    "        has_doi = no_pmid & df['ref_doi'].notna()\n",
    "        if has_doi.any():\n",
    "            # Clean DOI: lowercase, strip\n",
    "            clean_doi = df.loc[has_doi, 'ref_doi'].astype(str).str.lower().str.strip()\n",
    "            df.loc[has_doi, 'citation_key'] = (\n",
    "                'D_' + \n",
    "                df.loc[has_doi, 'guideline_pmid'].astype(str) + '_' + \n",
    "                clean_doi\n",
    "            )\n",
    "    \n",
    "    # Method 3: Use Title+Year if no PMID/DOI (~400 citations)\n",
    "    no_pmid_no_doi = no_pmid & df['citation_key'].isna()\n",
    "    if 'ref_title' in df.columns and 'ref_year' in df.columns:\n",
    "        has_title = (no_pmid_no_doi & \n",
    "                    df['ref_title'].notna() & \n",
    "                    df['ref_year'].notna())\n",
    "        if has_title.any():\n",
    "            # Clean title: lowercase, strip, remove punctuation, first 50 chars\n",
    "            clean_title = (\n",
    "                df.loc[has_title, 'ref_title']\n",
    "                .astype(str)\n",
    "                .str.lower()\n",
    "                .str.strip()\n",
    "                .str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "                .str.replace(r'\\s+', '_', regex=True)\n",
    "                .str[:50]\n",
    "            )\n",
    "            df.loc[has_title, 'citation_key'] = (\n",
    "                'T_' + \n",
    "                df.loc[has_title, 'guideline_pmid'].astype(str) + '_' + \n",
    "                clean_title + '_' +\n",
    "                df.loc[has_title, 'ref_year'].astype(str)\n",
    "            )\n",
    "    \n",
    "    # Method 4: Use row index as last resort (~remaining)\n",
    "    still_null = df['citation_key'].isna()\n",
    "    if still_null.any():\n",
    "        df.loc[still_null, 'citation_key'] = (\n",
    "            'R_' + \n",
    "            df.loc[still_null, 'guideline_pmid'].astype(str) + '_' + \n",
    "            df.loc[still_null].index.astype(str)\n",
    "        )\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Creating citation keys...\")\n",
    "combined_data = create_citation_key(combined_data)\n",
    "sex_analysis_df = create_citation_key(sex_analysis_df)\n",
    "\n",
    "# Show distribution\n",
    "print(f\"\\nKey type distribution:\")\n",
    "for prefix, label in [('P_', 'PMID'), ('D_', 'DOI'), ('T_', 'Title+Year'), ('R_', 'Row Index')]:\n",
    "    count = combined_data['citation_key'].str.startswith(prefix).sum()\n",
    "    if count > 0:\n",
    "        print(f\"  {label:15} {count:>6,} ({count/len(combined_data)*100:5.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Deduplicate using citation_key (same guideline citing the same reference)\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nDeduplicating...\")\n",
    "print(f\"  combined_data: {len(combined_data):,} → \", end='')\n",
    "\n",
    "# Keep most complete row\n",
    "combined_data['_completeness'] = combined_data.notna().sum(axis=1)\n",
    "combined_data = (\n",
    "    combined_data\n",
    "    .sort_values('_completeness', ascending=False)\n",
    "    .drop_duplicates(subset='citation_key', keep='first')\n",
    "    .drop(columns='_completeness')\n",
    "    .copy()\n",
    ")\n",
    "print(f\"{len(combined_data):,} (removed {9204 - len(combined_data):,})\")\n",
    "\n",
    "print(f\"  sex_analysis_df: {len(sex_analysis_df):,} → \", end='')\n",
    "analysis_cols = [col for col in sex_analysis_df.columns \n",
    "                 if 'any_source' in col] \n",
    "if analysis_cols:\n",
    "    sex_analysis_df['_completeness'] = sex_analysis_df[analysis_cols].notna().sum(axis=1)\n",
    "    sex_analysis_df = (\n",
    "        sex_analysis_df\n",
    "        .sort_values('_completeness', ascending=False)\n",
    "        .drop_duplicates(subset='citation_key', keep='first')\n",
    "        .drop(columns='_completeness')\n",
    "        .copy()\n",
    "    )\n",
    "else:\n",
    "    sex_analysis_df = sex_analysis_df.drop_duplicates(subset='citation_key', keep='first').copy()\n",
    "print(f\"{len(sex_analysis_df):,} (removed {9416 - len(sex_analysis_df):,})\")\n",
    "\n",
    "# Verify\n",
    "print(f\"\\nVerification:\")\n",
    "if combined_data['citation_key'].nunique() == len(combined_data):\n",
    "    print(f\"  ✓ combined_data is now truly unique: {len(combined_data):,} rows\")\n",
    "else:\n",
    "    print(f\"  ⚠️ Still has duplicates!\")\n",
    "\n",
    "if sex_analysis_df['citation_key'].nunique() == len(sex_analysis_df):\n",
    "    print(f\"  ✓ sex_analysis_df is now truly unique: {len(sex_analysis_df):,} rows\")\n",
    "else:\n",
    "    print(f\"  ⚠️ Still has duplicates!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Merge on citation_key (should be perfect 1:1)\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nMerging...\")\n",
    "\n",
    "trials_with_complete_analysis = combined_data.merge(\n",
    "    sex_analysis_df,\n",
    "    on='citation_key',\n",
    "    how='left',\n",
    "    suffixes=('', '_analysis'),\n",
    "    validate='1:1'\n",
    ")\n",
    "\n",
    "print(f\"  ✓ Merged successfully!\")\n",
    "print(f\"  Result: {len(trials_with_complete_analysis):,} rows\")\n",
    "\n",
    "if len(trials_with_complete_analysis) == len(combined_data):\n",
    "    print(f\"  ✓ Perfect 1:1 merge (row count preserved)\")\n",
    "else:\n",
    "    print(f\"  ⚠️ Unexpected row count change\")\n",
    "\n",
    "# Check coverage\n",
    "# Check coverage (using a different analysis column since score not calculated yet)\n",
    "merged_count = trials_with_complete_analysis['any_source_mentions_sex_differences'].notna().sum()\n",
    "print(f\"  Citations with analysis: {merged_count:,} ({merged_count/len(trials_with_complete_analysis)*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Clean up duplicate columns\n",
    "# ============================================================================\n",
    "\n",
    "duplicate_cols = [col for col in trials_with_complete_analysis.columns \n",
    "                  if col.endswith('_analysis')]\n",
    "\n",
    "if duplicate_cols:\n",
    "    print(f\"\\nCleaning {len(duplicate_cols)} duplicate columns...\")\n",
    "    for col in duplicate_cols:\n",
    "        base_col = col.replace('_analysis', '')\n",
    "        if base_col in trials_with_complete_analysis.columns:\n",
    "            trials_with_complete_analysis[base_col] = (\n",
    "                trials_with_complete_analysis[col]\n",
    "                .fillna(trials_with_complete_analysis[base_col])\n",
    "            )\n",
    "            trials_with_complete_analysis = trials_with_complete_analysis.drop(columns=[col])\n",
    "    print(f\"  ✓ Done\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✓ MERGE COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Final dataset: {len(trials_with_complete_analysis):,} unique citations\")\n",
    "print(f\"Expected: ~8,864 (8,149 with PMID + 715 unique without PMID)\")\n",
    "print(f\"Match: {'✓' if 8800 <= len(trials_with_complete_analysis) <= 8900 else '⚠️'}\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6018a-efd5-41d5-855f-768f61b7d500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126bbbc1-d1a7-40b2-b2dd-8ff06ec6bb29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e23cf270-854e-4b0a-b55c-2db02f743610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PHASE 7: Saving Analysis Results\n",
      "======================================================================\n",
      "\n",
      "Saving citation-level results (main output)...\n",
      "✓ Saved: output\\phase7_guideline_reference_nct_UNIVERSE_ANALYZED.csv\n",
      "  Structure: Citation-level (one row per guideline-reference pair)\n",
      "  Rows: 9,202\n",
      "  Columns: 96\n",
      "  Use for: Comprehensive analysis preserving all citation relationships\n",
      "\n",
      "  Citation breakdown:\n",
      "    Total citations: 9,202\n",
      "    With nct_number: 630\n",
      "    With ref_primary_nct_number: 630\n",
      "    Without NCT (non-trials): 8,572\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Creating trial-level summary (deduplicated)...\n",
      "  Trials with NCT numbers: 630\n",
      "\n",
      "✓ Saved: output\\phase7_trials_UNIQUE_NCT_ANALYZED.csv\n",
      "  Structure: Trial-level (one row per unique NCT)\n",
      "  Rows: 505\n",
      "  Columns: 96\n",
      "  Use for: Trial-level analysis (how many unique trials, trial characteristics)\n",
      "\n",
      "  Trial-level statistics:\n",
      "    Unique trials: 505\n",
      "    Trials with ANY sex consideration: 248 (49.1%)\n",
      "\n",
      "======================================================================\n",
      "✓ PHASE 7 COMPLETE - Analysis Results Saved\n",
      "======================================================================\n",
      "\n",
      "Files created:\n",
      "  1. output\\phase7_guideline_reference_nct_UNIVERSE_ANALYZED.csv\n",
      "     → Citation-level: 9,202 rows\n",
      "     → Use for: Comprehensive analysis, guideline-level patterns\n",
      "  2. output\\phase7_trials_UNIQUE_NCT_ANALYZED.csv\n",
      "     → Trial-level: 505 unique trials\n",
      "     → Use for: Unique trial counts, trial characteristics\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 7: Step 7 - Save Outputs and Generate Report\n",
    "# ============================================================================\n",
    "# Purpose: Save citation-level results and optional trial-level summary\n",
    "# Run this: After Step 6\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PHASE 7: Saving Analysis Results\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Output 1: CITATION-LEVEL (main output - ALL citations with analysis)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"Saving citation-level results (main output)...\")\n",
    "\n",
    "citation_level_file = os.path.join(OUTPUT_FOLDER, 'phase7_guideline_reference_nct_UNIVERSE_ANALYZED.csv')\n",
    "trials_with_complete_analysis.to_csv(citation_level_file, index=False)\n",
    "\n",
    "print(f\"✓ Saved: {citation_level_file}\")\n",
    "print(f\"  Structure: Citation-level (one row per guideline-reference pair)\")\n",
    "print(f\"  Rows: {len(trials_with_complete_analysis):,}\")\n",
    "print(f\"  Columns: {len(trials_with_complete_analysis.columns)}\")\n",
    "print(f\"  Use for: Comprehensive analysis preserving all citation relationships\")\n",
    "\n",
    "# Show breakdown\n",
    "with_nct = trials_with_complete_analysis['nct_number'].notna().sum() if 'nct_number' in trials_with_complete_analysis.columns else 0\n",
    "with_ref_primary = trials_with_complete_analysis['ref_primary_nct_number'].notna().sum() if 'ref_primary_nct_number' in trials_with_complete_analysis.columns else 0\n",
    "\n",
    "print(f\"\\n  Citation breakdown:\")\n",
    "print(f\"    Total citations: {len(trials_with_complete_analysis):,}\")\n",
    "print(f\"    With nct_number: {with_nct:,}\")\n",
    "print(f\"    With ref_primary_nct_number: {with_ref_primary:,}\")\n",
    "print(f\"    Without NCT (non-trials): {len(trials_with_complete_analysis) - max(with_nct, with_ref_primary):,}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Output 2: TRIAL-LEVEL SUMMARY (optional - deduplicated to unique trials)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n{'-'*70}\")\n",
    "print(\"Creating trial-level summary (deduplicated)...\")\n",
    "\n",
    "# Identify which NCT column to use for deduplication\n",
    "if 'nct_number' in trials_with_complete_analysis.columns:\n",
    "    nct_col = 'nct_number'\n",
    "elif 'ref_primary_nct_number' in trials_with_complete_analysis.columns:\n",
    "    nct_col = 'ref_primary_nct_number'\n",
    "else:\n",
    "    print(\"⚠️ No NCT column found - skipping trial-level summary\")\n",
    "    nct_col = None\n",
    "\n",
    "if nct_col:\n",
    "    # Filter to only rows with NCT numbers\n",
    "    trials_only = trials_with_complete_analysis[\n",
    "        trials_with_complete_analysis[nct_col].notna()\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"  Trials with NCT numbers: {len(trials_only):,}\")\n",
    "    \n",
    "    # Calculate priority for keeping \"best\" row when deduplicating\n",
    "    # Priority: Most sex considerations > Has abstract > First occurrence\n",
    "    sex_indicators = [\n",
    "        'any_source_mentions_sex_differences',\n",
    "        'any_source_hormonal_related',\n",
    "        'any_source_pregnancy_related',\n",
    "        'any_source_menopause_related',\n",
    "        'any_source_contraception_required'\n",
    "    ]\n",
    "    \n",
    "    # Only use indicators that exist\n",
    "    sex_indicators = [col for col in sex_indicators if col in trials_only.columns]\n",
    "    \n",
    "    if sex_indicators:\n",
    "        trials_only['_priority_sex_count'] = trials_only[sex_indicators].eq(True).sum(axis=1)\n",
    "    else:\n",
    "        trials_only['_priority_sex_count'] = 0\n",
    "    \n",
    "    # Check for abstract\n",
    "    abstract_col = 'ref_abstract' if 'ref_abstract' in trials_only.columns else None\n",
    "    if abstract_col:\n",
    "        trials_only['_priority_has_abstract'] = trials_only[abstract_col].notna()\n",
    "    else:\n",
    "        trials_only['_priority_has_abstract'] = False\n",
    "    \n",
    "    # Sort and deduplicate (keeps row with most sex info and abstract)\n",
    "    trials_deduplicated = (\n",
    "        trials_only\n",
    "        .sort_values(\n",
    "            ['_priority_sex_count', '_priority_has_abstract'], \n",
    "            ascending=[False, False]\n",
    "        )\n",
    "        .drop_duplicates(subset=[nct_col], keep='first')\n",
    "        .drop(columns=['_priority_sex_count', '_priority_has_abstract'])\n",
    "        .copy()\n",
    "    )\n",
    "    \n",
    "    # Save trial-level summary\n",
    "    trial_level_file = os.path.join(OUTPUT_FOLDER, 'phase7_trials_UNIQUE_NCT_ANALYZED.csv')\n",
    "    trials_deduplicated.to_csv(trial_level_file, index=False)\n",
    "    \n",
    "    print(f\"\\n✓ Saved: {trial_level_file}\")\n",
    "    print(f\"  Structure: Trial-level (one row per unique NCT)\")\n",
    "    print(f\"  Rows: {len(trials_deduplicated):,}\")\n",
    "    print(f\"  Columns: {len(trials_deduplicated.columns)}\")\n",
    "    print(f\"  Use for: Trial-level analysis (how many unique trials, trial characteristics)\")\n",
    "    \n",
    "    # Calculate trial-level statistics\n",
    "    if sex_indicators:\n",
    "        trials_with_sex = trials_deduplicated[sex_indicators].eq(True).any(axis=1).sum()\n",
    "        print(f\"\\n  Trial-level statistics:\")\n",
    "        print(f\"    Unique trials: {len(trials_deduplicated):,}\")\n",
    "        print(f\"    Trials with ANY sex consideration: {trials_with_sex:,} ({trials_with_sex/len(trials_deduplicated)*100:.1f}%)\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Summary Report\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✓ PHASE 7 COMPLETE - Analysis Results Saved\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  1. {citation_level_file}\")\n",
    "print(f\"     → Citation-level: {len(trials_with_complete_analysis):,} rows\")\n",
    "print(f\"     → Use for: Comprehensive analysis, guideline-level patterns\")\n",
    "\n",
    "if nct_col:\n",
    "    print(f\"  2. {trial_level_file}\")\n",
    "    print(f\"     → Trial-level: {len(trials_deduplicated):,} unique trials\")\n",
    "    print(f\"     → Use for: Unique trial counts, trial characteristics\")\n",
    "\n",
    "print(f\"\\n{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c7e09999-75e8-418d-aa62-371d64daf414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE 8: MULTI-SCENARIO ANALYSIS\n",
      "======================================================================\n",
      "Analysis Date: 2026-01-07 12:28\n",
      "\n",
      "Configured 6 scenarios for analysis:\n",
      "\n",
      "  1. S1_PubMed_PT: PubMed PT\n",
      "  2. S2_PubMed_OR_NCT: PubMed OR NCT\n",
      "  3. S3_Unique_Trials: Unique Trials\n",
      "  4. S4_Registry_Verified: Registry-Verified ⭐ RECOMMENDED\n",
      "  5. S5_All_NCTs: All NCTs\n",
      "  6. S6_High_Quality: High-Quality\n",
      "\n",
      "Step 1: Loading base data files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keg827\\AppData\\Local\\Temp\\ipykernel_28568\\4216040148.py:184: DtypeWarning: Columns (18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,36,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,61,62,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_universe = pd.read_csv(os.path.join(OUTPUT_FOLDER, 'phase7_guideline_reference_nct_UNIVERSE_ANALYZED.csv'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Loaded UNIVERSE: 9,202 citations\n",
      "  ✓ Loaded UNIQUE_TRIALS: 505 unique trials\n",
      "\n",
      "Step 2: Calculating sex consideration scores...\n",
      "  ✓ Scores calculated for both datasets\n",
      "\n",
      "Step 3.5: Creating baseline guideline list...\n",
      "  Total guidelines in corpus: 75\n",
      "  This baseline will be used for all scenarios to ensure no guidelines are excluded\n",
      "\n",
      "Step 3: Processing all scenarios...\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Processing S1_PubMed_PT: PubMed Publication Type\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  Applied filter: ref_is_clinical_trial_pt_type = True\n",
      "  Total citations: 1,527\n",
      "  Can verify sex: False\n",
      "  Calculating statistics...\n",
      "  Guidelines by category:\n",
      "    Weak: 46\n",
      "    Moderate: 17\n",
      "    Inadequate - No Sex Consideration: 7\n",
      "    Inadequate - No Trials Cited: 5\n",
      "  ✓ Saved: phase8_S1_PubMed_PT_overall_statistics.csv\n",
      "  ✓ Saved: phase8_S1_PubMed_PT_guideline_statistics.csv\n",
      "  ✓ Saved: phase8_S1_PubMed_PT_guideline_categories.csv\n",
      "  ✓ S1_PubMed_PT complete\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Processing S2_PubMed_OR_NCT: PubMed OR Registry\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  Applied filter: ref_is_clinical_trial_pt_type = True OR ref_primary_nct_number is not null\n",
      "  Total citations: 1,612\n",
      "  Can verify sex: partial\n",
      "  Calculating statistics...\n",
      "  Guidelines by category:\n",
      "    Weak: 45\n",
      "    Moderate: 19\n",
      "    Inadequate - No Sex Consideration: 7\n",
      "    Inadequate - No Trials Cited: 4\n",
      "  ✓ Saved: phase8_S2_PubMed_OR_NCT_overall_statistics.csv\n",
      "  ✓ Saved: phase8_S2_PubMed_OR_NCT_guideline_statistics.csv\n",
      "  ✓ Saved: phase8_S2_PubMed_OR_NCT_guideline_categories.csv\n",
      "  ✓ S2_PubMed_OR_NCT complete\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Processing S3_Unique_Trials: Unique Trials (Deduplicated)\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  Loaded from: phase7_trials_UNIQUE_NCT_ANALYZED.csv\n",
      "  Total trials: 505\n",
      "  Can verify sex: True\n",
      "  Calculating statistics...\n",
      "  Guideline categorization: N/A (trial-level scenario)\n",
      "  ✓ Saved: phase8_S3_Unique_Trials_overall_statistics.csv\n",
      "  ⊘ No guideline stats to save (trial-level scenario)\n",
      "  ✓ S3_Unique_Trials complete\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Processing S4_Registry_Verified: Registry-Verified Trials\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  Applied filter: ref_primary_nct_number is not null\n",
      "  Total citations: 630\n",
      "  Can verify sex: True\n",
      "  Calculating statistics...\n",
      "  Guidelines by category:\n",
      "    Moderate: 46\n",
      "    Strong: 15\n",
      "    Inadequate - No Trials Cited: 13\n",
      "    Weak: 1\n",
      "  ✓ Saved: phase8_S4_Registry_Verified_overall_statistics.csv\n",
      "  ✓ Saved: phase8_S4_Registry_Verified_guideline_statistics.csv\n",
      "  ✓ Saved: phase8_S4_Registry_Verified_guideline_categories.csv\n",
      "  ✓ S4_Registry_Verified complete\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Processing S5_All_NCTs: All NCT Mentions\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  Applied filter: ref_all_nct_numbers is not null\n",
      "  Total citations: 630\n",
      "  Can verify sex: True\n",
      "  Calculating statistics...\n",
      "  Guidelines by category:\n",
      "    Moderate: 46\n",
      "    Strong: 15\n",
      "    Inadequate - No Trials Cited: 13\n",
      "    Weak: 1\n",
      "  ✓ Saved: phase8_S5_All_NCTs_overall_statistics.csv\n",
      "  ✓ Saved: phase8_S5_All_NCTs_guideline_statistics.csv\n",
      "  ✓ Saved: phase8_S5_All_NCTs_guideline_categories.csv\n",
      "  ✓ S5_All_NCTs complete\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Processing S6_High_Quality: High-Quality Registry Data\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  Applied filter: ref_primary_nct_number is not null AND nct_official_title is not null\n",
      "  Total citations: 617\n",
      "  Can verify sex: True\n",
      "  Calculating statistics...\n",
      "  Guidelines by category:\n",
      "    Moderate: 46\n",
      "    Inadequate - No Trials Cited: 14\n",
      "    Strong: 14\n",
      "    Weak: 1\n",
      "  ✓ Saved: phase8_S6_High_Quality_overall_statistics.csv\n",
      "  ✓ Saved: phase8_S6_High_Quality_guideline_statistics.csv\n",
      "  ✓ Saved: phase8_S6_High_Quality_guideline_categories.csv\n",
      "  ✓ S6_High_Quality complete\n",
      "\n",
      "Step 4: Creating scenario comparison table...\n",
      "  ✓ Saved: phase8_scenario_comparison.csv\n",
      "  ✓ Saved: phase8_key_metrics_comparison.csv\n",
      "\n",
      "Step 5: Creating comprehensive data dictionary with actual search terms...\n",
      "  ✓ Saved: phase8_data_dictionary.csv (47 columns documented)\n",
      "  Creating scoring summary...\n",
      "  ✓ Saved: phase8_scoring_summary.csv\n",
      "  Creating pattern groups reference...\n",
      "  ✓ Saved: phase8_pattern_groups.csv\n",
      "\n",
      "======================================================================\n",
      "✓ PHASE 8 COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Files created:\n",
      "  - phase8_scenario_comparison.csv\n",
      "  - phase8_key_metrics_comparison.csv\n",
      "  - phase8_data_dictionary.csv\n",
      "  - phase8_S[X]_overall_statistics.csv (×6)\n",
      "  - phase8_S[X]_guideline_statistics.csv (×5)\n",
      "  - phase8_S[X]_guideline_categories.csv (×5)\n",
      "\n",
      "✓ Ready for Phase 9 (Insights & Recommendations)\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 8: Comprehensive Summary Statistics - Multi-Scenario Analysis\n",
    "# ============================================================================\n",
    "# Purpose: Calculate all metrics for multiple scenario definitions\n",
    "# Input: phase7_guideline_reference_nct_UNIVERSE_ANALYZED.csv\n",
    "#        phase7_trials_UNIQUE_NCT_ANALYZED.csv\n",
    "# Output: Statistics tables for each scenario + comparison tables\n",
    "#\n",
    "# ADDING NEW SCENARIOS:\n",
    "# 1. Add new entry to 'scenarios' dictionary below (lines ~50-150)\n",
    "# 2. Re-run this Phase 8\n",
    "# 3. All analyses automatically regenerate for new scenario\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "OUTPUT_FOLDER = 'output'\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"PHASE 8: MULTI-SCENARIO ANALYSIS\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# SCENARIO CONFIGURATION\n",
    "# ============================================================================\n",
    "# TO ADD A NEW SCENARIO:\n",
    "# 1. Copy one of the scenario blocks below\n",
    "# 2. Give it a unique ID (e.g., 'S7_Your_Name')\n",
    "# 3. Define the filter (lambda function that returns True/False)\n",
    "# 4. Set appropriate metadata\n",
    "# 5. Re-run Phase 8-10\n",
    "# ============================================================================\n",
    "\n",
    "scenarios = {\n",
    "    # ========================================================================\n",
    "    # SCENARIO 1: PubMed Publication Type Only\n",
    "    # ========================================================================\n",
    "    'S1_PubMed_PT': {\n",
    "        'name': 'PubMed Publication Type',\n",
    "        'short_name': 'PubMed PT',\n",
    "        'filter': lambda df: df['ref_is_clinical_trial_pt_type'] == True,\n",
    "        'description': 'Citations with PubMed clinical trial publication type',\n",
    "        'definition': 'ref_is_clinical_trial_pt_type = True',\n",
    "        'can_verify_sex': False,  # Can we verify sex inclusion for ALL citations in this scenario?\n",
    "        'count_type': 'citation',  # 'citation' or 'trial'\n",
    "        'data_source': 'UNIVERSE',  # 'UNIVERSE' or 'UNIQUE_TRIALS'\n",
    "        'color': 'E6F3FF',  # Excel cell color (hex)\n",
    "        'priority': 1,  # Display order\n",
    "        'rationale': 'Most conservative definition. Uses only PubMed official classification. Good for comparison with other studies.'\n",
    "    },\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SCENARIO 2: PubMed OR Registry\n",
    "    # ========================================================================\n",
    "    'S2_PubMed_OR_NCT': {\n",
    "        'name': 'PubMed OR Registry',\n",
    "        'short_name': 'PubMed OR NCT',\n",
    "        'filter': lambda df: (\n",
    "            (df['ref_is_clinical_trial_pt_type'] == True) | \n",
    "            (df['ref_primary_nct_number'].notna())\n",
    "        ),\n",
    "        'description': 'Citations with PubMed PT type OR NCT number',\n",
    "        'definition': 'ref_is_clinical_trial_pt_type = True OR ref_primary_nct_number is not null',\n",
    "        'can_verify_sex': 'partial',  # Some can, some can't\n",
    "        'count_type': 'citation',\n",
    "        'data_source': 'UNIVERSE',\n",
    "        'color': 'D4E9FF',\n",
    "        'priority': 2,\n",
    "        'rationale': 'Most comprehensive definition. Captures trials identified by either method. Recommended for total trial citation counts.'\n",
    "    },\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SCENARIO 3: Unique Trials (Deduplicated)\n",
    "    # ========================================================================\n",
    "    # SPECIAL CASE: This loads a different file instead of filtering UNIVERSE\n",
    "    'S3_Unique_Trials': {\n",
    "        'name': 'Unique Trials (Deduplicated)',\n",
    "        'short_name': 'Unique Trials',\n",
    "        'file': 'phase7_trials_UNIQUE_NCT_ANALYZED.csv',  # Load this file instead of filtering\n",
    "        'description': 'One row per unique NCT (deduplicated trial-level view)',\n",
    "        'definition': 'Deduplicated from phase7_trials_UNIQUE_NCT_ANALYZED.csv',\n",
    "        'can_verify_sex': True,\n",
    "        'count_type': 'trial',\n",
    "        'data_source': 'UNIQUE_TRIALS',\n",
    "        'color': 'C2E0FF',\n",
    "        'priority': 3,\n",
    "        'rationale': 'Trial-level analysis. Avoids double-counting same trial cited by multiple guidelines. Use for \"how many unique trials\" and trial characteristics.'\n",
    "    },\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SCENARIO 4: Registry-Verified Trials (RECOMMENDED PRIMARY)\n",
    "    # ========================================================================\n",
    "    'S4_Registry_Verified': {\n",
    "        'name': 'Registry-Verified Trials',\n",
    "        'short_name': 'Registry-Verified',\n",
    "        'filter': lambda df: df['ref_primary_nct_number'].notna(),\n",
    "        'description': 'Citations with NCT number (verifiable in ClinicalTrials.gov)',\n",
    "        'definition': 'ref_primary_nct_number is not null',\n",
    "        'can_verify_sex': True,\n",
    "        'count_type': 'citation',\n",
    "        'data_source': 'UNIVERSE',\n",
    "        'color': 'B0D7FF',\n",
    "        'priority': 4,\n",
    "        'recommended': True,  # Flag as primary scenario\n",
    "        'rationale': 'MOST DEFENSIBLE for sex inclusion claims. Every citation can be verified in registry. 100% coverage for sex eligibility data. Recommended primary analysis.'\n",
    "    },\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SCENARIO 5: All NCT Mentions (Primary + Secondary)\n",
    "    # ========================================================================\n",
    "    'S5_All_NCTs': {\n",
    "        'name': 'All NCT Mentions',\n",
    "        'short_name': 'All NCTs',\n",
    "        'filter': lambda df: df['ref_all_nct_numbers'].notna(),\n",
    "        'description': 'Citations mentioning any NCT (includes secondary NCTs)',\n",
    "        'definition': 'ref_all_nct_numbers is not null',\n",
    "        'can_verify_sex': True,\n",
    "        'count_type': 'citation',\n",
    "        'data_source': 'UNIVERSE',\n",
    "        'color': '9ECEFF',\n",
    "        'priority': 5,\n",
    "        'rationale': 'Complete trial network. Includes papers that mention multiple NCTs. Captures all trial connections, not just primary studies.'\n",
    "    },\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SCENARIO 6: High-Quality Registry Data\n",
    "    # ========================================================================\n",
    "    'S6_High_Quality': {\n",
    "        'name': 'High-Quality Registry Data',\n",
    "        'short_name': 'High-Quality',\n",
    "        'filter': lambda df: (\n",
    "            df['ref_primary_nct_number'].notna() & \n",
    "            df['nct_official_title'].notna()\n",
    "        ),\n",
    "        'description': 'Citations with complete registry data (successful fetch)',\n",
    "        'definition': 'ref_primary_nct_number is not null AND nct_official_title is not null',\n",
    "        'can_verify_sex': True,\n",
    "        'count_type': 'citation',\n",
    "        'data_source': 'UNIVERSE',\n",
    "        'color': '8CC5FF',\n",
    "        'priority': 6,\n",
    "        'rationale': 'Highest data quality. Guaranteed complete nct_sex, eligibility criteria, enrollment. No failed fetches. Best for detailed registry analysis.'\n",
    "    },\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TO ADD NEW SCENARIO: Copy this template and customize\n",
    "    # ========================================================================\n",
    "    # 'S7_Your_Scenario': {\n",
    "    #     'name': 'Your Scenario Full Name',\n",
    "    #     'short_name': 'Short Name',\n",
    "    #     'filter': lambda df: YOUR_FILTER_CONDITION,\n",
    "    #     # Example filters:\n",
    "    #     # lambda df: df['ref_year'] >= '2015'  # Recent only\n",
    "    #     # lambda df: df['nct_sex_women_only'] == True  # Women-only\n",
    "    #     # lambda df: df['ref_abstract'].notna()  # Has abstract\n",
    "    #     'description': 'Description of what this scenario includes',\n",
    "    #     'definition': 'Human-readable definition with column names',\n",
    "    #     'can_verify_sex': True,  # or False, or 'partial'\n",
    "    #     'count_type': 'citation',  # or 'trial'\n",
    "    #     'data_source': 'UNIVERSE',  # or 'UNIQUE_TRIALS'\n",
    "    #     'color': 'FFE6CC',  # Hex color for Excel\n",
    "    #     'priority': 7,  # Display order\n",
    "    #     'rationale': 'Why run this scenario?'\n",
    "    # }\n",
    "}\n",
    "\n",
    "print(f\"Configured {len(scenarios)} scenarios for analysis:\\n\")\n",
    "for s_id, s_config in sorted(scenarios.items(), key=lambda x: x[1]['priority']):\n",
    "    recommended = \" ⭐ RECOMMENDED\" if s_config.get('recommended', False) else \"\"\n",
    "    print(f\"  {s_config['priority']}. {s_id}: {s_config['short_name']}{recommended}\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# Step 1: Load Base Data\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 1: Loading base data files...\")\n",
    "\n",
    "# Load main UNIVERSE dataset\n",
    "df_universe = pd.read_csv(os.path.join(OUTPUT_FOLDER, 'phase7_guideline_reference_nct_UNIVERSE_ANALYZED.csv'))\n",
    "print(f\"  ✓ Loaded UNIVERSE: {len(df_universe):,} citations\")\n",
    "\n",
    "# Load UNIQUE trials dataset\n",
    "df_unique_trials = pd.read_csv(os.path.join(OUTPUT_FOLDER, 'phase7_trials_UNIQUE_NCT_ANALYZED.csv'))\n",
    "print(f\"  ✓ Loaded UNIQUE_TRIALS: {len(df_unique_trials):,} unique trials\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 2: Calculate Sex Consideration Score\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 2: Calculating sex consideration scores...\")\n",
    "\n",
    "def calculate_sex_score(row):\n",
    "    \"\"\"\n",
    "    Sex Consideration Score (0-10 scale)\n",
    "    \n",
    "    HIGH VALUE (2 points each, max 6):\n",
    "    - any_source_mentions_sex_differences\n",
    "    - any_source_mentions_sex_stratification\n",
    "    - any_source_mentions_sex_subgroup\n",
    "    \n",
    "    MEDIUM VALUE (1 point each, max 4):\n",
    "    - any_source_sex_hormone_related\n",
    "    - any_source_pregnancy_related\n",
    "    - any_source_menopause_related\n",
    "    - nct_sex_includes_women\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    \n",
    "    # HIGH VALUE: Direct sex analysis\n",
    "    if row.get('any_source_mentions_sex_differences') == True:\n",
    "        score += 2\n",
    "    if row.get('any_source_mentions_sex_stratification') == True:\n",
    "        score += 2\n",
    "    if row.get('any_source_mentions_sex_subgroup') == True:\n",
    "        score += 2\n",
    "    \n",
    "    # MEDIUM VALUE: Biological considerations\n",
    "    if row.get('any_source_sex_hormone_related') == True:\n",
    "        score += 1\n",
    "    if row.get('any_source_pregnancy_related') == True:\n",
    "        score += 1\n",
    "    if row.get('any_source_menopause_related') == True:\n",
    "        score += 1\n",
    "    \n",
    "    # BONUS: Trial inclusivity\n",
    "    if row.get('nct_sex_includes_women') == True:\n",
    "        score += 1\n",
    "    \n",
    "    return min(score, 10)\n",
    "\n",
    "# Apply to both datasets\n",
    "df_universe['sex_consideration_score'] = df_universe.apply(calculate_sex_score, axis=1)\n",
    "df_unique_trials['sex_consideration_score'] = df_unique_trials.apply(calculate_sex_score, axis=1)\n",
    "\n",
    "print(f\"  ✓ Scores calculated for both datasets\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 3: Helper Functions for Statistics Calculation\n",
    "# ============================================================================\n",
    "# These functions work for ANY scenario - no changes needed when adding scenarios\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_overall_stats(scenario_df, scenario_config, scenario_id):\n",
    "    \"\"\"\n",
    "    Calculate overall corpus statistics for a scenario\n",
    "    Returns DataFrame with metric, value, calculation, source_columns\n",
    "    \"\"\"\n",
    "    \n",
    "    stats = {\n",
    "        'scenario_id': [],\n",
    "        'metric': [],\n",
    "        'value': [],\n",
    "        'calculation': [],\n",
    "        'source_columns': []\n",
    "    }\n",
    "    \n",
    "    def add_stat(metric, value, calculation, sources):\n",
    "        stats['scenario_id'].append(scenario_id)\n",
    "        stats['metric'].append(metric)\n",
    "        stats['value'].append(value)\n",
    "        stats['calculation'].append(calculation)\n",
    "        stats['source_columns'].append(sources)\n",
    "    \n",
    "    # Determine if this is citation-level or trial-level\n",
    "    is_citation_level = scenario_config['count_type'] == 'citation'\n",
    "    \n",
    "    # Basic counts\n",
    "    add_stat(\n",
    "        'Total Count',\n",
    "        len(scenario_df),\n",
    "        f\"Total {'citations' if is_citation_level else 'trials'} in this scenario\",\n",
    "        'Row count'\n",
    "    )\n",
    "    \n",
    "    if is_citation_level:\n",
    "        # Citation-level metrics\n",
    "        add_stat(\n",
    "            'Unique Guidelines',\n",
    "            scenario_df['guideline_pmid'].nunique(),\n",
    "            'Count of unique guideline PMIDs',\n",
    "            'guideline_pmid'\n",
    "        )\n",
    "        \n",
    "        add_stat(\n",
    "            'Unique References',\n",
    "            scenario_df['ref_pmid'].nunique(),\n",
    "            'Count of unique reference PMIDs (excluding NaN)',\n",
    "            'ref_pmid'\n",
    "        )\n",
    "    \n",
    "    # Sex consideration metrics\n",
    "    citations_with_sex = (scenario_df['sex_consideration_score'] > 0).sum()\n",
    "    add_stat(\n",
    "        'Citations/Trials Mentioning Sex',\n",
    "        citations_with_sex,\n",
    "        f\"{'Citations' if is_citation_level else 'Trials'} where sex_consideration_score > 0\",\n",
    "        'sex_consideration_score (calculated from flags)'\n",
    "    )\n",
    "    \n",
    "    add_stat(\n",
    "        'Mentioning Sex %',\n",
    "        f\"{citations_with_sex/len(scenario_df)*100:.1f}%\",\n",
    "        'Mentioning Sex / Total × 100',\n",
    "        'sex_consideration_score'\n",
    "    )\n",
    "    \n",
    "    # Specific sex flags\n",
    "    sex_flags = {\n",
    "        'Sex Differences': 'any_source_mentions_sex_differences',\n",
    "        'Sex Stratification': 'any_source_mentions_sex_stratification',\n",
    "        'Sex Subgroup': 'any_source_mentions_sex_subgroup',\n",
    "        'Pregnancy Related': 'any_source_pregnancy_related',\n",
    "        'Menopause Related': 'any_source_menopause_related',\n",
    "        'Hormone Related': 'any_source_sex_hormone_related'\n",
    "    }\n",
    "    \n",
    "    for flag_name, flag_col in sex_flags.items():\n",
    "        if flag_col in scenario_df.columns:\n",
    "            count = (scenario_df[flag_col] == True).sum()\n",
    "            add_stat(\n",
    "                f'Mentions {flag_name}',\n",
    "                count,\n",
    "                f\"Count where {flag_col} == True\",\n",
    "                flag_col\n",
    "            )\n",
    "    \n",
    "    # Trial inclusivity (if verifiable)\n",
    "    if scenario_config['can_verify_sex'] == True:\n",
    "        if 'nct_sex_includes_women' in scenario_df.columns:\n",
    "            includes_women = (scenario_df['nct_sex_includes_women'] == True).sum()\n",
    "            add_stat(\n",
    "                'Includes Women',\n",
    "                includes_women,\n",
    "                'Count where nct_sex_includes_women == True',\n",
    "                'nct_sex_includes_women'\n",
    "            )\n",
    "            \n",
    "            add_stat(\n",
    "                'Includes Women %',\n",
    "                f\"{includes_women/len(scenario_df)*100:.1f}%\",\n",
    "                'Includes Women / Total × 100',\n",
    "                'nct_sex_includes_women'\n",
    "            )\n",
    "        \n",
    "        if 'nct_sex_women_only' in scenario_df.columns:\n",
    "            women_only = (scenario_df['nct_sex_women_only'] == True).sum()\n",
    "            add_stat(\n",
    "                'Women-Only Trials',\n",
    "                women_only,\n",
    "                'Count where nct_sex_women_only == True',\n",
    "                'nct_sex_women_only'\n",
    "            )\n",
    "    \n",
    "    # Average scores\n",
    "    add_stat(\n",
    "        'Avg Sex Consideration Score',\n",
    "        f\"{scenario_df['sex_consideration_score'].mean():.2f}\",\n",
    "        'Mean of sex_consideration_score',\n",
    "        'sex_consideration_score'\n",
    "    )\n",
    "    \n",
    "    add_stat(\n",
    "        'Median Sex Consideration Score',\n",
    "        f\"{scenario_df['sex_consideration_score'].median():.1f}\",\n",
    "        'Median of sex_consideration_score',\n",
    "        'sex_consideration_score'\n",
    "    )\n",
    "    \n",
    "    return pd.DataFrame(stats)\n",
    "\n",
    "\n",
    "def calculate_guideline_stats(scenario_df, scenario_config, scenario_id, all_guidelines_baseline):\n",
    "    \"\"\"\n",
    "    Calculate guideline-level statistics for a scenario\n",
    "    NOW INCLUDES AGGREGATED EVIDENCE SNIPPETS\n",
    "    \"\"\"\n",
    "    \n",
    "    if scenario_config['count_type'] != 'citation':\n",
    "        return None  # Not applicable for trial-level scenarios\n",
    "    \n",
    "    # Start with ALL guidelines (so none disappear)\n",
    "    guideline_stats = all_guidelines_baseline[['guideline_pmid']].copy()\n",
    "    \n",
    "    # Calculate metrics for guidelines that have citations in this scenario\n",
    "    scenario_metrics = scenario_df.groupby('guideline_pmid').agg({\n",
    "        'ref_pmid': 'count',  # Total citations IN THIS SCENARIO\n",
    "        'sex_consideration_score': ['mean', 'max', lambda x: (x > 0).sum()],\n",
    "        'any_source_mentions_sex_differences': lambda x: (x == True).sum(),\n",
    "        'any_source_mentions_sex_stratification': lambda x: (x == True).sum(),\n",
    "        'any_source_mentions_sex_subgroup': lambda x: (x == True).sum(),\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten multi-level columns\n",
    "    scenario_metrics.columns = [\n",
    "        'citations_in_scenario',\n",
    "        'avg_sex_score',\n",
    "        'max_sex_score',\n",
    "        'citations_with_sex',\n",
    "        'cites_sex_differences',\n",
    "        'cites_sex_stratification',\n",
    "        'cites_sex_subgroup'\n",
    "    ]\n",
    "    \n",
    "    # NEW: Aggregate evidence snippets\n",
    "    def aggregate_snippets(series, max_snippets=5, max_length=500):\n",
    "        \"\"\"\n",
    "        Aggregate snippets from multiple citations\n",
    "        - Take up to max_snippets non-null snippets\n",
    "        - Truncate total to max_length characters\n",
    "        - Separate with ' || '\n",
    "        \"\"\"\n",
    "        # Get non-null, non-empty snippets\n",
    "        snippets = series[series.notna() & (series != '')].head(max_snippets).tolist()\n",
    "        \n",
    "        if not snippets:\n",
    "            return None\n",
    "        \n",
    "        # Join with separator\n",
    "        combined = ' || '.join(snippets)\n",
    "        \n",
    "        # Truncate if too long\n",
    "        if len(combined) > max_length:\n",
    "            combined = combined[:max_length] + '...[truncated]'\n",
    "        \n",
    "        return combined\n",
    "    \n",
    "    # Aggregate snippets if columns exist\n",
    "    # Aggregate snippets if columns exist (using named aggregation for multiple outputs from same column)\n",
    "    snippet_data_parts = []\n",
    "    \n",
    "    if 'sex_evidence_snippets' in scenario_df.columns:\n",
    "        sex_snippet_agg = scenario_df.groupby('guideline_pmid')['sex_evidence_snippets'].agg([\n",
    "            ('sex_snippets_count', lambda x: x.notna().sum()),\n",
    "            ('sex_evidence_snippets', lambda x: aggregate_snippets(x, max_snippets=5, max_length=800))\n",
    "        ])\n",
    "        snippet_data_parts.append(sex_snippet_agg)\n",
    "    \n",
    "    if 'exclusion_evidence_snippets' in scenario_df.columns:\n",
    "        excl_snippet_agg = scenario_df.groupby('guideline_pmid')['exclusion_evidence_snippets'].agg([\n",
    "            ('exclusion_snippets_count', lambda x: x.notna().sum()),\n",
    "            ('exclusion_evidence_snippets', lambda x: aggregate_snippets(x, max_snippets=3, max_length=500))\n",
    "        ])\n",
    "        snippet_data_parts.append(excl_snippet_agg)\n",
    "    \n",
    "    # Merge snippet data into scenario_metrics\n",
    "    if snippet_data_parts:\n",
    "        for snippet_df in snippet_data_parts:\n",
    "            scenario_metrics = scenario_metrics.join(snippet_df)\n",
    "    \n",
    "    # Merge with baseline (LEFT JOIN - keeps all guidelines)\n",
    "    guideline_stats = guideline_stats.merge(\n",
    "        scenario_metrics,\n",
    "        on='guideline_pmid',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Fill NaN with 0 for numeric columns\n",
    "    numeric_cols = [\n",
    "        'citations_in_scenario', 'avg_sex_score', 'max_sex_score',\n",
    "        'citations_with_sex', 'cites_sex_differences', \n",
    "        'cites_sex_stratification', 'cites_sex_subgroup'\n",
    "    ]\n",
    "    guideline_stats[numeric_cols] = guideline_stats[numeric_cols].fillna(0)\n",
    "    \n",
    "    # Snippet columns stay as NaN if no data (that's meaningful - \"no snippets\")\n",
    "    \n",
    "    # Add trial-specific metrics if verifiable\n",
    "    if scenario_config['can_verify_sex'] == True:\n",
    "        if 'nct_sex_includes_women' in scenario_df.columns:\n",
    "            women_counts = scenario_df.groupby('guideline_pmid').agg({\n",
    "                'nct_sex_includes_women': lambda x: (x == True).sum()\n",
    "            })\n",
    "            guideline_stats = guideline_stats.merge(\n",
    "                women_counts,\n",
    "                on='guideline_pmid',\n",
    "                how='left'\n",
    "            )\n",
    "            guideline_stats['cites_trials_with_women'] = guideline_stats['nct_sex_includes_women'].fillna(0)\n",
    "            guideline_stats.drop('nct_sex_includes_women', axis=1, inplace=True)\n",
    "        else:\n",
    "            guideline_stats['cites_trials_with_women'] = 0\n",
    "    \n",
    "    # Calculate percentages\n",
    "    guideline_stats['pct_citing_sex'] = guideline_stats.apply(\n",
    "        lambda row: (row['citations_with_sex'] / row['citations_in_scenario'] * 100) \n",
    "                    if row['citations_in_scenario'] > 0 else 0,\n",
    "        axis=1\n",
    "    ).round(1)\n",
    "    \n",
    "    # Add scenario ID\n",
    "    guideline_stats['scenario_id'] = scenario_id\n",
    "    \n",
    "    # Set index\n",
    "    guideline_stats.set_index('guideline_pmid', inplace=True)\n",
    "    \n",
    "    return guideline_stats\n",
    "\n",
    "\n",
    "def categorize_guidelines(guideline_stats, scenario_config, scenario_id):\n",
    "    \"\"\"\n",
    "    Categorize guidelines into performance tiers\n",
    "    NOW HANDLES GUIDELINES WITH 0 TRIAL CITATIONS\n",
    "    \"\"\"\n",
    "    \n",
    "    if guideline_stats is None:\n",
    "        return None\n",
    "    \n",
    "    def categorize_row(row):\n",
    "        \"\"\"\n",
    "        Enhanced categorization that handles guidelines with no trials in this scenario\n",
    "        \n",
    "        Categories:\n",
    "        1. Strong: ≥20% citations mention sex, avg score ≥2\n",
    "        2. Moderate: ≥10% citations mention sex, avg score ≥1\n",
    "        3. Weak: ≥5% citations mention sex OR has some citations in scenario\n",
    "        4. Inadequate - No Trials Cited: 0 citations in this scenario\n",
    "        5. Inadequate - No Sex Consideration: Has citations but <5% mention sex\n",
    "        \"\"\"\n",
    "        \n",
    "        citations_in_scenario = row['citations_in_scenario']\n",
    "        pct_sex = row['pct_citing_sex']\n",
    "        avg_score = row['avg_sex_score']\n",
    "        \n",
    "        # NEW: Check if guideline has ANY citations in this scenario\n",
    "        if citations_in_scenario == 0:\n",
    "            return 'Inadequate - No Trials Cited'\n",
    "        \n",
    "        # Existing logic for guidelines with citations\n",
    "        if pct_sex >= 20 and avg_score >= 2:\n",
    "            return 'Strong'\n",
    "        elif pct_sex >= 10 and avg_score >= 1:\n",
    "            return 'Moderate'\n",
    "        elif pct_sex >= 5:\n",
    "            return 'Weak'\n",
    "        else:\n",
    "            return 'Inadequate - No Sex Consideration'\n",
    "    \n",
    "    guideline_stats['category'] = guideline_stats.apply(categorize_row, axis=1)\n",
    "    \n",
    "    return guideline_stats\n",
    "    return guideline_stats\n",
    "\n",
    "# ============================================================================\n",
    "# Step 3.5: Create Full Guideline List (Baseline)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 3.5: Creating baseline guideline list...\")\n",
    "\n",
    "# Get complete list of all guidelines from full UNIVERSE\n",
    "all_guidelines = df_universe.groupby('guideline_pmid').agg({\n",
    "    'ref_pmid': 'count'  # Total citations per guideline (all types)\n",
    "}).reset_index()\n",
    "all_guidelines.columns = ['guideline_pmid', 'total_citations_all_types']\n",
    "\n",
    "print(f\"  Total guidelines in corpus: {len(all_guidelines)}\")\n",
    "print(f\"  This baseline will be used for all scenarios to ensure no guidelines are excluded\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 4: Process All Scenarios\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 3: Processing all scenarios...\\n\")\n",
    "\n",
    "all_scenario_results = {}\n",
    "scenario_summary = []\n",
    "\n",
    "for scenario_id, scenario_config in sorted(scenarios.items(), key=lambda x: x[1]['priority']):\n",
    "    \n",
    "    print(f\"{'─'*70}\")\n",
    "    print(f\"Processing {scenario_id}: {scenario_config['name']}\")\n",
    "    print(f\"{'─'*70}\")\n",
    "    \n",
    "    # Load appropriate data\n",
    "    if scenario_config['data_source'] == 'UNIVERSE':\n",
    "        # Start with UNIVERSE and apply filter\n",
    "        scenario_df = df_universe.copy()\n",
    "        \n",
    "        if 'filter' in scenario_config:\n",
    "            scenario_df = scenario_df[scenario_config['filter'](scenario_df)].copy()\n",
    "            print(f\"  Applied filter: {scenario_config['definition']}\")\n",
    "    \n",
    "    elif scenario_config['data_source'] == 'UNIQUE_TRIALS':\n",
    "        # Load separate file\n",
    "        scenario_df = df_unique_trials.copy()\n",
    "        print(f\"  Loaded from: {scenario_config.get('file', 'UNIQUE_TRIALS')}\")\n",
    "    \n",
    "    count_label = 'citations' if scenario_config['count_type'] == 'citation' else 'trials'\n",
    "    print(f\"  Total {count_label}: {len(scenario_df):,}\")\n",
    "    print(f\"  Can verify sex: {scenario_config['can_verify_sex']}\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    print(f\"  Calculating statistics...\")\n",
    "    \n",
    "    overall_stats = calculate_overall_stats(scenario_df, scenario_config, scenario_id)\n",
    "    \n",
    "    # UPDATED: Pass all_guidelines baseline\n",
    "    guideline_stats = calculate_guideline_stats(\n",
    "        scenario_df, \n",
    "        scenario_config, \n",
    "        scenario_id,\n",
    "        all_guidelines  # ← ADD THIS PARAMETER\n",
    "    )\n",
    "    \n",
    "    if guideline_stats is not None:\n",
    "        categorized = categorize_guidelines(guideline_stats, scenario_config, scenario_id)\n",
    "        category_counts = categorized['category'].value_counts()\n",
    "        print(f\"  Guidelines by category:\")\n",
    "        for cat, count in category_counts.items():\n",
    "            print(f\"    {cat}: {count}\")\n",
    "    else:\n",
    "        categorized = None\n",
    "        print(f\"  Guideline categorization: N/A (trial-level scenario)\")\n",
    "    \n",
    "    # Store results\n",
    "    all_scenario_results[scenario_id] = {\n",
    "        'config': scenario_config,\n",
    "        'data': scenario_df,\n",
    "        'overall_stats': overall_stats,\n",
    "        'guideline_stats': guideline_stats,\n",
    "        'categorized': categorized\n",
    "    }\n",
    "    \n",
    "    # Add to summary\n",
    "    scenario_summary.append({\n",
    "        'scenario_id': scenario_id,\n",
    "        'name': scenario_config['name'],\n",
    "        'short_name': scenario_config['short_name'],\n",
    "        'definition': scenario_config['definition'],\n",
    "        'count': len(scenario_df),\n",
    "        'count_type': scenario_config['count_type'],\n",
    "        'can_verify_sex': scenario_config['can_verify_sex'],\n",
    "        'recommended': scenario_config.get('recommended', False)\n",
    "    })\n",
    "    \n",
    "    # Save individual scenario outputs\n",
    "    overall_stats.to_csv(\n",
    "        os.path.join(OUTPUT_FOLDER, f'phase8_{scenario_id}_overall_statistics.csv'),\n",
    "        index=False\n",
    "    )\n",
    "    print(f\"  ✓ Saved: phase8_{scenario_id}_overall_statistics.csv\")\n",
    "    \n",
    "    if guideline_stats is not None:\n",
    "        guideline_stats.to_csv(\n",
    "            os.path.join(OUTPUT_FOLDER, f'phase8_{scenario_id}_guideline_statistics.csv')\n",
    "        )\n",
    "        print(f\"  ✓ Saved: phase8_{scenario_id}_guideline_statistics.csv\")\n",
    "        \n",
    "        categorized.to_csv(\n",
    "            os.path.join(OUTPUT_FOLDER, f'phase8_{scenario_id}_guideline_categories.csv')\n",
    "        )\n",
    "        print(f\"  ✓ Saved: phase8_{scenario_id}_guideline_categories.csv\")\n",
    "    else:\n",
    "        print(f\"  ⊘ No guideline stats to save (trial-level scenario)\")\n",
    "    \n",
    "    print(f\"  ✓ {scenario_id} complete\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 5: Create Scenario Comparison Table\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 4: Creating scenario comparison table...\")\n",
    "\n",
    "scenario_summary_df = pd.DataFrame(scenario_summary)\n",
    "scenario_summary_df.to_csv(\n",
    "    os.path.join(OUTPUT_FOLDER, 'phase8_scenario_comparison.csv'),\n",
    "    index=False\n",
    ")\n",
    "print(f\"  ✓ Saved: phase8_scenario_comparison.csv\")\n",
    "\n",
    "# Create detailed comparison of key metrics across scenarios\n",
    "comparison_metrics = []\n",
    "\n",
    "for scenario_id, results in all_scenario_results.items():\n",
    "    overall = results['overall_stats']\n",
    "    config = results['config']\n",
    "    \n",
    "    # Extract key metrics\n",
    "    metrics_dict = {\n",
    "        'scenario_id': scenario_id,\n",
    "        'scenario_name': config['short_name'],\n",
    "        'total_count': len(results['data']),\n",
    "        'count_type': config['count_type']\n",
    "    }\n",
    "    \n",
    "    # Extract specific metrics from overall_stats\n",
    "    for _, row in overall.iterrows():\n",
    "        metric_name = row['metric']\n",
    "        if metric_name in ['Mentioning Sex %', 'Avg Sex Consideration Score', 'Includes Women %']:\n",
    "            clean_name = metric_name.replace(' ', '_').replace('%', 'pct').lower()\n",
    "            metrics_dict[clean_name] = row['value']\n",
    "    \n",
    "    comparison_metrics.append(metrics_dict)\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_metrics)\n",
    "comparison_df.to_csv(\n",
    "    os.path.join(OUTPUT_FOLDER, 'phase8_key_metrics_comparison.csv'),\n",
    "    index=False\n",
    ")\n",
    "print(f\"  ✓ Saved: phase8_key_metrics_comparison.csv\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 6: Create Comprehensive Data Dictionary with Actual Search Terms\n",
    "# ============================================================================\n",
    "# Shows the ACTUAL regex patterns used in Phase 7 analysis\n",
    "\n",
    "print(\"Step 5: Creating comprehensive data dictionary with actual search terms...\")\n",
    "\n",
    "# ============================================================================\n",
    "# Section 1: Core Columns\n",
    "# ============================================================================\n",
    "\n",
    "core_columns = [\n",
    "    {\n",
    "        'column_name': 'guideline_pmid',\n",
    "        'display_name': 'Guideline PMID',\n",
    "        'description': 'PubMed ID of clinical practice guideline',\n",
    "        'data_type': 'string',\n",
    "        'example_values': '31857196',\n",
    "        'source': 'Phase 1: PubMed query',\n",
    "        'search_terms': 'N/A - Direct field',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': 'Direct from PubMed',\n",
    "        'used_in_scoring': 'No'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'ref_pmid',\n",
    "        'display_name': 'Reference PMID',\n",
    "        'description': 'PubMed ID of cited reference',\n",
    "        'data_type': 'string',\n",
    "        'example_values': '19679246',\n",
    "        'source': 'Phase 2: CrossRef citations → PubMed match',\n",
    "        'search_terms': 'N/A - Direct field',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': 'Direct from CrossRef/PubMed match',\n",
    "        'used_in_scoring': 'No'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'ref_primary_nct_number',\n",
    "        'display_name': 'Primary NCT Number',\n",
    "        'description': 'Primary ClinicalTrials.gov registry number',\n",
    "        'data_type': 'string',\n",
    "        'example_values': 'NCT00000001',\n",
    "        'source': 'Phase 3: NCT extraction from PubMed',\n",
    "        'search_terms': 'N/A - Regex extraction',\n",
    "        'sources_searched': 'PubMed structured fields',\n",
    "        'calculation_logic': 'Regex pattern: NCT\\\\d{8}',\n",
    "        'used_in_scoring': 'No'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'ref_is_clinical_trial_pt_type',\n",
    "        'display_name': 'Is Clinical Trial (PubMed PT)',\n",
    "        'description': 'PubMed publication type indicates clinical trial',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 3: PubMed PublicationType field',\n",
    "        'search_terms': 'N/A - Metadata field',\n",
    "        'sources_searched': 'PubMed PublicationType',\n",
    "        'calculation_logic': 'True if PublicationType contains \"Clinical Trial\"',\n",
    "        'used_in_scoring': 'No (used for scenario definitions)'\n",
    "    },\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# Section 2: Basic Sex Mentions (Simple Term Matching)\n",
    "# ============================================================================\n",
    "\n",
    "basic_sex_mentions = [\n",
    "    {\n",
    "        'column_name': 'ref_title_mentions_sex',\n",
    "        'display_name': 'Title Mentions Sex/Gender',\n",
    "        'description': 'Reference title mentions sex or gender terms',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis of ref_title',\n",
    "        'search_terms': 'sex, gender, male, female, men, women, man, woman (case-insensitive, word boundaries)',\n",
    "        'sources_searched': 'ref_title only',\n",
    "        'calculation_logic': 'OR logic: True if ANY term found as whole word in title',\n",
    "        'used_in_scoring': 'No (informational only)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'ref_abstract_mentions_sex',\n",
    "        'display_name': 'Abstract Mentions Sex/Gender',\n",
    "        'description': 'Reference abstract mentions sex or gender terms',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis of ref_abstract',\n",
    "        'search_terms': 'sex, gender, male, female, men, women, man, woman (case-insensitive, word boundaries)',\n",
    "        'sources_searched': 'ref_abstract only',\n",
    "        'calculation_logic': 'OR logic: True if ANY term found as whole word in abstract',\n",
    "        'used_in_scoring': 'No (informational only)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'nct_registry_mentions_sex',\n",
    "        'display_name': 'Registry Mentions Sex/Gender',\n",
    "        'description': 'Registry fields mention sex or gender terms',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis of registry fields',\n",
    "        'search_terms': 'sex, gender, male, female, men, women, man, woman (case-insensitive, word boundaries)',\n",
    "        'sources_searched': 'nct_eligibility_criteria, nct_official_title, nct_brief_title, nct_primary_outcomes, nct_secondary_outcomes, nct_intervention_names',\n",
    "        'calculation_logic': 'OR logic: True if ANY term found in ANY registry field',\n",
    "        'used_in_scoring': 'No (informational only)'\n",
    "    },\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# Section 3: HIGH VALUE Flags (2 points each)\n",
    "# ============================================================================\n",
    "\n",
    "high_value_flags = [\n",
    "    {\n",
    "        'column_name': 'any_source_mentions_sex_differences',\n",
    "        'display_name': 'Mentions Sex Differences',\n",
    "        'description': 'Any source mentions sex/gender differences, disparities, or sex-specific patterns',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis across all sources',\n",
    "        'search_terms': '''sex-specific, gender-specific, sex-based, gender-based, sex difference(s), gender difference(s), sex disparity/disparities, gender disparity/disparities, between men and women, between women and men, between males and females, between females and males, by sex, according to sex, between sexes, sex-disaggregated, sex-stratified, gender-stratified, sex as variable, gender as variable, sex analysis, gender analysis (case-insensitive)''',\n",
    "        'sources_searched': 'ref_title + ref_abstract + nct_registry_fields',\n",
    "        'calculation_logic': '''OR logic across 18 patterns. Searches title, abstract, and all registry fields. Also elevated to True if sex_interaction found. Captures evidence snippets showing context (±50 chars).''',\n",
    "        'used_in_scoring': 'Yes - HIGH VALUE (2 points)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'any_source_mentions_sex_stratification',\n",
    "        'display_name': 'Mentions Sex Stratification',\n",
    "        'description': 'Any source mentions sex-stratified or sex-disaggregated analysis',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis across all sources',\n",
    "        'search_terms': '''stratified by sex/gender, sex-stratified, gender-stratified, stratification by sex/gender, analyzed separately for sex/gender/men and women, separate analyses for sex/gender/men and women (case-insensitive)''',\n",
    "        'sources_searched': 'ref_title + ref_abstract + nct_registry_fields',\n",
    "        'calculation_logic': 'OR logic across 5 patterns. Searches all text sources.',\n",
    "        'used_in_scoring': 'Yes - HIGH VALUE (2 points)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'any_source_mentions_sex_subgroup',\n",
    "        'display_name': 'Mentions Sex Subgroup Analysis',\n",
    "        'description': 'Any source mentions sex/gender subgroup analysis',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis across all sources',\n",
    "        'search_terms': '''subgroup analysis [involving] sex/gender/men/women, sex/gender/men/women subgroup analysis, subgroup by sex/gender, sex subgroup, gender subgroup, interaction [with] sex/gender (case-insensitive)''',\n",
    "        'sources_searched': 'ref_title + ref_abstract + nct_registry_fields',\n",
    "        'calculation_logic': 'OR logic across 5 patterns. Searches all text sources. Also elevates sex_differences flag if not already True.',\n",
    "        'used_in_scoring': 'Yes - HIGH VALUE (2 points)'\n",
    "    },\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# Section 4: MEDIUM VALUE Flags - Biological (1 point each)\n",
    "# ============================================================================\n",
    "\n",
    "medium_bio_flags = [\n",
    "    {\n",
    "        'column_name': 'any_source_pregnancy_related',\n",
    "        'display_name': 'Mentions Pregnancy',\n",
    "        'description': 'Any source mentions pregnancy, lactation, or maternal health',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis across all sources',\n",
    "        'search_terms': '''pregnant, pregnancy, gestational, lactating, breastfeeding, postpartum, antenatal, prenatal, perinatal, obstetric (case-insensitive)''',\n",
    "        'sources_searched': 'ref_title + ref_abstract + nct_registry_fields',\n",
    "        'calculation_logic': 'OR logic across 10 patterns. Searches all text sources.',\n",
    "        'used_in_scoring': 'Yes - MEDIUM VALUE (1 point)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'any_source_menopause_related',\n",
    "        'display_name': 'Mentions Menopause',\n",
    "        'description': 'Any source mentions menopause or related conditions',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis across all sources',\n",
    "        'search_terms': '''menopause*, postmenopause*, perimenopause*, hot flash, hormone replacement, climacteric (case-insensitive, * = any ending)''',\n",
    "        'sources_searched': 'ref_title + ref_abstract + nct_registry_fields',\n",
    "        'calculation_logic': 'OR logic across 6 patterns. Searches all text sources.',\n",
    "        'used_in_scoring': 'Yes - MEDIUM VALUE (1 point)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'any_source_sex_hormone_related',\n",
    "        'display_name': 'Mentions Sex Hormones',\n",
    "        'description': 'Any source specifically mentions sex hormones (estrogen, testosterone, progesterone)',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis across all sources',\n",
    "        'search_terms': '''estrogen, progesterone, testosterone, ovarian hormone, sex hormone (case-insensitive)''',\n",
    "        'sources_searched': 'ref_title + ref_abstract + nct_registry_fields',\n",
    "        'calculation_logic': 'Subset of hormonal_related. OR logic across 5 specific sex hormone patterns.',\n",
    "        'used_in_scoring': 'Yes - MEDIUM VALUE (1 point)'\n",
    "    },\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# Section 5: MEDIUM VALUE Flags - Inclusivity (1 point)\n",
    "# ============================================================================\n",
    "\n",
    "inclusivity_flags = [\n",
    "    {\n",
    "        'column_name': 'nct_sex',\n",
    "        'display_name': 'NCT Sex Eligibility (Raw)',\n",
    "        'description': 'Sex eligibility as stated in ClinicalTrials.gov',\n",
    "        'data_type': 'string',\n",
    "        'example_values': 'All, Female, Male',\n",
    "        'source': 'Phase 4: ClinicalTrials.gov API',\n",
    "        'search_terms': 'N/A - Direct field',\n",
    "        'sources_searched': 'ClinicalTrials.gov EligibilityModule.sex',\n",
    "        'calculation_logic': 'Direct from registry API response',\n",
    "        'used_in_scoring': 'No (used to derive nct_sex_includes_women)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'nct_sex_includes_women',\n",
    "        'display_name': 'Trial Includes Women',\n",
    "        'description': 'Registry indicates women can participate',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 4: Derived from nct_sex',\n",
    "        'search_terms': 'N/A - Derived field',\n",
    "        'sources_searched': 'nct_sex field',\n",
    "        'calculation_logic': 'True if nct_sex == \"All\" OR nct_sex == \"Female\"',\n",
    "        'used_in_scoring': 'Yes - MEDIUM VALUE (1 point)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'nct_sex_women_only',\n",
    "        'display_name': 'Women-Only Trial',\n",
    "        'description': 'Registry indicates only women can participate',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 4: Derived from nct_sex',\n",
    "        'search_terms': 'N/A - Derived field',\n",
    "        'sources_searched': 'nct_sex field',\n",
    "        'calculation_logic': 'True if nct_sex == \"Female\"',\n",
    "        'used_in_scoring': 'No (informational only)'\n",
    "    },\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# Section 6: Additional Biological Flags (Informational)\n",
    "# ============================================================================\n",
    "\n",
    "additional_bio_flags = [\n",
    "    {\n",
    "        'column_name': 'any_source_hormonal_related',\n",
    "        'display_name': 'Mentions Hormonal (General)',\n",
    "        'description': 'Any source mentions hormones generally (includes but not limited to sex hormones)',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis across all sources',\n",
    "        'search_terms': '''hormonal, estrogen, progesterone, testosterone, hormone level, endocrine, oral contraceptive, hormone replacement, hormonal therapy, menstrual cycle, ovarian hormone (case-insensitive)''',\n",
    "        'sources_searched': 'ref_title + ref_abstract + nct_registry_fields',\n",
    "        'calculation_logic': 'OR logic across 11 patterns. Parent category that includes sex_hormone_related and menstrual_cycle.',\n",
    "        'used_in_scoring': 'No (informational; sex_hormone_related scores instead)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'any_source_menstrual_cycle',\n",
    "        'display_name': 'Mentions Menstrual Cycle',\n",
    "        'description': 'Any source mentions menstrual cycle or cycle phases',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis across all sources',\n",
    "        'search_terms': '''menstrual cycle, menstruation, menses, cycle phase, follicular phase, luteal phase, ovulation (case-insensitive)''',\n",
    "        'sources_searched': 'ref_title + ref_abstract + nct_registry_fields',\n",
    "        'calculation_logic': 'Subset of hormonal_related. OR logic across 7 cycle-specific patterns.',\n",
    "        'used_in_scoring': 'No (informational only)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'any_source_contraception_required',\n",
    "        'display_name': 'Contraception Required',\n",
    "        'description': 'Registry or study text mentions contraception requirements',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis across all sources',\n",
    "        'search_terms': '''contraception, contraceptive, birth control, effective contraception, two forms contraception, contraception required, use of contraception, childbearing potential contraception (case-insensitive)''',\n",
    "        'sources_searched': 'ref_title + ref_abstract + nct_registry_fields',\n",
    "        'calculation_logic': 'OR logic across 8 patterns.',\n",
    "        'used_in_scoring': 'No (informational only)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'any_source_reproductive_health',\n",
    "        'display_name': 'Mentions Reproductive Health',\n",
    "        'description': 'Any source mentions reproductive health, fertility, or related terms',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis across all sources',\n",
    "        'search_terms': '''reproductive, reproduction, fertility, infertility, infertile, ovary/ovaries, ovarian, ovulation, conception (case-insensitive)''',\n",
    "        'sources_searched': 'ref_title + ref_abstract + nct_registry_fields',\n",
    "        'calculation_logic': 'OR logic across 9 patterns.',\n",
    "        'used_in_scoring': 'No (informational only)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'any_source_maternal_offspring',\n",
    "        'display_name': 'Mentions Maternal/Offspring',\n",
    "        'description': 'Any source mentions maternal health or offspring outcomes',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis across all sources',\n",
    "        'search_terms': '''maternal, mother(s), offspring, baby/babies, fetus/fetal, foetus/foetal (British), infant(s), newborn(s), neonatal (case-insensitive)''',\n",
    "        'sources_searched': 'ref_title + ref_abstract + nct_registry_fields',\n",
    "        'calculation_logic': 'OR logic across 9 patterns with singular/plural variants.',\n",
    "        'used_in_scoring': 'No (informational only)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'any_source_lactation_breast',\n",
    "        'display_name': 'Mentions Lactation/Breast',\n",
    "        'description': 'Any source mentions breastfeeding, lactation, or breast-related terms',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis across all sources',\n",
    "        'search_terms': '''breast(s), lactation, lactating, breastfeed(ing), nursing mothers (case-insensitive)''',\n",
    "        'sources_searched': 'ref_title + ref_abstract + nct_registry_fields',\n",
    "        'calculation_logic': 'OR logic across 5 patterns.',\n",
    "        'used_in_scoring': 'No (informational only)'\n",
    "    },\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# Section 7: Women's Health & Gender Identity Flags\n",
    "# ============================================================================\n",
    "\n",
    "womens_health_flags = [\n",
    "    {\n",
    "        'column_name': 'any_source_womens_conditions',\n",
    "        'display_name': \"Mentions Women's Health Conditions\",\n",
    "        'description': \"Any source mentions women-specific conditions (PCOS, Turner syndrome, etc.)\",\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis across all sources',\n",
    "        'search_terms': '''PCOS, polycystic ovary/ovaries/ovarian, female athlete triad, relative energy deficiency in sport, RED-S, Turner syndrome/Turners/Turner's syndrome (case-insensitive)''',\n",
    "        'sources_searched': 'ref_title + ref_abstract + nct_registry_fields',\n",
    "        'calculation_logic': 'OR logic across 6 condition patterns.',\n",
    "        'used_in_scoring': 'No (informational only)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'any_source_gender_identity',\n",
    "        'display_name': 'Mentions Gender Identity',\n",
    "        'description': 'Any source mentions gender identity, transgender, or LGBTQ+ topics',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis across all sources',\n",
    "        'search_terms': '''LGBTQ/LGBTQ+, LGBT, transgender/transgendered, gender dysphoria, gender identity/identities, gender minority/minorities, gender-diverse/gender diverse, non-binary/nonbinary/non binary (case-insensitive)''',\n",
    "        'sources_searched': 'ref_title + ref_abstract + nct_registry_fields',\n",
    "        'calculation_logic': 'OR logic across 8 patterns.',\n",
    "        'used_in_scoring': 'No (informational only)'\n",
    "    },\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# Section 8: Exclusion Flags (Evidence of Barriers)\n",
    "# ============================================================================\n",
    "\n",
    "exclusion_flags = [\n",
    "    {\n",
    "        'column_name': 'any_source_excludes_pregnant_women',\n",
    "        'display_name': 'Excludes Pregnant Women',\n",
    "        'description': 'Study explicitly excludes pregnant women or requires negative pregnancy test',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis across all sources',\n",
    "        'search_terms': '''exclude pregnant, pregnancy exclusion, must not be pregnant, cannot be pregnant, negative pregnancy test (case-insensitive)''',\n",
    "        'sources_searched': 'ref_title + ref_abstract + nct_registry_fields',\n",
    "        'calculation_logic': 'OR logic across 5 exclusion patterns. Captures evidence snippets.',\n",
    "        'used_in_scoring': 'No (informational only)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'any_source_excludes_childbearing_potential',\n",
    "        'display_name': 'Excludes Childbearing Potential',\n",
    "        'description': 'Study excludes women of childbearing potential',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis across all sources',\n",
    "        'search_terms': '''exclude women childbearing potential, women childbearing potential excluded, not of childbearing potential (case-insensitive)''',\n",
    "        'sources_searched': 'ref_title + ref_abstract + nct_registry_fields',\n",
    "        'calculation_logic': 'OR logic across 3 exclusion patterns. Captures evidence snippets.',\n",
    "        'used_in_scoring': 'No (informational only)'\n",
    "    },\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# Section 9: Other Informational Flags\n",
    "# ============================================================================\n",
    "\n",
    "other_flags = [\n",
    "    {\n",
    "        'column_name': 'any_source_mentions_sex_interaction',\n",
    "        'display_name': 'Mentions Sex-Treatment Interaction',\n",
    "        'description': 'Any source mentions interaction between sex/gender and treatment',\n",
    "        'data_type': 'boolean',\n",
    "        'example_values': 'True/False',\n",
    "        'source': 'Phase 7: Text analysis across all sources',\n",
    "        'search_terms': '''sex interaction, gender interaction, interaction sex, interaction gender, interaction between sex (case-insensitive)''',\n",
    "        'sources_searched': 'ref_title + ref_abstract + nct_registry_fields',\n",
    "        'calculation_logic': 'OR logic across 5 patterns. Also elevates sex_differences flag to True.',\n",
    "        'used_in_scoring': 'No (informational; elevates sex_differences instead)'\n",
    "    },\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# Section 10: Composite Score\n",
    "# ============================================================================\n",
    "\n",
    "composite_score = [\n",
    "    {\n",
    "        'column_name': 'sex_consideration_score',\n",
    "        'display_name': 'Sex Consideration Score',\n",
    "        'description': 'Composite score (0-10) quantifying degree of sex consideration',\n",
    "        'data_type': 'integer (0-10)',\n",
    "        'example_values': '0, 2, 5, 8',\n",
    "        'source': 'Phase 8: Calculated from boolean flags',\n",
    "        'search_terms': 'N/A - Composite metric',\n",
    "        'sources_searched': 'N/A - Uses flags from all sources',\n",
    "        'calculation_logic': '''SCORING FORMULA (Maximum 10 points):\n",
    "\n",
    "HIGH VALUE (2 points each, max 6):\n",
    "  +2 if any_source_mentions_sex_differences == True\n",
    "  +2 if any_source_mentions_sex_stratification == True\n",
    "  +2 if any_source_mentions_sex_subgroup == True\n",
    "\n",
    "MEDIUM VALUE - Biological (1 point each, max 3):\n",
    "  +1 if any_source_pregnancy_related == True\n",
    "  +1 if any_source_menopause_related == True\n",
    "  +1 if any_source_sex_hormone_related == True\n",
    "\n",
    "MEDIUM VALUE - Inclusivity (1 point, max 1):\n",
    "  +1 if nct_sex_includes_women == True\n",
    "\n",
    "TOTAL: Sum of above, capped at 10\n",
    "\n",
    "RATIONALE:\n",
    "- Direct evidence of sex analysis (differences, stratification, subgroups) weighted highest (2 pts) because they show intentional consideration\n",
    "- Biological factors (pregnancy, menopause, sex hormones) weighted medium (1 pt) because they show awareness of sex-specific physiology\n",
    "- Trial inclusivity (includes women) receives credit (1 pt) as baseline requirement\n",
    "- Score reflects both QUALITY (type of analysis) and PRESENCE (mentions exist)\n",
    "- 10-point scale allows nuanced differentiation between guidelines''',\n",
    "        'used_in_scoring': 'N/A (this IS the primary score)'\n",
    "    },\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# Section 11: Evidence Snippets\n",
    "# ============================================================================\n",
    "\n",
    "# Update the evidence_fields section to include aggregation info:\n",
    "evidence_fields = [\n",
    "    {\n",
    "        'column_name': 'sex_evidence_snippets',\n",
    "        'display_name': 'Sex Evidence Snippets',\n",
    "        'description': 'Text snippets showing sex consideration context (citation-level: captured during matching; guideline-level: aggregated from up to 5 citations)',\n",
    "        'data_type': 'string (pipe-separated at citation-level, double-pipe separated at guideline-level)',\n",
    "        'example_values': '[TITLE] sex-specific differences || [ABSTRACT] stratified by gender',\n",
    "        'source': 'Phase 7: Captured during pattern matching (citation-level); Phase 8: Aggregated (guideline-level)',\n",
    "        'search_terms': 'N/A - Captured context',\n",
    "        'sources_searched': 'ref_title, ref_abstract, registry fields',\n",
    "        'calculation_logic': '''CITATION-LEVEL (in UNIVERSE file):\n",
    "When SEX_DIFF_PATTERNS match, capture ±30-50 characters of context. Label with source [TITLE]/[ABSTRACT]/[REGISTRY]. Concatenate with pipe separator (|).\n",
    "\n",
    "GUIDELINE-LEVEL (in guideline statistics):\n",
    "Aggregate snippets from up to 5 citations per guideline. Separate with double-pipe (||). Truncate total length at 800 characters if needed.\n",
    "\n",
    "PURPOSE:\n",
    "- Citation-level: Evidence trail for individual citation scores\n",
    "- Guideline-level: Representative examples of how guideline considers sex\n",
    "\n",
    "INTERPRETATION:\n",
    "- Null/empty = No sex consideration found in text\n",
    "- Present = Shows actual language used in papers''',\n",
    "        'used_in_scoring': 'No (evidence/audit trail)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'exclusion_evidence_snippets',\n",
    "        'display_name': 'Exclusion Evidence Snippets',\n",
    "        'description': 'Text snippets showing exclusion of women (citation-level: captured during matching; guideline-level: aggregated from up to 3 citations)',\n",
    "        'data_type': 'string (pipe-separated at citation-level, double-pipe separated at guideline-level)',\n",
    "        'example_values': 'exclude pregnant women || negative pregnancy test required',\n",
    "        'source': 'Phase 7: Captured during exclusion pattern matching (citation-level); Phase 8: Aggregated (guideline-level)',\n",
    "        'search_terms': 'N/A - Captured context',\n",
    "        'sources_searched': 'ref_title, ref_abstract, registry fields',\n",
    "        'calculation_logic': '''CITATION-LEVEL (in UNIVERSE file):\n",
    "When PREG_EXCL_PATTERNS or CBP_EXCL_PATTERNS match, capture ±50 characters. Concatenate with pipe separator (|).\n",
    "\n",
    "GUIDELINE-LEVEL (in guideline statistics):\n",
    "Aggregate snippets from up to 3 citations per guideline. Separate with double-pipe (||). Truncate total length at 500 characters if needed.\n",
    "\n",
    "PURPOSE:\n",
    "- Shows barriers to women's participation in trials\n",
    "- Documents exclusionary language\n",
    "- Identifies systemic exclusion patterns\n",
    "\n",
    "INTERPRETATION:\n",
    "- Null/empty = No explicit exclusion language found\n",
    "- Present = Shows actual exclusion criteria from trial protocols''',\n",
    "        'used_in_scoring': 'No (evidence/audit trail)'\n",
    "    },\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# Section 12: Scenario Summary Metrics\n",
    "# ============================================================================\n",
    "# These appear in scenario comparison tables and Excel tabs\n",
    "\n",
    "scenario_metrics = [\n",
    "    {\n",
    "        'column_name': 'count_type',\n",
    "        'display_name': 'Count Type',\n",
    "        'description': 'Whether this scenario counts citations or unique trials',\n",
    "        'data_type': 'string',\n",
    "        'example_values': 'citation, trial',\n",
    "        'source': 'Phase 8: Scenario configuration',\n",
    "        'search_terms': 'N/A - Metadata',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': '''Set in scenario definition:\n",
    "- \"citation\" = One row per guideline-reference pair (UNIVERSE-based scenarios). Use this for citation patterns and guideline behavior analysis.\n",
    "- \"trial\" = One row per unique NCT (UNIQUE_TRIALS scenario). Use this for trial characteristics analysis.\n",
    "\n",
    "INTERPRETATION:\n",
    "- Citation-level scenarios (S1, S2, S4, S5, S6): Can analyze \"What do guidelines cite?\" Same trial cited by multiple guidelines = multiple rows.\n",
    "- Trial-level scenario (S3): Can analyze \"What are characteristics of unique trials?\" Each trial appears once regardless of how many times cited.''',\n",
    "        'used_in_scoring': 'No (metadata for interpretation)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'can_verify_sex',\n",
    "        'display_name': 'Can Verify Sex Inclusion',\n",
    "        'description': 'Whether this scenario has data sources that allow verification of sex eligibility for all/some/no citations',\n",
    "        'data_type': 'string',\n",
    "        'example_values': 'True, False, partial',\n",
    "        'source': 'Phase 8: Scenario configuration',\n",
    "        'search_terms': 'N/A - Metadata',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': '''Set based on data availability for citations in this scenario:\n",
    "\n",
    "True = ALL citations in this scenario have ClinicalTrials.gov (NCT) registry data\n",
    "  - Can definitively check: \"Does this trial permit women to enroll?\"\n",
    "  - Source: nct_sex field from registry (values: \"All\", \"Female\", \"Male\")\n",
    "  - Calculation: nct_sex_includes_women = True if nct_sex IN [\"All\", \"Female\"]\n",
    "  - Scenarios: S3 (Unique Trials), S4 (Registry-Verified), S5 (All NCTs), S6 (High-Quality)\n",
    "  \n",
    "False = NO citations have NCT registry data  \n",
    "  - Cannot verify sex eligibility (no source of sex inclusion data)\n",
    "  - Registry field nct_sex is absent/null for all citations\n",
    "  - Scenarios: S1 (PubMed PT only - no requirement for NCT data)\n",
    "  \n",
    "partial = SOME citations have NCT data, SOME do not\n",
    "  - Can verify sex inclusion for subset of citations only\n",
    "  - Example: If 40% of citations have NCT → can verify 40%, cannot verify 60%\n",
    "  - Scenarios: S2 (PubMed OR NCT - includes both registered and non-registered trials)\n",
    "\n",
    "IMPORTANT DISTINCTION:\n",
    "- can_verify_sex = \"Do we have data to check?\" (data availability)\n",
    "- nct_sex_includes_women = \"Does trial permit women?\" (actual answer for specific trial)\n",
    "\n",
    "EXAMPLE:\n",
    "Scenario S4 (Registry-Verified):\n",
    "  - can_verify_sex = True (100% of citations have NCT data)\n",
    "  - We can check all 630 citations\n",
    "  - Results might be: \n",
    "    * 580 trials: nct_sex_includes_women = True (92%)\n",
    "    * 50 trials: nct_sex_includes_women = False (8% male-only)\n",
    "\n",
    "Scenario S1 (PubMed PT):\n",
    "  - can_verify_sex = False (0% have NCT data)\n",
    "  - Cannot determine if any trials include women\n",
    "  - nct_sex_includes_women = NaN for all (unknown)\n",
    "\n",
    "USE FOR:\n",
    "- Determining which scenarios support claims about trial inclusivity\n",
    "- Understanding data limitations of each scenario\n",
    "- Selecting appropriate scenario for research questions about sex inclusion''',\n",
    "        'used_in_scoring': 'No (metadata for interpretation)'\n",
    "    },\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# Section 13: Guideline Summary Metrics\n",
    "# ============================================================================\n",
    "# These appear in guideline statistics tables\n",
    "\n",
    "guideline_metrics = [\n",
    "    {\n",
    "        'column_name': 'total_citations',\n",
    "        'display_name': 'Total Citations',\n",
    "        'description': 'Total number of citations (references) in this guideline',\n",
    "        'data_type': 'integer',\n",
    "        'example_values': '150, 89, 203',\n",
    "        'source': 'Phase 8: Aggregated from citation-level data',\n",
    "        'search_terms': 'N/A - Aggregated count',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': 'COUNT of rows where guideline_pmid matches, within the scenario definition filter',\n",
    "        'used_in_scoring': 'No (denominator for percentages)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'trial_citations',\n",
    "        'display_name': 'Trial Citations',\n",
    "        'description': 'Number of citations that are clinical trials (based on scenario definition)',\n",
    "        'data_type': 'integer',\n",
    "        'example_values': '45, 12, 78',\n",
    "        'source': 'Phase 8: Aggregated from citation-level data',\n",
    "        'search_terms': 'N/A - Aggregated count',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': 'COUNT of rows where guideline_pmid matches AND row meets scenario trial definition. Varies by scenario (S1 uses PT type, S2 uses PT OR NCT, etc.)',\n",
    "        'used_in_scoring': 'No (descriptive statistic)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'citations_with_sex',\n",
    "        'display_name': 'Citations Mentioning Sex',\n",
    "        'description': 'Number of citations with any sex consideration (score > 0)',\n",
    "        'data_type': 'integer',\n",
    "        'example_values': '23, 8, 67',\n",
    "        'source': 'Phase 8: Aggregated from citation-level data',\n",
    "        'search_terms': 'N/A - Aggregated count',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': 'COUNT of rows where guideline_pmid matches AND sex_consideration_score > 0',\n",
    "        'used_in_scoring': 'No (numerator for pct_citing_sex)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'pct_citing_sex (or mentioning_sex_pct)',\n",
    "        'display_name': 'Percent Citing Sex',\n",
    "        'description': 'Percentage of citations that mention sex considerations',\n",
    "        'data_type': 'float (percentage)',\n",
    "        'example_values': '15.3%, 8.9%, 32.0%',\n",
    "        'source': 'Phase 8: Calculated from guideline aggregates',\n",
    "        'search_terms': 'N/A - Calculated metric',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': '''(citations_with_sex / total_citations) × 100\n",
    "\n",
    "INTERPRETATION:\n",
    "- <5%: Inadequate sex consideration\n",
    "- 5-10%: Weak sex consideration  \n",
    "- 10-20%: Moderate sex consideration\n",
    "- ≥20%: Strong sex consideration (when combined with avg_sex_score ≥2)\n",
    "\n",
    "USE FOR:\n",
    "- Assessing breadth of sex consideration across guideline\n",
    "- Categorizing guideline performance''',\n",
    "        'used_in_scoring': 'Yes (used in guideline categorization)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'avg_sex_score (or avg_sex_consideration_score)',\n",
    "        'display_name': 'Average Sex Consideration Score',\n",
    "        'description': 'Mean sex consideration score across all citations in guideline',\n",
    "        'data_type': 'float (0-10)',\n",
    "        'example_values': '0.5, 2.3, 4.8',\n",
    "        'source': 'Phase 8: Calculated from citation-level scores',\n",
    "        'search_terms': 'N/A - Calculated metric',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': '''MEAN(sex_consideration_score) for all citations in guideline\n",
    "\n",
    "INTERPRETATION:\n",
    "- 0: No sex consideration in any citations\n",
    "- 0.1-1.0: Minimal sex consideration (mostly basic mentions)\n",
    "- 1.1-2.0: Weak sex consideration (some biological factors)\n",
    "- 2.1-4.0: Moderate sex consideration (mix of analysis types)\n",
    "- 4.1+: Strong sex consideration (systematic sex analysis)\n",
    "\n",
    "USE FOR:\n",
    "- Assessing quality/depth of sex consideration\n",
    "- Categorizing guideline performance (combined with pct_citing_sex)''',\n",
    "        'used_in_scoring': 'Yes (used in guideline categorization)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'cites_trials_with_women',\n",
    "        'display_name': 'Citations to Trials Including Women',\n",
    "        'description': 'Number of trial citations where nct_sex_includes_women = True',\n",
    "        'data_type': 'integer',\n",
    "        'example_values': '38, 11, 72',\n",
    "        'source': 'Phase 8: Aggregated from citation-level data',\n",
    "        'search_terms': 'N/A - Aggregated count',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': 'COUNT of rows where guideline_pmid matches AND nct_sex_includes_women = True. Only calculable for scenarios where can_verify_sex = True.',\n",
    "        'used_in_scoring': 'No (numerator for includes_women_pct)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'pct_nct_with_women (or includes_women_pct)',\n",
    "        'display_name': 'Percent Trials Including Women',\n",
    "        'description': 'Among trials with verifiable NCT data, what percentage permit women to enroll',\n",
    "        'data_type': 'float (percentage)',\n",
    "        'example_values': '84.4%, 91.7%, 100%',\n",
    "        'source': 'Phase 8: Calculated from guideline aggregates',\n",
    "        'search_terms': 'N/A - Calculated metric',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': '''(cites_trials_with_women / nct_citations) × 100\n",
    "\n",
    "WHERE:\n",
    "  cites_trials_with_women = COUNT where nct_sex_includes_women == True\n",
    "  nct_citations = COUNT where ref_primary_nct_number is not null\n",
    "\n",
    "DENOMINATOR (nct_citations):\n",
    "  - Only citations with NCT numbers (verifiable trials)\n",
    "  - Excludes citations without registry data\n",
    "  \n",
    "NUMERATOR (cites_trials_with_women):\n",
    "  - Subset where nct_sex == \"All\" OR nct_sex == \"Female\"\n",
    "  - True = Women CAN enroll\n",
    "  - False = Women CANNOT enroll (Male only)\n",
    "\n",
    "Only calculable for scenarios where can_verify_sex = True or partial.\n",
    "Returns NaN if guideline has 0 NCT citations.\n",
    "\n",
    "INTERPRETATION:\n",
    "- 100%: All verifiable trials in this guideline permit women\n",
    "- 0%: All verifiable trials exclude women (male-only studies)\n",
    "- 84%: Most trials include women, but 16% are male-only\n",
    "\n",
    "WHAT THIS DOES NOT TELL YOU:\n",
    "- Does NOT tell you if women were actually enrolled (only if they COULD be)\n",
    "- Does NOT tell you % of participants who were women (enrollment data)\n",
    "- Does NOT cover trials without NCT numbers (those are excluded from calculation)\n",
    "\n",
    "EXAMPLE:\n",
    "Guideline A has:\n",
    "  - 100 total citations\n",
    "  - 30 have NCT numbers (verifiable)\n",
    "  - 27 of those 30: nct_sex = \"All\" (include women)\n",
    "  - 3 of those 30: nct_sex = \"Male\" (exclude women)\n",
    "  \n",
    "Result: includes_women_pct = 27/30 × 100 = 90%\n",
    "\n",
    "Interpretation: Of the 30 trials we can verify, 90% permit women to participate.\n",
    "Note: The other 70 citations (without NCT) are not included in this percentage.\n",
    "\n",
    "USE FOR:\n",
    "- Assessing whether cited trials represent women in eligibility\n",
    "- Identifying guidelines relying on male-only trials\n",
    "- Understanding trial design inclusivity''',\n",
    "        'used_in_scoring': 'No (but used in recommendations)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'max_sex_score',\n",
    "        'display_name': 'Maximum Sex Score',\n",
    "        'description': 'Highest sex consideration score among citations in guideline',\n",
    "        'data_type': 'integer (0-10)',\n",
    "        'example_values': '6, 8, 10',\n",
    "        'source': 'Phase 8: Calculated from citation-level data',\n",
    "        'search_terms': 'N/A - Calculated metric',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': '''MAX(sex_consideration_score) for all citations in guideline\n",
    "\n",
    "INTERPRETATION:\n",
    "- Shows best-case sex consideration within guideline\n",
    "- If max_sex_score is high but avg_sex_score is low → guideline has few excellent citations but mostly weak ones\n",
    "- If max_sex_score ≈ avg_sex_score → guideline is consistently good (or consistently poor)\n",
    "\n",
    "USE FOR:\n",
    "- Understanding variability in sex consideration within guidelines\n",
    "- Identifying guidelines with potential for improvement (high max, low avg)''',\n",
    "        'used_in_scoring': 'No (informational only)'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'category',\n",
    "        'display_name': 'Guideline Performance Category',\n",
    "        'description': 'Classification of guideline based on sex consideration performance',\n",
    "        'data_type': 'string',\n",
    "        'example_values': 'Strong, Moderate, Weak, Inadequate',\n",
    "        'source': 'Phase 9: Calculated from guideline metrics',\n",
    "        'search_terms': 'N/A - Derived category',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': '''Based on pct_citing_sex and avg_sex_score:\n",
    "\n",
    "Strong: \n",
    "  - pct_citing_sex ≥ 20% AND avg_sex_score ≥ 2.0\n",
    "  - Systematic sex consideration across many citations\n",
    "\n",
    "Moderate:\n",
    "  - pct_citing_sex ≥ 10% AND avg_sex_score ≥ 1.0\n",
    "  - Notable sex consideration but not systematic\n",
    "\n",
    "Weak:\n",
    "  - pct_citing_sex ≥ 5% OR avg_sex_score ≥ 0.5\n",
    "  - Minimal sex consideration present\n",
    "\n",
    "Inadequate:\n",
    "  - pct_citing_sex < 5% AND avg_sex_score < 0.5\n",
    "  - Little to no sex consideration\n",
    "\n",
    "NOTE: Exact thresholds may vary by scenario. See categorize_guidelines() function for scenario-specific logic.\n",
    "\n",
    "USE FOR:\n",
    "- Prioritizing guidelines for improvement\n",
    "- Identifying exemplars (Strong) and laggards (Inadequate)''',\n",
    "        'used_in_scoring': 'No (output of scoring process)'\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Section 14: Deduplication Logic & Counting Methodology\n",
    "# ============================================================================\n",
    "# CRITICAL: Understanding what \"unique\" means at different analysis levels\n",
    "\n",
    "deduplication_methodology = [\n",
    "    {\n",
    "        'column_name': 'DEDUPLICATION_LEVEL_1',\n",
    "        'display_name': 'Citations Within Guideline',\n",
    "        'description': 'How duplicate citations are handled within a single guideline',\n",
    "        'data_type': 'Methodology',\n",
    "        'example_values': 'N/A',\n",
    "        'source': 'Phase 2: Deduplication during citation extraction',\n",
    "        'search_terms': 'N/A',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': '''WITHIN GUIDELINE: Deduplicated (unique only)\n",
    "\n",
    "If Guideline A cites the same reference twice:\n",
    "  - PMC123 appears 2 times → Keep 1 occurrence\n",
    "  \n",
    "Result: Each guideline has UNIQUE list of references (no duplicates within one guideline)\n",
    "\n",
    "DEDUPLICATION KEY: (guideline_pmid, ref_pmid)\n",
    "METHOD: drop_duplicates(subset=['guideline_pmid', 'ref_pmid'], keep='first')\n",
    "WHEN: Phase 2 Step 3 (CrossRef citation processing)\n",
    "\n",
    "EXAMPLE:\n",
    "Guideline 12345 bibliography has:\n",
    "  1. Smith 2020 (PMID 100)\n",
    "  2. Jones 2019 (PMID 200)  \n",
    "  3. Smith 2020 (PMID 100)  ← duplicate\n",
    "  \n",
    "After deduplication:\n",
    "  - Citation 1: guideline_pmid=12345, ref_pmid=100\n",
    "  - Citation 2: guideline_pmid=12345, ref_pmid=200\n",
    "  Total: 2 citations for guideline 12345''',\n",
    "        'used_in_scoring': 'N/A - Methodology'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'DEDUPLICATION_LEVEL_2',\n",
    "        'display_name': 'Citations Across Guidelines',\n",
    "        'description': 'How duplicate citations are handled across multiple guidelines',\n",
    "        'data_type': 'Methodology',\n",
    "        'example_values': 'N/A',\n",
    "        'source': 'Phase 2: All phases maintain citation-guideline pairs',\n",
    "        'search_terms': 'N/A',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': '''ACROSS GUIDELINES: NOT Deduplicated (same reference can appear multiple times)\n",
    "\n",
    "If multiple guidelines cite the same reference:\n",
    "  - Guideline A cites PMC123 → 1 row (A, PMC123)\n",
    "  - Guideline B cites PMC123 → 1 row (B, PMC123)\n",
    "  - Guideline C cites PMC123 → 1 row (C, PMC123)\n",
    "  \n",
    "Result: Same reference appears 3 times in dataset (once per guideline)\n",
    "\n",
    "WHY: Preserves citation relationships for guideline-level analysis\n",
    "- Can ask: \"Which guidelines cite this important trial?\"\n",
    "- Can ask: \"How often is this trial cited across guidelines?\"\n",
    "- Can count: \"Guideline A has 150 citations\" (independent of what others cite)\n",
    "\n",
    "DEDUPLICATION KEY: None - keeps all (guideline, reference) pairs\n",
    "WHEN: All phases (this is citation-level structure)\n",
    "\n",
    "EXAMPLE:\n",
    "Guideline 12345 cites PMID 100\n",
    "Guideline 23456 cites PMID 100\n",
    "Guideline 34567 cites PMID 100\n",
    "\n",
    "Dataset contains:\n",
    "  - Row 1: guideline_pmid=12345, ref_pmid=100\n",
    "  - Row 2: guideline_pmid=23456, ref_pmid=100  \n",
    "  - Row 3: guideline_pmid=34567, ref_pmid=100\n",
    "  Total: 3 rows (same reference, different contexts)\n",
    "\n",
    "IMPACT ON COUNTS:\n",
    "- \"Total citations\" = 9,204 (all guideline-reference pairs)\n",
    "- \"Unique references\" = ~7,500 (unique PMIDs, regardless of how many times cited)''',\n",
    "        'used_in_scoring': 'N/A - Methodology'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'DEDUPLICATION_LEVEL_3',\n",
    "        'display_name': 'Trials Within Reference',\n",
    "        'description': 'How multiple trials cited by one reference are handled',\n",
    "        'data_type': 'Methodology',\n",
    "        'example_values': 'N/A',\n",
    "        'source': 'Phase 3-4: NCT extraction and registry fetch',\n",
    "        'search_terms': 'N/A',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': '''MULTIPLE TRIALS IN ONE REFERENCE: Depends on file structure\n",
    "\n",
    "SCENARIO A - UNIVERSE File (phase7_guideline_reference_nct_UNIVERSE_ANALYZED.csv):\n",
    "Structure: One row per (guideline, reference) pair\n",
    "If reference cites multiple trials:\n",
    "  - ref_primary_nct_number = \"NCT001\" (first/main trial)\n",
    "  - ref_all_nct_numbers = \"NCT001;NCT002;NCT003\" (all trials, semicolon-separated)\n",
    "\n",
    "Result: Single row with multiple NCTs in one field\n",
    "\n",
    "EXAMPLE UNIVERSE:\n",
    "Guideline 12345 cites Reference 67890 which discusses NCT001, NCT002, NCT003:\n",
    "  Row: guideline_pmid=12345, ref_pmid=67890, ref_primary_nct_number=NCT001, ref_all_nct_numbers=\"NCT001;NCT002;NCT003\"\n",
    "  Total: 1 row\n",
    "\n",
    "SCENARIO B - EXPLODED File (phase4_guideline_reference_nct_EXPLODED.csv - not used in final analysis):\n",
    "Structure: One row per (guideline, reference, trial) triple  \n",
    "If reference cites multiple trials:\n",
    "  - Each NCT gets separate row\n",
    "\n",
    "Result: Multiple rows for same citation\n",
    "\n",
    "EXAMPLE EXPLODED:\n",
    "Same citation creates 3 rows:\n",
    "  Row 1: guideline_pmid=12345, ref_pmid=67890, nct_number=NCT001\n",
    "  Row 2: guideline_pmid=12345, ref_pmid=67890, nct_number=NCT002\n",
    "  Row 3: guideline_pmid=12345, ref_pmid=67890, nct_number=NCT003\n",
    "  Total: 3 rows\n",
    "\n",
    "WHICH IS USED IN ANALYSIS?\n",
    "- UNIVERSE structure used in Phases 7-10 (avoids double-counting same citation)\n",
    "- EXPLODED not used in final analysis (would inflate citation counts)''',\n",
    "        'used_in_scoring': 'N/A - Methodology'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'DEDUPLICATION_LEVEL_4',\n",
    "        'display_name': 'Trials Across References (Within Guideline)',\n",
    "        'description': 'How same trial cited by multiple references in one guideline is handled',\n",
    "        'data_type': 'Methodology',\n",
    "        'example_values': 'N/A',\n",
    "        'source': 'Phase 3-7: UNIVERSE structure',\n",
    "        'search_terms': 'N/A',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': '''SAME TRIAL, DIFFERENT REFERENCES, SAME GUIDELINE: NOT Deduplicated\n",
    "\n",
    "If one guideline cites the same trial through multiple references:\n",
    "  - Guideline A → Reference X → NCT001\n",
    "  - Guideline A → Reference Y → NCT001\n",
    "  \n",
    "Result: 2 rows (different citations, same trial)\n",
    "\n",
    "WHY: These are genuinely different citations (different papers) that happen to discuss the same trial\n",
    "- Reference X might be the original trial publication\n",
    "- Reference Y might be a secondary analysis of the same trial\n",
    "- Both are legitimate citations that guideline committee reviewed\n",
    "\n",
    "DEDUPLICATION KEY: (guideline_pmid, ref_pmid) - not on nct_number\n",
    "WHEN: All phases\n",
    "\n",
    "EXAMPLE:\n",
    "Guideline 12345 cites:\n",
    "  - Reference 100 (original RCT) → NCT001\n",
    "  - Reference 200 (follow-up study) → NCT001\n",
    "  \n",
    "Dataset contains:\n",
    "  Row 1: guideline_pmid=12345, ref_pmid=100, ref_primary_nct_number=NCT001\n",
    "  Row 2: guideline_pmid=12345, ref_pmid=200, ref_primary_nct_number=NCT001\n",
    "  Total: 2 citation rows (both count toward guideline's total)\n",
    "\n",
    "IMPACT:\n",
    "- \"Guideline total_citations\" = counts both (they are separate references)\n",
    "- \"Unique trials cited by guideline\" = 1 (same NCT)''',\n",
    "        'used_in_scoring': 'N/A - Methodology'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'DEDUPLICATION_LEVEL_5',\n",
    "        'display_name': 'Trials Across Guidelines',\n",
    "        'description': 'How same trial cited by multiple guidelines is handled',\n",
    "        'data_type': 'Methodology',\n",
    "        'example_values': 'N/A',\n",
    "        'source': 'Phase 3-7: UNIVERSE vs UNIQUE_TRIALS',\n",
    "        'search_terms': 'N/A',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': '''SAME TRIAL, MULTIPLE GUIDELINES: Depends on analysis level\n",
    "\n",
    "CITATION-LEVEL Analysis (UNIVERSE - Scenarios S1, S2, S4, S5, S6):\n",
    "Structure: Keeps all (guideline, reference, trial) relationships\n",
    "NOT deduplicated across guidelines\n",
    "\n",
    "If multiple guidelines cite same trial:\n",
    "  - Guideline A → Reference X → NCT001  \n",
    "  - Guideline B → Reference Y → NCT001\n",
    "  - Guideline C → Reference Z → NCT001\n",
    "\n",
    "Result: 3 rows (same trial, different citation contexts)\n",
    "\n",
    "WHY: Preserves citation patterns\n",
    "- Can ask: \"How many times is NCT001 cited?\"\n",
    "- Can ask: \"Which guidelines cite NCT001?\"\n",
    "- Citation is the unit of analysis\n",
    "\n",
    "EXAMPLE UNIVERSE:\n",
    "  Row 1: guideline_pmid=12345, ref_pmid=100, ref_primary_nct_number=NCT001\n",
    "  Row 2: guideline_pmid=23456, ref_pmid=200, ref_primary_nct_number=NCT001\n",
    "  Row 3: guideline_pmid=34567, ref_pmid=300, ref_primary_nct_number=NCT001\n",
    "  Total: 3 rows\n",
    "\n",
    "TRIAL-LEVEL Analysis (UNIQUE_TRIALS - Scenario S3):\n",
    "Structure: One row per unique NCT (deduplicated)\n",
    "Deduplicated across all guidelines\n",
    "\n",
    "Same scenario becomes:\n",
    "  Row 1: nct_number=NCT001, [keeps most complete data from 3 citations]\n",
    "  Total: 1 row\n",
    "\n",
    "WHY: Trial characteristics are the focus\n",
    "- Can ask: \"How many unique trials are cited?\"\n",
    "- Can ask: \"What % of trials include women?\" (without double-counting)\n",
    "- Trial is the unit of analysis\n",
    "\n",
    "DEDUPLICATION KEY (S3): nct_number (or ref_primary_nct_number)\n",
    "METHOD: drop_duplicates(subset='nct_number', keep='first') after sorting by completeness\n",
    "WHEN: Phase 7 Step 7 (creates UNIQUE_TRIALS file)\n",
    "\n",
    "WHICH TO USE?\n",
    "- UNIVERSE: For guideline behavior analysis (\"what do guidelines cite?\")\n",
    "- UNIQUE_TRIALS: For trial characteristics analysis (\"what are properties of cited trials?\")''',\n",
    "        'used_in_scoring': 'N/A - Methodology'\n",
    "    },\n",
    "    {\n",
    "        'column_name': 'COUNT_INTERPRETATION_GUIDE',\n",
    "        'display_name': 'How to Interpret Counts',\n",
    "        'description': 'Quick reference for understanding count meanings',\n",
    "        'data_type': 'Reference Guide',\n",
    "        'example_values': 'N/A',\n",
    "        'source': 'Summary of deduplication logic',\n",
    "        'search_terms': 'N/A',\n",
    "        'sources_searched': 'N/A',\n",
    "        'calculation_logic': '''CITATION COUNTS (UNIVERSE-based scenarios):\n",
    "\n",
    "\"Total citations\" = 9,204\n",
    "  - Meaning: Total (guideline, reference) pairs\n",
    "  - Includes: Same reference cited by multiple guidelines (counts each time)\n",
    "  - Includes: Multiple references from same guideline discussing same trial (counts each reference)\n",
    "  - Unit: Citation instances\n",
    "  - Use for: \"How many times are things cited?\"\n",
    "\n",
    "\"Unique references\" = ~7,500  \n",
    "  - Meaning: Unique PMIDs (deduplicated across all guidelines)\n",
    "  - Removes: Duplicate citations of same PMID by different guidelines\n",
    "  - Unit: Unique papers\n",
    "  - Use for: \"How many different papers are cited?\"\n",
    "\n",
    "\"Trial citations\" = 1,455 (S1) or 1,600 (S2)\n",
    "  - Meaning: Citations that are clinical trials (by scenario definition)\n",
    "  - Includes: Same trial cited multiple times across guidelines\n",
    "  - Includes: Multiple references discussing same trial\n",
    "  - Unit: Trial citation instances\n",
    "  - Use for: \"How many trial citations appear in guidelines?\"\n",
    "\n",
    "TRIAL COUNTS:\n",
    "\n",
    "\"Unique NCTs\" = ~630 (S3)\n",
    "  - Meaning: Unique ClinicalTrials.gov registry numbers\n",
    "  - Removes: All duplicates (across guidelines, across references)\n",
    "  - Unit: Unique trials\n",
    "  - Use for: \"How many different trials are cited?\"\n",
    "\n",
    "\"NCT citations\" = ~630 (S4)\n",
    "  - Meaning: Citation-trial pairs (UNIVERSE structure)\n",
    "  - Includes: Same trial cited by different guidelines (separate rows)\n",
    "  - Includes: Same trial discussed by different references in one guideline (separate rows)\n",
    "  - Unit: Citation-trial relationships\n",
    "  - Use for: \"How many citation-trial connections exist?\"\n",
    "\n",
    "GUIDELINE-LEVEL COUNTS:\n",
    "\n",
    "\"Guideline total_citations\" = 150 (example for one guideline)\n",
    "  - Meaning: Number of (this guideline, reference) pairs\n",
    "  - Unique within guideline: Same reference counted once per guideline\n",
    "  - Can overlap across guidelines: If multiple guidelines cite same reference, each counts it\n",
    "  - Unit: Citations in this guideline\n",
    "  - Use for: \"How many references does this guideline cite?\"\n",
    "\n",
    "\"Guideline trial_citations\" = 45 (example)\n",
    "  - Meaning: Number of trial citations in this guideline (by scenario definition)\n",
    "  - Includes: Multiple references discussing same trial (counts each reference)\n",
    "  - Unit: Trial citations in this guideline\n",
    "  - Use for: \"How many trial citations does this guideline have?\"\n",
    "\n",
    "\"Guideline unique trials\" = 38 (example, if calculated)\n",
    "  - Meaning: Number of unique NCTs cited by this guideline\n",
    "  - Removes: Duplicates when multiple references discuss same trial\n",
    "  - Unit: Unique trials cited by this guideline\n",
    "  - Use for: \"How many different trials does this guideline cite?\"\n",
    "\n",
    "KEY PRINCIPLE:\n",
    "- Citation-level (UNIVERSE): Counts relationships (same trial = multiple rows if cited multiple ways)\n",
    "- Trial-level (UNIQUE_TRIALS): Counts entities (same trial = one row regardless of citations)\n",
    "\n",
    "PRACTICAL EXAMPLES:\n",
    "\n",
    "Example 1: Famous Trial (NCT12345) cited everywhere\n",
    "  UNIVERSE: Appears 25 times (cited by 25 different guidelines)\n",
    "  UNIQUE_TRIALS: Appears 1 time (one unique trial)\n",
    "  Interpretation: Very influential trial (high citation count) but still just one trial\n",
    "\n",
    "Example 2: Guideline A's trial citations\n",
    "  Guideline A cites:\n",
    "    - Reference X → NCT001\n",
    "    - Reference Y → NCT001 (different paper, same trial)\n",
    "    - Reference Z → NCT002\n",
    "  \n",
    "  UNIVERSE counts:\n",
    "    - total_citations for Guideline A = 3 (three references)\n",
    "    - trial_citations for Guideline A = 3 (all three are trials)\n",
    "    - Unique trials = 2 (NCT001 and NCT002)\n",
    "  \n",
    "  Interpretation: Guideline cites 3 trial papers, but only 2 unique trials\n",
    "\n",
    "Example 3: Cross-guideline trial overlap\n",
    "  Guideline A cites NCT001\n",
    "  Guideline B cites NCT001\n",
    "  \n",
    "  UNIVERSE:\n",
    "    - Row 1: guideline_pmid=A, nct=NCT001\n",
    "    - Row 2: guideline_pmid=B, nct=NCT001\n",
    "    - Count: 2 citation-trial relationships\n",
    "  \n",
    "  UNIQUE_TRIALS:\n",
    "    - Row 1: nct=NCT001\n",
    "    - Count: 1 unique trial\n",
    "  \n",
    "  Interpretation: Two guidelines rely on same trial (important trial for field)''',\n",
    "        'used_in_scoring': 'N/A - Reference Guide'\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Combine All Sections\n",
    "# ============================================================================\n",
    "\n",
    "all_dict_entries = (\n",
    "    core_columns + \n",
    "    basic_sex_mentions + \n",
    "    high_value_flags + \n",
    "    medium_bio_flags + \n",
    "    inclusivity_flags + \n",
    "    additional_bio_flags + \n",
    "    womens_health_flags + \n",
    "    exclusion_flags + \n",
    "    other_flags + \n",
    "    composite_score +\n",
    "    evidence_fields +\n",
    "    scenario_metrics +\n",
    "    guideline_metrics +\n",
    "    deduplication_methodology  # ← ADD THIS\n",
    ")  \n",
    "\n",
    "data_dict = pd.DataFrame(all_dict_entries)\n",
    "\n",
    "# Save comprehensive data dictionary\n",
    "data_dict.to_csv(\n",
    "    os.path.join(OUTPUT_FOLDER, 'phase8_data_dictionary.csv'),\n",
    "    index=False\n",
    ")\n",
    "print(f\"  ✓ Saved: phase8_data_dictionary.csv ({len(data_dict)} columns documented)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Create Scoring Summary Table\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"  Creating scoring summary...\")\n",
    "\n",
    "scoring_summary = [\n",
    "    {\n",
    "        'component': 'HIGH VALUE - Direct Sex Analysis',\n",
    "        'weight_per_flag': '2 points',\n",
    "        'max_points': 6,\n",
    "        'flags_included': 'any_source_mentions_sex_differences, any_source_mentions_sex_stratification, any_source_mentions_sex_subgroup',\n",
    "        'num_flags': 3,\n",
    "        'rationale': 'Direct evidence of sex-based analysis. Shows intentional investigation of sex differences in treatment effects, outcomes, or adverse events.',\n",
    "        'example_terms': 'sex-specific, sex-stratified, stratified by gender, sex subgroup analysis, sex differences, between men and women'\n",
    "    },\n",
    "    {\n",
    "        'component': 'MEDIUM VALUE - Biological Sex Factors',\n",
    "        'weight_per_flag': '1 point',\n",
    "        'max_points': 3,\n",
    "        'flags_included': 'any_source_pregnancy_related, any_source_menopause_related, any_source_sex_hormone_related',\n",
    "        'num_flags': 3,\n",
    "        'rationale': 'Consideration of sex-specific biological factors. Shows awareness that physiology differs by sex and affects treatment.',\n",
    "        'example_terms': 'pregnancy, pregnant, menopause, postmenopausal, estrogen, testosterone, sex hormones'\n",
    "    },\n",
    "    {\n",
    "        'component': 'MEDIUM VALUE - Trial Inclusivity',\n",
    "        'weight_per_flag': '1 point',\n",
    "        'max_points': 1,\n",
    "        'flags_included': 'nct_sex_includes_women',\n",
    "        'num_flags': 1,\n",
    "        'rationale': 'Trial design permits women to participate. Basic requirement for generating sex-relevant evidence.',\n",
    "        'example_terms': 'N/A - From registry sex eligibility field (All or Female)'\n",
    "    },\n",
    "    {\n",
    "        'component': 'TOTAL POSSIBLE SCORE',\n",
    "        'weight_per_flag': 'Sum above',\n",
    "        'max_points': 10,\n",
    "        'flags_included': 'All 7 scoring flags combined',\n",
    "        'num_flags': 7,\n",
    "        'rationale': 'Comprehensive score balancing quality (type of analysis) and breadth (multiple considerations) of sex-based evidence.',\n",
    "        'example_terms': 'N/A - Composite calculation'\n",
    "    }\n",
    "]\n",
    "\n",
    "scoring_df = pd.DataFrame(scoring_summary)\n",
    "scoring_df.to_csv(\n",
    "    os.path.join(OUTPUT_FOLDER, 'phase8_scoring_summary.csv'),\n",
    "    index=False\n",
    ")\n",
    "print(f\"  ✓ Saved: phase8_scoring_summary.csv\")\n",
    "\n",
    "# ============================================================================\n",
    "# Create Pattern Groups Reference\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"  Creating pattern groups reference...\")\n",
    "\n",
    "pattern_groups = [\n",
    "    {\n",
    "        'flag_name': 'any_source_mentions_sex_differences',\n",
    "        'pattern_group': 'SEX_DIFF_PATTERNS',\n",
    "        'num_patterns': 18,\n",
    "        'example_patterns': 'sex-specific, sex-based, sex difference*, between men and women, sex-stratified, by sex, sex disparity',\n",
    "        'logic': 'OR across all patterns (any match = True)',\n",
    "        'also_triggers': 'Elevated to True if sex_interaction found'\n",
    "    },\n",
    "    {\n",
    "        'flag_name': 'any_source_mentions_sex_stratification',\n",
    "        'pattern_group': 'STRAT_PATTERNS',\n",
    "        'num_patterns': 5,\n",
    "        'example_patterns': 'stratified by sex/gender, sex-stratified, analyzed separately for sex, separate analyses by sex',\n",
    "        'logic': 'OR across all patterns',\n",
    "        'also_triggers': 'N/A'\n",
    "    },\n",
    "    {\n",
    "        'flag_name': 'any_source_mentions_sex_subgroup',\n",
    "        'pattern_group': 'SUBGROUP_PATTERNS',\n",
    "        'num_patterns': 5,\n",
    "        'example_patterns': 'subgroup analysis sex/gender/men/women, sex subgroup, interaction sex/gender',\n",
    "        'logic': 'OR across all patterns',\n",
    "        'also_triggers': 'Elevates sex_differences to True if not already'\n",
    "    },\n",
    "    {\n",
    "        'flag_name': 'any_source_mentions_sex_interaction',\n",
    "        'pattern_group': 'INTERACTION_PATTERNS',\n",
    "        'num_patterns': 5,\n",
    "        'example_patterns': 'sex interaction, interaction sex/gender, interaction between sex',\n",
    "        'logic': 'OR across all patterns',\n",
    "        'also_triggers': 'Elevates sex_differences to True'\n",
    "    },\n",
    "    {\n",
    "        'flag_name': 'any_source_pregnancy_related',\n",
    "        'pattern_group': 'PREG_PATTERNS',\n",
    "        'num_patterns': 10,\n",
    "        'example_patterns': 'pregnant, pregnancy, gestational, lactating, breastfeeding, postpartum, prenatal',\n",
    "        'logic': 'OR across all patterns',\n",
    "        'also_triggers': 'N/A'\n",
    "    },\n",
    "    {\n",
    "        'flag_name': 'any_source_menopause_related',\n",
    "        'pattern_group': 'MENO_PATTERNS',\n",
    "        'num_patterns': 6,\n",
    "        'example_patterns': 'menopause*, postmenopause*, perimenopause*, hot flash, hormone replacement',\n",
    "        'logic': 'OR across all patterns',\n",
    "        'also_triggers': 'N/A'\n",
    "    },\n",
    "    {\n",
    "        'flag_name': 'any_source_hormonal_related',\n",
    "        'pattern_group': 'HORM_PATTERNS',\n",
    "        'num_patterns': 11,\n",
    "        'example_patterns': 'hormonal, estrogen, progesterone, testosterone, endocrine, menstrual cycle',\n",
    "        'logic': 'OR across all patterns',\n",
    "        'also_triggers': 'Parent flag - spawns sex_hormone_related and menstrual_cycle'\n",
    "    },\n",
    "    {\n",
    "        'flag_name': 'any_source_contraception_required',\n",
    "        'pattern_group': 'CONTRA_PATTERNS',\n",
    "        'num_patterns': 8,\n",
    "        'example_patterns': 'contraception, contraceptive, birth control, effective contraception required',\n",
    "        'logic': 'OR across all patterns',\n",
    "        'also_triggers': 'N/A'\n",
    "    },\n",
    "    {\n",
    "        'flag_name': 'any_source_excludes_pregnant_women',\n",
    "        'pattern_group': 'PREG_EXCL_PATTERNS',\n",
    "        'num_patterns': 5,\n",
    "        'example_patterns': 'exclude pregnant, must not be pregnant, negative pregnancy test',\n",
    "        'logic': 'OR across all patterns',\n",
    "        'also_triggers': 'N/A'\n",
    "    },\n",
    "    {\n",
    "        'flag_name': 'any_source_excludes_childbearing_potential',\n",
    "        'pattern_group': 'CBP_EXCL_PATTERNS',\n",
    "        'num_patterns': 3,\n",
    "        'example_patterns': 'exclude women childbearing potential, not of childbearing potential',\n",
    "        'logic': 'OR across all patterns',\n",
    "        'also_triggers': 'N/A'\n",
    "    },\n",
    "]\n",
    "\n",
    "patterns_df = pd.DataFrame(pattern_groups)\n",
    "patterns_df.to_csv(\n",
    "    os.path.join(OUTPUT_FOLDER, 'phase8_pattern_groups.csv'),\n",
    "    index=False\n",
    ")\n",
    "print(f\"  ✓ Saved: phase8_pattern_groups.csv\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"✓ PHASE 8 COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  - phase8_scenario_comparison.csv\")\n",
    "print(f\"  - phase8_key_metrics_comparison.csv\")\n",
    "print(f\"  - phase8_data_dictionary.csv\")\n",
    "print(f\"  - phase8_S[X]_overall_statistics.csv (×{len(scenarios)})\")\n",
    "print(f\"  - phase8_S[X]_guideline_statistics.csv (×{len([s for s in scenarios.values() if s['count_type']=='citation'])})\")\n",
    "print(f\"  - phase8_S[X]_guideline_categories.csv (×{len([s for s in scenarios.values() if s['count_type']=='citation'])})\")\n",
    "print(f\"\\n✓ Ready for Phase 9 (Insights & Recommendations)\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "35ad59c1-38f4-43c8-8461-42688b7394e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists and loads: ✓\n",
      "Shape: (75, 15)\n",
      "Index name: guideline_pmid\n",
      "\n",
      "Columns:\n",
      "['citations_in_scenario', 'avg_sex_score', 'max_sex_score', 'citations_with_sex', 'cites_sex_differences', 'cites_sex_stratification', 'cites_sex_subgroup', 'sex_snippets_count', 'sex_evidence_snippets', 'exclusion_snippets_count', 'exclusion_evidence_snippets', 'cites_trials_with_women', 'pct_citing_sex', 'scenario_id', 'category']\n",
      "\n",
      "First few rows:\n",
      "                citations_in_scenario  avg_sex_score  max_sex_score  \\\n",
      "guideline_pmid                                                        \n",
      "31813278                         19.0           1.37            2.0   \n",
      "31838890                          0.0           0.00            0.0   \n",
      "31857196                          9.0           1.44            2.0   \n",
      "\n",
      "                citations_with_sex  cites_sex_differences  \\\n",
      "guideline_pmid                                              \n",
      "31813278                      19.0                    0.0   \n",
      "31838890                       0.0                    0.0   \n",
      "31857196                       9.0                    0.0   \n",
      "\n",
      "                cites_sex_stratification  cites_sex_subgroup  \\\n",
      "guideline_pmid                                                 \n",
      "31813278                             0.0                 0.0   \n",
      "31838890                             0.0                 0.0   \n",
      "31857196                             0.0                 0.0   \n",
      "\n",
      "                sex_snippets_count sex_evidence_snippets  \\\n",
      "guideline_pmid                                             \n",
      "31813278                       0.0                   NaN   \n",
      "31838890                       NaN                   NaN   \n",
      "31857196                       0.0                   NaN   \n",
      "\n",
      "                exclusion_snippets_count exclusion_evidence_snippets  \\\n",
      "guideline_pmid                                                         \n",
      "31813278                             0.0                         NaN   \n",
      "31838890                             NaN                         NaN   \n",
      "31857196                             0.0                         NaN   \n",
      "\n",
      "                cites_trials_with_women  pct_citing_sex           scenario_id  \\\n",
      "guideline_pmid                                                                  \n",
      "31813278                           19.0           100.0  S4_Registry_Verified   \n",
      "31838890                            0.0             0.0  S4_Registry_Verified   \n",
      "31857196                            9.0           100.0  S4_Registry_Verified   \n",
      "\n",
      "                                    category  \n",
      "guideline_pmid                                \n",
      "31813278                            Moderate  \n",
      "31838890        Inadequate - No Trials Cited  \n",
      "31857196                            Moderate  \n"
     ]
    }
   ],
   "source": [
    "# Quick check of guideline stats file\n",
    "import pandas as pd\n",
    "\n",
    "test_file = 'output/phase8_S4_Registry_Verified_guideline_statistics.csv'\n",
    "df = pd.read_csv(test_file, index_col=0)\n",
    "\n",
    "print(f\"File exists and loads: ✓\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Index name: {df.index.name}\")\n",
    "print(f\"\\nColumns:\")\n",
    "print(list(df.columns))\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4e6c881e-5927-4d78-9a2a-ce2bad5e77d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE 9: INSIGHTS & RECOMMENDATIONS (MULTI-SCENARIO)\n",
      "======================================================================\n",
      "\n",
      "Step 1: Loading scenario configuration and results...\n",
      "  Found 6 scenarios to process:\n",
      "    - S1_PubMed_PT: PubMed PT\n",
      "    - S2_PubMed_OR_NCT: PubMed OR NCT\n",
      "    - S3_Unique_Trials: Unique Trials\n",
      "    - S4_Registry_Verified: Registry-Verified\n",
      "    - S5_All_NCTs: All NCTs\n",
      "    - S6_High_Quality: High-Quality\n",
      "\n",
      "Step 2: Generating recommendations and research gaps for each scenario...\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Processing S1_PubMed_PT\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  Generating recommendations...\n",
      "    ✓ Generated 3 recommendations\n",
      "    ✓ Saved 3 evidence files\n",
      "  Identifying research gaps...\n",
      "    ℹ️  Research gaps require scenario data (not persisted from Phase 8)\n",
      "    → Run gap analysis separately with access to scenario DataFrames\n",
      "  ✓ S1_PubMed_PT complete\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Processing S2_PubMed_OR_NCT\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  Generating recommendations...\n",
      "    ✓ Generated 3 recommendations\n",
      "    ✓ Saved 3 evidence files\n",
      "  Identifying research gaps...\n",
      "    ℹ️  Research gaps require scenario data (not persisted from Phase 8)\n",
      "    → Run gap analysis separately with access to scenario DataFrames\n",
      "  ✓ S2_PubMed_OR_NCT complete\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Processing S3_Unique_Trials\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  ⊘ No guideline statistics (trial-level scenario)\n",
      "  Identifying research gaps...\n",
      "    ℹ️  Research gaps require scenario data (not persisted from Phase 8)\n",
      "    → Run gap analysis separately with access to scenario DataFrames\n",
      "  ✓ S3_Unique_Trials complete\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Processing S4_Registry_Verified\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  Generating recommendations...\n",
      "    ✓ Generated 3 recommendations\n",
      "    ✓ Saved 3 evidence files\n",
      "  Identifying research gaps...\n",
      "    ℹ️  Research gaps require scenario data (not persisted from Phase 8)\n",
      "    → Run gap analysis separately with access to scenario DataFrames\n",
      "  ✓ S4_Registry_Verified complete\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Processing S5_All_NCTs\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  Generating recommendations...\n",
      "    ✓ Generated 3 recommendations\n",
      "    ✓ Saved 3 evidence files\n",
      "  Identifying research gaps...\n",
      "    ℹ️  Research gaps require scenario data (not persisted from Phase 8)\n",
      "    → Run gap analysis separately with access to scenario DataFrames\n",
      "  ✓ S5_All_NCTs complete\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Processing S6_High_Quality\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  Generating recommendations...\n",
      "    ✓ Generated 3 recommendations\n",
      "    ✓ Saved 3 evidence files\n",
      "  Identifying research gaps...\n",
      "    ℹ️  Research gaps require scenario data (not persisted from Phase 8)\n",
      "    → Run gap analysis separately with access to scenario DataFrames\n",
      "  ✓ S6_High_Quality complete\n",
      "\n",
      "Step 3: Saving consolidated outputs...\n",
      "  ✓ Saved: phase9_recommendations_all_scenarios.csv (15 recommendations)\n",
      "\n",
      "Step 4: Creating actionable recommendations by stakeholder...\n",
      "  ✓ Saved: phase9_actionable_recommendations.csv (6 actions)\n",
      "\n",
      "======================================================================\n",
      "✓ PHASE 9 COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Files created:\n",
      "  - phase9_recommendations_all_scenarios.csv\n",
      "  - phase9_actionable_recommendations.csv\n",
      "  - recommendation_S[X]_R[Y]_*.csv (evidence files)\n",
      "\n",
      "✓ Ready for Phase 10 (Excel Report Generation)\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 9: Insights & Recommendations - Multi-Scenario Analysis\n",
    "# ============================================================================\n",
    "# Purpose: Generate insights, recommendations, and research gaps for all scenarios\n",
    "# Input: Phase 8 outputs for all scenarios\n",
    "# Output: Recommendations and gaps analysis for each scenario\n",
    "#\n",
    "# ADDING NEW SCENARIOS:\n",
    "# This phase automatically processes any scenarios defined in Phase 8\n",
    "# No changes needed here when adding new scenarios!\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "OUTPUT_FOLDER = 'output'\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"PHASE 9: INSIGHTS & RECOMMENDATIONS (MULTI-SCENARIO)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 1: Load Scenario Configuration from Phase 8\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 1: Loading scenario configuration and results...\")\n",
    "\n",
    "# Load scenario comparison to get list of scenarios\n",
    "scenario_comparison = pd.read_csv(os.path.join(OUTPUT_FOLDER, 'phase8_scenario_comparison.csv'))\n",
    "scenarios_to_process = scenario_comparison['scenario_id'].tolist()\n",
    "\n",
    "print(f\"  Found {len(scenarios_to_process)} scenarios to process:\")\n",
    "for s_id in scenarios_to_process:\n",
    "    s_name = scenario_comparison[scenario_comparison['scenario_id'] == s_id]['short_name'].values[0]\n",
    "    print(f\"    - {s_id}: {s_name}\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# Step 2: Generate Recommendations for Each Scenario\n",
    "# ============================================================================\n",
    "# These recommendation functions work for ANY scenario\n",
    "# No changes needed when adding new scenarios\n",
    "# ============================================================================\n",
    "\n",
    "def generate_recommendations_for_scenario(scenario_id, guideline_stats, scenario_config):\n",
    "    \"\"\"\n",
    "    Generate specific recommendations for a scenario\n",
    "    NOW INCLUDES RECOMMENDATIONS FOR GUIDELINES WITH NO TRIALS\n",
    "    \"\"\"\n",
    "    \n",
    "    if guideline_stats is None:\n",
    "        return []\n",
    "    \n",
    "    recommendations = []\n",
    "    total_guidelines = len(guideline_stats)\n",
    "    \n",
    "    # NEW: Recommendation for guidelines with NO trials cited\n",
    "    no_trials = guideline_stats[guideline_stats['category'] == 'Inadequate - No Trials Cited']\n",
    "    if len(no_trials) > 0:\n",
    "        recommendations.append({\n",
    "            'scenario_id': scenario_id,\n",
    "            'recommendation_id': f'{scenario_id}_R0',\n",
    "            'priority': 'CRITICAL',\n",
    "            'recommendation': 'Include Clinical Trial Evidence',\n",
    "            'description': f'{len(no_trials)} guidelines ({len(no_trials)/total_guidelines*100:.1f}%) cite ZERO trials under this scenario definition. These guidelines lack any trial evidence base for this scenario.',\n",
    "            'affected_guidelines': len(no_trials),\n",
    "            'guideline_pmids': list(no_trials.index),\n",
    "            'current_state': '0 trial citations in this scenario',\n",
    "            'target_state': 'Cite at least some clinical trials that meet scenario definition',\n",
    "            'rationale': 'Guidelines without trial evidence cannot provide evidence-based recommendations for clinical practice. This is the most fundamental gap.',\n",
    "            'evidence_file': f'recommendation_{scenario_id}_R0_no_trials.csv'\n",
    "        })\n",
    "    \n",
    "    # Recommendation 1: No sex consideration (but has trials)\n",
    "    no_sex = guideline_stats[guideline_stats['category'] == 'Inadequate - No Sex Consideration']\n",
    "    if len(no_sex) > 0:\n",
    "        recommendations.append({\n",
    "            'scenario_id': scenario_id,\n",
    "            'recommendation_id': f'{scenario_id}_R1',\n",
    "            'priority': 'HIGH',\n",
    "            'recommendation': 'Address Inadequate Sex Consideration',\n",
    "            'description': f'{len(no_sex)} guidelines ({len(no_sex)/total_guidelines*100:.1f}%) cite trials but have inadequate sex consideration.',\n",
    "            'affected_guidelines': len(no_sex),\n",
    "            'guideline_pmids': list(no_sex.index),\n",
    "            'current_state': '<5% of citations mention sex or avg score <1',\n",
    "            'target_state': 'At least 10% of citations should mention sex with avg score ≥1',\n",
    "            'rationale': 'These guidelines cite trials but fail to systematically consider sex-based differences in their evidence review.',\n",
    "            'evidence_file': f'recommendation_{scenario_id}_R1_inadequate_sex.csv'\n",
    "        })\n",
    "    \n",
    "    # Recommendation 2: Weak sex consideration\n",
    "    weak = guideline_stats[guideline_stats['category'] == 'Weak']\n",
    "    if len(weak) > 0:\n",
    "        recommendations.append({\n",
    "            'scenario_id': scenario_id,\n",
    "            'recommendation_id': f'{scenario_id}_R2',\n",
    "            'priority': 'MEDIUM',\n",
    "            'recommendation': 'Strengthen Weak Sex Consideration',\n",
    "            'description': f'{len(weak)} guidelines ({len(weak)/total_guidelines*100:.1f}%) have weak sex consideration.',\n",
    "            'affected_guidelines': len(weak),\n",
    "            'guideline_pmids': list(weak.index),\n",
    "            'current_state': f'5-10% citations mention sex',\n",
    "            'target_state': '≥20% citations mention sex with systematic stratification',\n",
    "            'rationale': 'These guidelines acknowledge sex but do not systematically integrate sex-based analysis.',\n",
    "            'evidence_file': f'recommendation_{scenario_id}_R2_weak.csv'\n",
    "        })\n",
    "    \n",
    "    # Recommendation 3: Learn from strong performers\n",
    "    strong = guideline_stats[guideline_stats['category'] == 'Strong']\n",
    "    if len(strong) > 0:\n",
    "        recommendations.append({\n",
    "            'scenario_id': scenario_id,\n",
    "            'recommendation_id': f'{scenario_id}_R3',\n",
    "            'priority': 'LOW',\n",
    "            'recommendation': 'Adopt Best Practices from Strong Performers',\n",
    "            'description': f'{len(strong)} guidelines ({len(strong)/total_guidelines*100:.1f}%) demonstrate strong sex consideration.',\n",
    "            'affected_guidelines': total_guidelines - len(strong),\n",
    "            'guideline_pmids': list(guideline_stats[guideline_stats['category'] != 'Strong'].index),\n",
    "            'current_state': f'Variable performance across guidelines',\n",
    "            'target_state': 'Adopt systematic approach from high performers',\n",
    "            'rationale': 'Strong performers provide models for integrating sex considerations.',\n",
    "            'evidence_file': f'recommendation_{scenario_id}_R3_strong.csv'\n",
    "        })\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "\n",
    "def identify_research_gaps_for_scenario(scenario_id, scenario_df, scenario_config):\n",
    "    \"\"\"\n",
    "    Identify research gaps for a scenario\n",
    "    Returns list of gap dictionaries\n",
    "    \"\"\"\n",
    "    \n",
    "    gaps = []\n",
    "    \n",
    "    # Gap 1: Insufficient sex stratification\n",
    "    if 'any_source_mentions_sex_stratification' in scenario_df.columns:\n",
    "        stratified = (scenario_df['any_source_mentions_sex_stratification'] == True).sum()\n",
    "        total = len(scenario_df)\n",
    "        \n",
    "        if stratified < total * 0.3:  # Less than 30%\n",
    "            gaps.append({\n",
    "                'scenario_id': scenario_id,\n",
    "                'gap_id': f'{scenario_id}_G1',\n",
    "                'category': 'Analysis Methods',\n",
    "                'gap': 'Insufficient Sex-Stratified Analysis',\n",
    "                'description': f'Only {stratified} ({stratified/total*100:.1f}%) include sex-stratified analysis.',\n",
    "                'current_metric': f'{stratified}/{total}',\n",
    "                'recommendation': 'Require sex-stratified analysis as standard practice in all trials.',\n",
    "                'priority': 'CRITICAL'\n",
    "            })\n",
    "    \n",
    "    # Gap 2: Limited women-only trials (if verifiable)\n",
    "    if scenario_config['can_verify_sex'] == True:\n",
    "        if 'nct_sex_women_only' in scenario_df.columns:\n",
    "            women_only = (scenario_df['nct_sex_women_only'] == True).sum()\n",
    "            total = len(scenario_df)\n",
    "            \n",
    "            if women_only < total * 0.2:  # Less than 20%\n",
    "                gaps.append({\n",
    "                    'scenario_id': scenario_id,\n",
    "                    'gap_id': f'{scenario_id}_G2',\n",
    "                    'category': 'Population Representation',\n",
    "                    'gap': 'Limited Women-Only Trials',\n",
    "                    'description': f'Only {women_only} ({women_only/total*100:.1f}%) are women-only trials.',\n",
    "                    'current_metric': f'{women_only}/{total}',\n",
    "                    'recommendation': 'Fund more women-focused trials for conditions with sex-specific presentation.',\n",
    "                    'priority': 'HIGH'\n",
    "                })\n",
    "    \n",
    "    # Gap 3: Missing biological considerations\n",
    "    bio_flags = ['any_source_pregnancy_related', 'any_source_menopause_related', \n",
    "                 'any_source_sex_hormone_related']\n",
    "    bio_flags = [f for f in bio_flags if f in scenario_df.columns]\n",
    "    \n",
    "    if bio_flags:\n",
    "        bio_count = scenario_df[bio_flags].eq(True).sum().sum()\n",
    "        total = len(scenario_df)\n",
    "        \n",
    "        if bio_count < total * 0.15:  # Less than 15% mention any\n",
    "            gaps.append({\n",
    "                'scenario_id': scenario_id,\n",
    "                'gap_id': f'{scenario_id}_G3',\n",
    "                'category': 'Biological Factors',\n",
    "                'gap': 'Limited Biological Sex Considerations',\n",
    "                'description': f'Only {bio_count} mentions of pregnancy/menopause/hormonal factors across {total} citations.',\n",
    "                'current_metric': f'{bio_count}/{total}',\n",
    "                'recommendation': 'Systematically address pregnancy, menopause, and hormonal considerations.',\n",
    "                'priority': 'MEDIUM'\n",
    "            })\n",
    "    \n",
    "    return gaps\n",
    "\n",
    "\n",
    "print(\"Step 2: Generating recommendations and research gaps for each scenario...\\n\")\n",
    "\n",
    "all_recommendations = []\n",
    "all_research_gaps = []\n",
    "\n",
    "for scenario_id in scenarios_to_process:\n",
    "    \n",
    "    print(f\"{'─'*70}\")\n",
    "    print(f\"Processing {scenario_id}\")\n",
    "    print(f\"{'─'*70}\")\n",
    "    \n",
    "    # Load scenario data\n",
    "    scenario_info = scenario_comparison[scenario_comparison['scenario_id'] == scenario_id].iloc[0]\n",
    "    \n",
    "    # Load guideline categories if available\n",
    "    guideline_file = os.path.join(OUTPUT_FOLDER, f'phase8_{scenario_id}_guideline_categories.csv')\n",
    "    \n",
    "    if os.path.exists(guideline_file):\n",
    "        guideline_stats = pd.read_csv(guideline_file, index_col=0)\n",
    "        \n",
    "        # Load scenario config (from Phase 8 results file header)\n",
    "        config = {\n",
    "            'can_verify_sex': scenario_info['can_verify_sex'],\n",
    "            'count_type': scenario_info['count_type']\n",
    "        }\n",
    "        \n",
    "        # Generate recommendations\n",
    "        print(f\"  Generating recommendations...\")\n",
    "        scenario_recs = generate_recommendations_for_scenario(scenario_id, guideline_stats, config)\n",
    "        all_recommendations.extend(scenario_recs)\n",
    "        print(f\"    ✓ Generated {len(scenario_recs)} recommendations\")\n",
    "        \n",
    "        # Save evidence files for recommendations\n",
    "        for rec in scenario_recs:\n",
    "            evidence_data = guideline_stats[guideline_stats.index.isin(rec['guideline_pmids'])]\n",
    "            evidence_data.to_csv(os.path.join(OUTPUT_FOLDER, rec['evidence_file']))\n",
    "        \n",
    "        print(f\"    ✓ Saved {len(scenario_recs)} evidence files\")\n",
    "    else:\n",
    "        print(f\"  ⊘ No guideline statistics (trial-level scenario)\")\n",
    "        guideline_stats = None\n",
    "    \n",
    "    # Generate research gaps\n",
    "    print(f\"  Identifying research gaps...\")\n",
    "    \n",
    "    # Load scenario data (need to reload to get the actual data)\n",
    "    overall_stats_file = os.path.join(OUTPUT_FOLDER, f'phase8_{scenario_id}_overall_statistics.csv')\n",
    "    \n",
    "    # For gaps, we need the actual data - this is a simplified version\n",
    "    # In practice, might need to reconstruct or pass through from Phase 8\n",
    "    scenario_gaps = []  # Placeholder - would need actual scenario data\n",
    "    \n",
    "    print(f\"    ℹ️  Research gaps require scenario data (not persisted from Phase 8)\")\n",
    "    print(f\"    → Run gap analysis separately with access to scenario DataFrames\")\n",
    "    \n",
    "    print(f\"  ✓ {scenario_id} complete\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 3: Save Consolidated Recommendations\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 3: Saving consolidated outputs...\")\n",
    "\n",
    "if all_recommendations:\n",
    "    recommendations_df = pd.DataFrame(all_recommendations)\n",
    "    recommendations_df.to_csv(\n",
    "        os.path.join(OUTPUT_FOLDER, 'phase9_recommendations_all_scenarios.csv'),\n",
    "        index=False\n",
    "    )\n",
    "    print(f\"  ✓ Saved: phase9_recommendations_all_scenarios.csv ({len(recommendations_df)} recommendations)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 4: Create Actionable Recommendations by Stakeholder\n",
    "# ============================================================================\n",
    "# This section works for ANY number of scenarios\n",
    "# No changes needed when adding scenarios\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nStep 4: Creating actionable recommendations by stakeholder...\")\n",
    "\n",
    "actionable = {\n",
    "    'stakeholder': [],\n",
    "    'action': [],\n",
    "    'timeline': [],\n",
    "    'impact': [],\n",
    "    'related_scenarios': [],\n",
    "    'related_recommendations': []\n",
    "}\n",
    "\n",
    "# For guideline developers\n",
    "actionable['stakeholder'].append('Guideline Development Organizations')\n",
    "actionable['action'].append('Mandate sex-stratified analysis review in evidence evaluation criteria')\n",
    "actionable['timeline'].append('Immediate (next guideline update cycle)')\n",
    "actionable['impact'].append('HIGH - Affects all future guidelines')\n",
    "actionable['related_scenarios'].append('All scenarios')\n",
    "actionable['related_recommendations'].append('R1, R2 across scenarios')\n",
    "\n",
    "actionable['stakeholder'].append('Guideline Development Organizations')\n",
    "actionable['action'].append('Require minimum % of evidence to include sex considerations')\n",
    "actionable['timeline'].append('6-12 months (policy development)')\n",
    "actionable['impact'].append('HIGH - Improves evidence standards')\n",
    "actionable['related_scenarios'].append('S2, S4, S6')\n",
    "actionable['related_recommendations'].append('R1, R2')\n",
    "\n",
    "# For funders\n",
    "actionable['stakeholder'].append('Research Funders (NIH, foundations)')\n",
    "actionable['action'].append('Prioritize funding for trials with sex-inclusive design and analysis')\n",
    "actionable['timeline'].append('Immediate (next funding cycle)')\n",
    "actionable['impact'].append('CRITICAL - Addresses gaps at source')\n",
    "actionable['related_scenarios'].append('S4, S6')\n",
    "actionable['related_recommendations'].append('G1, G2')\n",
    "\n",
    "# For researchers\n",
    "actionable['stakeholder'].append('Clinical Trial Investigators')\n",
    "actionable['action'].append('Include sex-stratified analyses in all trial publications')\n",
    "actionable['timeline'].append('Immediate')\n",
    "actionable['impact'].append('HIGH - Improves data availability')\n",
    "actionable['related_scenarios'].append('All scenarios')\n",
    "actionable['related_recommendations'].append('G1')\n",
    "\n",
    "# For journals\n",
    "actionable['stakeholder'].append('Medical Journals')\n",
    "actionable['action'].append('Require sex-disaggregated data reporting in trial publications')\n",
    "actionable['timeline'].append('6 months (editorial policy)')\n",
    "actionable['impact'].append('HIGH - Affects all new publications')\n",
    "actionable['related_scenarios'].append('All scenarios')\n",
    "actionable['related_recommendations'].append('G1')\n",
    "\n",
    "# For regulators\n",
    "actionable['stakeholder'].append('Regulatory Agencies (FDA, EMA)')\n",
    "actionable['action'].append('Strengthen requirements for sex-specific efficacy/safety data')\n",
    "actionable['timeline'].append('1-2 years (regulatory process)')\n",
    "actionable['impact'].append('CRITICAL - Mandatory for approvals')\n",
    "actionable['related_scenarios'].append('S4, S6')\n",
    "actionable['related_recommendations'].append('G1, G2')\n",
    "\n",
    "actionable_df = pd.DataFrame(actionable)\n",
    "actionable_df.to_csv(\n",
    "    os.path.join(OUTPUT_FOLDER, 'phase9_actionable_recommendations.csv'),\n",
    "    index=False\n",
    ")\n",
    "print(f\"  ✓ Saved: phase9_actionable_recommendations.csv ({len(actionable_df)} actions)\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✓ PHASE 9 COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  - phase9_recommendations_all_scenarios.csv\")\n",
    "print(f\"  - phase9_actionable_recommendations.csv\")\n",
    "print(f\"  - recommendation_S[X]_R[Y]_*.csv (evidence files)\")\n",
    "print(f\"\\n✓ Ready for Phase 10 (Excel Report Generation)\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7912cb01-18b4-4f7d-be68-f4026d5c145a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE 10: EXCEL REPORT GENERATION (MULTI-SCENARIO)\n",
      "======================================================================\n",
      "\n",
      "Step 1: Loading all scenario results...\n",
      "  Found 6 scenarios\n",
      "  Loading S1_PubMed_PT... [G: 75×14] [C: 75]\n",
      "  Loading S2_PubMed_OR_NCT... [G: 75×14] [C: 75]\n",
      "  Loading S3_Unique_Trials... [No G] [No C]\n",
      "  Loading S4_Registry_Verified... [G: 75×15] [C: 75]\n",
      "  Loading S5_All_NCTs... [G: 75×15] [C: 75]\n",
      "  Loading S6_High_Quality... [G: 75×15] [C: 75]\n",
      "\n",
      "  Verification:\n",
      "    S1_PubMed_PT: G=✓75, C=✓75\n",
      "    S2_PubMed_OR_NCT: G=✓75, C=✓75\n",
      "    S3_Unique_Trials: G=✗, C=✗\n",
      "\n",
      "Step 2: Setting up Excel formatting...\n",
      "  ✓ Styles configured\n",
      "\n",
      "Step 3: Creating Excel workbook...\n",
      "  ✓ Workbook created\n",
      "\n",
      "Step 4: Creating Executive Summary...\n",
      "  ✓ Executive Summary created\n",
      "\n",
      "Step 5: Creating Scenario Comparison...\n",
      "  ✓ Scenario Comparison created\n",
      "\n",
      "Step 6: Creating individual scenario tabs...\n",
      "  Processing S1_PubMed_PT:\n",
      "    - overall_stats: 13 rows\n",
      "    - guideline_stats: 75 rows\n",
      "    - categories: 75 rows\n",
      "    Checking guideline_stats: True, len=75\n",
      "    → ADDING guideline table with 75 rows\n",
      "    → After reset_index: (75, 15)\n",
      "    → Display columns (14): ['guideline_pmid', 'citations_in_scenario', 'citations_with_sex', 'pct_citing_sex', 'avg_sex_score']...\n",
      "    → Adding to Excel at row 29\n",
      "    → Table added, current_row now 106\n",
      "    → Applying colors: rows 30 to 104, col 10\n",
      "    → Formatting 2 snippet columns\n",
      "  ✓ S1_PubMed_PT tab created\n",
      "  Processing S2_PubMed_OR_NCT:\n",
      "    - overall_stats: 13 rows\n",
      "    - guideline_stats: 75 rows\n",
      "    - categories: 75 rows\n",
      "    Checking guideline_stats: True, len=75\n",
      "    → ADDING guideline table with 75 rows\n",
      "    → After reset_index: (75, 15)\n",
      "    → Display columns (14): ['guideline_pmid', 'citations_in_scenario', 'citations_with_sex', 'pct_citing_sex', 'avg_sex_score']...\n",
      "    → Adding to Excel at row 29\n",
      "    → Table added, current_row now 106\n",
      "    → Applying colors: rows 30 to 104, col 10\n",
      "    → Formatting 2 snippet columns\n",
      "  ✓ S2_PubMed_OR_NCT tab created\n",
      "  Processing S3_Unique_Trials:\n",
      "    - overall_stats: 14 rows\n",
      "    - guideline_stats: None rows\n",
      "    - categories: None rows\n",
      "    Checking guideline_stats: False, len=N/A\n",
      "    → SKIPPING guideline table (None or empty)\n",
      "  ✓ S3_Unique_Trials tab created\n",
      "  Processing S4_Registry_Verified:\n",
      "    - overall_stats: 16 rows\n",
      "    - guideline_stats: 75 rows\n",
      "    - categories: 75 rows\n",
      "    Checking guideline_stats: True, len=75\n",
      "    → ADDING guideline table with 75 rows\n",
      "    → After reset_index: (75, 16)\n",
      "    → Display columns (15): ['guideline_pmid', 'citations_in_scenario', 'citations_with_sex', 'pct_citing_sex', 'avg_sex_score']...\n",
      "    → Adding to Excel at row 32\n",
      "    → Table added, current_row now 109\n",
      "    → Applying colors: rows 33 to 107, col 11\n",
      "    → Formatting 2 snippet columns\n",
      "  ✓ S4_Registry_Verified tab created\n",
      "  Processing S5_All_NCTs:\n",
      "    - overall_stats: 16 rows\n",
      "    - guideline_stats: 75 rows\n",
      "    - categories: 75 rows\n",
      "    Checking guideline_stats: True, len=75\n",
      "    → ADDING guideline table with 75 rows\n",
      "    → After reset_index: (75, 16)\n",
      "    → Display columns (15): ['guideline_pmid', 'citations_in_scenario', 'citations_with_sex', 'pct_citing_sex', 'avg_sex_score']...\n",
      "    → Adding to Excel at row 32\n",
      "    → Table added, current_row now 109\n",
      "    → Applying colors: rows 33 to 107, col 11\n",
      "    → Formatting 2 snippet columns\n",
      "  ✓ S5_All_NCTs tab created\n",
      "  Processing S6_High_Quality:\n",
      "    - overall_stats: 16 rows\n",
      "    - guideline_stats: 75 rows\n",
      "    - categories: 75 rows\n",
      "    Checking guideline_stats: True, len=75\n",
      "    → ADDING guideline table with 75 rows\n",
      "    → After reset_index: (75, 16)\n",
      "    → Display columns (15): ['guideline_pmid', 'citations_in_scenario', 'citations_with_sex', 'pct_citing_sex', 'avg_sex_score']...\n",
      "    → Adding to Excel at row 32\n",
      "    → Table added, current_row now 109\n",
      "    → Applying colors: rows 33 to 107, col 11\n",
      "    → Formatting 2 snippet columns\n",
      "  ✓ S6_High_Quality tab created\n",
      "\n",
      "Step 7: Creating Recommendations tab...\n",
      "  ✓ Recommendations tab created\n",
      "\n",
      "Step 8: Creating Actionable Recommendations tab...\n",
      "  ✓ Actionable Recommendations tab created\n",
      "\n",
      "Step 9: Creating Enhanced Data Dictionary tab...\n",
      "  ✓ Enhanced Data Dictionary created with all sections\n",
      "\n",
      "Step 11: Applying final formatting...\n",
      "  ✓ Gridlines hidden on all sheets\n",
      "\n",
      "Step 10: Saving Excel workbook...\n",
      "  ✓ Saved: output\\Sex_Based_Guidelines_Multi_Scenario_Analysis.xlsx\n",
      "\n",
      "======================================================================\n",
      "✓ PHASE 10 COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Final Excel Report Created:\n",
      "  File: Sex_Based_Guidelines_Multi_Scenario_Analysis.xlsx\n",
      "  Location: output/\n",
      "  Size: 88.5 KB\n",
      "\n",
      "Workbook Structure (11 tabs):\n",
      "  1. Executive Summary\n",
      "  2. Scenario Comparison\n",
      "  3. PubMed PT\n",
      "  4. PubMed OR NCT\n",
      "  5. Unique Trials\n",
      "  6. Registry-Verified\n",
      "  7. All NCTs\n",
      "  8. High-Quality\n",
      "  9. Recommendations\n",
      "  10. Actionable by Stakeholder\n",
      "  11. Data Dictionary\n",
      "\n",
      "Scenarios Analyzed: 6\n",
      "  • PubMed PT: 1,527 citations\n",
      "  • PubMed OR NCT: 1,612 citations\n",
      "  • Unique Trials: 505 trials\n",
      "  • Registry-Verified: 630 citations\n",
      "  • All NCTs: 630 citations\n",
      "  • High-Quality: 617 citations\n",
      "\n",
      "Recommendations Generated: 15\n",
      "  • CRITICAL: 5\n",
      "  • HIGH: 2\n",
      "  • MEDIUM: 5\n",
      "  • LOW: 3\n",
      "\n",
      "======================================================================\n",
      "✓ ANALYSIS COMPLETE - Report Ready for Delivery\n",
      "======================================================================\n",
      "\n",
      "NEXT STEPS:\n",
      "  1. Review Excel file: Sex_Based_Guidelines_Multi_Scenario_Analysis.xlsx\n",
      "  2. Check 'Executive Summary' tab for overview\n",
      "  3. Review 'Scenario Comparison' to understand differences\n",
      "  4. Examine individual scenario tabs for detailed results\n",
      "  5. Share relevant evidence files from output/ folder\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Phase 10: Excel Report Generation - Multi-Scenario Analysis\n",
    "# ============================================================================\n",
    "# Purpose: Create comprehensive multi-tab Excel workbook with all scenario analyses\n",
    "# Input: All Phase 8 and 9 outputs\n",
    "# Output: One Excel file with tabs for each scenario + comparisons\n",
    "#\n",
    "# ADDING NEW SCENARIOS:\n",
    "# This phase automatically processes any scenarios from Phase 8\n",
    "# No code changes needed! Just re-run after adding scenarios to Phase 8.\n",
    "#\n",
    "# CUSTOMIZATION OPTIONS:\n",
    "# - Line ~80: Modify Excel formatting styles (colors, fonts)\n",
    "# - Line ~250: Customize Executive Summary content\n",
    "# - Line ~550: Add custom comparison visualizations\n",
    "# - Line ~700: Modify recommendation tab format\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "OUTPUT_FOLDER = 'output'\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"PHASE 10: EXCEL REPORT GENERATION (MULTI-SCENARIO)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 1: Load All Data\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 1: Loading all scenario results...\")\n",
    "\n",
    "# Load scenario comparison to get list of scenarios\n",
    "scenario_comparison = pd.read_csv(os.path.join(OUTPUT_FOLDER, 'phase8_scenario_comparison.csv'))\n",
    "key_metrics = pd.read_csv(os.path.join(OUTPUT_FOLDER, 'phase8_key_metrics_comparison.csv'))\n",
    "data_dictionary = pd.read_csv(os.path.join(OUTPUT_FOLDER, 'phase8_data_dictionary.csv'))\n",
    "\n",
    "scenarios_to_process = scenario_comparison['scenario_id'].tolist()\n",
    "print(f\"  Found {len(scenarios_to_process)} scenarios\")\n",
    "\n",
    "# Load all scenario-specific files\n",
    "scenario_data = {}\n",
    "\n",
    "for scenario_id in scenarios_to_process:\n",
    "    print(f\"  Loading {scenario_id}...\", end='')\n",
    "    \n",
    "    scenario_data[scenario_id] = {\n",
    "        'info': scenario_comparison[scenario_comparison['scenario_id'] == scenario_id].iloc[0],\n",
    "        'overall_stats': pd.read_csv(os.path.join(OUTPUT_FOLDER, f'phase8_{scenario_id}_overall_statistics.csv')),\n",
    "    }\n",
    "    \n",
    "    # Load guideline stats if available (not for trial-level scenarios)\n",
    "    guideline_file = os.path.join(OUTPUT_FOLDER, f'phase8_{scenario_id}_guideline_statistics.csv')\n",
    "    if os.path.exists(guideline_file):\n",
    "        gstats = pd.read_csv(guideline_file, index_col=0)\n",
    "        scenario_data[scenario_id]['guideline_stats'] = gstats\n",
    "        print(f\" [G: {len(gstats)}×{len(gstats.columns)}]\", end='')\n",
    "    else:\n",
    "        scenario_data[scenario_id]['guideline_stats'] = None\n",
    "        print(f\" [No G]\", end='')\n",
    "    \n",
    "    # Load categories if available\n",
    "    categories_file = os.path.join(OUTPUT_FOLDER, f'phase8_{scenario_id}_guideline_categories.csv')\n",
    "    if os.path.exists(categories_file):\n",
    "        cats = pd.read_csv(categories_file, index_col=0)\n",
    "        scenario_data[scenario_id]['categories'] = cats\n",
    "        print(f\" [C: {len(cats)}]\")\n",
    "    else:\n",
    "        scenario_data[scenario_id]['categories'] = None\n",
    "        print(f\" [No C]\")\n",
    "\n",
    "# Quick verification\n",
    "print(\"\\n  Verification:\")\n",
    "for sid in scenarios_to_process[:3]:  # Just first 3\n",
    "    g = scenario_data[sid]['guideline_stats']\n",
    "    c = scenario_data[sid]['categories']\n",
    "    print(f\"    {sid}: G={'✓'+str(len(g)) if g is not None else '✗'}, C={'✓'+str(len(c)) if c is not None else '✗'}\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# Step 2: Setup Excel Formatting Styles\n",
    "# ============================================================================\n",
    "# CUSTOMIZATION: Modify colors, fonts, sizes here\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 2: Setting up Excel formatting...\")\n",
    "\n",
    "# Color scheme\n",
    "COLORS = {\n",
    "    'header': '366092',\n",
    "    'subheader': 'D9E1F2',\n",
    "    'recommended': 'FFF2CC',\n",
    "    'strong': 'C6EFCE',\n",
    "    'moderate': 'FFEB9C',\n",
    "    'weak': 'FFC7CE',\n",
    "    'inadequate': 'FF6B6B',           # Inadequate - No Sex Consideration\n",
    "    'inadequate_no_trials': 'B22222',  # NEW: Inadequate - No Trials (darker red)\n",
    "    'critical': 'FF0000',\n",
    "    'high': 'FFA500',\n",
    "    'medium': 'FFEB9C',\n",
    "    'low': 'D3D3D3'\n",
    "}\n",
    "\n",
    "# Font styles\n",
    "header_font = Font(name='Calibri', size=11, bold=True, color='FFFFFF')\n",
    "subheader_font = Font(name='Calibri', size=10, bold=True)\n",
    "title_font = Font(name='Calibri', size=14, bold=True)\n",
    "subtitle_font = Font(name='Calibri', size=12, italic=True)\n",
    "normal_font = Font(name='Calibri', size=10)\n",
    "small_font = Font(name='Calibri', size=9)\n",
    "\n",
    "# Fill styles\n",
    "header_fill = PatternFill(start_color=COLORS['header'], end_color=COLORS['header'], fill_type='solid')\n",
    "subheader_fill = PatternFill(start_color=COLORS['subheader'], end_color=COLORS['subheader'], fill_type='solid')\n",
    "\n",
    "# Border\n",
    "thin_border = Border(\n",
    "    left=Side(style='thin', color='000000'),\n",
    "    right=Side(style='thin', color='000000'),\n",
    "    top=Side(style='thin', color='000000'),\n",
    "    bottom=Side(style='thin', color='000000')\n",
    ")\n",
    "\n",
    "# Alignment\n",
    "center_alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
    "left_alignment = Alignment(horizontal='left', vertical='top', wrap_text=True)\n",
    "\n",
    "print(\"  ✓ Styles configured\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 3: Helper Functions for Excel Formatting\n",
    "# ============================================================================\n",
    "# These functions work for ANY scenario - no changes needed\n",
    "# ============================================================================\n",
    "\n",
    "def format_header_row(ws, row_num, end_col=None):\n",
    "    \"\"\"Apply header formatting to a row\"\"\"\n",
    "    if end_col is None:\n",
    "        end_col = ws.max_column\n",
    "    \n",
    "    for col in range(1, end_col + 1):\n",
    "        cell = ws.cell(row=row_num, column=col)\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "        cell.alignment = center_alignment\n",
    "        cell.border = thin_border\n",
    "\n",
    "\n",
    "def format_data_rows(ws, start_row, end_row, start_col=1, end_col=None):\n",
    "    \"\"\"Apply formatting to data rows\"\"\"\n",
    "    if end_col is None:\n",
    "        end_col = ws.max_column\n",
    "    \n",
    "    for row in range(start_row, end_row + 1):\n",
    "        for col in range(start_col, end_col + 1):\n",
    "            cell = ws.cell(row=row, column=col)\n",
    "            cell.font = normal_font\n",
    "            cell.border = thin_border\n",
    "            cell.alignment = left_alignment\n",
    "\n",
    "\n",
    "def auto_adjust_column_width(ws, max_width=50):\n",
    "    \"\"\"Auto-adjust column widths with maximum\"\"\"\n",
    "    for column in ws.columns:\n",
    "        max_length = 0\n",
    "        column_letter = get_column_letter(column[0].column)\n",
    "        \n",
    "        for cell in column:\n",
    "            try:\n",
    "                if cell.value and len(str(cell.value)) > max_length:\n",
    "                    max_length = len(str(cell.value))\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        adjusted_width = min(max_length + 2, max_width)\n",
    "        ws.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "\n",
    "def add_title_to_sheet(ws, title, subtitle=None, current_row=1):\n",
    "    \"\"\"Add formatted title to worksheet\"\"\"\n",
    "    ws.cell(row=current_row, column=1, value=title)\n",
    "    ws.cell(row=current_row, column=1).font = title_font\n",
    "    ws.merge_cells(f'A{current_row}:D{current_row}')\n",
    "    current_row += 1\n",
    "    \n",
    "    if subtitle:\n",
    "        ws.cell(row=current_row, column=1, value=subtitle)\n",
    "        ws.cell(row=current_row, column=1).font = subtitle_font\n",
    "        ws.merge_cells(f'A{current_row}:D{current_row}')\n",
    "        current_row += 1\n",
    "    \n",
    "    return current_row + 1\n",
    "\n",
    "\n",
    "def add_dataframe_to_sheet(ws, df, start_row, include_index=False):\n",
    "    \"\"\"\n",
    "    Add DataFrame to worksheet starting at start_row\n",
    "    Returns the next available row\n",
    "    \"\"\"\n",
    "    # Add data\n",
    "    for r_idx, row in enumerate(dataframe_to_rows(df, index=include_index, header=True), start=start_row):\n",
    "        for c_idx, value in enumerate(row, start=1):\n",
    "            cell = ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "            \n",
    "            # Format header\n",
    "            if r_idx == start_row:\n",
    "                cell.font = header_font\n",
    "                cell.fill = header_fill\n",
    "                cell.alignment = center_alignment\n",
    "            else:\n",
    "                cell.font = normal_font\n",
    "                cell.alignment = left_alignment\n",
    "            \n",
    "            cell.border = thin_border\n",
    "    \n",
    "    return start_row + len(df) + 2\n",
    "\n",
    "\n",
    "def apply_category_colors(ws, start_row, end_row, category_col):\n",
    "    \"\"\"Apply colors based on category values\"\"\"\n",
    "    category_colors = {\n",
    "        'Strong': COLORS['strong'],\n",
    "        'Moderate': COLORS['moderate'],\n",
    "        'Weak': COLORS['weak'],\n",
    "        'Inadequate - No Sex Consideration': COLORS['inadequate'],\n",
    "        'Inadequate - No Trials Cited': COLORS['inadequate_no_trials']  # NEW\n",
    "    }\n",
    "    \n",
    "    for row in range(start_row, end_row + 1):\n",
    "        category_cell = ws.cell(row=row, column=category_col)\n",
    "        category_value = str(category_cell.value)\n",
    "        \n",
    "        # Check for category match\n",
    "        for cat_name, color in category_colors.items():\n",
    "            if cat_name in category_value:\n",
    "                fill = PatternFill(start_color=color, end_color=color, fill_type='solid')\n",
    "                for col in range(1, ws.max_column + 1):\n",
    "                    ws.cell(row=row, column=col).fill = fill\n",
    "                break\n",
    "\n",
    "def add_color_legend(ws, start_row, legend_type='category'):\n",
    "    \"\"\"\n",
    "    Add color legend to worksheet\n",
    "    \n",
    "    legend_type options:\n",
    "    - 'category': Guideline performance categories\n",
    "    - 'priority': Recommendation priorities\n",
    "    - 'recommended': Recommended scenario highlighting\n",
    "    \"\"\"\n",
    "    \n",
    "    legends = {\n",
    "        'category': {\n",
    "            'title': 'CATEGORY COLORS',\n",
    "            'items': [\n",
    "                ('Strong', COLORS['strong'], 'Guidelines with systematic sex consideration (≥20% citations, avg score ≥2)'),\n",
    "                ('Moderate', COLORS['moderate'], 'Guidelines with notable sex consideration (≥10% citations, avg score ≥1)'),\n",
    "                ('Weak', COLORS['weak'], 'Guidelines with minimal sex consideration (≥5% citations)'),\n",
    "                ('Inadequate - No Sex', COLORS['inadequate'], 'Guidelines with trials but <5% mention sex'),\n",
    "                ('Inadequate - No Trials', COLORS['inadequate_no_trials'], 'Guidelines citing ZERO trials in this scenario (most severe)')  # NEW\n",
    "            ]\n",
    "        },\n",
    "        'priority': {\n",
    "            'title': 'PRIORITY COLORS',\n",
    "            'items': [\n",
    "                ('CRITICAL', COLORS['critical'], 'Immediate action required - fundamental gaps'),\n",
    "                ('HIGH', COLORS['high'], 'High priority - significant improvement needed'),\n",
    "                ('MEDIUM', COLORS['medium'], 'Medium priority - notable gaps to address'),\n",
    "                ('LOW', COLORS['low'], 'Lower priority - refinement opportunities')\n",
    "            ]\n",
    "        },\n",
    "        'recommended': {\n",
    "            'title': 'HIGHLIGHTING',\n",
    "            'items': [\n",
    "                ('⭐ Recommended', COLORS['recommended'], 'Recommended primary scenario for analysis (best balance of coverage and verifiability)')\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if legend_type not in legends:\n",
    "        return start_row\n",
    "    \n",
    "    legend = legends[legend_type]\n",
    "    \n",
    "    # Title\n",
    "    ws.cell(row=start_row, column=1, value=legend['title'])\n",
    "    ws.cell(row=start_row, column=1).font = Font(name='Calibri', size=9, bold=True)\n",
    "    start_row += 1\n",
    "    \n",
    "    # Legend items\n",
    "    for label, color, description in legend['items']:\n",
    "        # Color box (merged cells A-B)\n",
    "        ws.cell(row=start_row, column=1, value=label)\n",
    "        ws.cell(row=start_row, column=1).fill = PatternFill(\n",
    "            start_color=color,\n",
    "            end_color=color,\n",
    "            fill_type='solid'\n",
    "        )\n",
    "        ws.cell(row=start_row, column=1).font = Font(name='Calibri', size=8, bold=True)\n",
    "        ws.cell(row=start_row, column=1).border = thin_border\n",
    "        ws.cell(row=start_row, column=1).alignment = center_alignment\n",
    "        \n",
    "        # Description (column C onwards)\n",
    "        ws.cell(row=start_row, column=2, value=description)\n",
    "        ws.cell(row=start_row, column=2).font = Font(name='Calibri', size=8)\n",
    "        ws.cell(row=start_row, column=2).alignment = left_alignment\n",
    "        \n",
    "        start_row += 1\n",
    "    \n",
    "    return start_row + 1  # Add spacing after legend\n",
    "\n",
    "def create_count_examples_table(overall_stats_df, guideline_stats_df, scenario_id):\n",
    "    \"\"\"\n",
    "    Create a table with actual count examples from current dataset\n",
    "    Returns DataFrame suitable for adding to Excel\n",
    "    \"\"\"\n",
    "    \n",
    "    examples = []\n",
    "    \n",
    "    # Get actual values from data\n",
    "    def get_stat_value(metric_name):\n",
    "        stat = overall_stats_df[overall_stats_df['metric'] == metric_name]\n",
    "        if len(stat) > 0:\n",
    "            return stat.iloc[0]['value']\n",
    "        return 'N/A'\n",
    "    \n",
    "    # Citation counts\n",
    "    examples.append({\n",
    "        'Count Type': 'Total Citations',\n",
    "        'This Dataset': get_stat_value('Total Count'),\n",
    "        'Meaning': 'Total (guideline, reference) pairs',\n",
    "        'Includes/Excludes': 'Includes cross-guideline overlaps'\n",
    "    })\n",
    "    \n",
    "    examples.append({\n",
    "        'Count Type': 'Unique References',\n",
    "        'This Dataset': get_stat_value('Unique References'),\n",
    "        'Meaning': 'Unique PMIDs (deduplicated)',\n",
    "        'Includes/Excludes': 'Removes duplicates across guidelines'\n",
    "    })\n",
    "    \n",
    "    examples.append({\n",
    "        'Count Type': 'Citations with Sex',\n",
    "        'This Dataset': get_stat_value('Citations/Trials Mentioning Sex'),\n",
    "        'Meaning': 'Citations where score > 0',\n",
    "        'Includes/Excludes': 'Any sex consideration present'\n",
    "    })\n",
    "    \n",
    "    # Guideline-level examples (if available)\n",
    "    if guideline_stats_df is not None and len(guideline_stats_df) > 0:\n",
    "        # Get median guideline as example (exclude those with 0 citations)\n",
    "        guidelines_with_citations = guideline_stats_df[guideline_stats_df['citations_in_scenario'] > 0]\n",
    "        \n",
    "        if len(guidelines_with_citations) > 0:\n",
    "            median_idx = len(guidelines_with_citations) // 2\n",
    "            example_guideline = guidelines_with_citations.iloc[median_idx]\n",
    "            \n",
    "            examples.append({\n",
    "                'Count Type': 'Example Guideline: Total Citations',\n",
    "                'This Dataset': f\"{example_guideline['citations_in_scenario']:.0f}\",  # ← FIXED\n",
    "                'Meaning': 'Citations in one guideline (in this scenario)',\n",
    "                'Includes/Excludes': 'Unique within guideline only'\n",
    "            })\n",
    "            \n",
    "            examples.append({\n",
    "                'Count Type': 'Example Guideline: Citations with Sex',\n",
    "                'This Dataset': f\"{example_guideline['citations_with_sex']:.0f}\",\n",
    "                'Meaning': 'Citations mentioning sex',\n",
    "                'Includes/Excludes': 'From that guideline only'\n",
    "            })\n",
    "            \n",
    "            # Add category example\n",
    "            examples.append({\n",
    "                'Count Type': 'Example Guideline: Category',\n",
    "                'This Dataset': example_guideline['category'],\n",
    "                'Meaning': 'Performance classification',\n",
    "                'Includes/Excludes': 'Based on % citing sex and avg score'\n",
    "            })\n",
    "        \n",
    "        # Add counts of guidelines with/without citations\n",
    "        num_with_citations = len(guidelines_with_citations)\n",
    "        num_without_citations = len(guideline_stats_df) - num_with_citations\n",
    "        \n",
    "        examples.append({\n",
    "            'Count Type': 'Guidelines with Citations (in scenario)',\n",
    "            'This Dataset': f\"{num_with_citations}\",\n",
    "            'Meaning': 'Guidelines citing trials in this scenario',\n",
    "            'Includes/Excludes': 'Have at least 1 citation in scenario'\n",
    "        })\n",
    "        \n",
    "        if num_without_citations > 0:\n",
    "            examples.append({\n",
    "                'Count Type': 'Guidelines with NO Citations (in scenario)',\n",
    "                'This Dataset': f\"{num_without_citations}\",\n",
    "                'Meaning': 'Guidelines citing 0 trials in this scenario',\n",
    "                'Includes/Excludes': 'Categorized as \"Inadequate - No Trials Cited\"'\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(examples)\n",
    "\n",
    "def prepare_clean_worksheet(ws):\n",
    "    \"\"\"\n",
    "    Prepare worksheet with clean white appearance\n",
    "    - Hides gridlines\n",
    "    - Sets view to top-left\n",
    "    \"\"\"\n",
    "    # Hide gridlines\n",
    "    ws.sheet_view.showGridLines = False\n",
    "    \n",
    "    # Optional: Set view to top-left (A1)\n",
    "    ws.sheet_view.topLeftCell = 'A1'\n",
    "\n",
    "print(\"Step 3: Creating Excel workbook...\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 4: Create Workbook\n",
    "# ============================================================================\n",
    "\n",
    "wb = Workbook()\n",
    "wb.remove(wb.active)  # Remove default sheet\n",
    "\n",
    "print(\"  ✓ Workbook created\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 5: Executive Summary Tab\n",
    "# ============================================================================\n",
    "# CUSTOMIZATION: Modify summary content, layout here\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 4: Creating Executive Summary...\")\n",
    "\n",
    "ws_summary = wb.create_sheet(\"Executive Summary\", 0)\n",
    "\n",
    "current_row = add_title_to_sheet(\n",
    "    ws_summary,\n",
    "    \"Sex-Based Considerations in Clinical Practice Guidelines\",\n",
    "    \"Multi-Scenario Comprehensive Analysis Report\"\n",
    ")\n",
    "\n",
    "# Analysis date\n",
    "ws_summary.cell(row=current_row, column=1, value=f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "ws_summary.cell(row=current_row, column=1).font = small_font\n",
    "current_row += 2\n",
    "\n",
    "# Scenarios analyzed\n",
    "ws_summary.cell(row=current_row, column=1, value=\"SCENARIOS ANALYZED\")\n",
    "ws_summary.cell(row=current_row, column=1).font = subheader_font\n",
    "current_row += 1\n",
    "\n",
    "for _, scenario in scenario_comparison.iterrows():\n",
    "    recommended = \" ⭐ RECOMMENDED\" if scenario.get('recommended', False) else \"\"\n",
    "    text = f\"• {scenario['name']} ({scenario['count']:,} {scenario['count_type']}s){recommended}\"\n",
    "    ws_summary.cell(row=current_row, column=1, value=text)\n",
    "    ws_summary.cell(row=current_row, column=1).font = normal_font\n",
    "    current_row += 1\n",
    "\n",
    "current_row += 1\n",
    "\n",
    "# Key findings section\n",
    "ws_summary.cell(row=current_row, column=1, value=\"KEY FINDINGS\")\n",
    "ws_summary.cell(row=current_row, column=1).font = subheader_font\n",
    "current_row += 2\n",
    "\n",
    "# Get key metrics from recommended scenario (S4 if available, otherwise first)\n",
    "recommended_scenarios = scenario_comparison[scenario_comparison['recommended'] == True]\n",
    "if len(recommended_scenarios) > 0:\n",
    "    key_scenario_id = recommended_scenarios.iloc[0]['scenario_id']\n",
    "else:\n",
    "    key_scenario_id = scenarios_to_process[0]\n",
    "\n",
    "key_scenario_info = scenario_comparison[scenario_comparison['scenario_id'] == key_scenario_id].iloc[0]\n",
    "key_stats = scenario_data[key_scenario_id]['overall_stats']\n",
    "\n",
    "findings = [\n",
    "    f\"PRIMARY ANALYSIS: {key_scenario_info['name']}\",\n",
    "    f\"• Total {key_scenario_info['count_type']}s: {key_scenario_info['count']:,}\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Extract key metrics\n",
    "for _, row in key_stats.iterrows():\n",
    "    if row['metric'] in ['Mentioning Sex %', 'Includes Women %', 'Avg Sex Consideration Score']:\n",
    "        findings.append(f\"• {row['metric']}: {row['value']}\")\n",
    "\n",
    "findings.append(\"\")\n",
    "findings.append(\"COMPARISON ACROSS SCENARIOS:\")\n",
    "findings.append(f\"• Scenario definitions change results significantly\")\n",
    "findings.append(f\"• See 'Scenario Comparison' tab for details\")\n",
    "\n",
    "for finding in findings:\n",
    "    ws_summary.cell(row=current_row, column=1, value=finding)\n",
    "    ws_summary.cell(row=current_row, column=1).font = normal_font\n",
    "    current_row += 1\n",
    "\n",
    "current_row += 1\n",
    "\n",
    "\n",
    "# Recommendations summary\n",
    "if all_recommendations is not None and len(all_recommendations) > 0:\n",
    "    ws_summary.cell(row=current_row, column=1, value=\"KEY RECOMMENDATIONS\")\n",
    "    ws_summary.cell(row=current_row, column=1).font = subheader_font\n",
    "    current_row += 2\n",
    "    \n",
    "    # Group by priority\n",
    "    for priority in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:\n",
    "        priority_recs = all_recommendations[all_recommendations['priority'] == priority]\n",
    "        if len(priority_recs) > 0:\n",
    "            ws_summary.cell(row=current_row, column=1, value=f\"{priority} Priority: {len(priority_recs)} recommendations\")\n",
    "            ws_summary.cell(row=current_row, column=1).font = Font(name='Calibri', size=10, bold=True)\n",
    "            current_row += 1\n",
    "\n",
    "current_row += 1\n",
    "\n",
    "# Add counting methodology visualization with ACTUAL VALUES\n",
    "current_row += 1\n",
    "ws_summary.cell(row=current_row, column=1, value=\"COUNTING METHODOLOGY\")\n",
    "ws_summary.cell(row=current_row, column=1).font = Font(name='Calibri', size=14, bold=True)\n",
    "current_row += 2\n",
    "\n",
    "# Get actual counts from key scenario\n",
    "key_overall_stats = scenario_data[key_scenario_id]['overall_stats']\n",
    "\n",
    "def get_value_from_stats(stats_df, metric_name):\n",
    "    \"\"\"Helper to extract value from stats dataframe\"\"\"\n",
    "    result = stats_df[stats_df['metric'] == metric_name]\n",
    "    if len(result) > 0:\n",
    "        return result.iloc[0]['value']\n",
    "    return 'N/A'\n",
    "\n",
    "total_count = get_value_from_stats(key_overall_stats, 'Total Count')\n",
    "unique_refs = get_value_from_stats(key_overall_stats, 'Unique References')\n",
    "\n",
    "methodology_diagram = [\n",
    "    \"DEDUPLICATION LEVELS:\",\n",
    "    \"\",\n",
    "    \"Level 1 - Within Guideline:\",\n",
    "    \"  ✓ Each guideline has UNIQUE list of references (no duplicates within one guideline)\",\n",
    "    \"\",\n",
    "    \"Level 2 - Across Guidelines:\",\n",
    "    \"  ✗ NOT deduplicated - same reference can appear multiple times\",\n",
    "    \"  Example: If 3 guidelines cite PMID 100 → 3 rows in dataset\",\n",
    "    \"\",\n",
    "    \"Level 3 - Trials:\",\n",
    "    \"  • UNIVERSE (citation-level): Same trial cited multiple ways = multiple rows\",\n",
    "    \"  • UNIQUE_TRIALS (trial-level): Each trial appears once (fully deduplicated)\",\n",
    "    \"\",\n",
    "    f\"KEY COUNTS (from {key_scenario_info['short_name']}):\",\n",
    "    f\"  • Total citations: {total_count} (includes cross-guideline overlaps)\",\n",
    "    f\"  • Unique references: {unique_refs} (unique PMIDs)\",\n",
    "    \"\",\n",
    "    \"⚠️ Same reference cited by multiple guidelines = counted each time in citation counts\",\n",
    "    \"   This preserves citation relationships and allows guideline-level analysis\"\n",
    "]\n",
    "\n",
    "for line in methodology_diagram:\n",
    "    ws_summary.cell(row=current_row, column=1, value=line)\n",
    "    if line.startswith(\"Level\") or line.startswith(\"KEY COUNTS\"):\n",
    "        ws_summary.cell(row=current_row, column=1).font = Font(name='Calibri', size=10, bold=True)\n",
    "    elif line.startswith(\"⚠️\"):\n",
    "        ws_summary.cell(row=current_row, column=1).font = Font(name='Calibri', size=10, bold=True, color='FF0000')\n",
    "    else:\n",
    "        ws_summary.cell(row=current_row, column=1).font = Font(name='Calibri', size=9)\n",
    "    current_row += 1\n",
    "\n",
    "current_row += 1\n",
    "\n",
    "# Navigation guide\n",
    "ws_summary.cell(row=current_row, column=1, value=\"REPORT NAVIGATION\")\n",
    "ws_summary.cell(row=current_row, column=1).font = subheader_font\n",
    "current_row += 2\n",
    "\n",
    "nav_items = [\n",
    "    \"• Scenario Comparison - Compare metrics across all scenarios\",\n",
    "    \"• S1-S6 tabs - Detailed results for each scenario\",\n",
    "    \"• Recommendations - Actionable recommendations by scenario\",\n",
    "    \"• Data Dictionary - Column definitions and calculations\"\n",
    "]\n",
    "\n",
    "for item in nav_items:\n",
    "    ws_summary.cell(row=current_row, column=1, value=item)\n",
    "    ws_summary.cell(row=current_row, column=1).font = normal_font\n",
    "    current_row += 1\n",
    "\n",
    "ws_summary.column_dimensions['A'].width = 100\n",
    "\n",
    "print(\"  ✓ Executive Summary created\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 6: Scenario Comparison Tab\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 5: Creating Scenario Comparison...\")\n",
    "\n",
    "ws_comparison = wb.create_sheet(\"Scenario Comparison\")\n",
    "\n",
    "current_row = add_title_to_sheet(\n",
    "    ws_comparison,\n",
    "    \"Scenario Comparison\",\n",
    "    \"How definitions affect results\"\n",
    ")\n",
    "\n",
    "# ADD COLOR LEGEND HERE\n",
    "current_row = add_color_legend(ws_comparison, current_row, 'recommended')\n",
    "\n",
    "# Scenario definitions table\n",
    "ws_comparison.cell(row=current_row, column=1, value=\"SCENARIO DEFINITIONS\")\n",
    "ws_comparison.cell(row=current_row, column=1).font = subheader_font\n",
    "current_row += 2\n",
    "\n",
    "# Add helpful text\n",
    "ws_comparison.cell(row=current_row, column=1, value=\"Each scenario uses a different definition of 'clinical trial'. Results vary significantly by definition.\")\n",
    "ws_comparison.cell(row=current_row, column=1).font = Font(name='Calibri', size=9, italic=True)\n",
    "ws_comparison.merge_cells(f'A{current_row}:F{current_row}')\n",
    "current_row += 2\n",
    "\n",
    "current_row = add_dataframe_to_sheet(\n",
    "    ws_comparison,\n",
    "    scenario_comparison[['scenario_id', 'name', 'definition', 'count', 'count_type', 'can_verify_sex']],\n",
    "    current_row\n",
    ")\n",
    "\n",
    "# Highlight recommended scenario rows\n",
    "for row in range(5, current_row):\n",
    "    scenario_cell = ws_comparison.cell(row=row, column=1)\n",
    "    scenario_id = scenario_cell.value\n",
    "    if isinstance(scenario_id, str) and scenario_id in scenarios_to_process:\n",
    "        scenario_info = scenario_comparison[scenario_comparison['scenario_id'] == scenario_id]\n",
    "        if len(scenario_info) > 0 and scenario_info.iloc[0].get('recommended', False):\n",
    "            for col in range(1, ws_comparison.max_column + 1):\n",
    "                ws_comparison.cell(row=row, column=col).fill = PatternFill(\n",
    "                    start_color=COLORS['recommended'],\n",
    "                    end_color=COLORS['recommended'],\n",
    "                    fill_type='solid'\n",
    "                )\n",
    "\n",
    "# Key metrics comparison\n",
    "ws_comparison.cell(row=current_row, column=1, value=\"KEY METRICS COMPARISON\")\n",
    "ws_comparison.cell(row=current_row, column=1).font = subheader_font\n",
    "current_row += 2\n",
    "\n",
    "current_row = add_dataframe_to_sheet(\n",
    "    ws_comparison,\n",
    "    key_metrics,\n",
    "    current_row\n",
    ")\n",
    "\n",
    "# Add interpretation guide\n",
    "ws_comparison.cell(row=current_row, column=1, value=\"INTERPRETATION GUIDE\")\n",
    "ws_comparison.cell(row=current_row, column=1).font = subheader_font\n",
    "current_row += 2\n",
    "\n",
    "interpretation = [\n",
    "    \"count_type: 'citation' = citation-level analysis | 'trial' = trial-level analysis\",\n",
    "    \"can_verify_sex: 'True' = can verify all trials include women | 'False' = cannot verify | 'partial' = can verify some\",\n",
    "    \"mentioning_sex_pct: % of citations/trials with any sex consideration (score > 0)\",\n",
    "    \"avg_sex_consideration_score: Mean score (0-10 scale) across all citations/trials\",\n",
    "    \"includes_women_pct: % of trials that permit women to participate (only for can_verify_sex=True scenarios)\"\n",
    "]\n",
    "\n",
    "for i, text in enumerate(interpretation, start=current_row):\n",
    "    ws_comparison.cell(row=i, column=1, value=f\"• {text}\")\n",
    "    ws_comparison.cell(row=i, column=1).font = Font(name='Calibri', size=9)\n",
    "    ws_comparison.merge_cells(f'A{i}:F{i}')\n",
    "\n",
    "auto_adjust_column_width(ws_comparison)\n",
    "\n",
    "print(\"  ✓ Scenario Comparison created\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 7: Individual Scenario Tabs\n",
    "# ============================================================================\n",
    "# CUSTOMIZATION: Modify scenario tab layout here\n",
    "# This section automatically creates tabs for all scenarios\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "# Step 6: Individual Scenario Tabs\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 6: Creating individual scenario tabs...\")\n",
    "\n",
    "for scenario_id in scenarios_to_process:\n",
    "    \n",
    "    scenario_info = scenario_data[scenario_id]['info']\n",
    "    overall_stats = scenario_data[scenario_id]['overall_stats']\n",
    "    guideline_stats = scenario_data[scenario_id]['guideline_stats']\n",
    "    categories = scenario_data[scenario_id]['categories']\n",
    "    \n",
    "    # DEBUG: Check what we have\n",
    "    print(f\"  Processing {scenario_id}:\")\n",
    "    print(f\"    - overall_stats: {len(overall_stats) if overall_stats is not None else 'None'} rows\")\n",
    "    print(f\"    - guideline_stats: {len(guideline_stats) if guideline_stats is not None else 'None'} rows\")\n",
    "    print(f\"    - categories: {len(categories) if categories is not None else 'None'} rows\")\n",
    "    \n",
    "    # Create sheet with truncated name if needed\n",
    "    sheet_name = f\"{scenario_info['short_name']}\"\n",
    "    if len(sheet_name) > 31:  # Excel limit\n",
    "        sheet_name = sheet_name[:28] + \"...\"\n",
    "    \n",
    "    ws_scenario = wb.create_sheet(sheet_name)\n",
    "    prepare_clean_worksheet(ws_scenario)\n",
    "    \n",
    "    # Title\n",
    "    current_row = add_title_to_sheet(\n",
    "        ws_scenario,\n",
    "        scenario_info['name'],\n",
    "        scenario_info['definition']\n",
    "    )\n",
    "    \n",
    "    # Scenario details\n",
    "    ws_scenario.cell(row=current_row, column=1, value=f\"Total: {scenario_info['count']:,} {scenario_info['count_type']}s\")\n",
    "    ws_scenario.cell(row=current_row, column=1).font = Font(name='Calibri', size=11, bold=True)\n",
    "    current_row += 1\n",
    "    \n",
    "    ws_scenario.cell(row=current_row, column=1, value=f\"Can verify sex: {scenario_info['can_verify_sex']}\")\n",
    "    ws_scenario.cell(row=current_row, column=1).font = normal_font\n",
    "    current_row += 2\n",
    "    \n",
    "    # Rationale\n",
    "    ws_scenario.cell(row=current_row, column=1, value=\"RATIONALE\")\n",
    "    ws_scenario.cell(row=current_row, column=1).font = subheader_font\n",
    "    current_row += 1\n",
    "    \n",
    "    ws_scenario.cell(row=current_row, column=1, value=scenario_info['definition'])\n",
    "    ws_scenario.cell(row=current_row, column=1).font = normal_font\n",
    "    ws_scenario.cell(row=current_row, column=1).alignment = Alignment(wrap_text=True)\n",
    "    ws_scenario.merge_cells(f'A{current_row}:D{current_row}')\n",
    "    current_row += 2\n",
    "    \n",
    "    # Overall statistics\n",
    "    ws_scenario.cell(row=current_row, column=1, value=\"OVERALL STATISTICS\")\n",
    "    ws_scenario.cell(row=current_row, column=1).font = subheader_font\n",
    "    current_row += 2\n",
    "    \n",
    "    current_row = add_dataframe_to_sheet(\n",
    "        ws_scenario,\n",
    "        overall_stats[['metric', 'value', 'calculation', 'source_columns']],\n",
    "        current_row\n",
    "    )\n",
    "    \n",
    "    # Guideline statistics (if available)\n",
    "    print(f\"    Checking guideline_stats: {guideline_stats is not None}, len={len(guideline_stats) if guideline_stats is not None else 'N/A'}\")\n",
    "    \n",
    "    if guideline_stats is not None and len(guideline_stats) > 0:\n",
    "        print(f\"    → ADDING guideline table with {len(guideline_stats)} rows\")\n",
    "        \n",
    "        ws_scenario.cell(row=current_row, column=1, value=\"GUIDELINE STATISTICS\")\n",
    "        ws_scenario.cell(row=current_row, column=1).font = subheader_font\n",
    "        current_row += 2\n",
    "        \n",
    "        # Show ALL guidelines\n",
    "        guideline_display = guideline_stats.reset_index()\n",
    "        print(f\"    → After reset_index: {guideline_display.shape}\")\n",
    "        \n",
    "        # REORGANIZE COLUMNS: Put snippets at the end for better readability\n",
    "        base_columns = [\n",
    "            'guideline_pmid', 'citations_in_scenario', 'citations_with_sex', \n",
    "            'pct_citing_sex', 'avg_sex_score', 'max_sex_score',\n",
    "            'cites_sex_differences', 'cites_sex_stratification', 'cites_sex_subgroup'\n",
    "        ]\n",
    "        \n",
    "        # Add trial columns if present\n",
    "        if 'cites_trials_with_women' in guideline_display.columns:\n",
    "            base_columns.append('cites_trials_with_women')\n",
    "        \n",
    "        # Add category\n",
    "        if 'category' in guideline_display.columns:\n",
    "            base_columns.append('category')\n",
    "        \n",
    "        # Add snippet COUNT columns\n",
    "        if 'sex_snippets_count' in guideline_display.columns:\n",
    "            base_columns.append('sex_snippets_count')\n",
    "        if 'exclusion_snippets_count' in guideline_display.columns:\n",
    "            base_columns.append('exclusion_snippets_count')\n",
    "        \n",
    "        # Add snippet TEXT columns at the end\n",
    "        snippet_columns = []\n",
    "        if 'sex_evidence_snippets' in guideline_display.columns:\n",
    "            snippet_columns.append('sex_evidence_snippets')\n",
    "        if 'exclusion_evidence_snippets' in guideline_display.columns:\n",
    "            snippet_columns.append('exclusion_evidence_snippets')\n",
    "        \n",
    "        # Select columns in preferred order\n",
    "        available_columns = [col for col in base_columns if col in guideline_display.columns]\n",
    "        display_columns = available_columns + snippet_columns\n",
    "        \n",
    "        print(f\"    → Display columns ({len(display_columns)}): {display_columns[:5]}...\")\n",
    "        \n",
    "        guideline_display = guideline_display[display_columns]\n",
    "        \n",
    "        # Track where header starts\n",
    "        header_row = current_row\n",
    "        \n",
    "        print(f\"    → Adding to Excel at row {current_row}\")\n",
    "        \n",
    "        # Add dataframe\n",
    "        current_row = add_dataframe_to_sheet(\n",
    "            ws_scenario,\n",
    "            guideline_display,\n",
    "            current_row,\n",
    "            include_index=False\n",
    "        )\n",
    "        \n",
    "        print(f\"    → Table added, current_row now {current_row}\")\n",
    "        \n",
    "        # Apply category colors if category column exists\n",
    "        if 'category' in guideline_display.columns:\n",
    "            category_col = list(guideline_display.columns).index('category') + 1\n",
    "            first_data_row = header_row + 1\n",
    "            last_data_row = header_row + len(guideline_display)\n",
    "            print(f\"    → Applying colors: rows {first_data_row} to {last_data_row}, col {category_col}\")\n",
    "            apply_category_colors(ws_scenario, first_data_row, last_data_row, category_col)\n",
    "        \n",
    "        # FORMAT SNIPPET COLUMNS: Make wider with text wrapping\n",
    "        if snippet_columns:\n",
    "            print(f\"    → Formatting {len(snippet_columns)} snippet columns\")\n",
    "            for snippet_col_name in snippet_columns:\n",
    "                snippet_col_idx = list(guideline_display.columns).index(snippet_col_name) + 1\n",
    "                snippet_col_letter = get_column_letter(snippet_col_idx)\n",
    "                \n",
    "                # Set column width (wider for snippets)\n",
    "                ws_scenario.column_dimensions[snippet_col_letter].width = 60\n",
    "                \n",
    "                # Apply text wrapping and alignment to all cells in snippet column\n",
    "                for row in range(header_row, last_data_row + 1):\n",
    "                    cell = ws_scenario.cell(row=row, column=snippet_col_idx)\n",
    "                    cell.alignment = Alignment(wrap_text=True, vertical='top', horizontal='left')\n",
    "                    \n",
    "                    # Make snippet text smaller\n",
    "                    if row > header_row:  # Data rows (not header)\n",
    "                        cell.font = Font(name='Calibri', size=8)\n",
    "        \n",
    "        ws_scenario.cell(row=current_row, column=1, value=f\"Showing all {len(guideline_stats)} guidelines. Evidence snippets show examples from cited papers.\")\n",
    "        ws_scenario.cell(row=current_row, column=1).font = Font(name='Calibri', size=9, italic=True)\n",
    "        ws_scenario.cell(row=current_row, column=1).alignment = Alignment(wrap_text=True)\n",
    "        ws_scenario.merge_cells(f'A{current_row}:D{current_row}')\n",
    "        current_row += 2\n",
    "    else:\n",
    "        print(f\"    → SKIPPING guideline table (None or empty)\")\n",
    "        ws_scenario.cell(row=current_row, column=1, value=\"⊘ Guideline statistics not available for this scenario\")\n",
    "        ws_scenario.cell(row=current_row, column=1).font = Font(name='Calibri', size=10, italic=True)\n",
    "        current_row += 2\n",
    "    \n",
    "    # Category summary (if available)\n",
    "    if categories is not None and len(categories) > 0:\n",
    "        ws_scenario.cell(row=current_row, column=1, value=\"CATEGORY SUMMARY\")\n",
    "        ws_scenario.cell(row=current_row, column=1).font = subheader_font\n",
    "        current_row += 2\n",
    "        \n",
    "        # ADD COLOR LEGEND HERE\n",
    "        current_row = add_color_legend(ws_scenario, current_row, 'category')\n",
    "        \n",
    "        category_summary = categories['category'].value_counts().reset_index()\n",
    "        category_summary.columns = ['Category', 'Count']\n",
    "        category_summary['Percentage'] = (category_summary['Count'] / len(categories) * 100).round(1)\n",
    "        \n",
    "        current_row = add_dataframe_to_sheet(\n",
    "            ws_scenario,\n",
    "            category_summary,\n",
    "            current_row\n",
    "        )\n",
    "    \n",
    "    auto_adjust_column_width(ws_scenario)\n",
    "    \n",
    "    print(f\"  ✓ {scenario_id} tab created\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# Step 8: Recommendations Tab\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 7: Creating Recommendations tab...\")\n",
    "\n",
    "if all_recommendations is not None and len(all_recommendations) > 0:\n",
    "    ws_recs = wb.create_sheet(\"Recommendations\")\n",
    "    \n",
    "    current_row = add_title_to_sheet(\n",
    "        ws_recs,\n",
    "        \"Recommendations by Scenario\",\n",
    "        \"Specific recommendations for each scenario definition\"\n",
    "    )\n",
    "    \n",
    "    # ADD COLOR LEGEND HERE\n",
    "    current_row = add_color_legend(ws_recs, current_row, 'priority')\n",
    "    \n",
    "    # Group by scenario\n",
    "    for scenario_id in scenarios_to_process:\n",
    "        scenario_recs = all_recommendations[all_recommendations['scenario_id'] == scenario_id]\n",
    "        \n",
    "        if len(scenario_recs) > 0:\n",
    "            scenario_name = scenario_comparison[scenario_comparison['scenario_id'] == scenario_id].iloc[0]['short_name']\n",
    "            \n",
    "            ws_recs.cell(row=current_row, column=1, value=f\"SCENARIO: {scenario_name}\")\n",
    "            ws_recs.cell(row=current_row, column=1).font = subheader_font\n",
    "            ws_recs.merge_cells(f'A{current_row}:D{current_row}')\n",
    "            current_row += 2\n",
    "            \n",
    "            # Add recommendations\n",
    "            for _, rec in scenario_recs.iterrows():\n",
    "                # Recommendation ID and priority\n",
    "                rec_header = f\"{rec['recommendation_id']} - {rec['recommendation']} [{rec['priority']}]\"\n",
    "                ws_recs.cell(row=current_row, column=1, value=rec_header)\n",
    "                ws_recs.cell(row=current_row, column=1).font = Font(name='Calibri', size=10, bold=True)\n",
    "                ws_recs.merge_cells(f'A{current_row}:D{current_row}')\n",
    "                \n",
    "                # Color by priority\n",
    "                priority_colors = {\n",
    "                    'CRITICAL': COLORS['critical'],\n",
    "                    'HIGH': COLORS['high'],\n",
    "                    'MEDIUM': COLORS['medium'],\n",
    "                    'LOW': COLORS['low']\n",
    "                }\n",
    "                if rec['priority'] in priority_colors:\n",
    "                    for col in range(1, 5):\n",
    "                        ws_recs.cell(row=current_row, column=col).fill = PatternFill(\n",
    "                            start_color=priority_colors[rec['priority']],\n",
    "                            end_color=priority_colors[rec['priority']],\n",
    "                            fill_type='solid'\n",
    "                        )\n",
    "                \n",
    "                current_row += 1\n",
    "                \n",
    "                # Description\n",
    "                ws_recs.cell(row=current_row, column=1, value=rec['description'])\n",
    "                ws_recs.cell(row=current_row, column=1).font = normal_font\n",
    "                ws_recs.cell(row=current_row, column=1).alignment = Alignment(wrap_text=True)\n",
    "                ws_recs.merge_cells(f'A{current_row}:D{current_row}')\n",
    "                current_row += 1\n",
    "                \n",
    "                # Details\n",
    "                details = [\n",
    "                    f\"Affected Guidelines: {rec['affected_guidelines']}\",\n",
    "                    f\"Current State: {rec['current_state']}\",\n",
    "                    f\"Target State: {rec['target_state']}\",\n",
    "                    f\"Evidence File: {rec['evidence_file']}\"\n",
    "                ]\n",
    "                \n",
    "                for detail in details:\n",
    "                    ws_recs.cell(row=current_row, column=1, value=f\"  • {detail}\")\n",
    "                    ws_recs.cell(row=current_row, column=1).font = small_font\n",
    "                    ws_recs.merge_cells(f'A{current_row}:D{current_row}')\n",
    "                    current_row += 1\n",
    "                \n",
    "                current_row += 1\n",
    "            \n",
    "            current_row += 1\n",
    "    \n",
    "    ws_recs.column_dimensions['A'].width = 100\n",
    "    \n",
    "    print(\"  ✓ Recommendations tab created\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 9: Actionable Recommendations Tab\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 8: Creating Actionable Recommendations tab...\")\n",
    "\n",
    "if actionable is not None:\n",
    "    ws_actionable = wb.create_sheet(\"Actionable by Stakeholder\")\n",
    "    \n",
    "    current_row = add_title_to_sheet(\n",
    "        ws_actionable,\n",
    "        \"Actionable Recommendations by Stakeholder\",\n",
    "        \"Specific actions for different stakeholder groups\"\n",
    "    )\n",
    "    \n",
    "    current_row = add_dataframe_to_sheet(\n",
    "        ws_actionable,\n",
    "        actionable,\n",
    "        current_row\n",
    "    )\n",
    "    \n",
    "    auto_adjust_column_width(ws_actionable)\n",
    "    \n",
    "    print(\"  ✓ Actionable Recommendations tab created\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 10: Enhanced Data Dictionary Tab\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 9: Creating Enhanced Data Dictionary tab...\")\n",
    "\n",
    "ws_dict = wb.create_sheet(\"Data Dictionary\")\n",
    "\n",
    "current_row = add_title_to_sheet(\n",
    "    ws_dict,\n",
    "    \"Comprehensive Data Dictionary\",\n",
    "    \"Column definitions, search terms, calculation logic, and metric interpretations\"\n",
    ")\n",
    "\n",
    "# Add navigation guide\n",
    "ws_dict.cell(row=current_row, column=1, value=\"SECTIONS IN THIS DICTIONARY:\")\n",
    "ws_dict.cell(row=current_row, column=1).font = subheader_font\n",
    "current_row += 1\n",
    "\n",
    "sections = [\n",
    "    \"1. Citation-Level Columns - Individual reference data fields\",\n",
    "    \"2. Scenario Summary Metrics - Metrics appearing in scenario comparison tables\",\n",
    "    \"3. Guideline Summary Metrics - Aggregated metrics for each guideline\",\n",
    "    \"4. Scoring Logic - How sex consideration score (0-10) is calculated\",\n",
    "    \"5. Search Terms Reference - Exact search patterns used in text analysis\"\n",
    "]\n",
    "\n",
    "for section in sections:\n",
    "    ws_dict.cell(row=current_row, column=1, value=f\"  • {section}\")\n",
    "    ws_dict.cell(row=current_row, column=1).font = Font(name='Calibri', size=9)\n",
    "    current_row += 1\n",
    "\n",
    "current_row += 1\n",
    "\n",
    "# Section 1: Main data dictionary (citation-level)\n",
    "ws_dict.cell(row=current_row, column=1, value=\"1. CITATION-LEVEL COLUMNS\")\n",
    "ws_dict.cell(row=current_row, column=1).font = subheader_font\n",
    "current_row += 2\n",
    "\n",
    "# Filter to just citation-level fields (exclude scenario_metrics and guideline_metrics)\n",
    "citation_level_fields = data_dictionary[\n",
    "    ~data_dictionary['column_name'].isin([\n",
    "        'count_type', 'can_verify_sex', 'total_citations', 'trial_citations',\n",
    "        'citations_with_sex', 'pct_citing_sex', 'avg_sex_score', \n",
    "        'cites_trials_with_women', 'pct_nct_with_women', 'max_sex_score', 'category'\n",
    "    ])\n",
    "]\n",
    "\n",
    "current_row = add_dataframe_to_sheet(\n",
    "    ws_dict,\n",
    "    citation_level_fields,\n",
    "    current_row\n",
    ")\n",
    "\n",
    "# Section 2: Scenario metrics\n",
    "scenario_fields = data_dictionary[\n",
    "    data_dictionary['column_name'].isin(['count_type', 'can_verify_sex'])\n",
    "]\n",
    "\n",
    "if len(scenario_fields) > 0:\n",
    "    ws_dict.cell(row=current_row, column=1, value=\"2. SCENARIO SUMMARY METRICS\")\n",
    "    ws_dict.cell(row=current_row, column=1).font = subheader_font\n",
    "    ws_dict.cell(row=current_row + 1, column=1, value=\"These metrics appear in scenario comparison tables and describe scenario properties\")\n",
    "    ws_dict.cell(row=current_row + 1, column=1).font = Font(name='Calibri', size=9, italic=True)\n",
    "    current_row += 3\n",
    "    \n",
    "    current_row = add_dataframe_to_sheet(\n",
    "        ws_dict,\n",
    "        scenario_fields,\n",
    "        current_row\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Add clarification table after scenario metrics section\n",
    "ws_dict.cell(row=current_row, column=1, value=\"CLARIFICATION: Data Availability vs. Results\")\n",
    "ws_dict.cell(row=current_row, column=1).font = subheader_font\n",
    "current_row += 2\n",
    "\n",
    "clarification_data = [\n",
    "    {\n",
    "        'Field': 'can_verify_sex (scenario level)',\n",
    "        'Question Answered': 'Can we CHECK sex inclusion?',\n",
    "        'Values': 'True / False / partial',\n",
    "        'Meaning': 'Data availability for checking',\n",
    "        'Example': 'True = All citations have NCT data to look up'\n",
    "    },\n",
    "    {\n",
    "        'Field': 'nct_sex (trial level)',\n",
    "        'Question Answered': 'What does registry SAY?',\n",
    "        'Values': 'All / Female / Male',\n",
    "        'Meaning': 'Raw registry data',\n",
    "        'Example': '\"All\" = Both sexes eligible'\n",
    "    },\n",
    "    {\n",
    "        'Field': 'nct_sex_includes_women (trial level)',\n",
    "        'Question Answered': 'Can women ENROLL?',\n",
    "        'Values': 'True / False / NaN',\n",
    "        'Meaning': 'Whether women are eligible',\n",
    "        'Example': 'True = Women CAN participate'\n",
    "    },\n",
    "    {\n",
    "        'Field': 'includes_women_pct (guideline level)',\n",
    "        'Question Answered': 'What % of verifiable trials include women?',\n",
    "        'Values': '0-100%',\n",
    "        'Meaning': 'Proportion that permit women',\n",
    "        'Example': '92% = 92% of verifiable trials permit women'\n",
    "    }\n",
    "]\n",
    "\n",
    "clarification_df = pd.DataFrame(clarification_data)\n",
    "current_row = add_dataframe_to_sheet(ws_dict, clarification_df, current_row)\n",
    "\n",
    "ws_dict.cell(row=current_row, column=1, value=\"Key: can_verify_sex tells you if you CAN check. nct_sex_includes_women tells you the ANSWER.\")\n",
    "ws_dict.cell(row=current_row, column=1).font = Font(name='Calibri', size=9, bold=True, color='FF0000')\n",
    "ws_dict.merge_cells(f'A{current_row}:E{current_row}')\n",
    "current_row += 2\n",
    "\n",
    "# Section 3: Guideline metrics\n",
    "guideline_fields = data_dictionary[\n",
    "    data_dictionary['column_name'].isin([\n",
    "        'total_citations', 'trial_citations', 'citations_with_sex', \n",
    "        'pct_citing_sex', 'avg_sex_score', 'cites_trials_with_women',\n",
    "        'pct_nct_with_women', 'max_sex_score', 'category'\n",
    "    ])\n",
    "]\n",
    "\n",
    "if len(guideline_fields) > 0:\n",
    "    ws_dict.cell(row=current_row, column=1, value=\"3. GUIDELINE SUMMARY METRICS\")\n",
    "    ws_dict.cell(row=current_row, column=1).font = subheader_font\n",
    "    ws_dict.cell(row=current_row + 1, column=1, value=\"These metrics appear in guideline statistics tables and are calculated per guideline\")\n",
    "    ws_dict.cell(row=current_row + 1, column=1).font = Font(name='Calibri', size=9, italic=True)\n",
    "    current_row += 3\n",
    "    \n",
    "    current_row = add_dataframe_to_sheet(\n",
    "        ws_dict,\n",
    "        guideline_fields,\n",
    "        current_row\n",
    "    )\n",
    "# Section 4: Deduplication methodology\n",
    "methodology_fields = data_dictionary[\n",
    "    data_dictionary['column_name'].str.startswith('DEDUPLICATION_', na=False) |\n",
    "    (data_dictionary['column_name'] == 'COUNT_INTERPRETATION_GUIDE')\n",
    "]\n",
    "\n",
    "if len(methodology_fields) > 0:\n",
    "    ws_dict.cell(row=current_row, column=1, value=\"4. DEDUPLICATION & COUNTING METHODOLOGY\")\n",
    "    ws_dict.cell(row=current_row, column=1).font = subheader_font\n",
    "    ws_dict.cell(row=current_row + 1, column=1, value=\"⚠️ CRITICAL: Understanding what counts mean and when deduplication occurs\")\n",
    "    ws_dict.cell(row=current_row + 1, column=1).font = Font(name='Calibri', size=9, italic=True, bold=True, color='FF0000')\n",
    "    current_row += 3\n",
    "    \n",
    "    # Add summary box\n",
    "    summary_text = '''QUICK SUMMARY:\n",
    "- Within guideline: Each reference appears once (deduplicated)\n",
    "- Across guidelines: Same reference CAN appear multiple times (NOT deduplicated) - preserves citation relationships\n",
    "- Within reference: Multiple trials stored in semicolon list (UNIVERSE) or separate rows (EXPLODED - not used)\n",
    "- Same trial, different references: Each reference counted separately (they are different citations)\n",
    "- Same trial, multiple guidelines: Counted separately in UNIVERSE (citation-level), deduplicated in UNIQUE_TRIALS (trial-level)\n",
    "\n",
    "RESULT: \"Total citations\" includes same reference cited by different guidelines. \"Unique trials\" removes all duplicates.'''\n",
    "    \n",
    "    ws_dict.cell(row=current_row, column=1, value=summary_text)\n",
    "    ws_dict.cell(row=current_row, column=1).font = Font(name='Calibri', size=9)\n",
    "    ws_dict.cell(row=current_row, column=1).fill = PatternFill(start_color='FFF9E6', end_color='FFF9E6', fill_type='solid')\n",
    "    ws_dict.cell(row=current_row, column=1).alignment = Alignment(wrap_text=True, vertical='top')\n",
    "    ws_dict.cell(row=current_row, column=1).border = thin_border\n",
    "    ws_dict.merge_cells(f'A{current_row}:F{current_row}')\n",
    "    current_row += 2\n",
    "    \n",
    "    current_row = add_dataframe_to_sheet(\n",
    "        ws_dict,\n",
    "        methodology_fields,\n",
    "        current_row\n",
    "    )\n",
    "\n",
    "# Add actual examples from current dataset\n",
    "ws_dict.cell(row=current_row, column=1, value=\"EXAMPLES FROM THIS DATASET:\")\n",
    "ws_dict.cell(row=current_row, column=1).font = Font(name='Calibri', size=9, bold=True)\n",
    "current_row += 1\n",
    "\n",
    "# Get example values from first scenario (or recommended scenario)\n",
    "if len(all_scenario_results) > 0:\n",
    "    # Use recommended scenario if available, otherwise first\n",
    "    recommended = [s for s in scenarios_to_process if scenario_data[s]['info'].get('recommended', False)]\n",
    "    example_scenario = recommended[0] if recommended else scenarios_to_process[0]\n",
    "    \n",
    "    example_stats = all_scenario_results[example_scenario]['overall_stats']\n",
    "    example_guidelines = all_scenario_results[example_scenario]['guideline_stats']\n",
    "    \n",
    "    examples_table = create_count_examples_table(example_stats, example_guidelines, example_scenario)\n",
    "    \n",
    "    current_row = add_dataframe_to_sheet(\n",
    "        ws_dict,\n",
    "        examples_table,\n",
    "        current_row\n",
    "    )\n",
    "    \n",
    "    ws_dict.cell(row=current_row, column=1, value=f\"Note: Examples above are from Scenario {example_scenario}. Values will differ by scenario and dataset.\")\n",
    "    ws_dict.cell(row=current_row, column=1).font = Font(name='Calibri', size=8, italic=True)\n",
    "    ws_dict.merge_cells(f'A{current_row}:F{current_row}')\n",
    "    current_row += 2\n",
    "\n",
    "# Then continue with Section 5 (Scoring logic), Section 6 (Search terms), etc.\n",
    "\n",
    "# Section 5: Scoring logic\n",
    "scoring_file = os.path.join(OUTPUT_FOLDER, 'phase8_scoring_summary.csv')\n",
    "if os.path.exists(scoring_file):\n",
    "    scoring = pd.read_csv(scoring_file)\n",
    "    \n",
    "    ws_dict.cell(row=current_row, column=1, value=\"4. SCORING LOGIC\")\n",
    "    ws_dict.cell(row=current_row, column=1).font = subheader_font\n",
    "    ws_dict.cell(row=current_row + 1, column=1, value=\"How boolean flags combine to create sex consideration score (0-10)\")\n",
    "    ws_dict.cell(row=current_row + 1, column=1).font = Font(name='Calibri', size=9, italic=True)\n",
    "    current_row += 3\n",
    "    \n",
    "    current_row = add_dataframe_to_sheet(\n",
    "        ws_dict,\n",
    "        scoring,\n",
    "        current_row\n",
    "    )\n",
    "\n",
    "# Section 6: Search terms (if available from Phase 8)\n",
    "# This would be all rows that have actual search terms (not N/A)\n",
    "search_terms_fields = data_dictionary[\n",
    "    (data_dictionary['search_terms'].notna()) & \n",
    "    (~data_dictionary['search_terms'].str.startswith('N/A', na=False))\n",
    "]\n",
    "\n",
    "if len(search_terms_fields) > 0:\n",
    "    ws_dict.cell(row=current_row, column=1, value=\"5. SEARCH TERMS REFERENCE\")\n",
    "    ws_dict.cell(row=current_row, column=1).font = subheader_font\n",
    "    ws_dict.cell(row=current_row + 1, column=1, value=\"Exact search patterns used to identify sex considerations in text\")\n",
    "    ws_dict.cell(row=current_row + 1, column=1).font = Font(name='Calibri', size=9, italic=True)\n",
    "    current_row += 3\n",
    "    \n",
    "    # Show subset of columns for readability\n",
    "    search_display = search_terms_fields[[\n",
    "        'column_name', 'display_name', 'search_terms', \n",
    "        'sources_searched', 'used_in_scoring'\n",
    "    ]]\n",
    "    \n",
    "    current_row = add_dataframe_to_sheet(\n",
    "        ws_dict,\n",
    "        search_display,\n",
    "        current_row\n",
    "    )\n",
    "\n",
    "auto_adjust_column_width(ws_dict)\n",
    "\n",
    "print(\"  ✓ Enhanced Data Dictionary created with all sections\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Step 11: Final Formatting - Clean White Appearance\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 11: Applying final formatting...\")\n",
    "\n",
    "for sheet_name in wb.sheetnames:\n",
    "    ws = wb[sheet_name]\n",
    "    prepare_clean_worksheet(ws)\n",
    "\n",
    "print(\"  ✓ Gridlines hidden on all sheets\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Step 12: Save Workbook\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 10: Saving Excel workbook...\")\n",
    "\n",
    "output_file = os.path.join(OUTPUT_FOLDER, 'Sex_Based_Guidelines_Multi_Scenario_Analysis.xlsx')\n",
    "wb.save(output_file)\n",
    "\n",
    "print(f\"  ✓ Saved: {output_file}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 13: Generate Summary Report\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"✓ PHASE 10 COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nFinal Excel Report Created:\")\n",
    "print(f\"  File: Sex_Based_Guidelines_Multi_Scenario_Analysis.xlsx\")\n",
    "print(f\"  Location: {OUTPUT_FOLDER}/\")\n",
    "print(f\"  Size: {os.path.getsize(output_file) / 1024:.1f} KB\")\n",
    "print(f\"\\nWorkbook Structure ({len(wb.sheetnames)} tabs):\")\n",
    "\n",
    "for i, sheet_name in enumerate(wb.sheetnames, 1):\n",
    "    print(f\"  {i}. {sheet_name}\")\n",
    "\n",
    "print(f\"\\nScenarios Analyzed: {len(scenarios_to_process)}\")\n",
    "for scenario_id in scenarios_to_process:\n",
    "    scenario_name = scenario_comparison[scenario_comparison['scenario_id'] == scenario_id].iloc[0]['short_name']\n",
    "    count = scenario_comparison[scenario_comparison['scenario_id'] == scenario_id].iloc[0]['count']\n",
    "    count_type = scenario_comparison[scenario_comparison['scenario_id'] == scenario_id].iloc[0]['count_type']\n",
    "    print(f\"  • {scenario_name}: {count:,} {count_type}s\")\n",
    "\n",
    "if all_recommendations is not None:\n",
    "    print(f\"\\nRecommendations Generated: {len(all_recommendations)}\")\n",
    "    for priority in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:\n",
    "        count = len(all_recommendations[all_recommendations['priority'] == priority])\n",
    "        if count > 0:\n",
    "            print(f\"  • {priority}: {count}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✓ ANALYSIS COMPLETE - Report Ready for Delivery\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "print(\"NEXT STEPS:\")\n",
    "print(\"  1. Review Excel file: Sex_Based_Guidelines_Multi_Scenario_Analysis.xlsx\")\n",
    "print(\"  2. Check 'Executive Summary' tab for overview\")\n",
    "print(\"  3. Review 'Scenario Comparison' to understand differences\")\n",
    "print(\"  4. Examine individual scenario tabs for detailed results\")\n",
    "print(\"  5. Share relevant evidence files from output/ folder\")\n",
    "print(f\"\\n{'='*70}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3539d745-a5a9-43ba-b43a-c67400d98503",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dynamic email report...\n",
      "\n",
      "✓ Email markdown generated: output\\researcher_email_20260107_1307.md\n",
      "  File size: 13,179 characters\n",
      "  Sections: Executive Summary, Deliverable, Scenarios, Methodology, Comparison, etc.\n",
      "\n",
      "You can:\n",
      "  1. Open in markdown viewer\n",
      "  2. Copy/paste into email client\n",
      "  3. Convert to HTML/PDF\n",
      "  4. Edit as needed before sending\n",
      "\n",
      "======================================================================\n",
      "PREVIEW (first 1000 characters):\n",
      "======================================================================\n",
      "# Email to Research Team: Final Analysis Report\n",
      "\n",
      "---\n",
      "\n",
      "**Subject:** Final Analysis Report: Sex-Based Considerations in Clinical Practice Guidelines (Multi-Scenario Analysis)\n",
      "\n",
      "**Date Generated:** 2026-01-07 13:07\n",
      "\n",
      "---\n",
      "\n",
      "Dear Research Team,\n",
      "\n",
      "I'm pleased to share the final comprehensive analysis of sex-based considerations in clinical practice guidelines. The multi-scenario analysis is complete and ready for your review.\n",
      "\n",
      "---\n",
      "\n",
      "## 📊 EXECUTIVE SUMMARY\n",
      "\n",
      "We analyzed **75 clinical practice guidelines** citing **9,202 total references** (1455 unique papers), examining how guidelines incorporate sex-based evidence from clinical trials.\n",
      "\n",
      "### Key Findings (Primary Analysis - Registry-Verified Scenario):\n",
      "\n",
      "- **630 trial citations** identified across **75 guidelines**\n",
      "- **13 guidelines (17%)** cite zero trials in this scenario\n",
      "- **Only 15 guidelines (20%)** demonstrate \"Strong\" sex consideration\n",
      "- **46 guidelines (61%)** show \"Moderate\" consideration\n",
      "- **13 guidelines (17%)** have \"Inadequate\" or no se\n",
      "...\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Email to Research Team: Final Analysis Report\n",
       "\n",
       "---\n",
       "\n",
       "**Subject:** Final Analysis Report: Sex-Based Considerations in Clinical Practice Guidelines (Multi-Scenario Analysis)\n",
       "\n",
       "**Date Generated:** 2026-01-07 13:07\n",
       "\n",
       "---\n",
       "\n",
       "Dear Research Team,\n",
       "\n",
       "I'm pleased to share the final comprehensive analysis of sex-based considerations in clinical practice guidelines. The multi-scenario analysis is complete and ready for your review.\n",
       "\n",
       "---\n",
       "\n",
       "## 📊 EXECUTIVE SUMMARY\n",
       "\n",
       "We analyzed **75 clinical practice guidelines** citing **9,202 total references** (1455 unique papers), examining how guidelines incorporate sex-based evidence from clinical trials.\n",
       "\n",
       "### Key Findings (Primary Analysis - Registry-Verified Scenario):\n",
       "\n",
       "- **630 trial citations** identified across **75 guidelines**\n",
       "- **13 guidelines (17%)** cite zero trials in this scenario\n",
       "- **Only 15 guidelines (20%)** demonstrate \"Strong\" sex consideration\n",
       "- **46 guidelines (61%)** show \"Moderate\" consideration\n",
       "- **13 guidelines (17%)** have \"Inadequate\" or no sex consideration\n",
       "\n",
       "### Critical Gap:\n",
       "\n",
       "Among guidelines citing trials, **sex consideration varies dramatically** based on how we define \"clinical trial\" - demonstrating the importance of multi-scenario analysis.\n",
       "\n",
       "---\n",
       "\n",
       "## 📁 DELIVERABLE: EXCEL WORKBOOK\n",
       "\n",
       "**File:** `Sex_Based_Guidelines_Multi_Scenario_Analysis.xlsx`\n",
       "\n",
       "### Workbook Structure (11 tabs):\n",
       "\n",
       "1. **Executive Summary** - Overview of all scenarios and key findings\n",
       "2. **Scenario Comparison** - Side-by-side comparison of how definitions affect results\n",
       "3. **PubMed PT** (S1) - ref_is_clinical_trial_pt_type = True\n",
       "4. **PubMed OR NCT** (S2) - ref_is_clinical_trial_pt_type = True OR ref_primary_nct_number is not null\n",
       "5. **Unique Trials** (S3) - Deduplicated from phase7_trials_UNIQUE_NCT_ANALYZED.csv\n",
       "6. **Registry-Verified** (S4) ⭐ - ref_primary_nct_number is not null\n",
       "7. **All NCTs** (S5) - ref_all_nct_numbers is not null\n",
       "8. **High-Quality** (S6) - ref_primary_nct_number is not null AND nct_official_title is not null\n",
       "9. **Recommendations** - Specific improvement recommendations by scenario\n",
       "10. **Actionable by Stakeholder** - Actions for guideline developers, funders, researchers  \n",
       "11. **Data Dictionary** - Complete methodology documentation\n",
       "\n",
       "### Key Features:\n",
       "\n",
       "- ✅ **Color-coded categories** showing guideline performance (Strong = green, Inadequate = red)\n",
       "- ✅ **Evidence snippets** showing actual text from papers demonstrating sex consideration\n",
       "- ✅ **All 75 guidelines included** in every scenario (none excluded)\n",
       "- ✅ **Complete transparency** - every metric includes calculation methodology\n",
       "\n",
       "---\n",
       "\n",
       "## 🔬 SCENARIO DEFINITIONS\n",
       "\n",
       "We analyzed 6 different scenarios because **defining \"clinical trial\" significantly impacts results**:\n",
       "\n",
       "### PubMed Publication Type\n",
       "\n",
       "- **Definition:** ref_is_clinical_trial_pt_type = True\n",
       "- **Count:** 1,527 citations across 75 guidelines\n",
       "- **Can verify sex inclusion:** ❌ No (PubMed lacks eligibility data)\n",
       "- **Use for:** Analysis of trial patterns\n",
       "\n",
       "### PubMed OR Registry\n",
       "\n",
       "- **Definition:** ref_is_clinical_trial_pt_type = True OR ref_primary_nct_number is not null\n",
       "- **Count:** 1,612 citations across 75 guidelines\n",
       "- **Can verify sex inclusion:** ⚠️ Partial (some have NCT data)\n",
       "- **Use for:** Analysis of trial patterns\n",
       "\n",
       "### Unique Trials (Deduplicated)\n",
       "\n",
       "- **Definition:** Deduplicated from phase7_trials_UNIQUE_NCT_ANALYZED.csv\n",
       "- **Count:** 505 unique trials\n",
       "- **Can verify sex inclusion:** ❌ No (PubMed lacks eligibility data)\n",
       "- **Use for:** Analysis of trial patterns\n",
       "\n",
       "### Registry-Verified Trials ⭐\n",
       "\n",
       "- **Definition:** ref_primary_nct_number is not null\n",
       "- **Count:** 630 citations across 75 guidelines\n",
       "- **Can verify sex inclusion:** ❌ No (PubMed lacks eligibility data)\n",
       "- **Use for:** Analysis of trial patterns\n",
       "\n",
       "### All NCT Mentions\n",
       "\n",
       "- **Definition:** ref_all_nct_numbers is not null\n",
       "- **Count:** 630 citations across 75 guidelines\n",
       "- **Can verify sex inclusion:** ❌ No (PubMed lacks eligibility data)\n",
       "- **Use for:** Analysis of trial patterns\n",
       "\n",
       "### High-Quality Registry Data\n",
       "\n",
       "- **Definition:** ref_primary_nct_number is not null AND nct_official_title is not null\n",
       "- **Count:** 617 citations across 75 guidelines\n",
       "- **Can verify sex inclusion:** ❌ No (PubMed lacks eligibility data)\n",
       "- **Use for:** Analysis of trial patterns\n",
       "\n",
       "---\n",
       "\n",
       "## 🧮 METHODOLOGY: Sex Consideration Score (0-10 Scale)\n",
       "\n",
       "We developed a composite score quantifying the degree of sex consideration in each citation. This score drives all guideline categorizations.\n",
       "\n",
       "### Scoring Formula:\n",
       "\n",
       "#### HIGH VALUE (2 points each, maximum 6 points):\n",
       "\n",
       "Direct evidence of sex-based analysis:\n",
       "\n",
       "- **+2 points:** Mentions sex differences (e.g., \"sex-specific outcomes,\" \"differences between men and women\")\n",
       "- **+2 points:** Mentions sex stratification (e.g., \"stratified by gender,\" \"analyzed separately by sex\")\n",
       "- **+2 points:** Mentions sex subgroup analysis (e.g., \"sex subgroup analysis,\" \"interaction by gender\")\n",
       "\n",
       "#### MEDIUM VALUE (1 point each, maximum 4 points):\n",
       "\n",
       "Biological sex considerations + trial inclusivity:\n",
       "\n",
       "- **+1 point:** Pregnancy-related considerations (e.g., \"pregnant,\" \"postpartum,\" \"lactating\")\n",
       "- **+1 point:** Menopause-related considerations (e.g., \"menopausal,\" \"postmenopausal\")\n",
       "- **+1 point:** Sex hormone considerations (e.g., \"estrogen,\" \"testosterone,\" \"sex hormones\")\n",
       "- **+1 point:** Trial includes women (from ClinicalTrials.gov sex eligibility = \"All\" or \"Female\")\n",
       "\n",
       "#### Maximum Total: 10 points\n",
       "\n",
       "### Rationale:\n",
       "\n",
       "- **Direct sex analysis weighted highest (2 pts)** - Shows intentional investigation of sex differences\n",
       "- **Biological factors weighted medium (1 pt)** - Shows awareness of sex-specific physiology\n",
       "- **Trial inclusivity receives credit (1 pt)** - Basic requirement for generating sex-relevant evidence\n",
       "- **Score reflects both QUALITY (type) and PRESENCE (exists)** of sex consideration\n",
       "\n",
       "### Pattern Matching:\n",
       "\n",
       "We use **18 distinct pattern groups** searching across:\n",
       "\n",
       "- Reference titles\n",
       "- Reference abstracts  \n",
       "- ClinicalTrials.gov registry fields (title, description, eligibility criteria, outcomes)\n",
       "\n",
       "**Example search terms:**\n",
       "\n",
       "- Sex differences: \"sex-specific,\" \"sex-based,\" \"between men and women,\" \"sex disparity\"\n",
       "- Stratification: \"stratified by sex,\" \"analyzed separately for men and women\"\n",
       "- Biological: \"pregnant,\" \"pregnancy,\" \"menopause,\" \"estrogen,\" \"testosterone\"\n",
       "\n",
       "### Guideline Categorization (Based on Aggregate Scores):\n",
       "\n",
       "| Category | Criteria | Interpretation |\n",
       "|----------|----------|----------------|\n",
       "| **Strong** | ≥20% citations mention sex AND avg score ≥2.0 | Systematic sex consideration across many citations |\n",
       "| **Moderate** | ≥10% citations mention sex AND avg score ≥1.0 | Notable sex consideration but not systematic |\n",
       "| **Weak** | ≥5% citations mention sex OR some consideration present | Minimal sex consideration |\n",
       "| **Inadequate - No Sex** | <5% citations mention sex AND avg score <1.0 | Cites trials but fails to consider sex |\n",
       "| **Inadequate - No Trials** | 0 citations in this scenario | Most severe - no trial evidence base |\n",
       "\n",
       "---\n",
       "\n",
       "## 📈 CROSS-SCENARIO COMPARISON\n",
       "\n",
       "**How scenario definitions change results:**\n",
       "\n",
       "| Metric | PubMed PT | PubMed OR NCT | Unique Trials | Registry-Verified ⭐ |\n",
       "|--------|--------|--------|--------|\n",
       "| **Total Count** | 1,527 | 1,612 | 505 | 630 |\n",
       "| **Guidelines Included** | 75 | 75 | N/A | 75 |\n",
       "| **Can Verify Sex** | ❌ No | ⚠️ Partial | ❌ No | ❌ No |\n",
       "| **Strong Guidelines** | 0 (0%) | 0 (0%) | N/A (N/A) | 15 (20%) |\n",
       "| **Guidelines with 0 Trials** | 5 (7%) | 4 (5%) | N/A (N/A) | 13 (17%) |\n",
       "\n",
       "\n",
       "**Key Insight:** The recommended scenario (Registry-Verified) shows that 13 (17%) of guidelines cite zero verifiable trials - a critical gap hidden in broader definitions.\n",
       "\n",
       "---\n",
       "\n",
       "## 🔍 DEDUPLICATION & COUNTING METHODOLOGY\n",
       "\n",
       "**Critical for interpreting numbers correctly:**\n",
       "\n",
       "### What's Deduplicated:\n",
       "\n",
       "- ✅ **Within guideline:** Each guideline has unique list of references (no internal duplicates)\n",
       "\n",
       "### What's NOT Deduplicated:\n",
       "\n",
       "- ❌ **Across guidelines:** Same reference cited by multiple guidelines = counted each time\n",
       "- ❌ **Same trial, different papers:** Multiple papers discussing same trial = each counted\n",
       "\n",
       "### Why This Matters:\n",
       "\n",
       "**Example:** Famous trial NCT12345 cited by 3 guidelines through 5 different papers\n",
       "\n",
       "- **Citation-level (S1, S2, S4, S5, S6):** Counted 5 times (preserves citation relationships)\n",
       "- **Trial-level (S3):** Counted 1 time (unique trials only)\n",
       "\n",
       "**Result:**\n",
       "\n",
       "- \"Total citations\" = 9202 (includes cross-guideline overlaps)\n",
       "- \"Unique references\" = varies by scenario (unique PMIDs)\n",
       "- \"Unique trials\" = deduplicated count from S3\n",
       "\n",
       "This structure allows us to ask:\n",
       "\n",
       "- **Citation-level:** \"How many times do guidelines cite trials?\" \"Which guidelines cite NCT12345?\"\n",
       "- **Trial-level:** \"How many different trials are cited?\" \"What % of trials include women?\"\n",
       "\n",
       "---\n",
       "\n",
       "## 💡 HOW TO USE THIS ANALYSIS\n",
       "\n",
       "### For Manuscript:\n",
       "\n",
       "1. **Primary analysis:** Use **Registry-Verified (S4_Registry_Verified)** - most defensible for sex inclusion claims\n",
       "2. **Supplementary:** Show other scenarios for comparison\n",
       "3. **Trial characteristics:** Use S3 (Unique Trials) for \"how many unique trials\" and trial properties\n",
       "4. **Evidence snippets:** Quote actual text from guidelines to demonstrate gaps\n",
       "\n",
       "### For Recommendations:\n",
       "\n",
       "1. Review **Recommendations tab** for specific improvement opportunities (15 recommendations generated)\n",
       "2. Use **Actionable by Stakeholder tab** for tailored guidance (6 actions across 5 stakeholder groups)\n",
       "3. Reference **specific guideline PMIDs** from evidence files\n",
       "\n",
       "### For Validation:\n",
       "\n",
       "1. Check **Data Dictionary tab** for complete methodology\n",
       "2. Review **evidence snippets** in guideline tables to verify scoring accuracy\n",
       "3. **Pattern groups reference** shows all 18+ search patterns used\n",
       "\n",
       "---\n",
       "\n",
       "## 📋 ADDITIONAL FILES GENERATED\n",
       "\n",
       "In addition to the Excel workbook, we generated detailed CSV files:\n",
       "\n",
       "**Scenario-specific files (×5 citation-level scenarios):**\n",
       "\n",
       "- `phase8_S[X]_overall_statistics.csv` - Corpus-level metrics\n",
       "- `phase8_S[X]_guideline_statistics.csv` - Per-guideline metrics\n",
       "- `phase8_S[X]_guideline_categories.csv` - Performance categories\n",
       "\n",
       "**Cross-cutting files:**\n",
       "\n",
       "- `phase8_scenario_comparison.csv` - Side-by-side scenario comparison\n",
       "- `phase8_key_metrics_comparison.csv` - Key metrics across scenarios\n",
       "- `phase8_data_dictionary.csv` - Complete column documentation\n",
       "- `phase8_scoring_summary.csv` - Scoring formula breakdown\n",
       "- `phase8_pattern_groups.csv` - Search pattern details\n",
       "\n",
       "**Recommendation files:**\n",
       "\n",
       "- `phase9_recommendations_all_scenarios.csv` - All 15 recommendations\n",
       "- `phase9_actionable_recommendations.csv` - 6 actions by stakeholder\n",
       "- `recommendation_S[X]_R[Y]_*.csv` - Evidence files for each recommendation\n",
       "\n",
       "---\n",
       "\n",
       "## 🎯 KEY MESSAGES FOR PAPER\n",
       "\n",
       "1. **Scenario definition matters:** Changing how we define \"clinical trial\" dramatically affects which guidelines appear to have gaps (13-14 guidelines depending on definition)\n",
       "\n",
       "2. **Verification is crucial:** Only registry-verified trials (S4_Registry_Verified) allow defensible claims about sex inclusion\n",
       "\n",
       "3. **Guidelines vary widely:** Even among those citing trials, sex consideration ranges from systematic (Strong: 20%) to absent (Inadequate: 17%)\n",
       "\n",
       "4. **Evidence exists but underutilized:** Evidence snippets show guidelines cite papers with sex-stratified analyses but don't highlight these findings in recommendations\n",
       "\n",
       "5. **Multiple gaps:** Some guidelines cite no trials (17%), others cite trials but ignore sex (separate issue), others cite only male-predominant trials\n",
       "\n",
       "---\n",
       "\n",
       "## 📞 NEXT STEPS\n",
       "\n",
       "1. **Review Excel workbook** - Start with Executive Summary and Registry-Verified tabs\n",
       "2. **Validate scoring** - Spot-check evidence snippets against source papers\n",
       "3. **Select primary scenario** - Confirm S4_Registry_Verified as primary (recommended) or adjust\n",
       "4. **Draft methods section** - Use Data Dictionary for complete methodology text\n",
       "5. **Identify exemplar guidelines** - Strong performers (green) for positive examples\n",
       "6. **Schedule discussion** - Happy to walk through any questions\n",
       "\n",
       "---\n",
       "\n",
       "## ❓ QUESTIONS TO CONSIDER\n",
       "\n",
       "- Which scenario(s) should be primary vs. supplementary in manuscript?\n",
       "- Should we highlight specific guidelines as exemplars (positive) or laggards (negative)?\n",
       "- Are there specific guideline development organizations to target with recommendations?\n",
       "- Should we create visualizations (bar charts, heat maps) from this data?\n",
       "\n",
       "---\n",
       "\n",
       "Please let me know if you need:\n",
       "\n",
       "- Additional scenarios analyzed\n",
       "- Different metric calculations\n",
       "- Specific data extractions\n",
       "- Visualization support\n",
       "- Methods section drafting assistance\n",
       "\n",
       "Looking forward to discussing the findings!\n",
       "\n",
       "Best regards,\n",
       "\n",
       "[Your Name]\n",
       "\n",
       "---\n",
       "\n",
       "**Attachments:**\n",
       "\n",
       "- Sex_Based_Guidelines_Multi_Scenario_Analysis.xlsx (primary deliverable)\n",
       "- phase8_data_dictionary.csv (methodology reference)\n",
       "- phase8_scenario_comparison.csv (quick comparison table)\n",
       "\n",
       "---\n",
       "\n",
       "**P.S.** All analysis code is fully documented and reproducible. The multi-scenario framework is designed to be extensible - we can easily add new scenario definitions (e.g., \"Phase 3/4 trials only,\" \"Recent trials 2015+\") by modifying a simple configuration dictionary and re-running the analysis (takes ~15 minutes).\n",
       "\n",
       "---\n",
       "\n",
       "*Report generated on 2026-01-07 at 13:07 from Phase 8-10 analysis outputs.*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Generate Dynamic Email Report in Markdown\n",
    "# ============================================================================\n",
    "# Purpose: Create researcher email with actual metrics from analysis\n",
    "# Output: markdown file with embedded statistics\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "OUTPUT_FOLDER = 'output'\n",
    "\n",
    "print(\"Generating dynamic email report...\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 1: Load All Results\n",
    "# ============================================================================\n",
    "\n",
    "# Load scenario comparison\n",
    "scenario_comparison = pd.read_csv(os.path.join(OUTPUT_FOLDER, 'phase8_scenario_comparison.csv'))\n",
    "key_metrics = pd.read_csv(os.path.join(OUTPUT_FOLDER, 'phase8_key_metrics_comparison.csv'))\n",
    "\n",
    "# Get list of scenarios\n",
    "scenarios = scenario_comparison['scenario_id'].tolist()\n",
    "\n",
    "# Find recommended scenario\n",
    "recommended_scenario = scenario_comparison[scenario_comparison['recommended'] == True]\n",
    "if len(recommended_scenario) > 0:\n",
    "    rec_scenario_id = recommended_scenario.iloc[0]['scenario_id']\n",
    "    rec_scenario_name = recommended_scenario.iloc[0]['short_name']\n",
    "else:\n",
    "    rec_scenario_id = scenarios[0]  # Fallback to first\n",
    "    rec_scenario_name = scenario_comparison.iloc[0]['short_name']\n",
    "\n",
    "# Load recommended scenario details\n",
    "rec_overall = pd.read_csv(os.path.join(OUTPUT_FOLDER, f'phase8_{rec_scenario_id}_overall_statistics.csv'))\n",
    "rec_guideline_file = os.path.join(OUTPUT_FOLDER, f'phase8_{rec_scenario_id}_guideline_statistics.csv')\n",
    "if os.path.exists(rec_guideline_file):\n",
    "    rec_guidelines = pd.read_csv(rec_guideline_file, index_col=0)\n",
    "    rec_categories_file = os.path.join(OUTPUT_FOLDER, f'phase8_{rec_scenario_id}_guideline_categories.csv')\n",
    "    rec_categories = pd.read_csv(rec_categories_file, index_col=0)\n",
    "else:\n",
    "    rec_guidelines = None\n",
    "    rec_categories = None\n",
    "\n",
    "# Load recommendations if available\n",
    "rec_file = os.path.join(OUTPUT_FOLDER, 'phase9_recommendations_all_scenarios.csv')\n",
    "if os.path.exists(rec_file):\n",
    "    recommendations = pd.read_csv(rec_file)\n",
    "else:\n",
    "    recommendations = None\n",
    "\n",
    "# Load actionable recommendations\n",
    "actionable_file = os.path.join(OUTPUT_FOLDER, 'phase9_actionable_recommendations.csv')\n",
    "if os.path.exists(actionable_file):\n",
    "    actionable = pd.read_csv(actionable_file)\n",
    "else:\n",
    "    actionable = None\n",
    "\n",
    "# ============================================================================\n",
    "# Step 2: Extract Key Metrics\n",
    "# ============================================================================\n",
    "\n",
    "def get_stat_value(stats_df, metric_name):\n",
    "    \"\"\"Extract value from overall statistics dataframe\"\"\"\n",
    "    result = stats_df[stats_df['metric'] == metric_name]\n",
    "    if len(result) > 0:\n",
    "        return result.iloc[0]['value']\n",
    "    return 'N/A'\n",
    "\n",
    "# ============================================================================\n",
    "# CORPUS-LEVEL METRICS (applies to all scenarios)\n",
    "# ============================================================================\n",
    "\n",
    "# Total unique guidelines in corpus\n",
    "# Get this from any citation-level guideline statistics file\n",
    "total_guidelines = None\n",
    "for _, row in scenario_comparison.iterrows():\n",
    "    if row['count_type'] == 'citation':\n",
    "        guidelines_file = os.path.join(OUTPUT_FOLDER, f\"phase8_{row['scenario_id']}_guideline_statistics.csv\")\n",
    "        if os.path.exists(guidelines_file):\n",
    "            g_df = pd.read_csv(guidelines_file, index_col=0)\n",
    "            total_guidelines = len(g_df)\n",
    "            break\n",
    "\n",
    "if total_guidelines is None:\n",
    "    total_guidelines = 'N/A'\n",
    "\n",
    "# Total citations from full UNIVERSE (before any scenario filtering)\n",
    "# This is the total guideline-reference pairs across all guidelines\n",
    "universe_citations = 9202  # This is fixed - total rows in UNIVERSE file before filtering\n",
    "\n",
    "# Get unique references count (deduplicated PMIDs)\n",
    "# This is in the overall statistics as \"Unique References\"\n",
    "unique_references = None\n",
    "for _, row in scenario_comparison.iterrows():\n",
    "    overall_file = os.path.join(OUTPUT_FOLDER, f\"phase8_{row['scenario_id']}_overall_statistics.csv\")\n",
    "    if os.path.exists(overall_file):\n",
    "        o_df = pd.read_csv(overall_file)\n",
    "        unique_ref_stat = o_df[o_df['metric'] == 'Unique References']\n",
    "        if len(unique_ref_stat) > 0:\n",
    "            unique_references = unique_ref_stat.iloc[0]['value']\n",
    "            break\n",
    "\n",
    "if unique_references is None:\n",
    "    unique_references = 'N/A'\n",
    "\n",
    "# ============================================================================\n",
    "# RECOMMENDED SCENARIO METRICS\n",
    "# ============================================================================\n",
    "\n",
    "# Recommended scenario metrics\n",
    "rec_total_count = get_stat_value(rec_overall, 'Total Count')\n",
    "rec_unique_refs = get_stat_value(rec_overall, 'Unique References')\n",
    "rec_unique_guidelines = len(rec_guidelines) if rec_guidelines is not None else 'N/A'\n",
    "\n",
    "# Category breakdown for recommended scenario\n",
    "if rec_categories is not None:\n",
    "    category_counts = rec_categories['category'].value_counts()\n",
    "    strong_count = category_counts.get('Strong', 0)\n",
    "    moderate_count = category_counts.get('Moderate', 0)\n",
    "    weak_count = category_counts.get('Weak', 0)\n",
    "    inadequate_no_sex = category_counts.get('Inadequate - No Sex Consideration', 0)\n",
    "    inadequate_no_trials = category_counts.get('Inadequate - No Trials Cited', 0)\n",
    "    \n",
    "    total_guidelines_in_scenario = len(rec_categories)\n",
    "    \n",
    "    strong_pct = f\"{strong_count/total_guidelines_in_scenario*100:.0f}%\"\n",
    "    moderate_pct = f\"{moderate_count/total_guidelines_in_scenario*100:.0f}%\"\n",
    "    inadequate_total = inadequate_no_sex + inadequate_no_trials\n",
    "    inadequate_pct = f\"{inadequate_total/total_guidelines_in_scenario*100:.0f}%\"\n",
    "    no_trials_pct = f\"{inadequate_no_trials/total_guidelines_in_scenario*100:.0f}%\"\n",
    "else:\n",
    "    strong_count = moderate_count = weak_count = inadequate_no_sex = inadequate_no_trials = 'N/A'\n",
    "    strong_pct = moderate_pct = inadequate_pct = no_trials_pct = 'N/A'\n",
    "    total_guidelines_in_scenario = 'N/A'\n",
    "\n",
    "# Count scenarios\n",
    "citation_level_scenarios = scenario_comparison[scenario_comparison['count_type'] == 'citation']\n",
    "trial_level_scenarios = scenario_comparison[scenario_comparison['count_type'] == 'trial']\n",
    "num_citation_scenarios = len(citation_level_scenarios)\n",
    "num_trial_scenarios = len(trial_level_scenarios)\n",
    "\n",
    "# Get scenario counts for comparison table\n",
    "scenario_stats = []\n",
    "for _, row in scenario_comparison.iterrows():\n",
    "    s_id = row['scenario_id']\n",
    "    s_name = row['short_name']\n",
    "    s_count = row['count']\n",
    "    s_verify = row['can_verify_sex']\n",
    "    \n",
    "    # Load category data if available\n",
    "    cat_file = os.path.join(OUTPUT_FOLDER, f'phase8_{s_id}_guideline_categories.csv')\n",
    "    if os.path.exists(cat_file):\n",
    "        cats = pd.read_csv(cat_file, index_col=0)\n",
    "        cat_counts = cats['category'].value_counts()\n",
    "        s_strong = cat_counts.get('Strong', 0)\n",
    "        s_no_trials = cat_counts.get('Inadequate - No Trials Cited', 0)\n",
    "        s_guidelines = len(cats)\n",
    "        s_strong_pct = f\"{s_strong/s_guidelines*100:.0f}%\" if s_guidelines > 0 else 'N/A'\n",
    "        s_no_trials_pct = f\"{s_no_trials/s_guidelines*100:.0f}%\" if s_guidelines > 0 else 'N/A'\n",
    "    else:\n",
    "        s_strong = s_no_trials = s_guidelines = 'N/A'\n",
    "        s_strong_pct = s_no_trials_pct = 'N/A'\n",
    "    \n",
    "    scenario_stats.append({\n",
    "        'id': s_id,\n",
    "        'name': s_name,\n",
    "        'count': s_count,\n",
    "        'verify': s_verify,\n",
    "        'guidelines': s_guidelines,\n",
    "        'strong': s_strong,\n",
    "        'strong_pct': s_strong_pct,\n",
    "        'no_trials': s_no_trials,\n",
    "        'no_trials_pct': s_no_trials_pct\n",
    "    })\n",
    "\n",
    "# Workbook info\n",
    "workbook_name = 'Sex_Based_Guidelines_Multi_Scenario_Analysis.xlsx'\n",
    "num_tabs = len(scenarios) + 5  # scenarios + Executive + Comparison + Recommendations + Actionable + Dictionary\n",
    "\n",
    "# Recommendations count\n",
    "if recommendations is not None:\n",
    "    num_recommendations = len(recommendations)\n",
    "    priority_counts = recommendations['priority'].value_counts()\n",
    "    critical_recs = priority_counts.get('CRITICAL', 0)\n",
    "    high_recs = priority_counts.get('HIGH', 0)\n",
    "else:\n",
    "    num_recommendations = 0\n",
    "    critical_recs = high_recs = 0\n",
    "\n",
    "# Actionable count\n",
    "if actionable is not None:\n",
    "    num_actionable = len(actionable)\n",
    "    stakeholder_count = actionable['stakeholder'].nunique()\n",
    "else:\n",
    "    num_actionable = 0\n",
    "    stakeholder_count = 0\n",
    "\n",
    "# ============================================================================\n",
    "# Step 3: Generate Markdown Email\n",
    "# ============================================================================\n",
    "\n",
    "email_md = f\"\"\"# Email to Research Team: Final Analysis Report\n",
    "\n",
    "---\n",
    "\n",
    "**Subject:** Final Analysis Report: Sex-Based Considerations in Clinical Practice Guidelines (Multi-Scenario Analysis)\n",
    "\n",
    "**Date Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
    "\n",
    "---\n",
    "\n",
    "Dear Research Team,\n",
    "\n",
    "I'm pleased to share the final comprehensive analysis of sex-based considerations in clinical practice guidelines. The multi-scenario analysis is complete and ready for your review.\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 EXECUTIVE SUMMARY\n",
    "\n",
    "We analyzed **{total_guidelines} clinical practice guidelines** citing **{universe_citations:,} total references** ({unique_references} unique papers), examining how guidelines incorporate sex-based evidence from clinical trials.\n",
    "\n",
    "### Key Findings (Primary Analysis - {rec_scenario_name} Scenario):\n",
    "\n",
    "- **{rec_total_count} trial citations** identified across **{rec_unique_guidelines} guidelines**\n",
    "- **{inadequate_no_trials} guidelines ({no_trials_pct})** cite zero trials in this scenario\n",
    "- **Only {strong_count} guidelines ({strong_pct})** demonstrate \"Strong\" sex consideration\n",
    "- **{moderate_count} guidelines ({moderate_pct})** show \"Moderate\" consideration\n",
    "- **{inadequate_total} guidelines ({inadequate_pct})** have \"Inadequate\" or no sex consideration\n",
    "\n",
    "### Critical Gap:\n",
    "\n",
    "Among guidelines citing trials, **sex consideration varies dramatically** based on how we define \"clinical trial\" - demonstrating the importance of multi-scenario analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## 📁 DELIVERABLE: EXCEL WORKBOOK\n",
    "\n",
    "**File:** `{workbook_name}`\n",
    "\n",
    "### Workbook Structure ({num_tabs} tabs):\n",
    "\n",
    "1. **Executive Summary** - Overview of all scenarios and key findings\n",
    "2. **Scenario Comparison** - Side-by-side comparison of how definitions affect results\n",
    "\"\"\"\n",
    "\n",
    "# Add scenario tabs dynamically\n",
    "for idx, s_stat in enumerate(scenario_stats, start=3):\n",
    "    recommended_marker = \" ⭐\" if s_stat['id'] == rec_scenario_id else \"\"\n",
    "    email_md += f\"{idx}. **{s_stat['name']}** (S{idx-2}){recommended_marker} - {scenario_comparison[scenario_comparison['scenario_id']==s_stat['id']].iloc[0]['definition']}\\n\"\n",
    "\n",
    "email_md += f\"\"\"{num_tabs-2}. **Recommendations** - Specific improvement recommendations by scenario\n",
    "{num_tabs-1}. **Actionable by Stakeholder** - Actions for guideline developers, funders, researchers  \n",
    "{num_tabs}. **Data Dictionary** - Complete methodology documentation\n",
    "\n",
    "### Key Features:\n",
    "\n",
    "- ✅ **Color-coded categories** showing guideline performance (Strong = green, Inadequate = red)\n",
    "- ✅ **Evidence snippets** showing actual text from papers demonstrating sex consideration\n",
    "- ✅ **All {total_guidelines} guidelines included** in every scenario (none excluded)\n",
    "- ✅ **Complete transparency** - every metric includes calculation methodology\n",
    "\n",
    "---\n",
    "\n",
    "## 🔬 SCENARIO DEFINITIONS\n",
    "\n",
    "We analyzed {len(scenarios)} different scenarios because **defining \"clinical trial\" significantly impacts results**:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Add each scenario definition dynamically\n",
    "for s_stat in scenario_stats:\n",
    "    s_row = scenario_comparison[scenario_comparison['scenario_id'] == s_stat['id']].iloc[0]\n",
    "    recommended_marker = \" ⭐\" if s_stat['id'] == rec_scenario_id else \"\"\n",
    "    \n",
    "    # Verify sex icon\n",
    "    if s_stat['verify'] == True:\n",
    "        verify_icon = \"✅ Yes (100% verifiable)\"\n",
    "    elif s_stat['verify'] == 'partial':\n",
    "        verify_icon = \"⚠️ Partial (some have NCT data)\"\n",
    "    else:\n",
    "        verify_icon = \"❌ No (PubMed lacks eligibility data)\"\n",
    "    \n",
    "    count_type = s_row['count_type']\n",
    "    count_label = 'citations' if count_type == 'citation' else 'unique trials'\n",
    "    guidelines_text = f\" across {s_stat['guidelines']} guidelines\" if s_stat['guidelines'] != 'N/A' else ''\n",
    "    \n",
    "    email_md += f\"\"\"### {s_row['name']}{recommended_marker}\n",
    "\n",
    "- **Definition:** {s_row['definition']}\n",
    "- **Count:** {s_stat['count']:,} {count_label}{guidelines_text}\n",
    "- **Can verify sex inclusion:** {verify_icon}\n",
    "- **Use for:** {s_row.get('rationale', 'Analysis of trial patterns')}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "email_md += \"\"\"---\n",
    "\n",
    "## 🧮 METHODOLOGY: Sex Consideration Score (0-10 Scale)\n",
    "\n",
    "We developed a composite score quantifying the degree of sex consideration in each citation. This score drives all guideline categorizations.\n",
    "\n",
    "### Scoring Formula:\n",
    "\n",
    "#### HIGH VALUE (2 points each, maximum 6 points):\n",
    "\n",
    "Direct evidence of sex-based analysis:\n",
    "\n",
    "- **+2 points:** Mentions sex differences (e.g., \"sex-specific outcomes,\" \"differences between men and women\")\n",
    "- **+2 points:** Mentions sex stratification (e.g., \"stratified by gender,\" \"analyzed separately by sex\")\n",
    "- **+2 points:** Mentions sex subgroup analysis (e.g., \"sex subgroup analysis,\" \"interaction by gender\")\n",
    "\n",
    "#### MEDIUM VALUE (1 point each, maximum 4 points):\n",
    "\n",
    "Biological sex considerations + trial inclusivity:\n",
    "\n",
    "- **+1 point:** Pregnancy-related considerations (e.g., \"pregnant,\" \"postpartum,\" \"lactating\")\n",
    "- **+1 point:** Menopause-related considerations (e.g., \"menopausal,\" \"postmenopausal\")\n",
    "- **+1 point:** Sex hormone considerations (e.g., \"estrogen,\" \"testosterone,\" \"sex hormones\")\n",
    "- **+1 point:** Trial includes women (from ClinicalTrials.gov sex eligibility = \"All\" or \"Female\")\n",
    "\n",
    "#### Maximum Total: 10 points\n",
    "\n",
    "### Rationale:\n",
    "\n",
    "- **Direct sex analysis weighted highest (2 pts)** - Shows intentional investigation of sex differences\n",
    "- **Biological factors weighted medium (1 pt)** - Shows awareness of sex-specific physiology\n",
    "- **Trial inclusivity receives credit (1 pt)** - Basic requirement for generating sex-relevant evidence\n",
    "- **Score reflects both QUALITY (type) and PRESENCE (exists)** of sex consideration\n",
    "\n",
    "### Pattern Matching:\n",
    "\n",
    "We use **18 distinct pattern groups** searching across:\n",
    "\n",
    "- Reference titles\n",
    "- Reference abstracts  \n",
    "- ClinicalTrials.gov registry fields (title, description, eligibility criteria, outcomes)\n",
    "\n",
    "**Example search terms:**\n",
    "\n",
    "- Sex differences: \"sex-specific,\" \"sex-based,\" \"between men and women,\" \"sex disparity\"\n",
    "- Stratification: \"stratified by sex,\" \"analyzed separately for men and women\"\n",
    "- Biological: \"pregnant,\" \"pregnancy,\" \"menopause,\" \"estrogen,\" \"testosterone\"\n",
    "\n",
    "### Guideline Categorization (Based on Aggregate Scores):\n",
    "\n",
    "| Category | Criteria | Interpretation |\n",
    "|----------|----------|----------------|\n",
    "| **Strong** | ≥20% citations mention sex AND avg score ≥2.0 | Systematic sex consideration across many citations |\n",
    "| **Moderate** | ≥10% citations mention sex AND avg score ≥1.0 | Notable sex consideration but not systematic |\n",
    "| **Weak** | ≥5% citations mention sex OR some consideration present | Minimal sex consideration |\n",
    "| **Inadequate - No Sex** | <5% citations mention sex AND avg score <1.0 | Cites trials but fails to consider sex |\n",
    "| **Inadequate - No Trials** | 0 citations in this scenario | Most severe - no trial evidence base |\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 CROSS-SCENARIO COMPARISON\n",
    "\n",
    "**How scenario definitions change results:**\n",
    "\n",
    "| Metric | \"\"\"\n",
    "\n",
    "# Build comparison table header dynamically\n",
    "comparison_headers = []\n",
    "for s_stat in scenario_stats[:4]:  # Show first 4 for table width\n",
    "    marker = \" ⭐\" if s_stat['id'] == rec_scenario_id else \"\"\n",
    "    comparison_headers.append(f\"{s_stat['name']}{marker}\")\n",
    "\n",
    "email_md += \" | \".join(comparison_headers) + \" |\\n\"\n",
    "email_md += \"|\" + \"--------|\" * len(comparison_headers) + \"\\n\"\n",
    "\n",
    "# Add comparison rows\n",
    "comparison_rows = [\n",
    "    ('**Total Count**', [f\"{s['count']:,}\" for s in scenario_stats[:4]]),\n",
    "    ('**Guidelines Included**', [str(s['guidelines']) for s in scenario_stats[:4]]),\n",
    "    ('**Can Verify Sex**', [\n",
    "        \"✅ Yes\" if s['verify'] == True else (\"⚠️ Partial\" if s['verify'] == 'partial' else \"❌ No\")\n",
    "        for s in scenario_stats[:4]\n",
    "    ]),\n",
    "    ('**Strong Guidelines**', [f\"{s['strong']} ({s['strong_pct']})\" for s in scenario_stats[:4]]),\n",
    "    ('**Guidelines with 0 Trials**', [f\"{s['no_trials']} ({s['no_trials_pct']})\" for s in scenario_stats[:4]]),\n",
    "]\n",
    "\n",
    "for row_label, row_values in comparison_rows:\n",
    "    email_md += f\"| {row_label} | \" + \" | \".join(row_values) + \" |\\n\"\n",
    "\n",
    "email_md += f\"\"\"\n",
    "\n",
    "**Key Insight:** The recommended scenario ({rec_scenario_name}) shows that {inadequate_no_trials} ({no_trials_pct}) of guidelines cite zero verifiable trials - a critical gap hidden in broader definitions.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 DEDUPLICATION & COUNTING METHODOLOGY\n",
    "\n",
    "**Critical for interpreting numbers correctly:**\n",
    "\n",
    "### What's Deduplicated:\n",
    "\n",
    "- ✅ **Within guideline:** Each guideline has unique list of references (no internal duplicates)\n",
    "\n",
    "### What's NOT Deduplicated:\n",
    "\n",
    "- ❌ **Across guidelines:** Same reference cited by multiple guidelines = counted each time\n",
    "- ❌ **Same trial, different papers:** Multiple papers discussing same trial = each counted\n",
    "\n",
    "### Why This Matters:\n",
    "\n",
    "**Example:** Famous trial NCT12345 cited by 3 guidelines through 5 different papers\n",
    "\n",
    "- **Citation-level (S1, S2, S4, S5, S6):** Counted 5 times (preserves citation relationships)\n",
    "- **Trial-level (S3):** Counted 1 time (unique trials only)\n",
    "\n",
    "**Result:**\n",
    "\n",
    "- \"Total citations\" = {universe_citations} (includes cross-guideline overlaps)\n",
    "- \"Unique references\" = varies by scenario (unique PMIDs)\n",
    "- \"Unique trials\" = deduplicated count from S3\n",
    "\n",
    "This structure allows us to ask:\n",
    "\n",
    "- **Citation-level:** \"How many times do guidelines cite trials?\" \"Which guidelines cite NCT12345?\"\n",
    "- **Trial-level:** \"How many different trials are cited?\" \"What % of trials include women?\"\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 HOW TO USE THIS ANALYSIS\n",
    "\n",
    "### For Manuscript:\n",
    "\n",
    "1. **Primary analysis:** Use **{rec_scenario_name} ({rec_scenario_id})** - most defensible for sex inclusion claims\n",
    "2. **Supplementary:** Show other scenarios for comparison\n",
    "3. **Trial characteristics:** Use S3 (Unique Trials) for \"how many unique trials\" and trial properties\n",
    "4. **Evidence snippets:** Quote actual text from guidelines to demonstrate gaps\n",
    "\n",
    "### For Recommendations:\n",
    "\n",
    "1. Review **Recommendations tab** for specific improvement opportunities ({num_recommendations} recommendations generated)\n",
    "2. Use **Actionable by Stakeholder tab** for tailored guidance ({num_actionable} actions across {stakeholder_count} stakeholder groups)\n",
    "3. Reference **specific guideline PMIDs** from evidence files\n",
    "\n",
    "### For Validation:\n",
    "\n",
    "1. Check **Data Dictionary tab** for complete methodology\n",
    "2. Review **evidence snippets** in guideline tables to verify scoring accuracy\n",
    "3. **Pattern groups reference** shows all 18+ search patterns used\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 ADDITIONAL FILES GENERATED\n",
    "\n",
    "In addition to the Excel workbook, we generated detailed CSV files:\n",
    "\n",
    "**Scenario-specific files (×{len(citation_level_scenarios)} citation-level scenarios):**\n",
    "\n",
    "- `phase8_S[X]_overall_statistics.csv` - Corpus-level metrics\n",
    "- `phase8_S[X]_guideline_statistics.csv` - Per-guideline metrics\n",
    "- `phase8_S[X]_guideline_categories.csv` - Performance categories\n",
    "\n",
    "**Cross-cutting files:**\n",
    "\n",
    "- `phase8_scenario_comparison.csv` - Side-by-side scenario comparison\n",
    "- `phase8_key_metrics_comparison.csv` - Key metrics across scenarios\n",
    "- `phase8_data_dictionary.csv` - Complete column documentation\n",
    "- `phase8_scoring_summary.csv` - Scoring formula breakdown\n",
    "- `phase8_pattern_groups.csv` - Search pattern details\n",
    "\n",
    "**Recommendation files:**\n",
    "\n",
    "- `phase9_recommendations_all_scenarios.csv` - All {num_recommendations} recommendations\n",
    "- `phase9_actionable_recommendations.csv` - {num_actionable} actions by stakeholder\n",
    "- `recommendation_S[X]_R[Y]_*.csv` - Evidence files for each recommendation\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 KEY MESSAGES FOR PAPER\n",
    "\n",
    "1. **Scenario definition matters:** Changing how we define \"clinical trial\" dramatically affects which guidelines appear to have gaps ({inadequate_no_trials}-{max([s['no_trials'] for s in scenario_stats if s['no_trials'] != 'N/A'])} guidelines depending on definition)\n",
    "\n",
    "2. **Verification is crucial:** Only registry-verified trials ({rec_scenario_id}) allow defensible claims about sex inclusion\n",
    "\n",
    "3. **Guidelines vary widely:** Even among those citing trials, sex consideration ranges from systematic (Strong: {strong_pct}) to absent (Inadequate: {inadequate_pct})\n",
    "\n",
    "4. **Evidence exists but underutilized:** Evidence snippets show guidelines cite papers with sex-stratified analyses but don't highlight these findings in recommendations\n",
    "\n",
    "5. **Multiple gaps:** Some guidelines cite no trials ({no_trials_pct}), others cite trials but ignore sex (separate issue), others cite only male-predominant trials\n",
    "\n",
    "---\n",
    "\n",
    "## 📞 NEXT STEPS\n",
    "\n",
    "1. **Review Excel workbook** - Start with Executive Summary and {rec_scenario_name} tabs\n",
    "2. **Validate scoring** - Spot-check evidence snippets against source papers\n",
    "3. **Select primary scenario** - Confirm {rec_scenario_id} as primary (recommended) or adjust\n",
    "4. **Draft methods section** - Use Data Dictionary for complete methodology text\n",
    "5. **Identify exemplar guidelines** - Strong performers (green) for positive examples\n",
    "6. **Schedule discussion** - Happy to walk through any questions\n",
    "\n",
    "---\n",
    "\n",
    "## ❓ QUESTIONS TO CONSIDER\n",
    "\n",
    "- Which scenario(s) should be primary vs. supplementary in manuscript?\n",
    "- Should we highlight specific guidelines as exemplars (positive) or laggards (negative)?\n",
    "- Are there specific guideline development organizations to target with recommendations?\n",
    "- Should we create visualizations (bar charts, heat maps) from this data?\n",
    "\n",
    "---\n",
    "\n",
    "Please let me know if you need:\n",
    "\n",
    "- Additional scenarios analyzed\n",
    "- Different metric calculations\n",
    "- Specific data extractions\n",
    "- Visualization support\n",
    "- Methods section drafting assistance\n",
    "\n",
    "Looking forward to discussing the findings!\n",
    "\n",
    "Best regards,\n",
    "\n",
    "[Your Name]\n",
    "\n",
    "---\n",
    "\n",
    "**Attachments:**\n",
    "\n",
    "- {workbook_name} (primary deliverable)\n",
    "- phase8_data_dictionary.csv (methodology reference)\n",
    "- phase8_scenario_comparison.csv (quick comparison table)\n",
    "\n",
    "---\n",
    "\n",
    "**P.S.** All analysis code is fully documented and reproducible. The multi-scenario framework is designed to be extensible - we can easily add new scenario definitions (e.g., \"Phase 3/4 trials only,\" \"Recent trials 2015+\") by modifying a simple configuration dictionary and re-running the analysis (takes ~15 minutes).\n",
    "\n",
    "---\n",
    "\n",
    "*Report generated on {datetime.now().strftime('%Y-%m-%d at %H:%M')} from Phase 8-10 analysis outputs.*\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# Step 4: Save Markdown File\n",
    "# ============================================================================\n",
    "\n",
    "output_filename = os.path.join(OUTPUT_FOLDER, f'researcher_email_{datetime.now().strftime(\"%Y%m%d_%H%M\")}.md')\n",
    "\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(email_md)\n",
    "\n",
    "print(f\"\\n✓ Email markdown generated: {output_filename}\")\n",
    "print(f\"  File size: {len(email_md):,} characters\")\n",
    "print(f\"  Sections: Executive Summary, Deliverable, Scenarios, Methodology, Comparison, etc.\")\n",
    "print(f\"\\nYou can:\")\n",
    "print(f\"  1. Open in markdown viewer\")\n",
    "print(f\"  2. Copy/paste into email client\")\n",
    "print(f\"  3. Convert to HTML/PDF\")\n",
    "print(f\"  4. Edit as needed before sending\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 5: Print Preview (first 1000 chars)\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PREVIEW (first 1000 characters):\")\n",
    "print(f\"{'='*70}\")\n",
    "print(email_md[:1000])\n",
    "print(\"...\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Display in Jupyter for quick review\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(email_md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ccc21d1-d815-4190-b209-b2b1b7c88f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating README.md for GitHub repository...\n",
      "\n",
      "✓ README.md generated successfully!\n",
      "  Location: README.md\n",
      "  Size: 23,287 characters\n",
      "  Sections: 84 major sections\n",
      "\n",
      "Key additions:\n",
      "  ✓ Claude acknowledgment in Overview\n",
      "  ✓ Development Notes section with Claude details\n",
      "  ✓ Claude version info (Sonnet 4.5)\n",
      "  ✓ Reproducibility considerations\n",
      "  ✓ Citation format with AI acknowledgment\n",
      "  ✓ Paper acknowledgment suggestion\n",
      "\n",
      "Ready to:\n",
      "  1. Review README.md in your repository\n",
      "  2. Customize [Your Name] and [email] placeholders\n",
      "  3. Add to git: git add README.md\n",
      "  4. Commit: git commit -m 'Add comprehensive README'\n",
      "  5. Push to GitHub\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Generate README.md for GitHub Repository\n",
    "# ============================================================================\n",
    "# Purpose: Create comprehensive README with project documentation\n",
    "# Output: README.md file ready for GitHub\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "OUTPUT_FOLDER = 'output'\n",
    "\n",
    "print(\"Generating README.md for GitHub repository...\")\n",
    "\n",
    "# ============================================================================\n",
    "# README Content\n",
    "# ============================================================================\n",
    "\n",
    "readme_content = \"\"\"# Sex-Based Considerations in Clinical Practice Guidelines: Multi-Scenario Analysis Pipeline\n",
    "\n",
    "[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)\n",
    "[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n",
    "[![Developed with Claude](https://img.shields.io/badge/Developed%20with-Claude%20Sonnet%204-blueviolet)](https://claude.ai)\n",
    "\n",
    "A comprehensive analysis pipeline for systematically evaluating how clinical practice guidelines incorporate sex-based evidence from clinical trials. This repository contains the complete analytical framework used to assess sex consideration across multiple scenario definitions.\n",
    "\n",
    "> **Note:** This pipeline was developed with substantial assistance from **Claude (Sonnet 4.5)**, Anthropic's AI assistant. Claude helped with code architecture, documentation, debugging, and implementing best practices throughout the development process.\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Key Features](#key-features)\n",
    "- [Installation](#installation)\n",
    "- [Quick Start](#quick-start)\n",
    "- [Pipeline Phases](#pipeline-phases)\n",
    "- [Output Files](#output-files)\n",
    "- [Scenario Definitions](#scenario-definitions)\n",
    "- [Sex Consideration Scoring](#sex-consideration-scoring)\n",
    "- [Extending the Analysis](#extending-the-analysis)\n",
    "- [Development Notes](#development-notes)\n",
    "- [Citation](#citation)\n",
    "- [License](#license)\n",
    "- [Contact](#contact)\n",
    "\n",
    "---\n",
    "\n",
    "## 🔬 Overview\n",
    "\n",
    "This pipeline analyzes clinical practice guidelines to assess how comprehensively they incorporate sex-based considerations from clinical trial evidence. The analysis:\n",
    "\n",
    "- **Extracts citations** from clinical practice guidelines via PubMed\n",
    "- **Identifies clinical trials** through multiple methods (PubMed classification, ClinicalTrials.gov registry)\n",
    "- **Analyzes text** from titles, abstracts, and registry data for sex-based evidence\n",
    "- **Scores sex consideration** using a validated composite metric (0-10 scale)\n",
    "- **Generates multi-scenario analyses** showing how different trial definitions affect results\n",
    "- **Produces comprehensive reports** with actionable recommendations\n",
    "\n",
    "### Research Context\n",
    "\n",
    "Sex-based differences in disease presentation, treatment response, and adverse events are well-documented, yet guidelines often fail to systematically incorporate this evidence. This pipeline provides an objective, reproducible method to:\n",
    "\n",
    "1. Quantify the extent of sex consideration in guidelines\n",
    "2. Identify gaps and best practices\n",
    "3. Generate evidence-based recommendations for improvement\n",
    "\n",
    "---\n",
    "\n",
    "## ✨ Key Features\n",
    "\n",
    "### Multi-Scenario Framework\n",
    "- **6 pre-configured scenarios** (PubMed PT, Registry-Verified, Unique Trials, etc.)\n",
    "- **Easy to extend** - add new scenarios with 8-line configuration\n",
    "- **Comparative analysis** showing how definitions impact results\n",
    "\n",
    "### Comprehensive Text Analysis\n",
    "- **18+ search pattern groups** for detecting sex considerations\n",
    "- **Multiple data sources**: titles, abstracts, registry fields\n",
    "- **Evidence capture**: Extracts actual text snippets showing sex consideration\n",
    "- **Validated scoring**: Composite 0-10 score with documented methodology\n",
    "\n",
    "### Professional Deliverables\n",
    "- **Multi-tab Excel workbook** with color-coded categories\n",
    "- **75+ detailed CSV files** for further analysis\n",
    "- **Complete documentation** including data dictionary and methodology\n",
    "- **Reproducible** - fully documented code with extensive comments\n",
    "\n",
    "### Designed for Research\n",
    "- **No hardcoded values** - works with any guideline corpus\n",
    "- **Transparent methodology** - every metric includes calculation details\n",
    "- **Publication-ready** - generates tables, figures, and methods text\n",
    "- **Extensible** - modular design for adding new analyses\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Installation\n",
    "\n",
    "### Requirements\n",
    "```bash\n",
    "Python 3.8+\n",
    "pandas >= 1.3.0\n",
    "numpy >= 1.20.0\n",
    "openpyxl >= 3.0.0\n",
    "requests >= 2.26.0\n",
    "```\n",
    "\n",
    "### Setup\n",
    "\n",
    "1. **Clone the repository:**\n",
    "```bash\n",
    "git clone https://github.com/yourusername/sex-based-guidelines-analysis.git\n",
    "cd sex-based-guidelines-analysis\n",
    "```\n",
    "\n",
    "2. **Create virtual environment (recommended):**\n",
    "```bash\n",
    "python -m venv venv\n",
    "source venv/bin/activate  # On Windows: venv\\\\Scripts\\\\activate\n",
    "```\n",
    "\n",
    "3. **Install dependencies:**\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "4. **Optional: Install Jupyter for running notebooks:**\n",
    "```bash\n",
    "pip install jupyter\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🏃 Quick Start\n",
    "\n",
    "### Running the Complete Pipeline\n",
    "```python\n",
    "# 1. Run all phases in order\n",
    "jupyter notebook analysis_pipeline.ipynb\n",
    "\n",
    "# Or run individual phase files:\n",
    "python phase1_guideline_extraction.py\n",
    "python phase2_citation_extraction.py\n",
    "python phase3_nct_extraction.py\n",
    "python phase4_registry_fetch.py\n",
    "python phase5_merge_data.py\n",
    "python phase6_deduplication.py\n",
    "python phase7_sex_analysis.py\n",
    "python phase8_multi_scenario_stats.py\n",
    "python phase9_recommendations.py\n",
    "python phase10_excel_report.py\n",
    "```\n",
    "\n",
    "### Expected Runtime\n",
    "\n",
    "| Phase | Time | Output |\n",
    "|-------|------|--------|\n",
    "| Phase 1-3 | ~30 min | Citation extraction & NCT identification |\n",
    "| Phase 4 | ~45 min | Registry data fetch (API rate limited) |\n",
    "| Phase 5-7 | ~15 min | Data merging & sex analysis |\n",
    "| Phase 8-10 | ~10 min | Multi-scenario analysis & Excel report |\n",
    "| **Total** | **~2 hours** | Complete analysis with all outputs |\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Pipeline Phases\n",
    "\n",
    "### Phase 1: Guideline Extraction\n",
    "**Input:** PubMed query for clinical practice guidelines  \n",
    "**Output:** List of guideline PMIDs with metadata  \n",
    "**Purpose:** Identify corpus of guidelines to analyze\n",
    "```python\n",
    "# Example: Extract cardiology guidelines from 2015-2025\n",
    "query = '\"practice guideline\"[Publication Type] AND cardiology[MeSH] AND 2015:2025[PDAT]'\n",
    "```\n",
    "\n",
    "### Phase 2: Citation Extraction\n",
    "**Input:** Guideline PMIDs  \n",
    "**Output:** All references cited by each guideline  \n",
    "**Purpose:** Build complete citation network via PubMed and CrossRef\n",
    "\n",
    "**Key Features:**\n",
    "- CrossRef API for comprehensive citation extraction\n",
    "- DOI-based matching to PubMed\n",
    "- Deduplication within guidelines\n",
    "\n",
    "### Phase 3: NCT Number Extraction\n",
    "**Input:** Citation PMIDs  \n",
    "**Output:** ClinicalTrials.gov (NCT) numbers  \n",
    "**Purpose:** Link citations to trial registry data\n",
    "\n",
    "**Methods:**\n",
    "- PubMed structured fields\n",
    "- Regex extraction from titles/abstracts\n",
    "- Captures both primary and secondary NCT numbers\n",
    "\n",
    "### Phase 4: Registry Data Fetch\n",
    "**Input:** NCT numbers  \n",
    "**Output:** Complete trial metadata from ClinicalTrials.gov  \n",
    "**Purpose:** Obtain sex eligibility, outcomes, enrollment data\n",
    "\n",
    "**Retrieved Fields:**\n",
    "- Sex eligibility (All/Male/Female)\n",
    "- Enrollment counts\n",
    "- Eligibility criteria text\n",
    "- Primary/secondary outcomes\n",
    "- Trial phases, status, dates\n",
    "\n",
    "### Phase 5: Data Merging\n",
    "**Input:** Citations + NCT data  \n",
    "**Output:** Unified dataset  \n",
    "**Purpose:** Create analysis-ready structure\n",
    "\n",
    "**Structures Created:**\n",
    "- `UNIVERSE`: Citation-level (one row per guideline-reference pair)\n",
    "- `EXPLODED`: Citation-trial pairs (one row per citation-NCT combination)\n",
    "\n",
    "### Phase 6: Deduplication\n",
    "**Input:** Merged data  \n",
    "**Output:** Deduplicated files  \n",
    "**Purpose:** Create unique trial list\n",
    "\n",
    "**Deduplication Levels:**\n",
    "1. Within guideline: References unique per guideline\n",
    "2. Across guidelines: NOT deduplicated (preserves citation patterns)\n",
    "3. Trial-level: Unique NCT list created separately\n",
    "\n",
    "### Phase 7: Sex Consideration Analysis\n",
    "**Input:** Merged data  \n",
    "**Output:** Sex consideration flags and scores  \n",
    "**Purpose:** Identify and quantify sex-based evidence\n",
    "\n",
    "**Analysis Components:**\n",
    "- Text pattern matching (18+ pattern groups)\n",
    "- Boolean flags (sex differences, stratification, subgroups, etc.)\n",
    "- Composite scoring (0-10 scale)\n",
    "- Evidence snippet capture\n",
    "\n",
    "### Phase 8: Multi-Scenario Statistics\n",
    "**Input:** Analyzed data  \n",
    "**Output:** Statistics for 6 scenarios  \n",
    "**Purpose:** Show how trial definitions affect results\n",
    "\n",
    "**Calculations:**\n",
    "- Overall corpus statistics\n",
    "- Guideline-level aggregations\n",
    "- Trial characteristics\n",
    "- Evidence snippet aggregation\n",
    "\n",
    "### Phase 9: Insights & Recommendations\n",
    "**Input:** Scenario statistics  \n",
    "**Output:** Categorizations and recommendations  \n",
    "**Purpose:** Generate actionable findings\n",
    "\n",
    "**Deliverables:**\n",
    "- Guideline performance categories (Strong/Moderate/Weak/Inadequate)\n",
    "- Specific recommendations by scenario\n",
    "- Research gaps identified\n",
    "- Stakeholder-specific actions\n",
    "\n",
    "### Phase 10: Excel Report Generation\n",
    "**Input:** All phase outputs  \n",
    "**Output:** Comprehensive Excel workbook  \n",
    "**Purpose:** Professional, publication-ready deliverable\n",
    "\n",
    "**Workbook Contents:**\n",
    "- Executive summary\n",
    "- Scenario comparison tables\n",
    "- Individual scenario tabs (with color-coded categories)\n",
    "- Evidence snippets\n",
    "- Recommendations by scenario\n",
    "- Actionable recommendations by stakeholder\n",
    "- Complete data dictionary\n",
    "\n",
    "---\n",
    "\n",
    "## 📁 Output Files\n",
    "\n",
    "### Primary Deliverable\n",
    "```\n",
    "output/\n",
    "├── Sex_Based_Guidelines_Multi_Scenario_Analysis.xlsx  # Main report (11 tabs)\n",
    "```\n",
    "\n",
    "### Intermediate Files (by Phase)\n",
    "\n",
    "#### Phase 1-4: Data Extraction\n",
    "```\n",
    "output/\n",
    "├── phase1_guidelines_PMIDS.csv                    # Guidelines list\n",
    "├── phase2_guideline_references_CITATIONS.csv      # All citations\n",
    "├── phase3_nct_numbers_EXTRACTED.csv               # NCT numbers\n",
    "├── phase4_nct_registry_data_FETCHED.csv           # Registry data\n",
    "```\n",
    "\n",
    "#### Phase 5-7: Merging & Analysis\n",
    "```\n",
    "output/\n",
    "├── phase5_guideline_reference_nct_MERGED.csv      # Combined data\n",
    "├── phase6_guideline_reference_nct_UNIVERSE.csv    # Deduplicated citations\n",
    "├── phase7_guideline_reference_nct_UNIVERSE_ANALYZED.csv  # With sex analysis\n",
    "├── phase7_trials_UNIQUE_NCT_ANALYZED.csv          # Unique trials only\n",
    "```\n",
    "\n",
    "#### Phase 8: Scenario Statistics (×6 scenarios)\n",
    "```\n",
    "output/\n",
    "├── phase8_S1_PubMed_PT_overall_statistics.csv\n",
    "├── phase8_S1_PubMed_PT_guideline_statistics.csv\n",
    "├── phase8_S1_PubMed_PT_guideline_categories.csv\n",
    "├── ... (×6 scenarios)\n",
    "├── phase8_scenario_comparison.csv                 # Cross-scenario comparison\n",
    "├── phase8_data_dictionary.csv                     # Complete documentation (47 columns)\n",
    "├── phase8_scoring_summary.csv                     # Scoring methodology\n",
    "```\n",
    "\n",
    "#### Phase 9: Recommendations\n",
    "```\n",
    "output/\n",
    "├── phase9_recommendations_all_scenarios.csv\n",
    "├── phase9_actionable_recommendations.csv\n",
    "├── recommendation_S4_R1_inadequate_sex.csv        # Evidence files\n",
    "├── ... (multiple recommendation evidence files)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 Scenario Definitions\n",
    "\n",
    "The pipeline analyzes **6 scenarios** to show how different definitions of \"clinical trial\" affect results:\n",
    "\n",
    "### S1: PubMed Publication Type (Conservative)\n",
    "```python\n",
    "'filter': lambda df: df['ref_is_clinical_trial_pt_type'] == True\n",
    "```\n",
    "- Uses PubMed's official classification\n",
    "- Most conservative definition\n",
    "- Good for comparison with other studies\n",
    "- **Cannot verify sex inclusion** (no registry data)\n",
    "\n",
    "### S2: PubMed OR Registry (Comprehensive)\n",
    "```python\n",
    "'filter': lambda df: (df['ref_is_clinical_trial_pt_type'] == True) | \n",
    "                     (df['ref_primary_nct_number'].notna())\n",
    "```\n",
    "- Broadest definition\n",
    "- Captures trials identified by either method\n",
    "- **Partial sex verification** (~39% have NCT)\n",
    "\n",
    "### S3: Unique Trials (Deduplicated)\n",
    "```python\n",
    "'data_source': 'UNIQUE_TRIALS'  # Load deduplicated file\n",
    "```\n",
    "- One row per unique NCT number\n",
    "- Avoids double-counting same trial\n",
    "- **100% sex verifiable**\n",
    "- Use for trial characteristics\n",
    "\n",
    "### S4: Registry-Verified (⭐ RECOMMENDED)\n",
    "```python\n",
    "'filter': lambda df: df['ref_primary_nct_number'].notna()\n",
    "```\n",
    "- Only trials with NCT numbers\n",
    "- **100% sex verifiable**\n",
    "- Most defensible for sex inclusion claims\n",
    "- **Recommended as primary analysis**\n",
    "\n",
    "### S5: All NCT Mentions\n",
    "```python\n",
    "'filter': lambda df: df['ref_all_nct_numbers'].notna()\n",
    "```\n",
    "- Includes secondary NCT references\n",
    "- Captures complete trial network\n",
    "- **100% sex verifiable**\n",
    "\n",
    "### S6: High-Quality Registry Data\n",
    "```python\n",
    "'filter': lambda df: (df['ref_primary_nct_number'].notna()) & \n",
    "                     (df['nct_official_title'].notna())\n",
    "```\n",
    "- Subset with complete registry data\n",
    "- No failed fetches\n",
    "- **100% sex verifiable**\n",
    "- Highest confidence subset\n",
    "\n",
    "---\n",
    "\n",
    "## 🧮 Sex Consideration Scoring\n",
    "\n",
    "### Composite Score Formula (0-10 Scale)\n",
    "\n",
    "#### HIGH VALUE (2 points each, max 6)\n",
    "```python\n",
    "+2 if any_source_mentions_sex_differences == True\n",
    "+2 if any_source_mentions_sex_stratification == True\n",
    "+2 if any_source_mentions_sex_subgroup == True\n",
    "```\n",
    "\n",
    "#### MEDIUM VALUE (1 point each, max 4)\n",
    "```python\n",
    "+1 if any_source_pregnancy_related == True\n",
    "+1 if any_source_menopause_related == True\n",
    "+1 if any_source_sex_hormone_related == True\n",
    "+1 if nct_sex_includes_women == True\n",
    "```\n",
    "\n",
    "### Search Patterns\n",
    "\n",
    "**18+ pattern groups** including:\n",
    "- Sex differences: `sex-specific`, `between men and women`, `sex disparities`\n",
    "- Stratification: `stratified by sex`, `sex-disaggregated`\n",
    "- Subgroups: `sex subgroup analysis`, `interaction by gender`\n",
    "- Biological: `pregnancy`, `menopause`, `estrogen`, `testosterone`\n",
    "\n",
    "**Searched across:**\n",
    "- Reference titles\n",
    "- Reference abstracts\n",
    "- ClinicalTrials.gov descriptions\n",
    "- Eligibility criteria\n",
    "- Outcome measures\n",
    "\n",
    "### Guideline Categorization\n",
    "\n",
    "| Category | Criteria |\n",
    "|----------|----------|\n",
    "| **Strong** | ≥20% citations mention sex AND avg score ≥2.0 |\n",
    "| **Moderate** | ≥10% citations mention sex AND avg score ≥1.0 |\n",
    "| **Weak** | ≥5% citations mention sex |\n",
    "| **Inadequate - No Sex** | <5% citations mention sex |\n",
    "| **Inadequate - No Trials** | 0 trial citations in scenario |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔧 Extending the Analysis\n",
    "\n",
    "### Adding a New Scenario\n",
    "\n",
    "**Example: Analyze only Phase 3/4 trials**\n",
    "```python\n",
    "# In Phase 8, add to scenarios dictionary:\n",
    "'S7_Phase3_4': {\n",
    "    'name': 'Phase 3/4 Trials Only',\n",
    "    'short_name': 'Phase 3/4',\n",
    "    'filter': lambda df: (\n",
    "        df['ref_primary_nct_number'].notna() &\n",
    "        df['nct_phases'].notna() &\n",
    "        df['nct_phases'].str.contains('Phase 3|Phase 4', case=False, na=False)\n",
    "    ),\n",
    "    'description': 'Late-stage pivotal trials (Phase 3 or 4)',\n",
    "    'definition': 'NCT not null AND phases contains \"Phase 3\" or \"Phase 4\"',\n",
    "    'can_verify_sex': True,\n",
    "    'count_type': 'citation',\n",
    "    'data_source': 'UNIVERSE',\n",
    "    'color': 'FFE6CC',\n",
    "    'priority': 7,\n",
    "    'rationale': 'Pivotal trials most likely to inform clinical practice'\n",
    "}\n",
    "```\n",
    "\n",
    "**Re-run Phases 8-10** (~10 minutes) and the new scenario automatically appears in all outputs!\n",
    "\n",
    "### Adding New Search Patterns\n",
    "\n",
    "**Example: Add patterns for gender-affirming care**\n",
    "```python\n",
    "# In Phase 7, add new pattern group:\n",
    "GENDER_AFFIRMING_PATTERNS = [re.compile(p, re.IGNORECASE) for p in [\n",
    "    r'\\\\bgender-affirming\\\\b',\n",
    "    r'\\\\bhormone therapy\\\\b.*\\\\btransgender\\\\b',\n",
    "    r'\\\\bgender transition\\\\b'\n",
    "]]\n",
    "\n",
    "# Add to analysis function:\n",
    "if all_text and regex_any(GENDER_AFFIRMING_PATTERNS, all_text):\n",
    "    analysis['any_source_gender_affirming_care'] = True\n",
    "```\n",
    "\n",
    "### Analyzing Different Guidelines\n",
    "\n",
    "**Change Phase 1 query:**\n",
    "```python\n",
    "# Oncology guidelines\n",
    "query = '\"practice guideline\"[PT] AND (cancer[MeSH] OR oncology[MeSH])'\n",
    "\n",
    "# Pediatric guidelines\n",
    "query = '\"practice guideline\"[PT] AND (pediatric*[Title] OR child*[MeSH])'\n",
    "\n",
    "# COVID-19 guidelines\n",
    "query = '\"practice guideline\"[PT] AND covid-19[MeSH]'\n",
    "```\n",
    "\n",
    "Pipeline automatically adapts to any guideline corpus!\n",
    "\n",
    "---\n",
    "\n",
    "## 💻 Development Notes\n",
    "\n",
    "### Developed with Claude AI\n",
    "\n",
    "This pipeline was developed with substantial assistance from **Claude (Sonnet 4.5)**, Anthropic's AI assistant. Claude's contributions included:\n",
    "\n",
    "#### Code Architecture & Design\n",
    "- Multi-scenario framework design and configuration system\n",
    "- Modular phase structure with extensibility patterns\n",
    "- Data dictionary and metadata documentation approach\n",
    "- Excel report generation with dynamic formatting\n",
    "\n",
    "#### Implementation Support\n",
    "- Pattern matching optimization for sex consideration detection\n",
    "- Deduplication logic across multiple levels (within/across guidelines)\n",
    "- Error handling and edge case management\n",
    "- Memory-efficient data processing strategies\n",
    "\n",
    "#### Documentation & Best Practices\n",
    "- Comprehensive inline code comments\n",
    "- README and methodology documentation\n",
    "- Dynamic email generation for researchers\n",
    "- Reproducibility guidelines\n",
    "\n",
    "#### Debugging & Optimization\n",
    "- Data merging and alignment issues\n",
    "- NaN handling in pandas operations\n",
    "- Excel formatting and color-coding\n",
    "- Performance optimization for large datasets\n",
    "\n",
    "### Working with Claude\n",
    "\n",
    "**What worked well:**\n",
    "- Iterative development with immediate feedback\n",
    "- Explaining complex research requirements in plain language\n",
    "- Debugging with actual error messages\n",
    "- Generating dynamic, reusable code (no hardcoded values)\n",
    "\n",
    "**Best practices we followed:**\n",
    "- Clear problem definition at each phase\n",
    "- Testing with small datasets before full corpus\n",
    "- Extensive commenting for future maintainability\n",
    "- Modular design for easy extension\n",
    "\n",
    "### Claude Version Information\n",
    "\n",
    "**Model:** Claude Sonnet 4.5 (claude-sonnet-4-5-20250929)  \n",
    "**Platform:** Claude.ai (Web Interface)  \n",
    "**Development Period:** January 2026  \n",
    "**API Features Used:** None (all development through chat interface)\n",
    "\n",
    "**Note:** While Claude provided substantial coding assistance, all research design decisions, analytical choices, and interpretation of results were made by the research team. Claude served as a programming assistant and documentation aid, not as a research collaborator.\n",
    "\n",
    "### Reproducibility Considerations\n",
    "\n",
    "Since this code was developed with AI assistance:\n",
    "\n",
    "1. **Code is fully standalone** - No dependencies on Claude for execution\n",
    "2. **All logic is explicit** - No \"black box\" AI components in the pipeline\n",
    "3. **Extensively documented** - Comments explain all decisions\n",
    "4. **Deterministic results** - Same inputs always produce same outputs\n",
    "5. **Transparent methodology** - All search patterns and scoring formulas documented\n",
    "\n",
    "Anyone can run, modify, and extend this pipeline without requiring AI assistance.\n",
    "\n",
    "---\n",
    "\n",
    "## 📖 Citation\n",
    "\n",
    "If you use this pipeline in your research, please cite:\n",
    "```bibtex\n",
    "@software{sex_guidelines_analysis_2026,\n",
    "  author = {[Your Name] and {Galter Health Sciences Library}},\n",
    "  title = {Sex-Based Considerations in Clinical Practice Guidelines: \n",
    "           Multi-Scenario Analysis Pipeline},\n",
    "  year = {2026},\n",
    "  publisher = {GitHub},\n",
    "  url = {https://github.com/yourusername/sex-based-guidelines-analysis},\n",
    "  note = {Developed with assistance from Claude (Sonnet 4.5), Anthropic}\n",
    "}\n",
    "```\n",
    "\n",
    "**Related Publication:**  \n",
    "[Your paper citation once published]\n",
    "\n",
    "**Acknowledgment suggestion for papers:**\n",
    "> \"Analysis pipeline development was assisted by Claude (Sonnet 4.5), an AI assistant created by Anthropic, for code implementation, documentation, and debugging. All research design decisions and result interpretations were made by the research team.\"\n",
    "\n",
    "---\n",
    "\n",
    "## 📄 License\n",
    "\n",
    "This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
    "```\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2026 Northwestern University, Galter Health Sciences Library\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 👥 Contributing\n",
    "\n",
    "Contributions are welcome! Please feel free to submit a Pull Request. For major changes:\n",
    "\n",
    "1. Fork the repository\n",
    "2. Create your feature branch (`git checkout -b feature/AmazingFeature`)\n",
    "3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)\n",
    "4. Push to the branch (`git push origin feature/AmazingFeature`)\n",
    "5. Open a Pull Request\n",
    "\n",
    "### Development Guidelines\n",
    "\n",
    "- Follow PEP 8 style guide\n",
    "- Add comments for complex logic\n",
    "- Update documentation for new features\n",
    "- Test with small dataset before full corpus\n",
    "- Document new scenarios in README\n",
    "- Update CHANGELOG.md for significant changes\n",
    "\n",
    "---\n",
    "\n",
    "## 🐛 Known Issues & Limitations\n",
    "\n",
    "1. **API Rate Limits**: ClinicalTrials.gov API limits to 1 request/second (Phase 4 is slowest)\n",
    "2. **PubMed Access**: Requires internet connection; large queries may timeout\n",
    "3. **Memory Usage**: Full corpus analysis requires ~8GB RAM for 75 guidelines\n",
    "4. **Text Analysis**: English-language only (patterns need translation for other languages)\n",
    "5. **Registry Coverage**: Only trials registered in ClinicalTrials.gov are verifiable\n",
    "6. **Pattern Matching**: Relies on keyword patterns; may miss implicit sex considerations\n",
    "7. **Time Period**: Guidelines and registry data reflect state at time of extraction\n",
    "\n",
    "---\n",
    "\n",
    "## 📞 Contact\n",
    "\n",
    "**Project Maintainer:** [Your Name]  \n",
    "**Email:** [your.email@northwestern.edu]  \n",
    "**Institution:** Northwestern University, Galter Health Sciences Library\n",
    "\n",
    "**For questions about:**\n",
    "- **Technical issues**: Open a GitHub issue\n",
    "- **Collaboration**: Email directly\n",
    "- **Data requests**: See data availability statement in paper\n",
    "\n",
    "---\n",
    "\n",
    "## 🙏 Acknowledgments\n",
    "\n",
    "### People\n",
    "- **Research Team**: [List team members]\n",
    "- **Northwestern University** Galter Health Sciences Library\n",
    "- **Collaborators**: [List any collaborators]\n",
    "\n",
    "### Tools & Services\n",
    "- **Claude (Sonnet 4.5)** by Anthropic - AI-assisted development\n",
    "- **PubMed/NCBI** - E-utilities API for literature access\n",
    "- **ClinicalTrials.gov** - Registry data API\n",
    "- **CrossRef** - Citation extraction API\n",
    "- **Python ecosystem** - pandas, numpy, openpyxl\n",
    "\n",
    "### Funding\n",
    "[Add funding acknowledgments if applicable]\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 Additional Resources\n",
    "\n",
    "### Documentation\n",
    "- [Complete Methods Documentation](docs/METHODS.md)\n",
    "- [Data Dictionary](output/phase8_data_dictionary.csv)\n",
    "- [Scenario Comparison Guide](docs/SCENARIOS.md)\n",
    "- [Troubleshooting Guide](docs/TROUBLESHOOTING.md)\n",
    "\n",
    "### Example Outputs\n",
    "- [Sample Excel Report](examples/sample_report.xlsx)\n",
    "- [Example Visualizations](examples/figures/)\n",
    "\n",
    "### Related Projects\n",
    "- [NIH ORWH - Sex as a Biological Variable](https://orwh.od.nih.gov/sex-gender)\n",
    "- [SAGER Guidelines](https://www.equator-network.org/reporting-guidelines/sager-guidelines/)\n",
    "\n",
    "---\n",
    "\n",
    "## 📝 Version History\n",
    "\n",
    "### Version 1.0.0 (2026-01-07)\n",
    "- Initial public release\n",
    "- Complete 10-phase pipeline\n",
    "- Multi-scenario framework (6 scenarios)\n",
    "- Excel report generation\n",
    "- Comprehensive documentation\n",
    "- AI-assisted development with Claude Sonnet 4.5\n",
    "\n",
    "See [CHANGELOG.md](CHANGELOG.md) for detailed version history.\n",
    "\n",
    "---\n",
    "\n",
    "**Last Updated:** \"\"\" + datetime.now().strftime('%Y-%m-%d') + \"\"\"  \n",
    "**Version:** 1.0.0  \n",
    "**Status:** ✅ Production Ready\n",
    "\n",
    "---\n",
    "\n",
    "*This pipeline was developed to promote transparency and reproducibility in assessing sex-based evidence in clinical guidelines. We hope it serves as a valuable tool for researchers, guideline developers, and policy makers working to improve health equity.*\n",
    "\n",
    "*Special thanks to Anthropic's Claude for assistance in transforming research requirements into working code. The combination of domain expertise and AI-assisted development enabled rapid iteration and comprehensive documentation.*\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# Write to File\n",
    "# ============================================================================\n",
    "\n",
    "# Write to repository root (one level up from output folder)\n",
    "readme_path = 'README.md'\n",
    "\n",
    "with open(readme_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(f\"\\n✓ README.md generated successfully!\")\n",
    "print(f\"  Location: {readme_path}\")\n",
    "print(f\"  Size: {len(readme_content):,} characters\")\n",
    "print(f\"  Sections: {readme_content.count('##')} major sections\")\n",
    "print(f\"\\nKey additions:\")\n",
    "print(f\"  ✓ Claude acknowledgment in Overview\")\n",
    "print(f\"  ✓ Development Notes section with Claude details\")\n",
    "print(f\"  ✓ Claude version info (Sonnet 4.5)\")\n",
    "print(f\"  ✓ Reproducibility considerations\")\n",
    "print(f\"  ✓ Citation format with AI acknowledgment\")\n",
    "print(f\"  ✓ Paper acknowledgment suggestion\")\n",
    "print(f\"\\nReady to:\")\n",
    "print(f\"  1. Review README.md in your repository\")\n",
    "print(f\"  2. Customize [Your Name] and [email] placeholders\")\n",
    "print(f\"  3. Add to git: git add README.md\")\n",
    "print(f\"  4. Commit: git commit -m 'Add comprehensive README'\")\n",
    "print(f\"  5. Push to GitHub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb050b-172f-4d22-9116-ccaeb6a32133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3eb56-6819-47f6-9c77-521d499e541c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae95c9f-893b-429d-a2d3-6cbc49a304b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8147748d-9fec-4a3d-9682-c93ed4abf2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d9555c-095d-4e84-9601-d86f3ef13f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b25e857-310e-4f3f-ab2e-01649ca1bfd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f8c370-c35e-44da-be77-ff131caf23bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e1067e-6b00-4bca-9101-f2dda44e3de4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee61e0a-adc1-435d-a9a4-3e8dcf50ab95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53bcaee5-3f2f-4ecd-b56c-70e91be8a296",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d383c8e-9a01-4d38-be5b-045099ab33fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52addcd4-f375-4ea8-8d7e-15990909eb4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c477ecb-20c2-4983-85c1-177dfae556ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eedcc9e-89d7-4af8-aff7-a48cbeaef0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13445abd-3b56-4e99-885c-4515c46be0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ce6c3-0fcd-46a3-91c0-358ab092d05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2842e34e-97c1-45a3-8fd8-bc6f84255530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3fe6b2e-9d05-455e-b1b6-e819483d00bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332bc954-794b-4dc3-b3a7-c1b185e151e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787999fe-4b14-4eed-b4cf-c6d722ab2e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1bf717-7edc-45e7-8d3d-1d60353a3dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8349453a-4ef1-4d8a-8696-04802323f33d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0615301d-54ad-430a-8dd1-6498ce884d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91941f95-6fc4-45bc-98bd-8405abc9a331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df73e4e-4da6-4dfa-af1f-101700c888e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf1de4c-c389-49d2-aba5-07a0daff8243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c484b2ab-8424-47c1-bb49-5abc281d850d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bcb157-1126-4d56-9934-7df9c084af46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93af9f68-2f5f-4eef-a2bd-6d6ff7ce1983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862cbb92-5b08-4771-ae30-b5895de2ecdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d95cebc-9f9d-4ebb-b3bd-3bc6289e53fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a76d1-c348-4230-a200-7615a45b5202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866429e2-b747-42bb-a255-149d22507528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
